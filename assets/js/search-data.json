{
  
    
        "post0": {
            "title": "Crack",
            "content": "import matplotlib.pyplot as plt import seaborn as sns import keras from keras.models import Sequential from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout from keras.preprocessing.image import ImageDataGenerator from keras.optimizers import Adam, RMSprop, Adagrad from keras.layers import BatchNormalization from sklearn.metrics import classification_report,confusion_matrix import tensorflow as tf import cv2 import os import time import numpy as np import warnings warnings.filterwarnings(&#39;ignore&#39;) . print(keras.__version__) print(cv2.__version__) print(sns.__version__) print(np.__version__) . 2.10.0 4.6.0 0.12.0 1.23.4 . os.getcwd() # í˜„ì¬ ì‘ì—… í´ë” . &#39;C: Users hanka Desktop dino BP2022 _notebooks&#39; . labels = [&#39;Negative_500&#39;, &#39;Positive_500&#39;] img_size = 120 # ì–´ë”” í´ë”ì˜ Nagative, Postiveë¥¼ ë¶ˆëŸ¬ì˜¤ê² ë‹¤. def read_images(data_dir): data = [] for label in labels: path = os.path.join(data_dir, label) class_num = labels.index(label) for img in os.listdir(path): try: img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # ì´ë¯¸ì§€ ë³€ê²½ resized_arr = cv2.resize(img_arr, (img_size, img_size)) data.append([resized_arr, class_num]) except Exception as e: print(e) return np.array(data) Dataset = read_images(&#39;./data/Surface_Crack_Detection_small&#39;) . print( Dataset.shape ) print( Dataset[0][0], Dataset[0][1]) # í”¼ì²˜ì™€ Target . (1000, 2) [[172 161 149 ... 183 182 184] [174 166 147 ... 176 175 177] [176 171 170 ... 180 176 176] ... [163 166 170 ... 175 175 173] [158 155 164 ... 172 173 171] [161 153 154 ... 170 172 170]] 0 . data_dir = &#39;./data/Surface_Crack_Detection_small&#39; path_negative = os.path.join(data_dir, &quot;Negative_500&quot;) path_positive = os.path.join(data_dir, &quot;Positive_500&quot;) # íŒŒì¼ ë° í´ë” ë‚´ìš© í™•ì¸ print( len(os.listdir(path_negative) )) print( len(os.listdir(path_positive) )) num_n = len(os.listdir(path_negative) ) num_p = len(os.listdir(path_positive) ) num = [num_n, num_p] . 500 500 . &#54028;&#51068; &#44060;&#49688; &#54869;&#51064; . Im = [&#39;Negative&#39;, &#39;Positive&#39;] num = [num_n, num_p] plt.figure(figsize=(10, 6)) x = np.arange(2) plt.bar(Im, num) . &lt;BarContainer object of 2 artists&gt; . Dataset[0] . array([array([[172, 161, 149, ..., 183, 182, 184], [174, 166, 147, ..., 176, 175, 177], [176, 171, 170, ..., 180, 176, 176], ..., [163, 166, 170, ..., 175, 175, 173], [158, 155, 164, ..., 172, 173, 171], [161, 153, 154, ..., 170, 172, 170]], dtype=uint8), 0], dtype=object) . print(Dataset.shape) . (1000, 2) . Dataset[0][0] # í”½ì…€ ë°ì´í„° . array([[172, 161, 149, ..., 183, 182, 184], [174, 166, 147, ..., 176, 175, 177], [176, 171, 170, ..., 180, 176, 176], ..., [163, 166, 170, ..., 175, 175, 173], [158, 155, 164, ..., 172, 173, 171], [161, 153, 154, ..., 170, 172, 170]], dtype=uint8) . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . x = [] y = [] for feature, label in Dataset: x.append(feature) y.append(label) x = np.array(x).reshape(-1, img_size, img_size, 1) x = x / 255 y = np.array(y) print(x.shape, y.shape) . (1000, 120, 120, 1) (1000,) . plt.subplot(1, 2, 1) plt.imshow(x[300].reshape(img_size, img_size), cmap=&#39;gray&#39;) plt.axis(&#39;off&#39;) . (-0.5, 119.5, 119.5, -0.5) . plt.subplot(1, 2, 2) plt.imshow(x[500].reshape(img_size, img_size), cmap=&#39;gray&#39;) plt.axis(&#39;off&#39;) . (-0.5, 119.5, 119.5, -0.5) . model = Sequential() model.add(Conv2D(64, 3,padding=&quot;same&quot;, activation=&quot;relu&quot;, input_shape = x.shape[1:])) model.add(MaxPool2D()) model.add(Conv2D(64, 3, padding=&quot;same&quot;, activation=&quot;relu&quot;)) model.add(MaxPool2D()) model.add(Conv2D(128, 3, padding=&quot;same&quot;, activation=&quot;relu&quot;)) model.add(MaxPool2D()) model.add(Flatten()) model.add(Dense(256,activation=&quot;relu&quot;)) model.add(Dropout(0.5)) model.add(BatchNormalization()) model.add(Dense(1, activation=&quot;sigmoid&quot;)) model.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 120, 120, 64) 640 max_pooling2d (MaxPooling2D (None, 60, 60, 64) 0 ) conv2d_1 (Conv2D) (None, 60, 60, 64) 36928 max_pooling2d_1 (MaxPooling (None, 30, 30, 64) 0 2D) conv2d_2 (Conv2D) (None, 30, 30, 128) 73856 max_pooling2d_2 (MaxPooling (None, 15, 15, 128) 0 2D) flatten (Flatten) (None, 28800) 0 dense (Dense) (None, 256) 7373056 dropout (Dropout) (None, 256) 0 batch_normalization (BatchN (None, 256) 1024 ormalization) dense_1 (Dense) (None, 1) 257 ================================================================= Total params: 7,485,761 Trainable params: 7,485,249 Non-trainable params: 512 _________________________________________________________________ . start = time.time() opt = Adam(lr=1e-5) model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;]) history = model.fit(x, y, epochs = 15, batch_size = 128, validation_split = 0.25, verbose=1) print(&quot;ì†Œìš”ì‹œê°„&quot;, time.time() - start ) . Epoch 1/15 6/6 [==============================] - 11s 2s/step - loss: 0.6236 - accuracy: 0.6627 - val_loss: 0.7916 - val_accuracy: 0.0000e+00 Epoch 2/15 6/6 [==============================] - 10s 2s/step - loss: 0.5544 - accuracy: 0.7147 - val_loss: 0.8501 - val_accuracy: 0.0000e+00 Epoch 3/15 6/6 [==============================] - 10s 2s/step - loss: 0.5201 - accuracy: 0.7573 - val_loss: 0.8742 - val_accuracy: 0.0000e+00 Epoch 4/15 6/6 [==============================] - 11s 2s/step - loss: 0.4800 - accuracy: 0.7827 - val_loss: 0.8732 - val_accuracy: 0.0000e+00 Epoch 5/15 6/6 [==============================] - 11s 2s/step - loss: 0.4774 - accuracy: 0.7960 - val_loss: 0.8605 - val_accuracy: 0.0000e+00 Epoch 6/15 6/6 [==============================] - 11s 2s/step - loss: 0.4546 - accuracy: 0.8027 - val_loss: 0.8374 - val_accuracy: 0.0000e+00 Epoch 7/15 6/6 [==============================] - 10s 2s/step - loss: 0.4381 - accuracy: 0.8173 - val_loss: 0.8102 - val_accuracy: 0.0000e+00 Epoch 8/15 6/6 [==============================] - 11s 2s/step - loss: 0.4358 - accuracy: 0.8133 - val_loss: 0.7829 - val_accuracy: 0.0000e+00 Epoch 9/15 6/6 [==============================] - 11s 2s/step - loss: 0.4164 - accuracy: 0.8227 - val_loss: 0.7499 - val_accuracy: 0.0080 Epoch 10/15 6/6 [==============================] - 12s 2s/step - loss: 0.3856 - accuracy: 0.8493 - val_loss: 0.7181 - val_accuracy: 0.2400 Epoch 11/15 6/6 [==============================] - 10s 2s/step - loss: 0.3797 - accuracy: 0.8533 - val_loss: 0.6935 - val_accuracy: 0.5760 Epoch 12/15 6/6 [==============================] - 11s 2s/step - loss: 0.3373 - accuracy: 0.8827 - val_loss: 0.6736 - val_accuracy: 0.7200 Epoch 13/15 6/6 [==============================] - 11s 2s/step - loss: 0.3323 - accuracy: 0.8747 - val_loss: 0.6644 - val_accuracy: 0.7480 Epoch 14/15 6/6 [==============================] - 11s 2s/step - loss: 0.3101 - accuracy: 0.8920 - val_loss: 0.6438 - val_accuracy: 0.8880 Epoch 15/15 6/6 [==============================] - 11s 2s/step - loss: 0.3218 - accuracy: 0.8747 - val_loss: 0.6266 - val_accuracy: 0.9560 ì†Œìš”ì‹œê°„ 162.9058222770691 . plt.figure(figsize=(12, 12)) plt.style.use(&#39;ggplot&#39;) plt.subplot(2,2,1) plt.plot(history.history[&#39;accuracy&#39;]) plt.plot(history.history[&#39;val_accuracy&#39;]) plt.title(&#39;Accuracy of the Model&#39;) plt.ylabel(&#39;Accuracy&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train accuracy&#39;, &#39;validation accuracy&#39;], loc=&#39;lower right&#39;, prop={&#39;size&#39;: 12}) plt.subplot(2,2,2) plt.plot(history.history[&#39;loss&#39;]) plt.plot(history.history[&#39;val_loss&#39;]) plt.title(&#39;Loss of the Model&#39;) . Text(0.5, 1.0, &#39;Loss of the Model&#39;) . í•œ ì—í­ ë‹¹ 6ë²ˆë°–ì— í•™ìŠµì„ ëª»í•˜ë‹ˆê¹Œ 8ì—í­ê¹Œì§€ ì„±ëŠ¥ë³€í™”ê°€ ì—†ë‹¤ê°€ ê·¸ ì´í›„ì— ì˜¬ë¼ê°€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. | . &#49884;&#46020; 1. barch size&#47484; &#51460;&#50668;&#49436; &#54620; &#50640;&#54253; &#45817; &#54617;&#49845;&#54943;&#49688;&#47484; &#45720;&#47536;&#45796;. . start = time.time() opt = Adam(lr=1e-5) model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;]) history = model.fit(x, y, epochs = 15, batch_size = 16, validation_split = 0.25, verbose=1) print(&quot;ì†Œìš”ì‹œê°„&quot;, time.time() - start ) . Epoch 1/15 47/47 [==============================] - 13s 256ms/step - loss: 0.2841 - accuracy: 0.8987 - val_loss: 0.5707 - val_accuracy: 0.9680 Epoch 2/15 47/47 [==============================] - 13s 279ms/step - loss: 0.2494 - accuracy: 0.9227 - val_loss: 0.5101 - val_accuracy: 0.9760 Epoch 3/15 47/47 [==============================] - 13s 273ms/step - loss: 0.2229 - accuracy: 0.9387 - val_loss: 0.4406 - val_accuracy: 0.9880 Epoch 4/15 47/47 [==============================] - 12s 264ms/step - loss: 0.1932 - accuracy: 0.9427 - val_loss: 0.3940 - val_accuracy: 0.9680 Epoch 5/15 47/47 [==============================] - 12s 260ms/step - loss: 0.1846 - accuracy: 0.9480 - val_loss: 0.2834 - val_accuracy: 0.9920 Epoch 6/15 47/47 [==============================] - 13s 269ms/step - loss: 0.1569 - accuracy: 0.9573 - val_loss: 0.2352 - val_accuracy: 0.9840 Epoch 7/15 47/47 [==============================] - 12s 261ms/step - loss: 0.1490 - accuracy: 0.9600 - val_loss: 0.1286 - val_accuracy: 0.9960 Epoch 8/15 47/47 [==============================] - 13s 271ms/step - loss: 0.1649 - accuracy: 0.9587 - val_loss: 0.1572 - val_accuracy: 0.9560 Epoch 9/15 47/47 [==============================] - 12s 259ms/step - loss: 0.1393 - accuracy: 0.9680 - val_loss: 0.0991 - val_accuracy: 0.9760 Epoch 10/15 47/47 [==============================] - 12s 259ms/step - loss: 0.1247 - accuracy: 0.9680 - val_loss: 0.0710 - val_accuracy: 0.9720 Epoch 11/15 47/47 [==============================] - 12s 259ms/step - loss: 0.1239 - accuracy: 0.9680 - val_loss: 0.0948 - val_accuracy: 0.9560 Epoch 12/15 47/47 [==============================] - 12s 258ms/step - loss: 0.1100 - accuracy: 0.9773 - val_loss: 0.0291 - val_accuracy: 0.9920 Epoch 13/15 47/47 [==============================] - 12s 258ms/step - loss: 0.1277 - accuracy: 0.9720 - val_loss: 0.0438 - val_accuracy: 0.9800 Epoch 14/15 47/47 [==============================] - 12s 258ms/step - loss: 0.1024 - accuracy: 0.9760 - val_loss: 0.0409 - val_accuracy: 0.9840 Epoch 15/15 47/47 [==============================] - 12s 258ms/step - loss: 0.0855 - accuracy: 0.9853 - val_loss: 0.0356 - val_accuracy: 0.9880 ì†Œìš”ì‹œê°„ 185.70813751220703 . plt.figure(figsize=(12, 12)) plt.style.use(&#39;ggplot&#39;) plt.subplot(2,2,1) plt.plot(history.history[&#39;accuracy&#39;]) plt.plot(history.history[&#39;val_accuracy&#39;]) plt.title(&#39;Accuracy of the Model&#39;) plt.ylabel(&#39;Accuracy&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train accuracy&#39;, &#39;validation accuracy&#39;], loc=&#39;lower right&#39;, prop={&#39;size&#39;: 12}) plt.subplot(2,2,2) plt.plot(history.history[&#39;loss&#39;]) plt.plot(history.history[&#39;val_loss&#39;]) plt.title(&#39;Loss of the Model&#39;) . Text(0.5, 1.0, &#39;Loss of the Model&#39;) . &#49884;&#46020; 2. &#50640;&#54253;&#51012; &#45720;&#47536;&#45796;. . start = time.time() opt = Adam(lr=1e-5) model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;]) history = model.fit(x, y, epochs = 30, batch_size = 128, validation_split = 0.25, verbose=1) print(&quot;ì†Œìš”ì‹œê°„&quot;, time.time() - start ) . Epoch 1/30 6/6 [==============================] - 9s 1s/step - loss: 0.0658 - accuracy: 0.9813 - val_loss: 0.0301 - val_accuracy: 0.9920 Epoch 2/30 6/6 [==============================] - 9s 1s/step - loss: 0.0662 - accuracy: 0.9853 - val_loss: 0.0309 - val_accuracy: 0.9920 Epoch 3/30 6/6 [==============================] - 9s 2s/step - loss: 0.0661 - accuracy: 0.9867 - val_loss: 0.0340 - val_accuracy: 0.9880 Epoch 4/30 6/6 [==============================] - 9s 1s/step - loss: 0.0650 - accuracy: 0.9840 - val_loss: 0.0298 - val_accuracy: 0.9920 Epoch 5/30 6/6 [==============================] - 9s 1s/step - loss: 0.0633 - accuracy: 0.9867 - val_loss: 0.0222 - val_accuracy: 0.9960 Epoch 6/30 6/6 [==============================] - 9s 2s/step - loss: 0.0618 - accuracy: 0.9867 - val_loss: 0.0239 - val_accuracy: 0.9960 Epoch 7/30 6/6 [==============================] - 9s 2s/step - loss: 0.0608 - accuracy: 0.9880 - val_loss: 0.0283 - val_accuracy: 0.9920 Epoch 8/30 6/6 [==============================] - 9s 1s/step - loss: 0.0638 - accuracy: 0.9880 - val_loss: 0.0290 - val_accuracy: 0.9920 Epoch 9/30 6/6 [==============================] - 9s 1s/step - loss: 0.0539 - accuracy: 0.9893 - val_loss: 0.0252 - val_accuracy: 0.9920 Epoch 10/30 6/6 [==============================] - 9s 1s/step - loss: 0.0631 - accuracy: 0.9853 - val_loss: 0.0396 - val_accuracy: 0.9800 Epoch 11/30 6/6 [==============================] - 9s 1s/step - loss: 0.0568 - accuracy: 0.9867 - val_loss: 0.0223 - val_accuracy: 0.9960 Epoch 12/30 6/6 [==============================] - 9s 1s/step - loss: 0.0562 - accuracy: 0.9853 - val_loss: 0.0232 - val_accuracy: 0.9960 Epoch 13/30 6/6 [==============================] - 9s 1s/step - loss: 0.0558 - accuracy: 0.9853 - val_loss: 0.0290 - val_accuracy: 0.9880 Epoch 14/30 6/6 [==============================] - 9s 1s/step - loss: 0.0568 - accuracy: 0.9867 - val_loss: 0.0269 - val_accuracy: 0.9920 Epoch 15/30 6/6 [==============================] - 9s 1s/step - loss: 0.0501 - accuracy: 0.9880 - val_loss: 0.0386 - val_accuracy: 0.9800 Epoch 16/30 6/6 [==============================] - 9s 1s/step - loss: 0.0542 - accuracy: 0.9853 - val_loss: 0.0350 - val_accuracy: 0.9800 Epoch 17/30 6/6 [==============================] - 9s 1s/step - loss: 0.0478 - accuracy: 0.9893 - val_loss: 0.0237 - val_accuracy: 0.9960 Epoch 18/30 6/6 [==============================] - 9s 1s/step - loss: 0.0520 - accuracy: 0.9893 - val_loss: 0.0174 - val_accuracy: 1.0000 Epoch 19/30 6/6 [==============================] - 9s 1s/step - loss: 0.0501 - accuracy: 0.9867 - val_loss: 0.0186 - val_accuracy: 0.9960 Epoch 20/30 6/6 [==============================] - 9s 1s/step - loss: 0.0520 - accuracy: 0.9893 - val_loss: 0.0270 - val_accuracy: 0.9840 Epoch 21/30 6/6 [==============================] - 9s 1s/step - loss: 0.0528 - accuracy: 0.9880 - val_loss: 0.0177 - val_accuracy: 1.0000 Epoch 22/30 6/6 [==============================] - 9s 1s/step - loss: 0.0532 - accuracy: 0.9880 - val_loss: 0.0278 - val_accuracy: 0.9840 Epoch 23/30 6/6 [==============================] - 9s 1s/step - loss: 0.0449 - accuracy: 0.9893 - val_loss: 0.0273 - val_accuracy: 0.9840 Epoch 24/30 6/6 [==============================] - 9s 1s/step - loss: 0.0509 - accuracy: 0.9893 - val_loss: 0.0188 - val_accuracy: 1.0000 Epoch 25/30 6/6 [==============================] - 9s 1s/step - loss: 0.0472 - accuracy: 0.9907 - val_loss: 0.0212 - val_accuracy: 0.9960 Epoch 26/30 6/6 [==============================] - 9s 1s/step - loss: 0.0466 - accuracy: 0.9893 - val_loss: 0.0254 - val_accuracy: 0.9880 Epoch 27/30 6/6 [==============================] - 9s 1s/step - loss: 0.0426 - accuracy: 0.9920 - val_loss: 0.0262 - val_accuracy: 0.9840 Epoch 28/30 6/6 [==============================] - 9s 1s/step - loss: 0.0437 - accuracy: 0.9907 - val_loss: 0.0321 - val_accuracy: 0.9800 Epoch 29/30 6/6 [==============================] - 9s 1s/step - loss: 0.0473 - accuracy: 0.9893 - val_loss: 0.0176 - val_accuracy: 1.0000 Epoch 30/30 6/6 [==============================] - 9s 1s/step - loss: 0.0432 - accuracy: 0.9907 - val_loss: 0.0303 - val_accuracy: 0.9840 ì†Œìš”ì‹œê°„ 260.3884177207947 . plt.figure(figsize=(12, 12)) plt.style.use(&#39;ggplot&#39;) plt.subplot(2,2,1) plt.plot(history.history[&#39;accuracy&#39;]) plt.plot(history.history[&#39;val_accuracy&#39;]) plt.title(&#39;Accuracy of the Model&#39;) plt.ylabel(&#39;Accuracy&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train accuracy&#39;, &#39;validation accuracy&#39;], loc=&#39;lower right&#39;, prop={&#39;size&#39;: 12}) plt.subplot(2,2,2) plt.plot(history.history[&#39;loss&#39;]) plt.plot(history.history[&#39;val_loss&#39;]) plt.title(&#39;Loss of the Model&#39;) . Text(0.5, 1.0, &#39;Loss of the Model&#39;) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/25/crack.html",
            "relUrl": "/python/2022/10/25/crack.html",
            "date": " â€¢ Oct 25, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "import numpy as np . 1/(1+np.exp(-1.67))*0.093 . 0.07826655136741911 .",
            "url": "https://pinkocto.github.io/BP2022/2022/10/25/Untitled.html",
            "relUrl": "/2022/10/25/Untitled.html",
            "date": " â€¢ Oct 25, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "(221025) MNIST",
            "content": "- CNNì˜ ê¸°ë³¸ ì´í•´ - CNNì„ ì‹¤ìŠµì„ í†µí•´ ì•Œì•„ë³´ê¸° . from IPython.display import display, Image import os, warnings warnings.filterwarnings(action=&#39;ignore&#39;) . import tensorflow as tf from tensorflow.keras import models from tensorflow.keras import layers # from tensorflow.keras import models import Sequential print(tf.__version__) . 2.10.0 . ì´ë¯¸ì§€ - Conv - Pooling - Conv - Polling - FCL (filter)3x3 2x2 (f)3x3 2x2 32ê°œ 64ê°œ . Conv: 3x3 í•„í„°, 32ê°œì˜ í•„í„°ê°œìˆ˜, ì…ë ¥ ì´ë¯¸ì§€(28,28,,1) | Maxpooling (2,2) | Conv: 3x3 í•„í„°, 64ê°œì˜ í•„í„°ê°œìˆ˜ | Maxpooling (2,2) | Fully Conneted Layer | . model = models.Sequential() model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation=&#39;relu&#39;, input_shape=(28,28,1) )) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=&#39;relu&#39; )) model.add(layers.MaxPooling2D((2, 2))) model.summary() . Model: &#34;sequential_4&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_1 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_2 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_2 (MaxPooling (None, 5, 5, 64) 0 2D) ================================================================= Total params: 18,816 Trainable params: 18,816 Non-trainable params: 0 _________________________________________________________________ . model.add( layers.Flatten() ) model.add( layers.Dense(64, activation=&#39;relu&#39;)) model.add( layers.Dense(10, activation=&#39;softmax&#39;)) . model.summary() . Model: &#34;sequential_4&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_1 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_2 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_2 (MaxPooling (None, 5, 5, 64) 0 2D) flatten (Flatten) (None, 1600) 0 dense (Dense) (None, 64) 102464 dense_1 (Dense) (None, 10) 650 ================================================================= Total params: 121,930 Trainable params: 121,930 Non-trainable params: 0 _________________________________________________________________ . from tensorflow.keras.datasets import mnist from tensorflow.keras.utils import to_categorical (train_images, train_labels), (test_images, test_labels) = mnist.load_data() . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz 11490434/11490434 [==============================] - 1s 0us/step . train_images = train_images.reshape((60000, 28, 28, 1)) train_images = train_images.astype(&#39;float32&#39;) / 255 test_images = test_images.reshape((10000, 28, 28, 1)) test_images = test_images.astype(&#39;float32&#39;) / 255 . train_labels = to_categorical(train_labels) test_labels = to_categorical(test_labels) . print(&quot;ì…ë ¥ì¸µ ë°ì´í„°(X) : &quot;,train_images.shape, test_images.shape ) print(&quot;ì¶œë ¥ì¸µ ë°ì´í„°(y) : &quot;,train_labels.shape, test_labels.shape ) . ì…ë ¥ì¸µ ë°ì´í„°(X) : (60000, 28, 28, 1) (10000, 28, 28, 1) ì¶œë ¥ì¸µ ë°ì´í„°(y) : (60000, 10) (10000, 10) . %%time model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5, batch_size=64) . Epoch 1/5 938/938 [==============================] - 19s 20ms/step - loss: 0.1647 - accuracy: 0.9501 - val_loss: 0.0481 - val_accuracy: 0.9834 Epoch 2/5 938/938 [==============================] - 19s 21ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.0359 - val_accuracy: 0.9879 Epoch 3/5 938/938 [==============================] - 20s 21ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0369 - val_accuracy: 0.9881 Epoch 4/5 938/938 [==============================] - 19s 20ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0255 - val_accuracy: 0.9912 Epoch 5/5 938/938 [==============================] - 19s 20ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.0236 - val_accuracy: 0.9924 CPU times: total: 7min 15s Wall time: 1min 36s . &lt;keras.callbacks.History at 0x20e4747ed00&gt; . test_loss, test_acc = model.evaluate(test_images, test_labels) print(test_acc) . 313/313 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9924 0.9923999905586243 . Conv &#44228;&#52789; &#52628;&#44032;&#54644;&#48372;&#44592; . model = models.Sequential() model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation=&#39;relu&#39;, input_shape=(28,28,1) )) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=&#39;relu&#39; )) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=&#39;relu&#39; )) model.add(layers.MaxPooling2D((2, 2))) model.summary() . Model: &#34;sequential_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_3 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_3 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_4 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_4 (MaxPooling (None, 5, 5, 64) 0 2D) conv2d_5 (Conv2D) (None, 3, 3, 64) 36928 max_pooling2d_5 (MaxPooling (None, 1, 1, 64) 0 2D) ================================================================= Total params: 55,744 Trainable params: 55,744 Non-trainable params: 0 _________________________________________________________________ . model.add( layers.Flatten() ) model.add( layers.Dense(64, activation=&#39;relu&#39;)) model.add( layers.Dense(10, activation=&#39;softmax&#39;)) . model.summary() . Model: &#34;sequential_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_3 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_3 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_4 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_4 (MaxPooling (None, 5, 5, 64) 0 2D) conv2d_5 (Conv2D) (None, 3, 3, 64) 36928 max_pooling2d_5 (MaxPooling (None, 1, 1, 64) 0 2D) flatten_1 (Flatten) (None, 64) 0 dense_2 (Dense) (None, 64) 4160 dense_3 (Dense) (None, 10) 650 ================================================================= Total params: 60,554 Trainable params: 60,554 Non-trainable params: 0 _________________________________________________________________ . from tensorflow.keras.datasets import mnist from tensorflow.keras.utils import to_categorical (train_images, train_labels), (test_images, test_labels) = mnist.load_data() . train_images = train_images.reshape((60000, 28, 28, 1)) train_images = train_images.astype(&#39;float32&#39;) / 255 test_images = test_images.reshape((10000, 28, 28, 1)) test_images = test_images.astype(&#39;float32&#39;) / 255 . train_labels = to_categorical(train_labels) test_labels = to_categorical(test_labels) . print(&quot;ì…ë ¥ì¸µ ë°ì´í„°(X) : &quot;,train_images.shape, test_images.shape ) print(&quot;ì¶œë ¥ì¸µ ë°ì´í„°(y) : &quot;,train_labels.shape, test_labels.shape ) . ì…ë ¥ì¸µ ë°ì´í„°(X) : (60000, 28, 28, 1) (10000, 28, 28, 1) ì¶œë ¥ì¸µ ë°ì´í„°(y) : (60000, 10) (10000, 10) . %%time model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5, batch_size=64) . Epoch 1/5 938/938 [==============================] - 20s 21ms/step - loss: 0.2627 - accuracy: 0.9182 - val_loss: 0.0972 - val_accuracy: 0.9697 Epoch 2/5 938/938 [==============================] - 21s 22ms/step - loss: 0.0785 - accuracy: 0.9762 - val_loss: 0.0790 - val_accuracy: 0.9775 Epoch 3/5 938/938 [==============================] - 22s 23ms/step - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.0549 - val_accuracy: 0.9833 Epoch 4/5 938/938 [==============================] - 22s 23ms/step - loss: 0.0432 - accuracy: 0.9871 - val_loss: 0.0490 - val_accuracy: 0.9853 Epoch 5/5 938/938 [==============================] - 21s 23ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0620 - val_accuracy: 0.9818 CPU times: total: 7min 49s Wall time: 1min 45s . &lt;keras.callbacks.History at 0x20e4879fe20&gt; . test_loss, test_acc = model.evaluate(test_images, test_labels) print(test_acc) . 313/313 [==============================] - 1s 4ms/step - loss: 0.0620 - accuracy: 0.9818 0.9818000197410583 . ì¶”ê°€ ì „ : 0.9923999905586243 | ì¶”ê°€ í›„ : 0.9818000197410583 | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/25/DNN.html",
            "relUrl": "/python/2022/10/25/DNN.html",
            "date": " â€¢ Oct 25, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "(22/10/24) ğŸ˜ Cross Validation",
            "content": "import time import gc import os, warnings import numpy as np # ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œí•˜ê±°ë‚˜ ìˆ¨ê¸¸ë•Œ(ignore), ë‹¤ì‹œë³´ì´ê²Œ(default) # warnings.filterwarnings(action=&#39;default&#39;) warnings.filterwarnings(action=&#39;ignore&#39;) . import mglearn mglearn.plots.plot_cross_validation() . from sklearn.datasets import load_iris from sklearn.neighbors import KNeighborsClassifier from sklearn.linear_model import LogisticRegression from sklearn.model_selection import cross_val_score . 00. Base . iris = load_iris() logreg = LogisticRegression() . scores = cross_val_score(logreg, iris.data, iris.target) print(scores) . [0.96666667 1. 0.93333333 0.96666667 1. ] . 01. CV=10 . scores_cv = cross_val_score(logreg, iris.data, iris.target, cv=10) print(scores_cv) . [1. 0.93333333 1. 1. 0.93333333 0.93333333 0.93333333 1. 1. 1. ] . 02. Kfold (n_splits = 3) . iris.target . array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) . from sklearn.model_selection import KFold # ê°ì²´ë¥¼ ì‚¬ìš©í•´ì„œ ë„£ì–´ì¤„ ìˆ˜ë„ ìˆë‹¤. kfold = KFold(n_splits = 3) print(&#39;êµì°¨ ê²€ì¦ ì ìˆ˜ : n{}&#39;.format(cross_val_score(logreg, iris.data, iris.target, cv=kfold))) . êµì°¨ ê²€ì¦ ì ìˆ˜ : [0. 0. 0.] . ë¬¸ì œ ë°œìƒ! | shuffle=True ì˜µì…˜ì„ ì§€ì •í•´ì£¼ì§€ ì•Šìœ¼ë©´ ì•ì—ì„œë¶€í„° 3ë“±ë¶„ ë‚˜ëˆ ì§„ë‹¤. | ê·¸ë ‡ê²Œë˜ë©´ ì²«ë²ˆì§¸ foldëŠ” 0ë§Œ, ë‘ë²ˆì§¸ foldëŠ” 1ë§Œ, ì„¸ë²ˆì§¸ foldëŠ” 2ë§Œ ìˆê²Œë˜ëŠ”ë° | . kfold_random = KFold(n_splits = 3, shuffle=True, random_state=0) print(&#39;êµì°¨ ê²€ì¦ ì ìˆ˜ : n{}&#39;.format(cross_val_score(logreg, iris.data, iris.target, cv=kfold_random))) . êµì°¨ ê²€ì¦ ì ìˆ˜ : [0.98 0.96 0.96] . ë¬¸ì œ í•´ê²°! | . 03. Boston Houst Price . from sklearn.model_selection import cross_val_score from sklearn.datasets import load_boston from sklearn.linear_model import LinearRegression import sklearn import pandas as pd import mglearn print(sklearn.__version__) . 1.1.2 . boston = load_boston() df = pd.DataFrame(boston.data, columns=boston.feature_names) df[&#39;price&#39;] = boston.target print(df.shape) . (506, 14) . X = df.drop([&#39;price&#39;], axis=1) y = df[&#39;price&#39;] . cv=5 . lr_model = LinearRegression() msescores = cross_val_score(lr_model, X, y, scoring=&#39;neg_mean_squared_error&#39;, cv=5) . rmse = np.sqrt(-1 * msescores) print(rmse) . [3.52991509 5.10378498 5.75101191 8.9867887 5.77179405] . print(&#39;í‰ê·  RMSE : {0:.3f}&#39;.format(np.mean(rmse))) . í‰ê·  RMSE : 5.829 . cv=10 . lr_model = LinearRegression() msescores = cross_val_score(lr_model, X, y, scoring=&#39;neg_mean_squared_error&#39;, cv=10) . rmse = np.sqrt(-1 * msescores) print(rmse) . [ 3.04744921 3.76181913 3.75148053 5.93354231 5.64669077 4.45374875 3.15392917 12.9759539 5.77319193 3.3106511 ] . print(&#39;í‰ê·  RMSE : {0:.3f}&#39;.format(np.mean(rmse))) . í‰ê·  RMSE : 5.181 . cvë¥¼ $5 to10$ìœ¼ë¡œ ë³€ê²½í›„ RMSEì˜ í‰ê· ì„ êµ¬í•œ ê²°ê³¼ | ì ìˆ˜ê°€ $5.829 to 5.181$ë¡œ ë–¨ì–´ì¡Œë‹¤. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/24/Cross_Validation_Class_For_Amex.html",
            "relUrl": "/python/2022/10/24/Cross_Validation_Class_For_Amex.html",
            "date": " â€¢ Oct 24, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "(OpenCV - Chap6) í™”ì†Œ(pixel)ì²˜ë¦¬",
            "content": "&#54868;&#49548;&#51032; &#44060;&#45392; . í™”ì†Œë€ í™”ë©´(ì˜ìƒ)ì„ êµ¬ì„±í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” ë‹¨ìœ„ë¥¼ ë§í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì˜ìƒì²˜ë¦¬ ì…ë¬¸ì—ì„œ ê°€ì¥ ë¨¼ì € ë‹¤ë£¨ëŠ” ë‚´ìš©ì´ í™”ì†Œê°’ ê¸°ë°˜ ì²˜ë¦¬ì´ë‹¤. ì´ê²ƒì€ ì˜ìƒ êµ¬ì¡°ì— ëŒ€í•´ ì•Œê¸° ìœ„í•´ ê°€ì¥ ë¨¼ì € ì´í•´í•´ì•¼ í•˜ëŠ” ê²ƒì´ í™”ì†Œì— ëŒ€í•œ ê¸°ë³¸ ê°œë…ì´ê¸° ë•Œë¬¸ì´ë‹¤. . ë””ì§€í„¸ ì˜ìƒì€ ì´ í™”ì†Œë“¤ì˜ ì§‘í•©ì„ ì˜ë¯¸í•˜ë©°, ì´ í™”ì†Œë“¤ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì—°ì‚°ì„ í•˜ëŠ” ê²ƒì´ ì˜ìƒì²˜ë¦¬ì´ë‹¤. . 6.1 &#50689;&#49345;&#54868;&#49548;&#51032; &#51217;&#44540; . ì˜ìƒì²˜ë¦¬ë¥¼ ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ ë§í•´ë³´ë©´, 2ì°¨ì› ë°ì´í„°ì— ëŒ€í•œ í–‰ë ¬ ì—°ì‚°ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì˜ìƒì„ ë‹¤ë£¨ë ¤ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ì˜ìƒì˜ í™”ì†Œì— ì ‘ê·¼í•˜ê³ , ê·¸ ê°’ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ìƒˆë¡œ ë§Œë“¤ ìˆ˜ ìˆì–´ì•¼ í•œë‹¤. . ê³¼ê±° OpenCVì™€ ê°™ì€ ëŒ€ì¤‘ì ì¸ ì˜ìƒì²˜ë¦¬ APIê°€ ì—†ì—ˆì„ ë•Œ, ì˜ìƒ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ì €ì¥í•˜ëŠ” ê²ƒì´ ì‰½ì§€ë§Œì€ ì•Šì€ ì¼ì´ì—ˆë‹¤. í•˜ì§€ë§Œ íŒŒì´ì¬ì—ì„œëŠ” í–‰ë ¬ ë°ì´í„° ì²˜ë¦¬ì— ìœ ìš©í•œ ë„˜íŒŒì´(Numpy) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì§€ì›í•˜ê³  ìˆìœ¼ë©°, OpenCV APIë„ numpy.ndarray ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ìƒ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•œë‹¤. 6.1.1 &#54868;&#49548;(&#54665;&#47148; &#50896;&#49548;) &#51217;&#44540; . ë‹¤ìŒì€ ëª¨ë“  ì›ì†Œë¥¼ ìˆœíšŒí•˜ì—¬ ì›ì†Œê°’ì„ 2ë°°ë¡œ ë³€ê²½í•˜ëŠ” ì˜ˆì œì´ë‹¤. . - ë°©ë²•1 . í–‰ë ¬ì˜ ì›ì†Œë¥¼ ìˆœíšŒí•˜ë©° ì§ì ‘ ì›ì†Œê°’ì„ ê°€ì ¸ì™€ì„œ ê³„ì‚° . import numpy as np def mat_access1(mat): for i in range(mat.shape[0]): for j in range(mat.shape[1]): k = mat[i, j] mat[i, j] = k * 2 . mat1 = np.arange(10).reshape(2,5) mat1 . array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) . print(&#39;ì›ì†Œ ì²˜ë¦¬ ì „: n%s n&#39; % mat1) mat_access1(mat1) print(&#39;ì›ì†Œ ì²˜ë¦¬ í›„: n%s n&#39; % mat1) . ì›ì†Œ ì²˜ë¦¬ ì „: [[ 0 2 4 6 8] [10 12 14 16 18]] ì›ì†Œ ì²˜ë¦¬ í›„: [[ 0 4 8 12 16] [20 24 28 32 36]] . - ë°©ë²•2 . í–‰ë ¬ ì›ì†Œë¥¼ ìˆœíšŒí•˜ë©°, ndarray í´ë˜ìŠ¤ì˜ ë‚´ë¶€ ë©”ì„œë“œì¸ item() í•¨ìˆ˜ì™€ itemset() í•¨ìˆ˜ë¡œ ê°€ì ¸ì™€ì„œ ê°’ì„ ë³€ê²½ . def mat_access2(mat): for i in range(mat.shape[0]): for j in range(mat.shape[1]): k = mat.item(i, j) # mat.itemset((i, j), k*2) . mat2 = np.arange(10).reshape(2, 5) mat2 . array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) . print(&#39;ì›ì†Œ ì²˜ë¦¬ ì „: n%s n&#39; % mat2) mat_access2(mat2) print(&#39;ì›ì†Œ ì²˜ë¦¬ í›„: n%s n&#39; % mat2) . ì›ì†Œ ì²˜ë¦¬ ì „: [[0 1 2 3 4] [5 6 7 8 9]] ì›ì†Œ ì²˜ë¦¬ í›„: [[ 0 2 4 6 8] [10 12 14 16 18]] . 6.1.2 &#50689;&#49345; &#48152;&#51204;&#51012; &#49688;&#54665;&#54616;&#45716; &#45796;&#50577;&#54620; &#48169;&#48277;&#46308; . í–‰ë ¬ì„ ì²˜ë¦¬í•˜ì—¬ ì˜ìƒì˜ ë°˜ì „ì„ ìˆ˜í–‰í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì„ í•¨ìˆ˜ë¡œ ë§Œë“¤ê³ , ê° ë°©ë²•ì˜ ìˆ˜í–‰ì†ë„ë¥¼ ê³„ì‚°í•´ë³´ì. . import numpy as np, cv2, time ## í™”ì†Œ ì§ì ‘ì ‘ê·¼ def pixel_access1(image): image1 = np.zeros(image.shape[:2], image.dtype) for i in range(image.shape[0]): for j in range(image.shape[1]): pixel = image[i,j] # í™”ì†Œì ‘ê·¼ image1[i, j] = 255 - pixel # í™”ì†Œí• ë‹¹ return image1 . def pixel_access2(image): # item() í•¨ìˆ˜ ì ‘ê·¼ ë°©ë²• image2 = np.zeros(image.shape[:2], image.dtype) for i in range(image.shape[0]): for j in range(image.shape[1]): pixel = image.item(i, j) # í™”ì†Œì ‘ê·¼ image2.itemset((i, j), 255 - pixel) # í™”ì†Œí• ë‹¹ return image2 . def pixel_access3(image): lut = [255 - i for i in range(256)] lut = np.array(lut, np.uint8) image3 = lut[image] return image3 . def pixel_access4(image): image4 = cv2.subtract(255, image) return image4 . def pixel_access5(image): image5 = 255 - image return image5 . image = cv2.imread(&#39;./ghtop_images/chap06_images/bright.jpg&#39;, cv2.IMREAD_GRAYSCALE) . image.shape . (450, 360) . def time_check(func, msg): start_time = time.perf_counter() ret_img = func(image) elapsed = (time.perf_counter() - start_time) * 1000 print(msg, &quot;ìˆ˜í–‰ì‹œê°„ : %0.2f ms&quot; % elapsed ) return ret_img . image1 = time_check(pixel_access1, &quot;[ë°©ë²•1] ì§ì ‘ ì ‘ê·¼ ë°©ì‹&quot;) image2 = time_check(pixel_access2, &quot;[ë°©ë²•2] item() ì ‘ê·¼ ë°©ì‹&quot;) image3 = time_check(pixel_access3, &quot;[ë°©ë²•3] ë£©ì—…í…Œì´ë¸” ë°©ì‹&quot;) image4 = time_check(pixel_access4, &quot;[ë°©ë²•4] OpenCV í•¨ìˆ˜ ë°©ì‹&quot;) image5 = time_check(pixel_access5, &quot;[ë°©ë²•5] ndarray ë°©ì‹&quot;) . [ë°©ë²•1] ì§ì ‘ ì ‘ê·¼ ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 550.22 ms [ë°©ë²•2] item() ì ‘ê·¼ ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 108.73 ms [ë°©ë²•3] ë£©ì—…í…Œì´ë¸” ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 0.92 ms [ë°©ë²•4] OpenCV í•¨ìˆ˜ ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 0.08 ms [ë°©ë²•5] ndarray ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 0.19 ms . ì‹¤í–‰ê²°ê³¼ë¥¼ ë³´ë©´, OpenCV ë˜ëŠ” ndarray ë°©ì‹ìœ¼ë¡œ í™”ì†Œì— ì ‘ê·¼í•˜ëŠ” ê²½ìš° ì†ë„ê°€ ë¹ ë¥¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. . ë”°ë¼ì„œ í™”ì†Œ ì§ì ‘ ì ‘ê·¼ ë°©ë²•ë³´ë‹¤ëŠ” OpenCVì—ì„œ ì œê³µí•˜ëŠ” í•¨ìˆ˜ë“¤ì„ ì¡°í•©í•˜ê±°ë‚˜ ndarray ê°ì²´ì˜ ì›ì†Œê°„ ì—°ì‚°ìœ¼ë¡œ êµ¬í˜„ ë‚´ìš©ì„ ë§Œë“œëŠ” ê²ƒì´ ì¢‹ë‹¤. . 6.2 &#54868;&#49548; &#48157;&#44592; &#48320;&#54872; . 6.2.1 &#44536;&#47112;&#51060; &#49828;&#52992;&#51068; (&#47749;&#50516;&#46020;) &#50689;&#49345; . ì¼ë°˜ì ìœ¼ë¡œ ì´í•´í•˜ëŠ” ì»¬ëŸ¬ê°€ ì•„ë‹Œ ì˜ìƒì„ ìš°ë¦¬ëŠ” í‘ë°±ì˜ìƒì´ë¼ê³  ì‰½ê²Œ ë¶€ë¥´ì§€ë§Œ, ì—„ë°€í•œ ì˜ë¯¸ì—ì„œ í‘ë°± ì˜ìƒì´ë¼ëŠ” ê²ƒì€ ê²€ì€ìƒ‰ê³¼ í°ìƒ‰ìœ¼ë¡œ êµ¬ì„±ëœ ì˜ìƒì„ ì˜ë¯¸í•˜ê¸° ë•Œë¬¸ì— ë‹¨ì¼ì±„ë„ ì˜ìƒì— ì´ ì´ë¦„ì„ ë¶™ì´ëŠ” ê²ƒì´ ë§ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤. . ë””ì§€í„¸ ì˜ìƒì²˜ë¦¬ì—ì„œ ë³´í†µ ë‹¨ì¼ì±„ë„ì˜ ì˜ìƒì„ ê·¸ë ˆì´ ìŠ¤ì¼€ì¼(gray-scale)ì˜ìƒ í˜¹ì€ ëª…ì•”ë„ ì˜ìƒì´ë¼ê³  í•œë‹¤. . ê·¸ë ˆì´ ìŠ¤ì¼€ì¼ ì˜ìƒ . 0~255ì˜ ê°’ì„ ê°€ì§€ëŠ” í™”ì†Œë“¤ì´ ëª¨ì—¬ì„œ êµ¬ì„±ëœ ì˜ìƒ | 0ì€ ê²€ì€ìƒ‰, 255ëŠ” í°ìƒ‰ì„ ì˜ë¯¸ | 0~255 ì‚¬ì´ ê°’ë“¤ì€ ì§„í•œ íšŒìƒ‰ì—ì„œ ì—°í•œ íšŒìƒ‰ê¹Œì§€ë¥¼ ë‚˜íƒ€ëƒ„ | . | . import numpy as np import cv2 . image1 = np.zeros((50,512), np.uint8) # 50x512 ì˜ìƒ ìƒì„± image2 = np.zeros((50,512), np.uint8) rows, cols = image1.shape[:2] for i in range(rows): for j in range(cols): image1.itemset((i,j), j//2) # í™”ì†Œê°’ ì ì§„ì  ì¦ê°€ image2.itemset((i,j), j // 20*10) # ê³„ë‹¨ í˜„ìƒ ì¦ê°€ . cv2.imshow(&quot;image1&quot;, image1) cv2.imshow(&quot;image2&quot;, image2) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/image1_226.png&#39;, image1) # ì´ë¯¸ì§€ ì €ì¥ cv2.imwrite(&#39;./prac_image/image2_226.png&#39;, image2) # ì´ë¯¸ì§€ ì €ì¥ cv2.destroyAllWindows() . . - ì‹¤í–‰ê²°ê³¼ . image1 . ë‚˜ëˆ—ì…ˆ ëª« ì—°ì‚°ìë¡œ 2ë¡œ ë‚˜ëˆˆ ëª«ì„ ì €ì¥í•˜ëŠ” ê²ƒì€ ê°€ë¡œ ì¸ë±ìŠ¤ì˜ ì ˆë°˜ ê°’ìœ¼ë¡œ jì—´ ì›ì†Œì˜ í™”ì†Œê°’ì„ ì„¤ì •í•œ ê²ƒì´ë‹¤. ë”°ë¼ì„œ í™”ì†Œê°’ì€ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ 0ì—ì„œ 255ì˜ ê°’ê¹Œì§€ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•œë‹¤. | . image2 . (j // 20 * 10) ì€ ëª« ì—°ì‚°ìë¡œ ì¸í•´ì„œ ê³„ì‚° ê°’ì˜ ì†Œìˆ˜ ë¶€ë¶„ì€ ë‚ ë¼ê°„ë‹¤. ë”°ë¼ì„œ 20í™”ì†Œì”© ã…£ê°™ì€ ê°’ì„ ê°–ê²Œ ë˜ì–´ ê³„ë‹¨ í˜„ìƒì„ ë‚˜íƒ€ë‚´ë©° ì¦ê°€í•œë‹¤. | . 6.2.2 &#50689;&#49345;&#51032; &#54868;&#49548; &#54364;&#54788; . ì˜ìƒíŒŒì¼ì„ ì½ì–´ ë“¤ì—¬ ê·¸ ì˜ìƒì˜ íŠ¹ì • ë¶€ë¶„ì˜ í™”ì†Œë“¤ì„ í™•ì¸í•´ë³´ì. ì˜ìƒíŒŒì¼ì„ í–‰ë ¬ì— ì €ì¥í•˜ê³ , ê´€ì‹¬ ì˜ì—­ì„ ì§€ì •í•´ì„œ ì¶œë ¥í•˜ë©´ ê°„ë‹¨íˆ ì˜ìƒ ë°ì´í„°ì¸ í™”ì†Œë“¤ì˜ ê°’ì„ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤. . # ì˜ìƒ í™”ì†Œê°’ í™•ì¸ (pixel_value) import cv2 image = cv2.imread(&#39;./ghtop_images/chap06_images/pixel.jpg&#39;, cv2.IMREAD_GRAYSCALE) (x, y), (w, h) = (180, 37), (15, 10) roi_img = image[y:y+h, x:x+w] # í–‰ì€ ì‹œì‘ yì¢Œí‘œì—ì„œ y+hê¹Œì§€, ì—´ì€ ì‹œì‘ xì¢Œí‘œì—ì„œ x+wê¹Œì§€ #print(&quot;[roi img] = n&quot;, roi_img) . $(x, y)$ëŠ” ì‚¬ê°í˜•ì˜ ì‹œì‘ì¢Œí‘œ | $(w, h)$ëŠ” ì‚¬ê°í˜•ì˜ í¬ê¸° | ì¦‰, ì‚¬ê°í˜•ì˜ ì‹œì‘ì¢Œí‘œì™€ í¬ê¸°ë¡œ ê´€ì‹¬ì˜ì—­ì„ ì§€ì •í•œë‹¤. | . print(&quot;[roi_img] =&quot;) for row in roi_img: for p in row: print(&quot;%4d&quot; % p, end=&quot;&quot;) print() . [roi_img] = 56 51 59 66 84 104 154 206 220 208 203 207 205 204 204 75 57 53 53 72 71 100 152 195 214 212 201 209 207 205 88 76 65 53 51 60 73 96 143 200 219 200 206 204 202 91 92 80 63 53 59 59 61 89 144 195 222 205 200 205 89 94 90 82 63 54 51 56 65 92 149 203 223 209 196 89 91 90 89 84 64 54 55 51 56 94 140 208 223 203 91 86 84 85 97 86 72 59 50 53 66 81 148 211 216 92 86 85 88 92 95 88 70 55 53 59 64 89 155 211 88 85 86 90 87 87 89 86 72 56 50 53 59 88 175 87 85 86 88 87 84 86 90 86 70 53 44 51 56 111 . cv2.rectangle(image, (x,y,w,h) , 255, 1) # ê´€ì‹¬ ì˜ì—­ì— ì‚¬ê°í˜• í‘œì‹œ cv2.imshow(&quot;image&quot;, image) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/image_227.png&#39;, image) # ì´ë¯¸ì§€ ì €ì¥ cv2.destroyAllWindows() . . ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³´ë©´, ì˜ìƒì˜ ìš°ìƒë‹¨ì— í°ìƒ‰ì˜ ì‘ì€ ì‚¬ê°í˜•ì´ ê·¸ë ¤ì ¸ ìˆë‹¤. ì´ ì‚¬ê°í˜•ì´ ê´€ì‹¬ ì˜ì—­ì´ë©°, ì´ ì˜ì—­ì˜ í™”ì†Œê°’ê³¼ ë¹„êµí•´ë³´ì. | . print(&quot;[roi img] = n&quot;, roi_img) . [roi img] = [[ 56 51 59 66 84 104 154 206 220 208 203 207 205 204 204] [ 75 57 53 53 72 71 100 152 195 214 212 201 209 207 205] [ 88 76 65 53 51 60 73 96 143 200 219 200 206 204 202] [ 91 92 80 63 53 59 59 61 89 144 195 222 205 200 205] [ 89 94 90 82 63 54 51 56 65 92 149 203 223 209 196] [ 89 91 90 89 84 64 54 55 51 56 94 140 208 223 203] [ 91 86 84 85 97 86 72 59 50 53 66 81 148 211 216] [ 92 86 85 88 92 95 88 70 55 53 59 64 89 155 211] [ 88 85 86 90 87 87 89 86 72 56 50 53 59 88 175] [ 87 85 86 88 87 84 86 90 86 70 53 44 51 56 111]] . ê´€ì‹¬ì˜ì—­ ì¦‰, í°ìƒ‰ ì‚¬ê°í˜•ì´ ê·¸ë ¤ì ¸ ìˆëŠ” ë¶€ë¶„ì„ ë³´ë©´ ì£¼ëŒ€ê°ì„  ìœ— ë¶€ë¶„ì€ í°ìƒ‰(ë°ì€ìƒ‰)ì´ê³  ì•„ë«ë¶€ë¶„ì€ ì§„í•œíšŒìƒ‰(ì–´ë‘ìš´ìƒ‰)ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤. | í™”ì†Œ ê°’ì„ ë³´ë©´ ì£¼ëŒ€ê°ì„  ê¸°ì¤€ ìœ—ë¶€ë¶„ì€ í™”ì†Œê°’ì€ ëŒ€ëµ $200 sim225$ë²”ìœ„ì˜ ê°’ì„ ë‚˜íƒ€ë‚´ê³ , ê·¸ ì•„ë˜ë¶€ë¶„ì€ ëŒ€ëµ $50 sim80$ë²”ìœ„ì˜ ê°’ì„ì„ í™•ì¸ | ì¦‰, í°ìƒ‰ë¶€ë¶„ì€ í™”ì†Œê°’ì´ 255ì™€ ê°€ê¹ê³ , ì–´ë‘ìš´ ë¶€ë¶„ì€ 0ì— ê°€ê¹Œìš´ ê°’ì„ ê°–ëŠ”ë‹¤. | . 6.2.3 &#50689;&#49345; &#48157;&#44592;&#51032; &#44032;&#44048;&#50689;&#49345; . í™”ì†Œê°’ì´ ì˜ìƒì˜ ë°ê¸°ë¥¼ ë‚˜íƒ€ë‚´ê¸° ë•Œë¬¸ì— ì´ í™”ì†Œê°’ì„ ë³€ê²½í•˜ë©´ ì˜ìƒì˜ ë°ê¸°ë¥¼ ë°”ê¿€ ìˆ˜ ìˆë‹¤. . ì˜ˆë¥¼ ë“¤ì–´ ì˜ìƒì˜ í™”ì†Œì— íŠ¹ì •í•œ ìƒìˆ«ê°’ì„ ë”í•˜ë©´ ì˜ìƒì´ ë°ì•„ì§€ê³ , ìƒìˆ«ê°’ì„ ë¹¼ë©´ ì˜ìƒì´ ì–´ë‘ì›Œì§„ë‹¤. | ë˜í•œ, í™”ì†Œê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìµœëŒ“ê°’(ì˜ˆë¡œ 255)ì—ì„œ ê·¸ í™”ì†Œì˜ ê°’ì„ ë¹¼ë©´ ë°˜ì „ ì˜ìƒì´ ë§Œë“¤ì–´ì§„ë‹¤. | . 6.2.4 &#54665;&#47148; &#45927;&#49480; &#48143; &#44273;&#49480;&#51012; &#51060;&#50857;&#54620; &#50689;&#49345; &#54633;&#49457; . ì˜ìƒì— ìƒìˆ˜ë¥¼ ë”í•˜ê±°ë‚˜ ë¹¼ëŠ” ì—°ì‚°ì„ í™•ì¥í•˜ë©´ ë‘ ê°œì˜ ì˜ìƒì„ ë”í•˜ê±°ë‚˜ ë¹¼ëŠ” ì—°ì‚°ì„ ìƒê°í•´ ë³¼ ìˆ˜ ìˆë‹¤. ë‘ ì˜ìƒì„ í•©í•˜ë©´ ì˜ìƒ í•©ì„±ì´ ë˜ë©°, ë‘ ì˜ìƒì„ ë¹¼ë©´ ì°¨ì˜ìƒ(difference image)ì´ ëœë‹¤. . ë‹¤ìŒì€ ì•Œë ‰ì‚°ë” ëŒ€ì™• ë™ìƒ ì˜ìƒ($A$)ê³¼ ì‚¬ë„ì˜ ê±´ë¬¼ ì˜ìƒ($B$), ë‘ ì˜ìƒì„ í•©ì„±í•œ ì˜ìƒ($A+B$)ì„ êµ¬í•˜ëŠ” ì˜ˆì œì´ë‹¤. . ğŸ¤” ë¬¸ì œë°œìƒ&lt;/p&gt; ë‘ ê°œì˜ í–‰ë ¬ì„ í•©í•˜ê²Œ ë˜ë©´, saturation ì—°ì‚°ìœ¼ë¡œ ì¸í•´ 255ê°€ ë„˜ì–´ê°€ëŠ” í™”ì†Œë“¤ì€ í°ìƒ‰ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ì„œ ì˜ìƒì˜ í•©ì„±ì´ ì œëŒ€ë¡œ ìˆ˜í–‰ë˜ì§€ ì•ŠëŠ”ë‹¤. . | ì°¸ê³ ë¡œ í–‰ë ¬ì˜ ë§ì…ˆê³¼ ëº„ì…ˆì—ì„œ OpenCVëŠ” saturation ë°©ì‹ì„ ì‚¬ìš©í•˜ê³ , numpyëŠ” modulo ë°©ì‹ì„ ì‚¬ìš©í•œë‹¤. . &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; ğŸ˜ í•´ê²°ë°©ë²• 1. $dst(y,x) = image1(y,x)*0.5 + image2(y,x)*0.5$ 2. $dst(y,x) = image1(y,x)* alpha + image2(y,x)*(1- alpha)$ 3. $dst(y,x) = image1(y,x)* alpha + image2(y,x)* beta$ &#54665;&#47148; &#54633;&#44284; &#44273; &#50672;&#49328;&#51012; &#53685;&#54620; &#50689;&#49345; &#54633;&#49457; . import numpy as np, cv2 image1 = cv2.imread(&#39;./ghtop_images/chap06_images/add1.jpg&#39;, cv2.IMREAD_GRAYSCALE) # ì˜ìƒ ì½ê¸° image2 = cv2.imread(&#39;./ghtop_images/chap06_images/add2.jpg&#39;, cv2.IMREAD_GRAYSCALE) . alpha, beta = 0.6, 0.7 # ê³±ì…ˆ ë¹„ìœ¨ add_img1 = cv2.add(image1, image2) # ë‘ ì˜ìƒ ë‹¨ìˆœ ë”í•˜ê¸° add_img2 = cv2.add(image1 * alpha, image2 * beta) # ë‘ ì˜ìƒ ë¹„ìœ¨ì— ë”°ë¥¸ ë”í•˜ê¸° add_img2 = np.clip(add_img2, 0, 255).astype(&#39;uint8&#39;) # saturation ì²˜ë¦¬ add_img3 = cv2.addWeighted(image1, alpha, image2, beta, 0) # ë‘ ì˜ìƒ ë¹„ìœ¨ì— ë”°ë¥¸ ë”í•˜ê¸° titles = [&#39;image1&#39;, &#39;image2&#39;,&#39;add_img1&#39;,&#39;add_img2&#39;,&#39;add_img3&#39;] # ìœˆë„ìš° ì´ë¦„ for t in titles: cv2.imshow(t, eval(t)) # ì˜ìƒ í‘œì‹œ cv2.waitKey(0) cv2.destroyAllWindows() . titles = [&#39;image1&#39;, &#39;image2&#39;,&#39;add_img1&#39;,&#39;add_img2&#39;,&#39;add_img3&#39;] eval(titles[1]) . array([[110, 122, 118, ..., 165, 166, 166], [143, 159, 168, ..., 165, 166, 166], [115, 117, 140, ..., 165, 166, 166], ..., [ 32, 41, 45, ..., 34, 32, 30], [ 27, 35, 40, ..., 110, 109, 108], [ 41, 36, 31, ..., 146, 148, 149]], dtype=uint8) . íŒŒì´ì¬ ë‚´ì¥í•¨ìˆ˜ eval()í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ë¦¬ìŠ¤íŠ¸ ì›ì†Œì˜ ë¬¸ìì—´ì„ í–‰ë ¬ ë³€ìˆ˜ë¡œ ì‚¬ìš©í•˜ì—¬ í–‰ë ¬ì„ ìœˆë„ìš°ì— í‘œì‹œí•œë‹¤. | . &lt;/div&gt; | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/15/opencv.html",
            "relUrl": "/python/2022/10/15/opencv.html",
            "date": " â€¢ Oct 15, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "(OpenCV - Chap5) 10ì›” 13ì¼(2)",
            "content": "5.3.1 &#49324;&#52825; &#50672;&#49328; (&#54665;&#47148; &#49328;&#49696; &#50672;&#49328;) . ì‚¬ì¹™ì—°ì‚°ì„ ìœ„í•œ OpenCVí•¨ìˆ˜ì— ëŒ€í•´ ì•Œì•„ë³´ì. . cv2.add(src1, src2[, mask[, dtype]]]) -&gt; dst . ë‘ ê°œì˜ ë°°ì—´ í˜¹ì€ ë°°ì—´ê³¼ ìŠ¤ì¹¼ë¼ì˜ ê° ì›ì†Œ ê°„ í•©ì„ ê³„ì‚°í•œë‹¤. ì…ë ¥ì¸ìˆ˜ src1, src2 ì¤‘ í•˜ë‚˜ëŠ” ìŠ¤ì¹¼ë¼ê°’ì¼ ìˆ˜ ìˆë‹¤. . $dst(i) = saturate(src1(i) + src2(i)) quad text{if } mask(i) neq 0$ | $dst(i) = saturate(src1 + src2(i)) quad text{if } mask(i) neq 0$ | $dst(i) = saturate(src1(i) + src2) quad text{if } mask(i) neq 0$ | . | . | . cv2.addWeighted(src1, alpha1, src2, beta, gamma[,[dst[,dtype]]) -&gt; dst ë‘ ë°°ì—´ì˜ ê° ì›ì†Œì— ê°€ì¤‘ì¹˜ë¥¼ ê³±í•œ í›„ì— ê° ì›ì†Œ ê°„ í•© ì¦‰, ê°€ì¤‘ëœ(weighted) í•©ì„ ê³„ì‚°í•œë‹¤. | ìˆ˜ì‹: $dst(i) = saturate(src1(i) cdot alpha + src2(i) cdot beta + gamma)$ | . | . [ ì°¸ê³  ] OpenCVì—ì„œ **saturate()** ëŠ” 0ì´í•˜ëŠ” 0ìœ¼ë¡œ, 255ì´ìƒì€ 255ë¡œ ë²”ìœ„ë¥¼ í•œì •ì‹œí‚¤ëŠ” ì—°ì‚°ì´ë‹¤. import numpy as np, cv2 m1 = np.full((3,6), 10, np.uint8) # ë‹¨ì¼ì±„ë„ ìƒì„± ë° ì´ˆê¸°í™” m2 = np.full((3,6), 50, np.uint8) m_mask = np.zeros(m1.shape, np.uint8) # ë§ˆìŠ¤í¬ ìƒì„± m_mask[:,3:] = 1 # ê´€ì‹¬ ì˜ì—­(ëª¨ë“ í–‰, 3ì—´ë¶€í„°)ì„ ì§€ì •í•œ í›„, 1ì„ í• ë‹¹ . . m1 . array([[10, 10, 10, 10, 10, 10], [10, 10, 10, 10, 10, 10], [10, 10, 10, 10, 10, 10]], dtype=uint8) . m2 . array([[50, 50, 50, 50, 50, 50], [50, 50, 50, 50, 50, 50], [50, 50, 50, 50, 50, 50]], dtype=uint8) . m_mask . array([[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1]], dtype=uint8) . - í–‰ë ¬ ë§ì…ˆ . m_add1 = cv2.add(m1, m2) m_add1 . array([[60, 60, 60, 60, 60, 60], [60, 60, 60, 60, 60, 60], [60, 60, 60, 60, 60, 60]], dtype=uint8) . m_add2 = cv2.add(m1, m2, mask=m_mask) m_add2 . array([[ 0, 0, 0, 60, 60, 60], [ 0, 0, 0, 60, 60, 60], [ 0, 0, 0, 60, 60, 60]], dtype=uint8) . ë§ˆìŠ¤í¬ ì˜ì—­ (ê´€ì‹¬ì˜ì—­)ë§Œ ë§ì…ˆ ì—°ì‚°ì´ ëœ ê²ƒì„ í™•ì¸! | . - í–‰ë ¬ ë‚˜ëˆ—ì…ˆ . m_div1 = cv2.divide(m1, m2) m_div1 . array([[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], dtype=uint8) . ì „ë¶€ 0ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤? 0.2ê°€ ë‚˜ì™€ì•¼ í•˜ëŠ”ë°?? (ì†Œìˆ˜ ë¶€ë¶„ì´ ìƒì‹¤ë˜ì—ˆë‹¤.) | . - ì†Œìˆ˜ë¶€ë¶„ ì†Œì‹¤ ë°©ì§€ . í–‰ë ¬ ì›ì†Œ ìë£Œí˜•ì„ 32ë¹„íŠ¸ ì‹¤ìˆ˜í˜•(np.float32)ë¡œ ë³€í™˜ . m1 = m1.astype(np.float32) # ì†Œìˆ˜ë¶€ë¶„ ë³´ì¡´ìœ„í•´ í–‰ë³€í™˜ m2 = np.float32(m2) # í˜• ë³€í™˜ ë°©ë²•2 m_div2 = cv2.divide(m1, m2) m_div2 . array([[0.2, 0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.2, 0.2, 0.2, 0.2, 0.2]], dtype=float32) . ì†Œìˆ˜ë¶€ë¶„ ì†Œì‹¤ ë¬¸ì œê°€ ì˜ í•´ê²°ë˜ì—ˆë‹¤. | . 5.3.2 &#51648;&#49688;, &#47196;&#44536;, &#51228;&#44273;&#44540; &#44288;&#47144; &#54632;&#49688; . import numpy as np, cv2 ## ndarray ìƒì„± v1 = np.array([1,2,3], np.float32) # 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ í–‰ë ¬ ìƒì„± v2 = np.array([[1],[2],[3]], np.float32) # 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ (3í–‰, 1ì—´) - ì—´ë²¡í„° v3 = np.array([[1,2,3]],np.float32) # 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ (1í–‰, 3ì—´) - í–‰ë²¡í„° . . v1 # 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ í–‰ë ¬ ìƒì„± . array([1., 2., 3.], dtype=float32) . v2 # 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ (3í–‰, 1ì—´) - ì—´ë²¡í„° . array([[1.], [2.], [3.]], dtype=float32) . v3 # 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ (1í–‰, 3ì—´) - í–‰ë²¡í„° . array([[1., 2., 3.]], dtype=float32) . v_exp = cv2.exp(v1) # 1ì°¨ì› í–‰ë ¬ì— ëŒ€í•œ ì§€ìˆ˜ m_exp = cv2.exp(v2) # í–‰ë²¡í„° (1*3)ì— ëŒ€í•œ ì§€ìˆ˜ê³„ì‚° m_exp = cv2.exp(v3) # ì—´ë²¡í„° (3*1)ì— ëŒ€í•œ ì§€ìˆ˜ ê³„ì‚° v_log = cv2.log(v1) # ë¡œê·¸ ê³„ì‚° m_sqrt = cv2.sqrt(v2) # ì œê³±ê·¼ ê³„ì‚° m_pow = cv2.pow(v3, 3) # 3ì˜ ê±°ë“­ì œê³± ê³„ì‚° . . v_exp . array([[ 2.718282 ], [ 7.3890557], [20.085539 ]], dtype=float32) . np.array([[np.exp(1)], [np.exp(2)],[np.exp(3)]]) . array([[ 2.71828183], [ 7.3890561 ], [20.08553692]]) . ì˜ ê³„ì‚°ë˜ëŠ”êµ¬ë§Œ! | . m_exp . array([[ 2.718282 , 7.3890557, 20.085539 ]], dtype=float32) . v_log . array([[0. ], [0.6931472], [1.0986123]], dtype=float32) . m_sqrt . array([[1. ], [1.4142135], [1.7320508]], dtype=float32) . m_pow . array([[ 1., 8., 27.]], dtype=float32) . &#54665;&#48289;&#53552;&#47484; &#50676;&#48289;&#53552;&#47196;, &#50676;&#48289;&#53552;&#47484; &#54665;&#48289;&#53552;&#47196; (Transpose) . print( v_log.T) . [[0. 0.6931472 1.0986123]] . print(m_sqrt.T) . [[1. 1.4142135 1.7320508]] . print(m_pow.T) . [[ 1.] [ 8.] [27.]] . ì—´ë²¡í„°ëŠ” í–‰ë²¡í„°ë¡œ, í–‰ë²¡í„°ëŠ” ì—´ë²¡í„°ë¡œ ë³€í™˜í•˜ì˜€ë‹¤! | . 2&#52264;&#50896; &#54665;&#47148;&#51012; &#48289;&#53552;(1&#52264;&#50896;)&#47196; &#48320;&#54872; . np.ravel | .flatten() | . print(m_sqrt) . [[1. ] [1.4142135] [1.7320508]] . print(np.ravel(m_sqrt)) . [1. 1.4142135 1.7320508] . Numpy ëª¨ë“ˆì˜ ravel() í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ 2ì°¨ì› í–‰ë ¬ì„ ë²¡í„°(1ì°¨ì›)ìœ¼ë¡œ ë³€í™˜. | ravel() í•¨ìˆ˜ëŠ” ë¦¬ìŠ¤íŠ¸ë‚˜ ë„˜íŒŒì´ ë°°ì—´ë¿ë§Œ ì•„ë‹ˆë¼ ëª¨ë“  ë‹¤ì°¨ì› ë°°ì—´ì„ ë²¡í„°(1ì°¨ì›)ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤. | . print(m_pow, type(m_pow)) print(m_pow.flatten(), type(m_pow.flatten())) . [[ 1. 8. 27.]] &lt;class &#39;numpy.ndarray&#39;&gt; [ 1. 8. 27.] &lt;class &#39;numpy.ndarray&#39;&gt; . ndarray í´ë˜ìŠ¤ì˜ ë‚´ë¶€ ë©”ì†Œë“œì¸ flatten() í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ë²¡í„°ë¡œ ë³€í™˜í•œë‹¤. | . &#54665;&#47148; &#53356;&#44592; &#48143; &#50948;&#49345; &#50672;&#49328; . ë‹¤ìŒì€ cv2.magnitude()ì™€ cv2.phase() í•¨ìˆ˜ì˜ ì˜ˆì‹œì´ë‹¤. OpenCV í•¨ìˆ˜ì—ì„œ ì—°ì‚°ì˜ ê²°ê³¼ê°€ ì‹¤ìˆ˜ê°’ì„ ê°–ëŠ” ê²½ìš° ëŒ€ë¶€ë¶„ ì…ë ¥ í–‰ë ¬ ì›ì†Œì˜ ìë£Œí˜•ë„ np.float32í˜•ì´ì—¬ì•¼ í•œë‹¤. . import numpy as np, cv2 . . x = np.array([1,2,3,5,10], np.float32) # ë¦¬ìŠ¤íŠ¸ë¡œ ndarray ê°ì²´ ìƒì„± y = np.array([2,5,7,2,9]).astype(&#39;float32&#39;) # í–‰ë ¬ ìƒì„± í›„ ì‹¤ìˆ˜í˜• ë³€í™˜ . x . array([ 1., 2., 3., 5., 10.], dtype=float32) . y . array([2., 5., 7., 2., 9.], dtype=float32) . - í¬ê¸° ê³„ì‚° . mag = cv2.magnitude(x, y) mag . array([[ 2.236068 ], [ 5.3851647], [ 7.615773 ], [ 5.3851647], [13.453624 ]], dtype=float32) . - ê°ë„(ë°©í–¥) ê³„ì‚° . ang = cv2.phase(x, y) ang . array([[1.1071129], [1.1902124], [1.1658309], [0.3805839], [0.7329612]], dtype=float32) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/14/operations_func.html",
            "relUrl": "/python/2022/10/14/operations_func.html",
            "date": " â€¢ Oct 14, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "(OpenCV - Chap5) 10ì›” 13ì¼",
            "content": "05. &#44592;&#48376; &#48176;&#50676; &#50672;&#49328; &#54632;&#49688; . OpenCVëŠ” ìˆ˜í•™ê³¼ ê³¼í•™ ì—°ì‚°ì„ ìœ„í•œ íŒŒì´ì¬ íŒ¨í‚¤ì§€ì¸ ë„˜íŒŒì´(numpy)ì™€ ì—°ë™í•´ ë°°ì—´ì„ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŸ° ë°°ì—´ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì—°ì‚°í•¨ìˆ˜ë¥¼ ì§€ì›í•œë‹¤. . íŒŒì´ì¬ì—ì„œëŠ” ë°°ì—´ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìë£Œí˜•ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ì‚¬ì „ ë“±ì˜ ì—´ê±°í˜•(sequence) ê°ì²´ê°€ ìˆë‹¤. ë¦¬ìŠ¤íŠ¸ëŠ” ë‹¤ì°¨ì›ì˜ ë°°ì—´ì„ ë§Œë“¤ê³  ì›ì†Œë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìœ¼ë©°, íŠœí”Œì€ ë‹¤ì°¨ì›ì˜ ë°°ì—´ì„ ë§Œë“¤ ìˆ˜ ìˆì§€ë§Œ, ìˆ˜ì •ì´ ë¶ˆê°€ëŠ¥í•œ ìë£Œí˜•ì´ë‹¤. OpenCV ëª¨ë“ˆì˜ í•¨ìˆ˜ë“¤ì€ ë„˜íŒŒì´ ëª¨ë“ˆì˜ ë°°ì—´(ndarray) ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì…ë ¥ ë°°ì—´ê³¼ ì¶œë ¥ ë°°ì—´ì„ ì‚¬ìš©í•œë‹¤. . ì´ ì¥ì—ì„œëŠ” OpenCVì—ì„œ ì§€ì›í•˜ëŠ” ì—¬ëŸ¬ ë°°ì—´ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì‚´í´ë³¸ë‹¤. . 5.1 &#44592;&#48376; &#48176;&#50676; (Array) &#54632;&#49688; . OpenCVì—ì„œëŠ” ë°°ì—´ì„ ì˜µì…˜ì— ë”°ë¼ ì—¬ëŸ¬ ë°©í–¥ìœ¼ë¡œ ë’¤ì§‘ê±°ë‚˜ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•˜ëŠ” ë“± ë°°ì—´ ìì²´ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì œê³µí•˜ê³  ìˆë‹¤. . ë‹¤ìŒ ì˜ˆì œëŠ” ì˜ìƒíŒŒì¼ì„ ì½ì€ í›„, cv2.flip(), cv2.repeat, cv2.transpose() í•¨ìˆ˜ë¥¼ í™œìš©í•´ì„œ ìƒí•˜ì¢Œìš°ë¡œ ë’¤ì§‘ëŠ” ì˜ˆì‹œì´ë‹¤. . import cv2 image = cv2.imread(&#39;./ghtop_images/chap05_images/flip_test.jpg&#39;, cv2.IMREAD_COLOR) if image is None: raise Exception(&quot;ì˜ìƒíŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ë°œìƒ&quot;) # ì˜ˆì™¸ ì²˜ë¦¬ . . - &#50896;&#48376; &#51060;&#48120;&#51648; . image = cv2.imshow(&#39;image&#39;, image) cv2.waitKey(0) cv2.destroyAllWindows() . . ì›ë³¸ ì´ë¯¸ì§€ . . - x&#52629; &#44592;&#51456;&#51004;&#47196; &#46244;&#51665;&#51008; &#51060;&#48120;&#51648; . x_axis = cv2.flip(image, 0) # xì¶• ê¸°ì¤€ ìƒí•˜ ë’¤ì§‘ê¸° cv2.imshow(&#39;x_axis&#39;, x_axis) cv2.waitKey(0) cv2.destroyAllWindows() . . x-axis flip . . - y&#52629; &#44592;&#51456;&#51004;&#47196; &#46244;&#51665;&#51008; &#51060;&#48120;&#51648; . y_axis = cv2.flip(image, 1) # yì¶• ê¸°ì¤€ ì¢Œìš° ë’¤ì§‘ê¸° cv2.imshow(&#39;y_axis&#39;, y_axis) cv2.waitKey(0) cv2.destroyAllWindows() . . y_axis flip . . - x, y&#52629; &#44592;&#51456; &#49345;&#54616;&#51340;&#50864; &#46244;&#51665;&#44592; . xy_axis = cv2.flip(image, -1) # ì–‘ì¶•(x,yì¶•) ê¸°ì¤€ ìƒí•˜ì¢Œìš° ë’¤ì§‘ê¸° cv2.imshow(&#39;xy_axis&#39;, xy_axis) cv2.waitKey(0) cv2.destroyAllWindows() . . xy_axis flip . . - &#48373;&#49324;&#48376; &#47564;&#46308;&#44592; . cv.repeat(src, ny, nx[,dst[) -&gt; dst . src, dst : ì…ë ¥, ì¶œë ¥ ë°°ì—´ . | ny, nx : ìˆ˜ì§, ìˆ˜í‰ë°©í–¥ ë°˜ë³µ íšŸìˆ˜ . | . | . ì…ë ¥ ë°°ì—´ì˜ ë°˜ë³µëœ ë³µì‚¬ë³¸ìœ¼ë¡œ ì¶œë ¥ ë°°ì—´ì„ ì±„ìš´ë‹¤. | . rep_image = cv2.repeat(image, 1, 2) # ë°˜ë³µ ë³µì‚¬ cv2.imshow(&#39;rep_image&#39;, rep_image) cv2.waitKey(0) cv2.destroyAllWindows() . . repeat_image . . - &#51204;&#52824; &#51060;&#48120;&#51648; . ì…ë ¥ í–‰ë ¬ì˜ ì „ì¹˜ í–‰ë ¬ì„ ì¶œë ¥ìœ¼ë¡œ ë°˜í™˜í•œë‹¤. | . trans_image = cv2.transpose(image) # í–‰ë ¬ ì „ì¹˜ cv2.imshow(&#39;trans_image&#39;, trans_image) cv2.waitKey(0) cv2.destroyAllWindows() . . trans_image . . image.shape . . (267, 360, 3) . trans_image.shape . . (360, 267, 3) . $267 times 360 times 3 to 360 times 267 times 3$ìœ¼ë¡œ ì „ì¹˜ëœ ê²ƒ í™•ì¸! . 5.2 &#52292;&#45328; &#52376;&#47532; &#54632;&#49688; . ì»¬ëŸ¬ ì˜ìƒì€ íŒŒë€ìƒ‰(B), ë…¹ìƒ‰(G), ë¹¨ê°„ìƒ‰(R)ì˜ ê°ê¸° ë…ë¦½ì ì¸ 2ì°¨ì› ì •ë³´ë¥¼ í•©ì³ ë†“ì€ ë°°ì—´ì´ë¼ê³  ì •ì˜í•  ìˆ˜ ìˆë‹¤. ìš”ì¦ˆìŒ ì˜ìƒì²˜ë¦¬ APIì—ì„œëŠ” ì»¬ëŸ¬ ì˜ìƒì„ í‘œí˜„í•˜ê¸° ìœ„í•´ ì±„ë„(Channel)ì´ë¼ëŠ” ê°œë…ì„ ë„ì…í•œë‹¤. ì¦‰, ë¹¨ê°„ìƒ‰, ë…¹ìƒ‰, íŒŒë€ìƒ‰ì˜ ë…ë¦½ì ì¸ 2ì°¨ì› ì •ë³´ëŠ” ê°ê° Blueì±„ë„, Greenì±„ë„, Red ì±„ë„ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í‘œí˜„ëœë‹¤. . ë‹¤ìŒì€ ë‹¨ì¼ì±„ë„ í–‰ë ¬ì„ ì—¬ëŸ¬ ê°œ í•©ì¹˜ê±°ë‚˜, ë‹¤ì±„ë„ì„ ë¶„ë¦¬í•˜ëŠ” ë“± ì±„ë„ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ì— ëŒ€í•œ ì„¤ëª…ì´ë‹¤. . ê°„ë‹¨í•œ ì˜ˆì œë¡œ ì±„ë„ì— ëŒ€í•œ ê°œë…ì„ ì•Œì•„ë³´ì. . 1. ë‹¨ì¼ì±„ë„ í–‰ë ¬ 3ê°œë¥¼ ìƒì„± | 2. 3ê°œì˜ ì±„ë„ì„ í•©ì³ í•˜ë‚˜ì˜ ë‹¤ì±„ë„ í–‰ë ¬ë¡œ ìƒì„± | 3. ê·¸ í›„ í•©ì³ì§„ ë‹¤ì±„ë„ í–‰ë ¬ì„ ë‹¤ì‹œ ë‹¨ì¼ì±„ë„ë¡œ ë¶„ë¦¬ | . import numpy as np import cv2 . . ## numpy.ndarrayë¥¼ ì´ìš©í•´ í–‰ë ¬ ìƒì„± ë° ì´ˆê¸°í™” ë°©ë²• ch0 = np.zeros((2,4), np.uint8) + 10 # 0ì›ì†Œ í–‰ë ¬ ì„ ì–¸ í›„ 10 ë”í•˜ê¸° ch1 = np.ones((2,4), np.uint8) * 20 # 1ì›ì†Œ í–‰ë ¬ ì„ ì–¸ í›„ 20 ê³±í•˜ê¸° ch2 = np.full((2,4), 30, np.uint8) # í–‰ë ¬ì„ ìƒì„±í•˜ë©° 30ìœ¼ë¡œ ì´ˆê¸°í™” list_bgr = [ch0, ch1, ch2] # ë‹¨ì¼ì±„ë„ í–‰ë ¬ë“¤ì„ ëª¨ì•„ ë¦¬ìŠ¤íŠ¸ êµ¬ì„± merge_bgr = cv2.merge(list_bgr) # ì±„ë„ í•©ì„± split_bgr = cv2.split(merge_bgr) # ì±„ë„ ë¶„ë¦¬ : ì»¬ëŸ¬ì˜ìƒ &gt; 3ì±„ë„ ë¶„ë¦¬ . . ch0 . . array([[10, 10, 10, 10], [10, 10, 10, 10]], dtype=uint8) . ch1 . . array([[20, 20, 20, 20], [20, 20, 20, 20]], dtype=uint8) . ch2 . . array([[30, 30, 30, 30], [30, 30, 30, 30]], dtype=uint8) . # ë‹¨ì¼ ì±„ë„ í–‰ë ¬ 3ê°œ (ch0, ch1, ch2) list_bgr . . [array([[10, 10, 10, 10], [10, 10, 10, 10]], dtype=uint8), array([[20, 20, 20, 20], [20, 20, 20, 20]], dtype=uint8), array([[30, 30, 30, 30], [30, 30, 30, 30]], dtype=uint8)] . print(&#39;merge_bgr í–‰ë ¬ í˜•íƒœ: &#39;, merge_bgr.shape) print(&#39; &#39;) print(merge_bgr) . . merge_bgr í–‰ë ¬ í˜•íƒœ: (2, 4, 3) [[[10 20 30] [10 20 30] [10 20 30] [10 20 30]] [[10 20 30] [10 20 30] [10 20 30] [10 20 30]]] . print(&#39;split_bar í–‰ë ¬ í˜•íƒœ: &#39;, np.array(split_bgr).shape) # numpyì˜ shape() í•¨ìˆ˜ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ ndarrayê°ì²´ë¡œ ë³€ê²½í•˜ì—¬ í–‰ë ¬ í˜•íƒœë¡œ ì¶œë ¥ print(&#39; &#39;) print(split_bgr[0]) print(&#39; &#39;) print(split_bgr[1]) print(&#39; &#39;) print(split_bgr[2]) . . split_bar í–‰ë ¬ í˜•íƒœ: (3, 2, 4) [[10 10 10 10] [10 10 10 10]] [[20 20 20 20] [20 20 20 20]] [[30 30 30 30] [30 30 30 30]] . 2ì—´ 3í–‰ ê¹Šì´ê°€ 4 | . split_bgr . . (array([[10, 10, 10, 10], [10, 10, 10, 10]], dtype=uint8), array([[20, 20, 20, 20], [20, 20, 20, 20]], dtype=uint8), array([[30, 30, 30, 30], [30, 30, 30, 30]], dtype=uint8)) . np.array(split_bgr) . . array([[[10, 10, 10, 10], [10, 10, 10, 10]], [[20, 20, 20, 20], [20, 20, 20, 20]], [[30, 30, 30, 30], [30, 30, 30, 30]]], dtype=uint8) . &#50696;&#51228; &#49892;&#49845; . import cv2 . . image = cv2.imread(&#39;./ghtop_images/chap05_images/color.jpg&#39;, cv2.IMREAD_COLOR) # ì˜ìƒ ì½ê¸° if image is None: raise Exception(&#39;ì˜ìƒíŒŒì¼ ì½ê¸° ì˜¤ë¥˜&#39;) # ì˜ˆì™¸ì²˜ë¦¬ if image.ndim != 3: raise Exception(&quot;ì»¬ëŸ¬ ì˜ìƒ ì•„ë‹˜&quot;) # ì˜ˆì™¸ ì²˜ë¦¬ - ì»¬ëŸ¬ ì˜ìƒ í™•ì¸ . bgr = cv2.split(image) # blue, green, red = cv2.split(image) ## 3ê°œ ë³€ìˆ˜ë¡œ ë°˜í™˜ë°›ê¸° ê°€ëŠ¥! print(&#39;bgr ìë£Œí˜•:&#39;,type(bgr), type(bgr[0]), type(bgr[0][0][0])) . bgr ìë£Œí˜•: &lt;class &#39;tuple&#39;&gt; &lt;class &#39;numpy.ndarray&#39;&gt; &lt;class &#39;numpy.uint8&#39;&gt; . ## ê° ì±„ë„ì„ ìœˆë„ìš°ì— ë„ìš°ê¸° cv2.imshow(&#39;image&#39;, image) cv2.imshow(&#39;Blue chnnel&#39;, bgr[0]) cv2.imshow(&#39;Green chnnel&#39;, bgr[1]) cv2.imshow(&#39;Red chnnel&#39;, bgr[2]) cv2.waitKey(0) cv2.destroyAllWindows() . . original image vs. Blue channel . Blue Channel ì•„ë˜ìª½ íŒŒë€ìƒ‰ ë§ˆí¬ ë¶€ë¶„ì´ Blue channelì—ì„œëŠ” ë°ê²Œ ë‚˜íƒ€ë‚œë‹¤. | . original image vs. Green channel . ì›ë³¸ì´ë¯¸ì§€ ì•„ë˜ìª½ì— ë…¹ìƒ‰ì„ ë„ëŠ” ì§„ì—´ëŒ€ ë¶€ë¶„ì´ Green Channelì—ì„œ ë°ê²Œ ë‚˜íƒ€ë‚œë‹¤. | . original image vs. red channel . ì›ë³¸ì´ë¯¸ì§€ì˜ ì™¼ìª½ ëƒ‰ì¥ ì „ì‹œë¬¼ì˜ ë¶‰ì€ìª½ ë¬¸ ë¶€ë¶„ì´ Red Chnnelì—ì„œ ë°ê²Œ ë‚˜íƒ€ë‚œë‹¤. | . 5.3.0 &#49328;&#49696; &#50672;&#49328; &#54632;&#49688; . í–‰ë ¬ì—°ì‚°ì€ ì£¼ë¡œ ì²« ë²ˆì§¸ ë°°ì—´ì˜ ië²ˆì§¸ ì›ì†Œì™€ ë‘ ë²ˆì§¸ ë°°ì—´ì˜ ië²ˆì§¸ ì›ì†Œ ê°„ì— ì—°ì‚°ì„ ìˆ˜í–‰í•´ì„œ ê²°ê³¼ ë°°ì—´ì˜ ië²ˆì§¸ ì›ì†Œì— ì €ì¥í•˜ëŠ” ë°©ì‹ì„ ì·¨í•œë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì„ ì›ì†Œê°„ (per-element, element-wise) ì—°ì‚°ì´ë¼ í•œë‹¤. . 5.3.1 &#49324;&#52825;&#50672;&#49328; . OpenCVì—ì„œ ë°°ì—´ì— ëŒ€í•œ ì‚¬ì¹™ ì—°ì‚°ì€ ë‘ ë°°ì—´ì˜ ì›ì†Œê°„(per-element) ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤. . 5.3.2 &#51648;&#49688;, &#47196;&#44536;, &#51228;&#44273;&#44540; &#44288;&#47144; &#54632;&#49688; . OpenCVëŠ” ë°°ì—´ ì›ì†Œì˜ ì§€ìˆ˜ì™€ ë¡œê·¸ ë° ì œê³±ê·¼ ê´€ë ¨ í•¨ìˆ˜ë¥¼ ì§€ì›í•œë‹¤. .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/13/operatios_func.html",
            "relUrl": "/python/2022/10/13/operatios_func.html",
            "date": " â€¢ Oct 13, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "OpenCV intro",
            "content": "ref: https://www.youtube.com/watch?v=F2FRpmh9sQo . &#51060;&#48120;&#51648; &#51069;&#50612;&#49436; &#49332;&#54196;&#48372;&#44592; . 01. cv2.imread(file_name, flag) . cv2.imread(file_name, flag) : ì´ë¯¸ì§€ë¥¼ ì½ì–´ Numpy ê°ì²´ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜ file_name : ì½ê³ ì í•˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ | flag : ì´ë¯¸ì§€ë¥¼ ì½ëŠ” ë°©ë²• ì„¤ì • . IMREAD_COLOR : ì´ë¯¸ì§€ë¥¼ Colorë¡œ ì½ê³ , íˆ¬ëª…í•œ ë¶€ë¶„ì€ ë¬´ì‹œ | IMREAD_GRAYSCALE : ì´ë¯¸ì§€ë¥¼ Grayscaleë¡œ ì½ê¸° | IMREAD_UNCHANGED : ì´ë¯¸ì§€ë¥¼ Colorë¡œ ì½ê³ , íˆ¬ëª…í•œ ë¶€ë¶„ë„ ì½ê¸° (Alpha) | . | ë°˜í™˜ ê°’ : Numpy ê°ì²´ (í–‰, ì—´, ìƒ‰ìƒ: ê¸°ë³¸ BGR) . | . 02. cv2. imshow(title, image) . cv2.imshow(title, image) : íŠ¹ì •í•œ ì´ë¯¸ì§€ë¥¼ í™”ë©´ì— ì¶œë ¥ title: ìœˆë„ìš° ì°½ì˜ ì œëª© | image : ì¶œë ¥í•  ì´ë¯¸ì§€ ê°ì²´ | . 03. cv2.imwrite(file_name, image) . cv2.imwrite(file_name, image) : íŠ¹ì •í•œ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ file_name : ì €ì¥í•  ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ | image : ì €ì¥í•  ì´ë¯¸ì§€ ê°ì²´ | . 04. cv2.waitKey(time) . cv2.waitKey(time) : í‚¤ë³´ë“œ ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ time : ì…ë ¥ ëŒ€ê¸° ì‹œê°„ (ë¬´í•œëŒ€ê¸°: 0) . | ë°˜í™˜ ê°’: ì‚¬ìš©ìê°€ ì…ë ¥í•œ Ascii Code (ESC: 27) . | . 05. cv2.destroyAllWindows() . cv2.destroyAllWindows() : í™”ë©´ì˜ ëª¨ë“  ìœˆë„ìš°ë¥¼ ë‹«ëŠ” í•¨ìˆ˜ import cv2 img_basic = cv2.imread(&#39;./ghtop_images/chap05_images/color.jpg&#39;, cv2.IMREAD_COLOR) cv2.imshow(&#39;Image Basic&#39;, img_basic) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/img_basic.png&#39;, img_basic) # ì´ë¯¸ì§€ ì €ì¥ cv2.destroyAllWindows() . . img_gray = cv2.cvtColor(img_basic, cv2.COLOR_BGR2GRAY) cv2.imshow(&quot;Image Gray&quot;, img_gray) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/img_gray.png&#39;, img_gray) # ì´ë¯¸ì§€ ì €ì¥ cv2.destroyAllWindows() . .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/09/01/opencv-intro.html",
            "relUrl": "/python/2022/09/01/opencv-intro.html",
            "date": " â€¢ Sep 1, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "(1ì£¼ì°¨ ML2) 4ì›” 28ì¼",
            "content": "",
            "url": "https://pinkocto.github.io/BP2022/python/2022/04/28/ML.html",
            "relUrl": "/python/2022/04/28/ML.html",
            "date": " â€¢ Apr 28, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "OpenCV",
            "content": "https://www.youtube.com/watch?v=XK3eU9egll8 . &#54872;&#44221; &#49444;&#51221; . Anaconda promptì—ì„œ ë‹¤ìŒ ëª…ë ¹ ìˆ˜í–‰ . pip install opencv-pythoon . import cv2 cv2.__version__ . &#39;4.5.5&#39; . OpenCV (Computer Vision) . ë‹¤ì–‘í•œ ì˜ìƒ (ì´ë¯¸ì§€) / ë™ì˜ìƒ ì²˜ë¦¬ì— ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ . 1. &#51060;&#48120;&#51648; &#52636;&#47141; . import cv2 img = cv2.imread(&#39;./my_icons/img.jpg&#39;) # í•´ë‹¹ ê²½ë¡œì˜ íŒŒì¼ ì½ì–´ì˜¤ê¸° cv2.imshow(&#39;img&#39;, img) # img ë¼ëŠ” ì´ë¦„ì˜ ì°½ì— imgë¥¼ í‘œì‹œ cv2.waitKey(5000) # ì§€ì •ëœ ì‹œê°„(ms) ë™ì•ˆ ì‚¬ìš©ì í‚¤ ì…ë ¥ ëŒ€ê¸° print(key) cv2.destroyAllWindows() # ëª¨ë“  ì°½ ë‹«ê¸° . 98 . &#51069;&#44592; &#50741;&#49496; . cv2.IMREAD_COLOR : ì»¬ëŸ¬ ì´ë¯¸ì§€,. íˆ¬ëª… ì˜ì—­ì€ ë¬´ì‹œ (ê¸°ë³¸ê°’) | cv2.IMREAD_GRAYSCALE : í‘ë°±ì´ë¯¸ì§€ | cv2.IMREAD_UNCHANGED : íˆ¬ëª… ì˜ì—³ê¹Œì§€ í¬í•¨ | import cv2 img_color = cv2.imread(&#39;./my_icons/img.jpg&#39;, cv2.IMREAD_COLOR) img_gray = cv2.imread(&#39;./my_icons/img.jpg&#39;, cv2.IMREAD_GRAYSCALE) img_unchanged = cv2.imread(&#39;./my_icons/img.jpg&#39;, cv2.IMREAD_UNCHANGED) cv2.imshow(&#39;img_color&#39;, img_color) cv2.imshow(&#39;img_gray&#39;, img_gray) cv2.imshow(&#39;img_unchanged&#39;, img_unchanged) cv2.waitKey(0) cv2.destroyAllWindows() . Shape . ì´ë¯¸ì§€ì˜ height, width, channel ì •ë³´ . import cv2 img = cv2.imread(&#39;./my_icons/img.jpg&#39;) img.shape # ì„¸ë¡œ, ê°€ë¡œ, Channel . (390, 640, 3) . 2. &#46041;&#50689;&#49345; &#52636;&#47141; . &#46041;&#50689;&#49345; &#54028;&#51068; &#52636;&#47141; . import cv2 cap = cv2.VideoCapture(&#39;./my_icons/video.mp4&#39;) while cap.isOpened(): # ë™ì˜ìƒ íŒŒì¼ì´ ì˜¬ë°”ë¡œ ì—´ë ¸ëŠ”ì§€? ret, frame = cap.read() # ret : ì„±ê³µ ì—¬ë¶€, frame : ë°›ì•„ì˜¨ ì´ë¯¸ì§€ (í”„ë ˆì„) if not ret: print(&#39;ë” ì´ìƒ ê°€ì ¸ì˜¬ í”„ë ˆì„ì´ ì—†ì–´ìš”&#39;) break cv2.imshow(&#39;video&#39;, frame) if cv2.waitKey(1) == ord(&#39;q&#39;): print(&#39;ì‚¬ìš©ì ì…ë ¥ì— ì˜í•´ ì¢…ë£Œí•©ë‹ˆë‹¤&#39;) break cap.release() # ìì› í•´ì œ cv2.destroyAllWindows() # ëª¨ë“  ì°½ ë‹«ê¸° . ë” ì´ìƒ ê°€ì ¸ì˜¬ í”„ë ˆì„ì´ ì—†ì–´ìš” . &#52852;&#47700;&#46972; &#52636;&#47141; . import cv2 cap = cv2.VideoCapture(0) # 0ë²ˆì§¸ ì¹´ë©”ë¼ ì¥ì¹˜ (Device ID) if not cap.isOpened(): # ì¹´ë©”ë¼ê°€ ì˜ ì—´ë¦¬ì§€ ì•Šì€ ê²½ìš° exit() # í”„ë¡œê·¸ë¨ ì¢…ë£Œ while True: ret, frame = cap.read() if not ret: break cv2.imshow(&#39;camera&#39;, frame) if cv2.waitKey(1) == ord(&#39;q&#39;): # ì‚¬ìš©ìê°€ që¥¼ ì…ë ¥í•˜ë©´ break cap.release() cv2.destroyAllWindows() . 3. &#46020;&#54805; &#44536;&#47532;&#44592; . &#48712; &#49828;&#52992;&#52824;&#48513; &#47564;&#46308;&#44592; . import cv2 import numpy as np # ì„¸ë¡œ 480 X ê°€ë¡œ 640, 3 Channel (RGB) ì— í•´ë‹¹í•˜ëŠ” ìŠ¤ì¼€ì¹˜ë¶ ë§Œë“¤ê¸° img = np.zeros((480, 640, 3), dtype = np.uint8) # img[:] = (255, 255, 255) # ì „ì²´ ê³µê°„ì„ í°ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸° (B,G,R) # print(img) cv2.imshow(&#39;img&#39;, img) cv2.waitKey(0) cv2.destroyAllWindows() .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/04/26/opencv.html",
            "relUrl": "/python/2022/04/26/opencv.html",
            "date": " â€¢ Apr 26, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "(1ì£¼ì°¨ ML2) 4ì›” 26ì¼",
            "content": "import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns . import matplotlib.pyplot as plt ## íŒŒì´ì¬ ë‚´ì—ì„œ ê·¸ë˜í”„ ì¶œë ¥ì‹œ ë””í…Œì¼í•œ ì˜µì…˜ import matplotlib as mpl ## í•œê¸€í°íŠ¸ ì„¤ì •, ê¸€ì”¨ì²´ íë¦¿í•œ ê²ƒì„ ì„ ëª…í•˜ê²Œ (ì „ì²´ì ì¸ í° í‹€ì˜ ì˜µì…˜) . mpl.rc(&#39;font&#39;, family=&#39;Malgun Gothic&#39;) ## ë§‘ì€ ê³ ë”• . 1. Data . ìœ„ìŠ¤ì½˜ì‹  ìœ ë°©ì•” ë°ì´í„°(Wisconsin Breast Cancer data)ë¥¼ ë¶„ì„í•´ë³´ì. . ë¶„ì„ì˜ ëª©ì ì€ 30ê°œì˜ ì„¤ëª…ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ ì§„ë‹¨ê°’ì´ ì•…ì„±ì¸ì§€ ì–‘ì„±ì¸ì§€ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. . 1.1 Data Load . from sklearn.datasets import load_breast_cancer . cancer = load_breast_cancer() . cancer[&quot;feature_names&quot;] . array([&#39;mean radius&#39;, &#39;mean texture&#39;, &#39;mean perimeter&#39;, &#39;mean area&#39;, &#39;mean smoothness&#39;, &#39;mean compactness&#39;, &#39;mean concavity&#39;, &#39;mean concave points&#39;, &#39;mean symmetry&#39;, &#39;mean fractal dimension&#39;, &#39;radius error&#39;, &#39;texture error&#39;, &#39;perimeter error&#39;, &#39;area error&#39;, &#39;smoothness error&#39;, &#39;compactness error&#39;, &#39;concavity error&#39;, &#39;concave points error&#39;, &#39;symmetry error&#39;, &#39;fractal dimension error&#39;, &#39;worst radius&#39;, &#39;worst texture&#39;, &#39;worst perimeter&#39;, &#39;worst area&#39;, &#39;worst smoothness&#39;, &#39;worst compactness&#39;, &#39;worst concavity&#39;, &#39;worst concave points&#39;, &#39;worst symmetry&#39;, &#39;worst fractal dimension&#39;], dtype=&#39;&lt;U23&#39;) . Variable name Description . radius | ë°˜ì§€ë¦„ | . texture | ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ê°’ì˜ í‘œì¤€í¸ì°¨ | . perimeter | ë‘˜ë ˆ | . area | ë©´ì  | . smoothness | ë°˜ì§€ë¦„ì˜ êµ­ì†Œì  ë³€í™”ì •ë„(local variation) | . compactness | $ frac{ text{perimeter}^2}{area}-1.0$ | . concavity | ì˜¤ëª©í•œ ì •ë„(severity of concave portions of the contour) | . concave_points | ì˜¤ëª©í•œ ì ë“¤ì˜ ê°œìˆ˜(number of concave portions of contour) | . symmetry | ëŒ€ì¹­ë„ | . fractal dimension | í”„ë™íƒˆ ì°¨ì›($ text{&quot;coastline approximation&quot;} - 1$) | . cancer[&quot;target_names&quot;] . array([&#39;malignant&#39;, &#39;benign&#39;], dtype=&#39;&lt;U9&#39;) . malignant : ì•…ì„± ($0$) | benign : ì–‘ì„± ($1$) | . - ë°ì´í„°ì™€ ì •ë‹µì„ í™•ì¸í•´ë³´ì. . data, target = cancer[&quot;data&quot;], cancer[&quot;target&quot;] . data . array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01, 1.189e-01], [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01, 8.902e-02], [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01, 8.758e-02], ..., [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01, 7.820e-02], [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01, 1.240e-01], [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01, 7.039e-02]]) . target . array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]) . 1.2 EDA . df = pd.DataFrame(data, columns=cancer[&quot;feature_names&quot;]) df.describe() . mean radius mean texture mean perimeter mean area mean smoothness mean compactness mean concavity mean concave points mean symmetry mean fractal dimension ... worst radius worst texture worst perimeter worst area worst smoothness worst compactness worst concavity worst concave points worst symmetry worst fractal dimension . count 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | ... | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | . mean 14.127292 | 19.289649 | 91.969033 | 654.889104 | 0.096360 | 0.104341 | 0.088799 | 0.048919 | 0.181162 | 0.062798 | ... | 16.269190 | 25.677223 | 107.261213 | 880.583128 | 0.132369 | 0.254265 | 0.272188 | 0.114606 | 0.290076 | 0.083946 | . std 3.524049 | 4.301036 | 24.298981 | 351.914129 | 0.014064 | 0.052813 | 0.079720 | 0.038803 | 0.027414 | 0.007060 | ... | 4.833242 | 6.146258 | 33.602542 | 569.356993 | 0.022832 | 0.157336 | 0.208624 | 0.065732 | 0.061867 | 0.018061 | . min 6.981000 | 9.710000 | 43.790000 | 143.500000 | 0.052630 | 0.019380 | 0.000000 | 0.000000 | 0.106000 | 0.049960 | ... | 7.930000 | 12.020000 | 50.410000 | 185.200000 | 0.071170 | 0.027290 | 0.000000 | 0.000000 | 0.156500 | 0.055040 | . 25% 11.700000 | 16.170000 | 75.170000 | 420.300000 | 0.086370 | 0.064920 | 0.029560 | 0.020310 | 0.161900 | 0.057700 | ... | 13.010000 | 21.080000 | 84.110000 | 515.300000 | 0.116600 | 0.147200 | 0.114500 | 0.064930 | 0.250400 | 0.071460 | . 50% 13.370000 | 18.840000 | 86.240000 | 551.100000 | 0.095870 | 0.092630 | 0.061540 | 0.033500 | 0.179200 | 0.061540 | ... | 14.970000 | 25.410000 | 97.660000 | 686.500000 | 0.131300 | 0.211900 | 0.226700 | 0.099930 | 0.282200 | 0.080040 | . 75% 15.780000 | 21.800000 | 104.100000 | 782.700000 | 0.105300 | 0.130400 | 0.130700 | 0.074000 | 0.195700 | 0.066120 | ... | 18.790000 | 29.720000 | 125.400000 | 1084.000000 | 0.146000 | 0.339100 | 0.382900 | 0.161400 | 0.317900 | 0.092080 | . max 28.110000 | 39.280000 | 188.500000 | 2501.000000 | 0.163400 | 0.345400 | 0.426800 | 0.201200 | 0.304000 | 0.097440 | ... | 36.040000 | 49.540000 | 251.200000 | 4254.000000 | 0.222600 | 1.058000 | 1.252000 | 0.291000 | 0.663800 | 0.207500 | . 8 rows Ã— 30 columns . cancer[&quot;feature_names&quot;] . array([&#39;mean radius&#39;, &#39;mean texture&#39;, &#39;mean perimeter&#39;, &#39;mean area&#39;, &#39;mean smoothness&#39;, &#39;mean compactness&#39;, &#39;mean concavity&#39;, &#39;mean concave points&#39;, &#39;mean symmetry&#39;, &#39;mean fractal dimension&#39;, &#39;radius error&#39;, &#39;texture error&#39;, &#39;perimeter error&#39;, &#39;area error&#39;, &#39;smoothness error&#39;, &#39;compactness error&#39;, &#39;concavity error&#39;, &#39;concave points error&#39;, &#39;symmetry error&#39;, &#39;fractal dimension error&#39;, &#39;worst radius&#39;, &#39;worst texture&#39;, &#39;worst perimeter&#39;, &#39;worst area&#39;, &#39;worst smoothness&#39;, &#39;worst compactness&#39;, &#39;worst concavity&#39;, &#39;worst concave points&#39;, &#39;worst symmetry&#39;, &#39;worst fractal dimension&#39;], dtype=&#39;&lt;U23&#39;) . ì–‘ì„±ê³¼ ì•…ì„±ì˜ ë¹„ìœ¨ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. . pd.Series(cancer[&quot;target&quot;]).value_counts() . 1 357 0 212 dtype: int64 . ì¢…ì–‘ì§„ë‹¨ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” class ë³€ìˆ˜ì˜ ë„ìˆ˜ë¶„í¬ë¡œë¶€í„° 357 ëª…ì˜ ê´€ì¸¡ì¹˜ê°€ ì–‘ì„±(benign, class=0)ì— í•´ë‹¹í•˜ê³ , ì´ë³´ë‹¤ ì ì€ 212ëª…ì˜ ê´€ì¸¡ì¹˜ê°€ ì•…ì„±(malign, class=1)ì— í•´ë‹¹í•¨ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. . sns.countplot(x=target) plt.title(&quot;ì¢…ì–‘ì§„ë‹¨ classë³„ ë„ìˆ˜ë¶„í¬&quot;) plt.xlabel(&quot;class&quot;) plt.ylim([0, 450]) plt.text(-0.1, 220, &quot;ì•…ì„±&quot;) plt.text(.9, 370, &quot;ì–‘ì„±&quot;) plt.show() . sns.boxplot(x=target, y=df[&quot;mean concave points&quot;]) plt.xlabel(&quot;class&quot;) . Text(0.5, 0, &#39;class&#39;) . ì•…ì„± ì¢…ì–‘ì„¸í¬ì—ì„œ mean_concave_points ê°’ì´ í›¨ì”¬ ë†’ì€ í¸ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. | . sns.boxplot(x=target, y=df[&quot;mean radius&quot;]) . &lt;AxesSubplot:ylabel=&#39;mean radius&#39;&gt; . ì•…ì„± ì¢…ì–‘ì„¸í¬ì—ì„œ mean_radius ê°’ì´ í›¨ì”¬ ë†’ì€ í¸ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. | . plt.scatter(x=df[&quot;mean concave points&quot;], y=df[&quot;mean radius&quot;], alpha=.5) plt.xlabel(&quot;mean_concave_points&quot;) plt.ylabel(&quot;mean_radius&quot;) . Text(0, 0.5, &#39;mean_radius&#39;) . ìœ„ì˜ ê·¸ë¦¼ì€ mean_concave_pointsì™€ mean_radius ë³€ìˆ˜ ì‚¬ì´ì˜ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. | . 1.3 Data Split . ë°ì´í„°ë¥¼ $7:3$ì˜ ë¹„ìœ¨ë¡œ train/test setìœ¼ë¡œ ë‚˜ëˆ„ì . from sklearn.model_selection import train_test_split train_data, test_data, train_target, test_target = train_test_split( data, target, train_size= 0.7, random_state=1001, ) . print(&quot;train data ê°œìˆ˜:&quot;, len(train_data)) print(&quot;test data ê°œìˆ˜:&quot;, len(test_data)) . train data ê°œìˆ˜: 398 test data ê°œìˆ˜: 171 . 2. Linear Regression and Categorical Label . Logistic Regressionì„ í•™ìŠµí•˜ê¸°ì— ì•ì„œ Linear Regressionìœ¼ë¡œ í•™ìŠµí•  ê²½ìš° ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ë³´ì. . from sklearn.linear_model import LinearRegression linear_regressor = LinearRegression() . 2.1 &#54617;&#49845; . linear_regressor.fit(train_data, train_target) . LinearRegression() . 2.2 &#50696;&#52769; . train_pred = linear_regressor.predict(train_data) test_pred = linear_regressor.predict(test_data) . ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ë©´ $0 sim 1$ ì‚¬ì´ë¥¼ ë²—ì–´ë‚œ ì˜ˆì¸¡ê°’ì´ ë³´ì´ëŠ”ë°..? | ì¼ë‹¨ ë„˜ì–´ê°€ì.. | . 2.3 &#49884;&#44033;&#54868; . fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5)) preds = [ (&quot;Train&quot;, train_data, train_pred), (&quot;Test&quot;, test_data, test_pred), ] for idx, (name, d, pred) in enumerate(preds): ax = axes[idx] ax.scatter(x=d[:,0], y=pred) ax.axhline(0, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.axhline(1, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.set_xlabel(&#39;mean_radius&#39;) ax.set_ylabel(&#39;predict&#39;) ax.set_title(f&quot;{name} Data&quot;) plt.show() . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . 2.4 &#54217;&#44032;&#54616;&#44592; . Linear Regressionì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ì„œëŠ” ìš°ì„  ì˜ˆì¸¡ê°’ì„ 0ê³¼ 1ë¡œ ë³€í™˜ì‹œì¼œì¤˜ì•¼ í•©ë‹ˆë‹¤. . Youden&#39;s Indexë¥¼ ì´ìš©í•´ Best Thresholdë¥¼ ì°¾ì€ í›„, 0ê³¼ 1ë¡œ ë³€í™”ì‹œí‚¨ í›„ ì •í™•ë„ë¥¼ ë¹„êµí•´ë³´ì. . ($ star$)Youden&#39;s J statistic . ì°¸ê³ ë§í¬: https://en.wikipedia.org/wiki/Youden%27s_J_statistic . $$ J = text{sensitivity} + text{specificity} - 1$$ . $$ J = frac{ text{True positives}}{ text{True positives}+ text{False negatives}} + frac{ text{True negatives}}{ text{True negatives}+ text{False positives}} - 1$$ . . from sklearn.metrics import auc, roc_curve fpr, tpr, threshold = roc_curve(train_target, train_pred) auroc = auc(fpr, tpr) . fpr . array([0. , 0. , 0. , 0.00699301, 0.00699301, 0.01398601, 0.01398601, 0.02097902, 0.02097902, 0.02797203, 0.02797203, 0.04195804, 0.04195804, 0.06993007, 0.06993007, 0.12587413, 0.12587413, 1. ]) . tpr . array([0. , 0.00392157, 0.70980392, 0.70980392, 0.90980392, 0.90980392, 0.93333333, 0.93333333, 0.96862745, 0.96862745, 0.98431373, 0.98431373, 0.99215686, 0.99215686, 0.99607843, 0.99607843, 1. , 1. ]) . threshold . array([ 2.35725299, 1.35725299, 0.82521489, 0.82466702, 0.70119883, 0.69924511, 0.67546196, 0.67513605, 0.63707749, 0.63401065, 0.61560836, 0.59241528, 0.58134679, 0.50969629, 0.50796669, 0.43013177, 0.42764525, -0.53936311]) . AUROCë¥¼ ê·¸ë ¤ë³´ì. . plt.plot(fpr, tpr) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) . Text(0, 0.5, &#39;tpr&#39;) . AUROC ê°’ì„ ê³„ì‚°í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. . print(f&quot;AUROC : {auroc: .4f}&quot;) . AUROC : 0.9960 . ì´ì œ Best Thresholdë¥¼ ê³„ì‚°í•´ë³´ì. . np.argmax(tpr - fpr) . 10 . 10ì¸ index ì—ì„œ Best Thresholdë¥¼ ê°–ëŠ”ë‹¤ëŠ” ì˜ë¯¸ | . J = tpr - fpr idx = np.argmax(J) best_thresh = threshold[idx] print(f&quot;Best Threshold is {best_thresh:.4f}&quot;) print(f&quot;Best Threshold&#39;s sensitivity is {tpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s specificity is {1-fpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s J is {J[idx]:.4f}&quot;) . Best Threshold is 0.6156 Best Threshold&#39;s sensitivity is 0.9843 Best Threshold&#39;s specificity is 0.9720 Best Threshold&#39;s J is 0.9563 . Best ThresholdëŠ” AUROC ê·¸ë˜í”„ì—ì„œ ì§ì„ ì´ ê°€ì¥ ê¸´ ê³³ì…ë‹ˆë‹¤. . plt.plot(fpr, tpr) plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10)) plt.plot((fpr[idx], fpr[idx]), (fpr[idx], tpr[idx]), color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) plt.show() . ì˜ˆì¸¡ê°’ì—ì„œì˜ Best threshold ì˜ ìœ„ì¹˜ë¥¼ ê·¸ë ¤ë³´ì . fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5)) preds = [ (&quot;Train&quot;, train_data, train_pred), (&quot;Test&quot;, test_data, test_pred), ] for idx, (name, d, pred) in enumerate(preds): ax = axes[idx] ax.scatter(x=d[:,0], y=pred) ax.axhline(0, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.axhline(1, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.set_xlabel(&quot;mean_radius&quot;) ax.set_ylabel(&quot;predict&quot;) ax.set_title(f&quot;{name} Data&quot;) ax.axhline(best_thresh, color=&quot;blue&quot;) plt.show() . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . ì´ì œ Thresholdë¡œ ì˜ˆì¸¡ê°’ì„ $0,1$ë¡œ ë³€í™˜ í›„ ì •í™•ë„ë¥¼ ë³´ì . train_pred_label = list(map(int, (train_pred &gt; best_thresh))) test_pred_label = list(map(int, (test_pred &gt; best_thresh))) . from sklearn.metrics import accuracy_score linear_train_accuracy = accuracy_score(train_target, train_pred_label) linear_test_accuracy = accuracy_score(test_target, test_pred_label) . print(f&quot;Train accuracy is : {linear_train_accuracy:.2f}&quot;) print(f&quot;Test accuracy is : {linear_test_accuracy:.2f}&quot;) . Train accuracy is : 0.98 Test accuracy is : 0.96 . 3. Logistic Regression . ì´ë²ˆì—ëŠ” Logistic Regressionì„ ì´ìš©í•˜ì—¬ ì˜ˆì¸¡í•´ ë³´ì. . 3.1 Scaling . Logistic Regressionì€ í•™ìŠµí•˜ê¸°ì— ì•ì„œ í•™ìŠµì‹œí‚¬ ë°ì´í„°ë¥¼ ì •ê·œí™”í•´ì•¼ í•©ë‹ˆë‹¤. . Logistic Regressiondì—ëŠ” expê°€ ìˆëŠ”ë°, expëŠ” ê°’ì´ í´ ê²½ìš° overflowê°€ ì¼ì–´ë‚  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. . from sklearn.preprocessing import StandardScaler scaler = StandardScaler() . ì •ê·œí™”ëŠ” í•­ìƒ train dataë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµí•˜ê³  valid, test ë°ì´í„°ë¥¼ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. . ëª¨ë“  ë°ì´í„°ë¥¼ í•œë²ˆì— í•™ìŠµí•  ê²½ìš° ë³¸ì ì´ ì—†ëŠ” valiation dataì˜ í‰ê· ê³¼ ë¶„ì‚°ì´ ë°˜ì˜ë˜ê³  ì´ëŠ” overfittingì„ ì¼ìœ¼í‚¤ëŠ” ì›ì¸ì´ ë©ë‹ˆë‹¤. . scaler.fit(train_data) . StandardScaler() . í•™ìŠµëœ Scalerë¡œ train/test ë°ì´í„°ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤. . scaled_train_data = scaler.transform(train_data) scaled_test_data = scaler.transform(test_data) . train_data[0] . array([1.953e+01, 1.890e+01, 1.295e+02, 1.217e+03, 1.150e-01, 1.642e-01, 2.197e-01, 1.062e-01, 1.792e-01, 6.552e-02, 1.111e+00, 1.161e+00, 7.237e+00, 1.330e+02, 6.056e-03, 3.203e-02, 5.638e-02, 1.733e-02, 1.884e-02, 4.787e-03, 2.593e+01, 2.624e+01, 1.711e+02, 2.053e+03, 1.495e-01, 4.116e-01, 6.121e-01, 1.980e-01, 2.968e-01, 9.929e-02]) . scaled_train_data[0] . array([ 1.55665013, -0.08374209, 1.56894905, 1.61738288, 1.35230219, 1.15579113, 1.64920637, 1.53999266, -0.05508639, 0.36872483, 2.57200558, -0.10081561, 2.13099893, 1.96746196, -0.29563095, 0.3786633 , 0.72463661, 0.88545529, -0.19263957, 0.37716933, 2.07668666, 0.10014731, 1.96594854, 2.15156304, 0.75699447, 1.00247978, 1.60389716, 1.3188727 , 0.1245053 , 0.85035853]) . 3.2 &#54617;&#49845; . ì´ì œ í‘œì¤€í™”ëœ ë°ì´í„°ë¡œ Logistic Regressionì„ í•™ìŠµí•´ ë³´ì. . from sklearn.linear_model import LogisticRegression logit_regressor = LogisticRegression() . logit_regressor.fit(scaled_train_data, train_target) . LogisticRegression() . 3.3 &#50696;&#52769; . Classificationì„ í•˜ëŠ” ëª¨ë¸ì˜ ê²½ìš° ì˜ˆì¸¡ì„ í•˜ëŠ” ë°©ë²•ì€ ë‘ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. . predict . | predict_proba . | predictëŠ” í•´ë‹¹ ë°ì´í„°ê°€ ì–´ë–¤ classë¡œ ë¶„ë¥˜í• ì§€ ë°”ë¡œ ì•Œë ¤ì¤ë‹ˆë‹¤. . ë°˜ë©´, predict_probaëŠ” ê° classì— ì†í•  í™•ë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. . train_pred = logit_regressor.predict(scaled_train_data) test_pred = logit_regressor.predict(scaled_test_data) . train_pred[:10] . array([0, 1, 0, 0, 1, 0, 1, 0, 0, 1]) . train_pred_logit = logit_regressor.predict_proba(scaled_train_data) test_pred_logit = logit_regressor.predict_proba(scaled_test_data) . train_pred_logit[:10] . array([[9.99999984e-01, 1.62885674e-08], [1.30750892e-03, 9.98692491e-01], [9.93452400e-01, 6.54760017e-03], [6.39996411e-01, 3.60003589e-01], [5.71378493e-05, 9.99942862e-01], [9.96253495e-01, 3.74650484e-03], [5.02851011e-04, 9.99497149e-01], [9.95986445e-01, 4.01355535e-03], [9.99998296e-01, 1.70356931e-06], [7.13730423e-04, 9.99286270e-01]]) . ê° classì— ì†í•  í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. . í˜„ì¬ ë°ì´í„°ì˜ ê²½ìš° ì•…ì„±ê³¼ ì–‘ì„± 2ê°œì˜ í´ë˜ìŠ¤ê°€ ìˆê¸° ë•Œë¬¸ì— 2ê°œì˜ í™•ë¥ ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. . ë§Œì•½ ì²« ë²ˆì§¸ classì— ì†í•  í™•ë¥ ì´ í¬ë‹¤ë©´ ë°ì´í„°ëŠ” 0ë²ˆ í´ë˜ìŠ¤ì— ì†í•˜ê²Œ ë˜ëŠ” ê²ƒ..! . train_pred_logit[0] . array([9.99999984e-01, 1.62885674e-08]) . 3.4 &#54217;&#44032; . ë°ì´í„°ì˜ AUROCë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” 1ì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜ë  í™•ë¥  í•˜ë‚˜ë§Œ í•„ìš”í•©ë‹ˆë‹¤. ë°˜ë©´ ìš°ë¦¬ê°€ ê°–ê³  ìˆëŠ” ì˜ˆì¸¡ê°’ì€ 0ê³¼ 1ë¡œ ë¶„ë¥˜ë  í™•ë¥ ì„ ëª¨ë‘ í‘œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ 1ì— ì†í•  í™•ë¥ ë§Œ ë‚¨ê¸°ê² ìŠµë‹ˆë‹¤. . train_pred_logit = train_pred_logit[:, 1] test_pred_logit = test_pred_logit[:, 1] . train_pred_logit[0] . 1.628856736535896e-08 . from sklearn.metrics import auc, roc_curve fpr, tpr, threshold = roc_curve(train_target, train_pred_logit) auroc = auc(fpr, tpr) . plt.plot(fpr, tpr) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) . Text(0, 0.5, &#39;tpr&#39;) . print(f&quot;AUROC : {auroc:.4f}&quot;) . AUROC : 0.9971 . J = tpr - fpr idx = np.argmax(J) best_thresh = threshold[idx] print(f&quot;Best Threshold is {best_thresh:.4f}&quot;) print(f&quot;Best Threshold&#39;s sensitivity is {tpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s specificity is {1-fpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s J is {J[idx]:.4f}&quot;) . Best Threshold is 0.5692 Best Threshold&#39;s sensitivity is 0.9961 Best Threshold&#39;s specificity is 0.9790 Best Threshold&#39;s J is 0.9751 . plt.plot(fpr, tpr) plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10)) plt.plot((fpr[idx],fpr[idx]), (fpr[idx], tpr[idx]), color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) . Text(0, 0.5, &#39;tpr&#39;) . plt.scatter(x=scaled_train_data[:,0], y=train_pred_logit) plt.axhline(best_thresh, color=&quot;blue&quot;) plt.axhline(0, color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.axhline(1, color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.xlabel(&quot;mean radius&quot;) plt.ylabel(&quot;Probability&quot;) plt.show() . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . ì´ì œ Thresholdë¡œ ì˜ˆì¸¡ê°’ì„ 0,1ë¡œ ë³€í™˜ í›„ ì •í™•ë„ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤. . train_pred_label = list(map(int, (train_pred_logit &gt; best_thresh))) test_pred_label = list(map(int, (test_pred_logit &gt; best_thresh))) . proba_train_accuracy = accuracy_score(train_target, train_pred_label) proba_test_accuracy = accuracy_score(test_target, test_pred_label) . print(f&quot;Train accuracy is : {proba_train_accuracy:.2f}&quot;) print(f&quot;Test accuracy is : {proba_test_accuracy:.2f}&quot;) . Train accuracy is : 0.99 Test accuracy is : 0.98 . ì´ë²ˆì—ëŠ” predictì˜ ê²°ê³¼ê°’ìœ¼ë¡œ ì •í™•ë„ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤. . train_accuracy = accuracy_score(train_target, train_pred) test_accuracy = accuracy_score(test_target, test_pred) . print(f&quot;Train accuracy is : {train_accuracy:.2f}&quot;) print(f&quot;Test accuracy is : {test_accuracy:.2f}&quot;) . Train accuracy is : 0.99 Test accuracy is : 0.97 . predict_probaì˜ best_thresholdë¡œ ê³„ì‚°í•œ ê²°ê³¼ì™€ predictë¡œ ê³„ì‚°í•œ ê²°ê³¼ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‘ 0ê³¼ 1ë¡œ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ì„œ (0.49, 0.51)ì˜ í™•ë¥ ì´ ìˆì„ ë•Œ predictì˜ ê²½ìš° class 1ì˜ í™•ë¥ ì— ì†í•  í™•ë¥ ì´ í¬ê¸° ë•Œë¬¸ì— 1ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ best_thresholdê°€ 0.52ë¼ë©´ predict_probaì˜ ê²½ìš° classë¥¼ 0ìœ¼ë¡œ ë¶„ë¥˜í•˜ê²Œ ë©ë‹ˆë‹¤ . 4. &#47560;&#47924;&#47532; . ì„¸ê°œì˜ ëª¨ë¸ë“¤ì˜ ì •í™•ë„ë¥¼ ë¹„êµí•´ ë³´ê² ìŠµë‹ˆë‹¤. . print(f&quot;Linear Regression Test Accuracy: {linear_test_accuracy:.2f}&quot;) print(f&quot;Logistic Regression predict_proba Test Accuracy: {proba_test_accuracy:.2f}&quot;) print(f&quot;Logistic Regression predict Test Accuracy: {test_accuracy:.2f}&quot;) . Linear Regression Test Accuracy: 0.96 Logistic Regression predict_proba Test Accuracy: 0.98 Logistic Regression predict Test Accuracy: 0.97 .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/04/26/ML.html",
            "relUrl": "/python/2022/04/26/ML.html",
            "date": " â€¢ Apr 26, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "(3ì£¼ì°¨ ML) 3ì›” 24ì¼",
            "content": "&#45336;&#54028;&#51060;&#47196; &#45936;&#51060;&#53552; &#51456;&#48708; . import numpy as np . fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] . fish_data = np.column_stack((fish_length, fish_weight)) . fish_data[:5] . array([[ 25.4, 242. ], [ 26.3, 290. ], [ 26.5, 340. ], [ 29. , 363. ], [ 29. , 430. ]]) . fish_target = np.concatenate((np.ones(35), np.zeros(14))) . fish_target . array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) . &#49324;&#51060;&#53431;&#47088;&#51004;&#47196; &#45936;&#51060;&#53552; &#45208;&#45572;&#44592; . from sklearn.model_selection import train_test_split ## model selection ëª¨ë“ˆ ì•„ë˜ì— train_test_split í•¨ìˆ˜ . train_input, test_input, train_target, test_target = train_test_split( fish_data, fish_target, stratify = fish_target, random_state = 42) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/24/ML.html",
            "relUrl": "/python/2022/03/24/ML.html",
            "date": " â€¢ Mar 24, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "(3ì£¼ì°¨ DV) 3ì›” 23ì¼",
            "content": "- How to upload your CSV file online for data analysis . https://evidencen.com/how-to-upload-your-csv-file-online/ . &#45800;&#51068;&#48320;&#49688; . import seaborn as sns import pandas as pd . df1 = pd.read_csv(&#39;https://raw.githubusercontent.com/pinkocto/BP2022/master/_notebooks/Data03.csv&#39;) df1.head() . id type_of_contract type_of_contract2 channel datetime Term payment_type product amount state overdue_count overdue credit rating bank cancellation age Mileage . 0 66758234 | ë Œíƒˆ | Normal | ì„œë¹„ìŠ¤ ë°©ë¬¸ | 2019-10-20 | 60 | CMS | K1 | 96900 | ê³„ì•½í™•ì • | 0 | ì—†ìŒ | 9.0 | ìƒˆë§ˆì„ê¸ˆê³  | ì •ìƒ | 43.0 | 1862.0 | . 1 66755948 | ë Œíƒˆ | Extension_Rental | ì„œë¹„ìŠ¤ ë°©ë¬¸ | 2019-10-20 | 60 | ì¹´ë“œì´ì²´ | K1 | 102900 | ê³„ì•½í™•ì • | 0 | ì—†ìŒ | 2.0 | í˜„ëŒ€ì¹´ë“œ | ì •ìƒ | 62.0 | 2532.0 | . 2 66756657 | ë Œíƒˆ | Normal | í™ˆì‡¼í•‘/ë°©ì†¡ | 2019-10-20 | 60 | CMS | K1 | 96900 | ê³„ì•½í™•ì • | 0 | ì—†ìŒ | 8.0 | ìš°ë¦¬ì€í–‰ | ì •ìƒ | 60.0 | 2363.0 | . 3 66423450 | ë©¤ë²„ì‹­ | TAS | ë Œíƒˆì¬ê³„ì•½ | 2019-10-20 | 12 | CMS | K1 | 66900 | ê³„ì•½í™•ì • | 0 | ì—†ìŒ | 5.0 | ë†í˜‘ì€í–‰ | ì •ìƒ | 60.0 | 2449.0 | . 4 66423204 | ë©¤ë²„ì‹­ | TAS | ë Œíƒˆì¬ê³„ì•½ | 2019-10-20 | 12 | CMS | K1 | 66900 | í•´ì•½í™•ì • | 12 | ìˆìŒ | 8.0 | ë†í˜‘ì€í–‰ | í•´ì•½ | 51.0 | 1942.0 | . 1 &#48276;&#51452;&#54805; &#48320;&#49688; . df1[&#39;type_of_contract&#39;].value_counts() . ë Œíƒˆ 46481 ë©¤ë²„ì‹­ 4819 Name: type_of_contract, dtype: int64 . sns.countplot(data=df1, x=&#39;type_of_contract&#39;) . &lt;AxesSubplot:xlabel=&#39;type_of_contract&#39;, ylabel=&#39;count&#39;&gt; . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 47116 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 53448 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 47716 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 48260 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 49901 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 47116 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 53448 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 47716 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 48260 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 49901 missing from current font. font.set_text(s, 0, flags=flags) . í•œê¸€ ê¸€ì”¨ì²´ ì„¤ì •ì´ í•„ìš”í•´ ë³´ì¸ë‹¤. | . df1[&#39;product&#39;].value_counts() . K1 39134 K2 8995 K3 2082 K5 645 K4 327 K6 120 Name: product, dtype: int64 . sns.countplot(data=df1, x=&#39;product&#39;, hue=&#39;type_of_contract2&#39;) . &lt;AxesSubplot:xlabel=&#39;product&#39;, ylabel=&#39;count&#39;&gt; . ë²”ë¡€ì™€ ê·¸ë˜í”„ê°€ ê²¹ì³ë‚˜ì˜¤ëŠ” ë¬¸ì œê°€ ë°œìƒ $ to$ matplotlib ì˜µì…˜ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥ | . &#54620;&#44544; &#44648;&#51664; &#54644;&#44208; . import matplotlib.pyplot as plt ## íŒŒì´ì¬ ë‚´ì—ì„œ ê·¸ë˜í”„ ì¶œë ¥ì‹œ ë””í…Œì¼í•œ ì˜µì…˜ import matplotlib as mpl ## í•œê¸€í°íŠ¸ ì„¤ì •, ê¸€ì”¨ì²´ íë¦¿í•œ ê²ƒì„ ì„ ëª…í•˜ê²Œ (ì „ì²´ì ì¸ í° í‹€ì˜ ì˜µì…˜) . mpl.rc(&#39;font&#39;, family=&#39;Malgun Gothic&#39;) ## ë§‘ì€ ê³ ë”• . Cë“œë¼ì´ë¸Œ $ to$ Windows $ to$ Fonts $ to$ Malgun Gothic | . sns.countplot(data=df1, x=&#39;type_of_contract&#39;) . &lt;AxesSubplot:xlabel=&#39;type_of_contract&#39;, ylabel=&#39;count&#39;&gt; . &#45936;&#51060;&#53552; &#44536;&#47000;&#54532; &#44217;&#52840;&#47928;&#51228; . - ê·¸ë˜í”„ ì‚¬ì´ì¦ˆ í‚¤ìš°ê¸° . plt.figure(figsize=[10,5]) ## Size ì¡°ì • sns.countplot(data=df1, x=&#39;product&#39;, hue=&#39;type_of_contract2&#39;) plt.legend(loc=&#39;right&#39;) ## ë²”ë¡€ ì˜¤ë¥¸ìª½ì— ìœ„ì¹˜ plt.savefig(&#39;img1.png&#39;) ## ì´ë¯¸ì§€ íŒŒì¼ í˜•íƒœë¡œ ì €ì¥ # plt.savefig(&#39;img1.pdf&#39;) . 2 &#50672;&#49549;&#54805; &#48320;&#49688; . sns.histplot(data=df1, x=&#39;age&#39;) . &lt;AxesSubplot:xlabel=&#39;age&#39;, ylabel=&#39;Count&#39;&gt; . - kde = True ì˜µì…˜ ì¶”ê°€ . plt.title(&#39;ê³„ì•½ ìœ í˜• ë³„. ê³ ê° ì—°ë ¹ ë¶„í¬&#39;) sns.histplot(data=df1, x=&#39;age&#39;, kde = True, hue=&#39;type_of_contract&#39;) ## í™•ë¥ ë¶„í¬ì„  (kde=True) plt.show() . 3 &#44536; &#50808; &#52628;&#44032; &#50741;&#49496;&#46308; . - ê·¸ë˜í”„ ì¶•ì— ìˆëŠ” ê¸€ì”¨ ê²¹ì¹¨ . sns.countplot(data=df1, x=&#39;bank&#39;) . &lt;AxesSubplot:xlabel=&#39;bank&#39;, ylabel=&#39;count&#39;&gt; . plt.figure(figsize=[5, 10]) sns.countplot(data=df1, y=&#39;bank&#39;) . &lt;AxesSubplot:xlabel=&#39;count&#39;, ylabel=&#39;bank&#39;&gt; . bank columnì— ë°ì´í„°ê°€ êµ‰ì¥íˆ ë§ë‹¤. ë¹ˆë„ìˆ˜ê°€ ë†’ì€ ìƒìœ„ 10ê°œ ë°ì´í„°ë§Œ ë½‘ì•„ì„œ ì‹œê°í™”ë¥¼ í•´ë³´ì. | . - ë¹ˆë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ . df1[&#39;bank&#39;].value_counts() ## ë¹ˆë„ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì¶œë ¥ . êµ­ë¯¼ì€í–‰ 9901 ë¡¯ë°ì¹´ë“œ 9518 ë†í˜‘ì€í–‰ 6278 ì‹ í•œì€í–‰ 3522 ìš°ë¦¬ì€í–‰ 3386 ê¸°ì—…ì€í–‰ 1963 ì‹ í•œì¹´ë“œ 1533 í•˜ë‚˜ì€í–‰ 1446 êµ­ë¯¼ì¹´ë“œ 1311 BCì¹´ë“œ 1264 ìƒˆë§ˆì„ê¸ˆê³  964 ë¶€ì‚°ì€í–‰ 888 ì‚¼ì„±ì¹´ë“œ 884 í˜„ëŒ€ì¹´ë“œ 876 ëŒ€êµ¬ì€í–‰ 746 ìš°ì²´êµ­ 717 ì™¸í™˜ì€í–‰ 586 ì™¸í™˜ì¹´ë“œ 530 ê²½ë‚¨ì€í–‰ 442 SCì œì¼ì€í–‰ 439 ê´‘ì£¼ì€í–‰ 347 ì‹ í˜‘ì¤‘ì•™íšŒ 341 ì „ë¶ì€í–‰ 195 ì”¨í‹°ì€í–‰ 162 ìˆ˜í˜‘ì¤‘ì•™íšŒ 160 ì œì£¼ì€í–‰ 40 ìœ ì•ˆíƒ€ì¦ê¶Œ 27 ì‚°ì—…ì€í–‰ 23 í˜„ëŒ€ì¦ê¶Œ 11 ì‚¼ì„±ì¦ê¶Œ 7 í•˜ë‚˜SK 6 ë¯¸ë˜ì—ì…‹ì¦ê¶Œ 5 NHë†í˜‘ì¹´ë“œ 4 í•œêµ­íˆ¬ìì¦ê¶Œ 4 ì‹ í•œê¸ˆìœµíˆ¬ì 4 ìš°ë¦¬ì¹´ë“œ 3 ëŒ€ìš°ì¦ê¶Œ 2 í•˜ì´íˆ¬ìì¦ê¶Œ 1 ë©”ë¦¬ì¸ ì¢…í•©ê¸ˆìœµì¦ê¶Œ 1 ìˆ˜í˜‘ì¹´ë“œ 1 ìƒí˜¸ì €ì¶•ì€í–‰ 1 SKì¦ê¶Œ 1 í•˜ë‚˜ëŒ€íˆ¬ì¦ê¶Œ 1 ì‚°ë¦¼ì¡°í•©ì¤‘ì•™íšŒ 1 ëŒ€ì‹ ì¦ê¶Œ 1 ì”¨í‹°ì¹´ë“œ 1 Name: bank, dtype: int64 . sns.countplot(data=df1, x=&#39;bank&#39;, order=[&#39;êµ­ë¯¼ì€í–‰&#39;, &#39;ë¡¯ë°ì¹´ë“œ&#39;, &#39;ë†í˜‘ì€í–‰&#39;, &#39;ì‹ í•œì€í–‰&#39;]) . &lt;AxesSubplot:xlabel=&#39;bank&#39;, ylabel=&#39;count&#39;&gt; . - ë¹ˆë„ ìˆœ ì •ë ¬ . order_list = df1[&#39;bank&#39;].value_counts().index.tolist() ## ë¹ˆë„ ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì¸ë±ìŠ¤ ì¶œë ¥ . sns.countplot(data=df1, x=&#39;bank&#39;, order=order_list) . &lt;AxesSubplot:xlabel=&#39;bank&#39;, ylabel=&#39;count&#39;&gt; . - ìƒìœ„ 10ê°œë§Œ ì‹œê°í™” . plt.figure(figsize=[10,5]) ## figure size ì¡°ì •. sns.countplot(data=df1, x=&#39;bank&#39;, order=order_list[0:10]) plt.savefig(&#39;img10.pdf&#39;) ## ì´ë¯¸ì§€ pdf í˜•íƒœë¡œ ì €ì¥ . - ì´ë¯¸ì§€ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ . import os print(os.getcwd()) # print(os.listdir(os.getcwd())) . C: Users 82103 Desktop dino BP2022 _notebooks . os.path.exists(&#39;C:/Users/82103/Desktop/dino/BP2022/_notebooks/img10.pdf&#39;) . True . ë”°ë¼ì„œ ìœ„ì˜ ê²½ë¡œ(í˜„ì¬ ì‘ì—… í´ë”)ì— img10.pdf ì´ë¯¸ì§€ íŒŒì¼ì´ ì €ì¥ë˜ì–´ ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/23/DV.html",
            "relUrl": "/python/2022/03/23/DV.html",
            "date": " â€¢ Mar 23, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "(3ì£¼ì°¨ ML) 3ì›” 17ì¼",
            "content": "training set / test set . fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] . len(fish_length), len(fish_weight) . (49, 49) . fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)] fish_target = [1]*35 + [0]*14 . fish_data[0] . [25.4, 242.0] . KNN (&#52395;&#48264;&#51704; &#49884;&#46020;) . from sklearn.neighbors import KNeighborsClassifier kn = KNeighborsClassifier() . print(fish_data[4]) . [29.0, 430.0] . print(fish_data[0:5]) . [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0]] . print(fish_data[:5]) . [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0]] . print(fish_data[44:]) . [[12.2, 12.2], [12.4, 13.4], [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]] . train_input = fish_data[:35] ## index 0~34 train_target = fish_target[:35] test_input = fish_data[35:] ## index 35~48 test_target = fish_target[35:] . len(train_input), len(train_target) . (35, 35) . len(test_input), len(test_target) . (14, 14) . kn = kn.fit(train_input, train_target) kn.score(test_input, test_target) . 0.0 . ì •í™•ë„ê°€ 0% ì´ë‹¤? | test inputì— ìˆëŠ” ìƒ˜í”Œ 14ê°œë¥¼ ëª¨ë‘ ëª» ë§ì·„ë‹¤ëŠ” ê²ƒì´ë‹¤. | WHY ? $ Rightarrow$ ìƒ˜í”Œë§ í¸í–¥ | . &#49368;&#54540;&#47553; &#54200;&#54693; . ì™œê·¸ëŸ°ê°€ ë´¤ë”ë‹ˆ ì²˜ìŒì— fish_lengthì™€ fish_weightë¥¼ ë„ë¯¸ 35ê°œ, ë¹™ì–´ 14ê°œë¥¼ ì­‰ ëŠ˜ì–´ë†“ê³  ë‘ ë¦¬ìŠ¤íŠ¸ë¥¼ í•©ì³¤ë‹¤. | ë‘ ë¦¬ìŠ¤íŠ¸ë¥¼ í•©ì¹œ fish_dataì—ì„œ ì•ì— 35ê°œë¥¼ í›ˆë ¨ ë’¤ì— 14ê°œë¥¼ test setìœ¼ë¡œ ì˜ëë‹¤. | ì¦‰, í›ˆë ¨ì„¸íŠ¸ì—ëŠ” ë¹™ì–´ê°€ í•˜ë‚˜ë„ ì—†ê³ , í…ŒìŠ¤íŠ¸ì…‹ì—ëŠ” ë„ë¯¸ê°€ í•˜ë‚˜ë„ ì—†ê²Œ ëœë‹¤. $ Rightarrow$ ë¯¸ì ë¶„ ê³µë¶€í•˜ê³  í™•í†µì‹œí—˜ ë³¸ ê²©.. | . | train setê³¼ test setì„ ë‚˜ëˆŒ ë•Œì—ëŠ” ë¹™ì–´ì™€ ë„ë¯¸ ë‘ classê°€ ì˜ ì„ì—¬ìˆë„ë¡ ë§Œë“¤ì–´ì•¼ í•œë‹¤. | . Numpy . ì´ì œ Numpyë¥¼ ì´ìš©í•´ì„œ ì˜ ì„ì–´ì„œ train setê³¼ test setìœ¼ë¡œ ë‚˜ëˆ ë³´ì. | NumpyëŠ” íŒŒì´ì¬ì˜ ëŒ€í‘œì ì¸ ë°°ì—´ library | scikit-learnì´ë‚˜ matplotlib librayrë„ ë„˜íŒŒì´ì— í¬ê²Œ ì˜ì¡´í•˜ê³  ìˆê³ , ì…ë ¥ ë°ì´í„°ê°€ Numpyë¡œ ì „ë‹¬ë  ê±°ë¼ê³  ê°€ì •í•˜ê³  ìˆë‹¤. predict method ê²°ê³¼ê°’ì´ array([1])ì´ëŸ° í˜•íƒœë¡œ ì¶œë ¥ë˜ëŠ” ê²ƒë„ ì´ëŸ¬í•œ ì´ìœ .(ì‚¬ì´í‚·ëŸ°ì˜ predict ë©”ì„œë“œì˜ ë°˜í™˜ê°’ì„ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë¦¬í„´) | . | ë”¥ëŸ¬ë‹ TensorFlowë„ Numpyì™€ë„ íƒ€ì´íŠ¸í•œ ê´€ê³„ê°€ ìˆë‹¤. | . . 1ì°¨ì› ë°°ì—´(ë²¡í„°), 2ì°¨ì› ë°°ì—´(í–‰ë ¬), 3ì°¨ì› ë°°ì—´ | . training set / test set (using Numpy) . inputê³¼ targetì´ í•¨ê»˜ ì„ì—¬ì„œ ì´ë™ì„ í•´ì•¼í•œë‹¤. (ì„ì—¬ì•¼ í•œë‹¤) | ì§€ë„í•™ìŠµì—ì„œ ì…ë ¥ê³¼ íƒ€ê²Ÿì´ ìŒì„ ì´ë£¨ê³  ìˆê²Œ ë˜ëŠ”ë° ë”°ë¡œë”°ë¡œ ì„ì—¬ë²„ë¦¬ë©´ ì •ë‹µì„ ì œëŒ€ë¡œ ëª»ì£¼ê²Œ ë˜ì„œ ì—‰í„°ë¦¬ í›ˆë ¨ì´ ë˜ë²„ë¦°ë‹¤. | ì…ë ¥ë°ì´í„° íŠ¹ì„±ê°’ê³¼ íƒ€ê¹‚ê°’ì´ ìŒìœ¼ë¡œ ì˜ ë”°ë¼ì„œ ì„ì´ë„ë¡ ë§Œë“¤ì–´ì•¼ í•˜ëŠ”ê²ƒì´ ì¤‘ìš”!!! indexë¥¼ ì„ì–´ ë¶„ë¦¬í•˜ëŠ” ë°©ë²• | . | . import numpy as np . input_arr = np.array(fish_data) target_arr = np.array(fish_target) . print(input_arr) . [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ] [ 29.7 450. ] [ 29.7 500. ] [ 30. 390. ] [ 30. 450. ] [ 30.7 500. ] [ 31. 475. ] [ 31. 500. ] [ 31.5 500. ] [ 32. 340. ] [ 32. 600. ] [ 32. 600. ] [ 33. 700. ] [ 33. 700. ] [ 33.5 610. ] [ 33.5 650. ] [ 34. 575. ] [ 34. 685. ] [ 34.5 620. ] [ 35. 680. ] [ 35. 700. ] [ 35. 725. ] [ 35. 720. ] [ 36. 714. ] [ 36. 850. ] [ 37. 1000. ] [ 38.5 920. ] [ 38.5 955. ] [ 39.5 925. ] [ 41. 975. ] [ 41. 950. ] [ 9.8 6.7] [ 10.5 7.5] [ 10.6 7. ] [ 11. 9.7] [ 11.2 9.8] [ 11.3 8.7] [ 11.8 10. ] [ 11.8 9.9] [ 12. 9.8] [ 12.2 12.2] [ 12.4 13.4] [ 13. 12.2] [ 14.3 19.7] [ 15. 19.9]] . print(input_arr.shape) . (49, 2) . - 0~48ê¹Œì§€ ì •ìˆ˜ë¡œëœ index ë§Œë“¤ê¸° . index = np.arange(49) index . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]) . - indexë¥¼ ì„ì–´ì¤€ë‹¤. . np.random.seed(42) np.random.shuffle(index) . print(index) . [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] . ì˜ ì„ì˜€ë‹¤... | . input_arr[:5] . array([[ 25.4, 242. ], [ 26.3, 290. ], [ 26.5, 340. ], [ 29. , 363. ], [ 29. , 430. ]]) . print(input_arr[[1,3]]) . [[ 26.3 290. ] [ 29. 363. ]] . - ëœë¤í•˜ê²Œ ì„ì¸ ì¸ë±ìŠ¤ ë°°ì—´ì—ì„œ ì•ë¶€ë¶„ 35ê°œë¥¼ í›ˆë ¨ì…‹ìœ¼ë¡œ ë‘ê³ , ë’·ë¶€ë¶„ 14ê°œë¥¼ í…ŒìŠ¤íŠ¸ ì…‹ìœ¼ë¡œ ë‘”ë‹¤ . print(index) . [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] . train_input = input_arr[index[:35]] train_target = target_arr[index[:35]] . print(input_arr[13], train_input[0]) . [ 32. 340.] [ 32. 340.] . test_input = input_arr[index[35:]] test_target = target_arr[index[35:]] . import matplotlib.pyplot as plt plt.scatter(train_input[:,0], train_input[:,1]) plt.scatter(test_input[:,0], test_input[:,1]) plt.xlabel(&#39;length&#39;) plt.ylabel(&#39;weight&#39;) plt.show() . KNN (&#46160;&#48264;&#51704; &#49884;&#46020;) . kn = kn.fit(train_input, train_target) . kn.score(test_input, test_target) . 1.0 . ì˜ í›ˆë ¨ë˜ì—ˆë‹¤. | . kn.predict(test_input) . array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) . test_target . array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) . Summary . Numpyë¥¼ ì´ìš©í•´ì„œ ë°ì´í„°ë¥¼ ì„ì–´ì„œ ë§Œë“¤ë•Œ, ë°°ì—´ ìì²´ë¥¼ ì„ì§€ ì•Šê³  (íŠ¹ì„±ë°ì´í„°ì™€ íƒ€ê¹ƒí…Œì´í„°ê°€ ìŒì„ ì´ë£¨ì–´ì„œ ì„ì–´ì•¼ í•˜ë¯€ë¡œ) . | ë°°ì—´ì˜ ì¸ë±ìŠ¤ë°°ì—´ì„ ë§Œë“¤ì–´ì„œ ì¸ë±ìŠ¤ë¥¼ ì„ì€ í›„ì— . | ì„ì¸ ì¸ë±ìŠ¤ë¥¼ ê°€ì§€ê³  ë°°ì—´ ìŠ¬ë¼ì´ì‹±ì„ í•˜ì—¬ í›ˆë ¨ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ë‚˜ëˆˆë‹¤. . | ì´ë ‡ê²Œ ë‚˜ëˆˆ ê²ƒìœ¼ë¡œ KNNìœ¼ë¡œ ë‹¤ì‹œ í›ˆë ¨í•´ì„œ ëª¨ë¸ì„ í‰ê°€ . | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/19/ML.html",
            "relUrl": "/python/2022/03/19/ML.html",
            "date": " â€¢ Mar 19, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "(3ì£¼ì°¨ DV) 3ì›” 18ì¼",
            "content": "import pandas as pd . pd.read_csv(&#39;C:/Users/82103/Desktop/2022-1/ë¨¸ì‹ ëŸ¬ë‹/data/train.csv&#39;) . Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice . 0 1 | 60 | RL | 65.0 | 8450 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 2 | 2008 | WD | Normal | 208500 | . 1 2 | 20 | RL | 80.0 | 9600 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 5 | 2007 | WD | Normal | 181500 | . 2 3 | 60 | RL | 68.0 | 11250 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 9 | 2008 | WD | Normal | 223500 | . 3 4 | 70 | RL | 60.0 | 9550 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 2 | 2006 | WD | Abnorml | 140000 | . 4 5 | 60 | RL | 84.0 | 14260 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 12 | 2008 | WD | Normal | 250000 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1455 1456 | 60 | RL | 62.0 | 7917 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 8 | 2007 | WD | Normal | 175000 | . 1456 1457 | 20 | RL | 85.0 | 13175 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | MnPrv | NaN | 0 | 2 | 2010 | WD | Normal | 210000 | . 1457 1458 | 70 | RL | 66.0 | 9042 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | GdPrv | Shed | 2500 | 5 | 2010 | WD | Normal | 266500 | . 1458 1459 | 20 | RL | 68.0 | 9717 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 4 | 2010 | WD | Normal | 142125 | . 1459 1460 | 20 | RL | 75.0 | 9937 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 6 | 2008 | WD | Normal | 147500 | . 1460 rows Ã— 81 columns . df_train = pd.read_csv(&#39;C:/Users/82103/Desktop/2022-1/ë¨¸ì‹ ëŸ¬ë‹/data/train.csv&#39;) df_test = pd.read_csv(&#39;C:/Users/82103/Desktop/2022-1/ë¨¸ì‹ ëŸ¬ë‹/data/test.csv&#39;) . from pandas.core.groupby.generic import ScalarResult import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import numpy as np from scipy.stats import norm from sklearn.preprocessing import StandardScaler from scipy import stats import warnings warnings.filterwarnings(&#39;ignore&#39;) %matplotlib inline . df_train.columns . Index([&#39;Id&#39;, &#39;MSSubClass&#39;, &#39;MSZoning&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;Street&#39;, &#39;Alley&#39;, &#39;LotShape&#39;, &#39;LandContour&#39;, &#39;Utilities&#39;, &#39;LotConfig&#39;, &#39;LandSlope&#39;, &#39;Neighborhood&#39;, &#39;Condition1&#39;, &#39;Condition2&#39;, &#39;BldgType&#39;, &#39;HouseStyle&#39;, &#39;OverallQual&#39;, &#39;OverallCond&#39;, &#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;RoofStyle&#39;, &#39;RoofMatl&#39;, &#39;Exterior1st&#39;, &#39;Exterior2nd&#39;, &#39;MasVnrType&#39;, &#39;MasVnrArea&#39;, &#39;ExterQual&#39;, &#39;ExterCond&#39;, &#39;Foundation&#39;, &#39;BsmtQual&#39;, &#39;BsmtCond&#39;, &#39;BsmtExposure&#39;, &#39;BsmtFinType1&#39;, &#39;BsmtFinSF1&#39;, &#39;BsmtFinType2&#39;, &#39;BsmtFinSF2&#39;, &#39;BsmtUnfSF&#39;, &#39;TotalBsmtSF&#39;, &#39;Heating&#39;, &#39;HeatingQC&#39;, &#39;CentralAir&#39;, &#39;Electrical&#39;, &#39;1stFlrSF&#39;, &#39;2ndFlrSF&#39;, &#39;LowQualFinSF&#39;, &#39;GrLivArea&#39;, &#39;BsmtFullBath&#39;, &#39;BsmtHalfBath&#39;, &#39;FullBath&#39;, &#39;HalfBath&#39;, &#39;BedroomAbvGr&#39;, &#39;KitchenAbvGr&#39;, &#39;KitchenQual&#39;, &#39;TotRmsAbvGrd&#39;, &#39;Functional&#39;, &#39;Fireplaces&#39;, &#39;FireplaceQu&#39;, &#39;GarageType&#39;, &#39;GarageYrBlt&#39;, &#39;GarageFinish&#39;, &#39;GarageCars&#39;, &#39;GarageArea&#39;, &#39;GarageQual&#39;, &#39;GarageCond&#39;, &#39;PavedDrive&#39;, &#39;WoodDeckSF&#39;, &#39;OpenPorchSF&#39;, &#39;EnclosedPorch&#39;, &#39;3SsnPorch&#39;, &#39;ScreenPorch&#39;, &#39;PoolArea&#39;, &#39;PoolQC&#39;, &#39;Fence&#39;, &#39;MiscFeature&#39;, &#39;MiscVal&#39;, &#39;MoSold&#39;, &#39;YrSold&#39;, &#39;SaleType&#39;, &#39;SaleCondition&#39;, &#39;SalePrice&#39;], dtype=&#39;object&#39;) . df_test.columns . Index([&#39;Id&#39;, &#39;MSSubClass&#39;, &#39;MSZoning&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;Street&#39;, &#39;Alley&#39;, &#39;LotShape&#39;, &#39;LandContour&#39;, &#39;Utilities&#39;, &#39;LotConfig&#39;, &#39;LandSlope&#39;, &#39;Neighborhood&#39;, &#39;Condition1&#39;, &#39;Condition2&#39;, &#39;BldgType&#39;, &#39;HouseStyle&#39;, &#39;OverallQual&#39;, &#39;OverallCond&#39;, &#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;RoofStyle&#39;, &#39;RoofMatl&#39;, &#39;Exterior1st&#39;, &#39;Exterior2nd&#39;, &#39;MasVnrType&#39;, &#39;MasVnrArea&#39;, &#39;ExterQual&#39;, &#39;ExterCond&#39;, &#39;Foundation&#39;, &#39;BsmtQual&#39;, &#39;BsmtCond&#39;, &#39;BsmtExposure&#39;, &#39;BsmtFinType1&#39;, &#39;BsmtFinSF1&#39;, &#39;BsmtFinType2&#39;, &#39;BsmtFinSF2&#39;, &#39;BsmtUnfSF&#39;, &#39;TotalBsmtSF&#39;, &#39;Heating&#39;, &#39;HeatingQC&#39;, &#39;CentralAir&#39;, &#39;Electrical&#39;, &#39;1stFlrSF&#39;, &#39;2ndFlrSF&#39;, &#39;LowQualFinSF&#39;, &#39;GrLivArea&#39;, &#39;BsmtFullBath&#39;, &#39;BsmtHalfBath&#39;, &#39;FullBath&#39;, &#39;HalfBath&#39;, &#39;BedroomAbvGr&#39;, &#39;KitchenAbvGr&#39;, &#39;KitchenQual&#39;, &#39;TotRmsAbvGrd&#39;, &#39;Functional&#39;, &#39;Fireplaces&#39;, &#39;FireplaceQu&#39;, &#39;GarageType&#39;, &#39;GarageYrBlt&#39;, &#39;GarageFinish&#39;, &#39;GarageCars&#39;, &#39;GarageArea&#39;, &#39;GarageQual&#39;, &#39;GarageCond&#39;, &#39;PavedDrive&#39;, &#39;WoodDeckSF&#39;, &#39;OpenPorchSF&#39;, &#39;EnclosedPorch&#39;, &#39;3SsnPorch&#39;, &#39;ScreenPorch&#39;, &#39;PoolArea&#39;, &#39;PoolQC&#39;, &#39;Fence&#39;, &#39;MiscFeature&#39;, &#39;MiscVal&#39;, &#39;MoSold&#39;, &#39;YrSold&#39;, &#39;SaleType&#39;, &#39;SaleCondition&#39;], dtype=&#39;object&#39;) . df_train[&#39;SalePrice&#39;].describe() ## ë¶€ë™ì‚° ê°€ê²©ì˜ ê¸°ìˆ í†µê³„ëŸ‰ . count 1460.000000 mean 180921.195890 std 79442.502883 min 34900.000000 25% 129975.000000 50% 163000.000000 75% 214000.000000 max 755000.000000 Name: SalePrice, dtype: float64 . sns.distplot(df_train[&#39;SalePrice&#39;]) ## line : kernel density plot ## ëª©í‘œë³€ìˆ˜ì— ëŒ€í•œ íˆìŠ¤í† ê·¸ë¨ê³¼ kernel density plot . print(&quot;Skewness: %f&quot; % df_train[&#39;SalePrice&#39;].skew()) print(&quot;Kurtosis: %f&quot; % df_train[&#39;SalePrice&#39;].kurt()) ## ê¼¬ë¦¬ê°€ ë‘í„°ìš´ ì •ë„ (ì´ìƒì¹˜ê°€ ë§ì„ìˆ˜ë¡ ë‘êº¼ì›€) . Skewness: 1.882876 Kurtosis: 6.536282 . $-2 sim2$ ì‚¬ì´ì˜ ê°’ì´ë¯€ë¡œ ì¹˜ìš°ì¹¨ì´ ì—†ëŠ” ë°ì´í„° (by. George &amp; Mallery, 2010) | ì²¨ë„ê°€ ë†’ìœ¼ë©´ (Kurtosis &gt; 3) ì´ìƒì¹˜ê°€ ë§ì´ ìˆë‹¤ëŠ” ê²ƒ. | . ë§ì€ í†µê³„ê¸°ë²•ë“¤ì´ ì •ê·œì„±ì„ ê°€ì •í•œë‹¤. | . positive skewness : ì˜¤ë¥¸ìª½ ê¼¬ë¦¬, ì™¼ìª½ì— ë°ì´í„°ê°€ ë§ë‹¤. | negative skewness : ì™¼ìª½ ê¼¬ë¦¬, ì˜¤ë¥¸ìª½ì— ë°ì´í„°ê°€ ë§ë‹¤. | . ì™œë„, ì²¨ë„ ì½ì–´ë³´ê¸° . . . var1 = &#39;GrLivArea&#39; # ì§€ìƒ ê±°ì‹¤ ë©´ì  í‰ë°©í”¼íŠ¸ data1 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var1]], axis=1) ## ì—´ë¡œ í•©ì¹˜ê¸°(axis=1) . data1.plot.scatter(x=var1, y=&#39;SalePrice&#39;, ylim=(0,800000)) . &lt;AxesSubplot:xlabel=&#39;GrLivArea&#39;, ylabel=&#39;SalePrice&#39;&gt; . linear relationship | . var2 = &#39;TotalBsmtSF&#39; # ì§€í•˜ ì´ í‰ë°© í”¼íŠ¸ data2 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var2]], axis=1) # ì—´ê¸°ì¤€ìœ¼ë¡œ ë¶™ì„ data2.plot.scatter(x=var2, y=&#39;SalePrice&#39;, ylim=(0,800000)) . &lt;AxesSubplot:xlabel=&#39;TotalBsmtSF&#39;, ylabel=&#39;SalePrice&#39;&gt; . ë” strong í•œ linear relationship ( ë” ê°€íŒŒë¥´ë‹¤. ) | . var1 = &#39;GrLivArea&#39; data1 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var1]], axis=1) plt.scatter(var1, y=&#39;SalePrice&#39;, data = data1) . &lt;matplotlib.collections.PathCollection at 0x24f2102bca0&gt; . var2 = &#39;TotalBsmtSF&#39; data2 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var2]], axis=1) plt.scatter(var2, y=&#39;SalePrice&#39;, data = data2) . &lt;matplotlib.collections.PathCollection at 0x24f21535ac0&gt; . data2 . SalePrice OverallQual . 0 208500 | 7 | . 1 181500 | 6 | . 2 223500 | 7 | . 3 140000 | 7 | . 4 250000 | 8 | . ... ... | ... | . 1455 175000 | 6 | . 1456 210000 | 6 | . 1457 266500 | 7 | . 1458 142125 | 5 | . 1459 147500 | 5 | . 1460 rows Ã— 2 columns . var3 = &#39;OverallQual&#39; # ì „ì²´ ì œë£Œ ë° ë§ˆê°í’ˆì§ˆ data3 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var3]], axis=1) # ì—´ë¡œ í•©ì¹˜ê¸° f, ax = plt.subplots(figsize=(8,6)) fig = sns.boxplot(x=var3, y=&quot;SalePrice&quot;, data=data3) fig.axis(ymin=0, ymax=800000) . (-0.5, 9.5, 0.0, 800000.0) . var4 = &#39;YearBuilt&#39; # ì›ë˜ ê±´ì„¤ ë‚ ì§œ data4 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var4]], axis=1) f, ax = plt.subplots(figsize=(16,8)) fig = sns.boxplot(x=var4, y=&quot;SalePrice&quot;, data=data4) fig.axis(ymin=0, ymax=800000) plt.xticks(rotation=90) # xì¶• ëˆˆê¸ˆ ê°’ 90ë„ íšŒì „. .",
            "url": "https://pinkocto.github.io/BP2022/2022/03/18/DV.html",
            "relUrl": "/2022/03/18/DV.html",
            "date": " â€¢ Mar 18, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "(2ì£¼ì°¨ ML) 3ì›” 10ì¼",
            "content": "&#49373;&#49440; &#48516;&#47448; &#47928;&#51228; . &#46020;&#48120;(bream) &#45936;&#51060;&#53552; &#51456;&#48708;&#54616;&#44592; . bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0] bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0] . import matplotlib.pyplot as plt plt.scatter(bream_length, bream_weight) plt.xlabel(&#39;length&#39;) # ëª¸ ê¸¸ì´ plt.ylabel(&#39;weight&#39;) # ëª¸ ë¬´ê²Œ . Text(0, 0.5, &#39;weight&#39;) . &#48729;&#50612;(smelt) &#45936;&#51060;&#53552; &#51456;&#48708;&#54616;&#44592; . smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] . plt.scatter(bream_length, bream_weight, label=&#39;bream&#39;) ## ë„ë¯¸ plt.scatter(smelt_length, smelt_weight, label=&#39;smelt&#39;) ## ë¹™ì–´ plt.xlabel(&#39;length&#39;) plt.ylabel(&#39;weight&#39;) plt.legend() plt.show() . ë¹™ì–´ëŠ” ê¸¸ì´ê°€ ëŠ˜ì–´ë‚˜ë”ë¼ë„ ë¬´ê²Œê°€ ë§ì´ ëŠ˜ì§€ ì•ŠëŠ”ë‹¤. $ Rightarrow$ ë¹™ì–´ì˜ ì‚°ì ë„ ì—­ì‹œ ì„ í˜•ì ì´ì§€ë§Œ ë¬´ê²Œê°€ ê¸¸ì´ì— ì˜í–¥ì„ ëœ ë°›ëŠ”ë‹¤. | . binary classification (&#46020;&#48120;, &#48729;&#50612;) &#51456;&#48708; . ë‹¤ìŒìœ¼ë¡œ ë°ì´í„°ë§Œ ë³´ê³  ì–´ë–¤ ê²ƒì´ ë„ë¯¸ì´ê³  ì–´ë–¤ ê²ƒì´ ë¹™ì–´ì¸ì§€ ìŠ¤ìŠ¤ë¡œ êµ¬ë¶„í•˜ê¸° ìœ„í•´ í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ì–´ ë³´ì! | KNN(K-Nearest Neighbors) ë°©ë²•ì„ ì´ìš©í•  ê²ƒ. | . - ìš°ì„  KNN ì•Œê³ ë¦¬ì¦˜ì„ ì¨ë¨¹ìœ¼ë ¤ë©´ ë„ë¯¸ì™€ ë¹™ì–´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°ë¡œ í•©ì³ì•¼ í•œë‹¤. . length = bream_length + smelt_length weight = bream_weight + smelt_length . + ì—°ì‚°ìê°€ list ì¼ ê²½ìš°ì—ëŠ” í•©ì³ì§€ëŠ” ì—­í• ì„ í•˜ê³ , ì •ìˆ˜ì¼ ë•ŒëŠ” ìš°ë¦¬ê°€ ì¼ë°˜ì ìœ¼ë¡œ ì•Œê³ ìˆëŠ” ë§ì…ˆ ì—°ì‚°ì„ í•œë‹¤. | . len(bream_length), len(smelt_length), len(bream_weight), len(smelt_length) . (35, 14, 35, 14) . len(length), len(weight) . (49, 49) . ì˜ í•©ì³ì§„ ê²ƒ ê°™ë‹¤. | . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ ë³´ì. (Scikit-learnì„ ì‚¬ìš©í•˜ê¸°ìœ„í•´) . ## ì´ëŸ° ì‹ìœ¼ë¡œ 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê²ƒ! ê¸¸ì´ ë¬´ê²Œ [[25.4, 242.0], [26.3, 290.0]. . . . . . . [15.0, 19.9]] . fish_data = [[l,w] for l, w in zip(length, weight)] . - ì •ë‹µ ì¤€ë¹„ . ë„ë¯¸(bream)ë¥¼ 1ë¡œ ë†“ê³ , ë¹™ì–´(smelt)ë¥¼ 0ìœ¼ë¡œ ë†“ì. (0ê³¼ 1ë¡œ ë¶„ë¥˜í•˜ëŠ” ì´ì§„ë¶„ë¥˜) | . fish_target = [1]*35 + [0]*14 . K-&#52572;&#44540;&#51217; &#51060;&#50883; . from sklearn.neighbors import KNeighborsClassifier . kn = KNeighborsClassifier() # classì˜ instance(ê°ì²´) ë¥¼ ë§Œë“ ë‹¤. . kn.fit(fish_data, fish_target) ## knì„ ëª¨ë¸ì´ë¼ ë¶€ë¦„ . KNeighborsClassifier() . ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œê·¸ë¨ì˜ ì•Œê³ ë¦¬ì¦˜ì´ ê°ì²´í™” ëœê²ƒì„ ëª¨ë¸ì´ë¼ê³  ë¶€ë¥¸ë‹¤. | ì¢…ì¢… ê·¸ ì•Œê³ ë¦¬ì¦˜ ìì²´ë¥¼ ëª¨ë¸ì´ë¼ê³ ë„ ë¶€ë¦„. | . kn.score(fish_data, fish_target) . 1.0 . 100% ë‹¤ ë§ì·„ë‹¤! (100% ì •í™•ë„ ë‹¬ì„±!) | . &#49352;&#47196;&#50868; &#49373;&#49440; &#50696;&#52769; . ê·¸ë˜í”„ì— í‘œì‹œëœ ì´ˆë¡ìƒ‰ ì‚¼ê°í˜•ì€ ì–´ë–¤ ìƒì„ ì¼ê¹Œ? | . plt.scatter(bream_length, bream_weight, label=&#39;bream&#39;) plt.scatter(smelt_length, smelt_weight, label=&#39;smelt&#39;) plt.scatter(30, 600, marker=&#39;^&#39;) plt.xlabel(&#39;length&#39;) plt.ylabel(&#39;weight&#39;) plt.legend() plt.show() . ì§ê´€ì ìœ¼ë¡œ ë´¤ì„ë•Œ ë„ë¯¸(bream) ì¼ ê²ƒ ê°™ë‹¤. | ì‹¤ì œë¡œë„ ê·¸ëŸ°ì§€ í™•ì¸í•´ë³´ì. | . kn.predict([[30, 600]]) ## predict method . array([1]) . predict method ì•ˆì— ë„£ì„ ë•Œë„ 2ì°¨ì› ë°°ì—´ ë°ì´í„°ë¥¼ ë„£ì–´ì¤€ë‹¤. (ì‚¬ì´í‚·ëŸ°ì´ ê¸°ëŒ€í•˜ëŠ” ê²ƒ) | n_neighbors=5ê°€ default, ì£¼ìœ„ì— ìˆëŠ” ì´ì›ƒì˜ ê°œìˆ˜(K)ë§Œí¼ ì£¼ë³€ ìƒ˜í”Œì˜ class ì¤‘ ê°€ì¥ ë§ì€ í´ë˜ìŠ¤ë¥¼ ì •ë‹µí´ë˜ìŠ¤ë¡œ ì‚¼ëŠ”ë‹¤. | . print(kn._fit_X) . [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ] [ 29.7 450. ] [ 29.7 500. ] [ 30. 390. ] [ 30. 450. ] [ 30.7 500. ] [ 31. 475. ] [ 31. 500. ] [ 31.5 500. ] [ 32. 340. ] [ 32. 600. ] [ 32. 600. ] [ 33. 700. ] [ 33. 700. ] [ 33.5 610. ] [ 33.5 650. ] [ 34. 575. ] [ 34. 685. ] [ 34.5 620. ] [ 35. 680. ] [ 35. 700. ] [ 35. 725. ] [ 35. 720. ] [ 36. 714. ] [ 36. 850. ] [ 37. 1000. ] [ 38.5 920. ] [ 38.5 955. ] [ 39.5 925. ] [ 41. 975. ] [ 41. 950. ] [ 9.8 9.8] [ 10.5 10.5] [ 10.6 10.6] [ 11. 11. ] [ 11.2 11.2] [ 11.3 11.3] [ 11.8 11.8] [ 11.8 11.8] [ 12. 12. ] [ 12.2 12.2] [ 12.4 12.4] [ 13. 13. ] [ 14.3 14.3] [ 15. 15. ]] . print(kn._y) . [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0] . &#47924;&#51312;&#44148; &#46020;&#48120; . Fish ë°ì´í„°ì˜ ì´ ê°œìˆ˜ëŠ” 49ê°œì´ë‹¤. ì´ë²ˆì—ëŠ” n_neighbors = 49ë¡œ ì§€ì • í•´ë³´ì. . kn49 = KNeighborsClassifier(n_neighbors=49) . kn49.fit(fish_data, fish_target) . KNeighborsClassifier(n_neighbors=49) . kn49.score(fish_data, fish_target) ## ì ìˆ˜ . 0.7142857142857143 . score method : í›ˆë ¨í•œ ëª¨ë¸ì„ ê°€ì§€ê³  ì–´ë–¤ ë°ì´í„°ë¥¼ ì§‘ì–´ ë„£ì–´ì„œ ì–¼ë§ˆë§Œí¼ ì˜ ë§ëŠ”ì§€ë¥¼ í™•ì¸í•´ ë³´ëŠ” ê²ƒì´ë‹¤. | ë¶„ë¥˜ë¬¸ì œì¼ ê²½ìš°ì—ëŠ” ì •í™•ë„ë¥¼ ì¶œë ¥ (ëª¨ë¸ì´ ì–´ëŠì •ë„ ì •í™•í•œì§€ë¥¼ ì•Œì•„ë³´ëŠ” ë©”ì„œë“œ.) | . print(35/49) . 0.7142857142857143 . ì´ë ‡ê²Œ ëª¨ë¸ì„ ë§Œë“¤ë©´ ì „ì²´ ìƒ˜í”Œì˜ ë‹¤ìˆ˜ëŠ” ë„ë¯¸ $ to$ ë¬´ì¡°ê±´ ë‹¤ ë„ë¯¸ | n_neighbors ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ìœ„ì˜ ìƒ˜í”Œê°œìˆ˜ë¥¼ ë°”ê¿”ë³¼ ìˆ˜ë„ ìˆë‹¤. ë°”ê¾¸ë©´ ì•Œê³ ë¦¬ì¦˜ì˜ ì •í™•ë„ê°€ ë†’ì„ìˆ˜ë¡, ë‚®ì„ìˆ˜ë„ ìˆë‹¤. | . &#54869;&#51064; &#47928;&#51228; . kn = KNeighborsClassifier() kn.fit(fish_data, fish_target) for n in range(5, 50): # ìµœê·¼ì ‘ ì´ì›ƒ ê°œìˆ˜ ì„¤ì • kn.n_neighbors = n #ì ‘ìˆ˜ ê³„ì‚° score = kn.score(fish_data, fish_target) # 100% ì •í™•ë„ì— ë¯¸ì¹˜ì§€ ëª»í•˜ëŠ” ì´ì›ƒ ê°œìˆ˜ ì¶œë ¥ if score &lt; 1: print(n, score) break . 18 0.9795918367346939 .",
            "url": "https://pinkocto.github.io/BP2022/2022/03/17/ML.html",
            "relUrl": "/2022/03/17/ML.html",
            "date": " â€¢ Mar 17, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "tips",
            "content": "1. csv&#54028;&#51068; upload . ì°¸ê³ ë§í¬ : https://evidencen.com/how-to-upload-your-csv-file-online/ . import pandas as pd . autompg.csv github notebooksì— upload | autommpg.csv íŒŒì¼ click | Raw / Blameì—ì„œ Raw ë²„íŠ¼ click | ìƒë‹¨ì˜ ë§í¬ ë³µì‚¬ | . ë³µì‚¬í•œ ì£¼ì†Œ : https://raw.githubusercontent.com/pinkocto/BP2022/master/_notebooks/autompg.csv . pd.read_csv(&quot;https://raw.githubusercontent.com/pinkocto/BP2022/master/_notebooks/autompg.csv&quot;) . mpg cyl disp hp wt accler year origin carname . 0 18.0 | 8 | 307.0 | 17 | 3504 | 12.0 | 70 | 1 | chevrolet chevelle malibu | . 1 15.0 | 8 | 350.0 | 35 | 3693 | 11.5 | 70 | 1 | buick skylark 320 | . 2 18.0 | 8 | 318.0 | 29 | 3436 | 11.0 | 70 | 1 | plymouth satellite | . 3 16.0 | 8 | 304.0 | 29 | 3433 | 12.0 | 70 | 1 | amc rebel sst | . 4 17.0 | 8 | 302.0 | 24 | 3449 | 10.5 | 70 | 1 | ford torino | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 393 27.0 | 4 | 140.0 | 82 | 2790 | 15.6 | 82 | 1 | ford mustang gl | . 394 44.0 | 4 | 97.0 | 53 | 2130 | 24.6 | 82 | 2 | vw pickup | . 395 32.0 | 4 | 135.0 | 80 | 2295 | 11.6 | 82 | 1 | dodge rampage | . 396 28.0 | 4 | 120.0 | 75 | 2625 | 18.6 | 82 | 1 | ford ranger | . 397 31.0 | 4 | 119.0 | 78 | 2720 | 19.4 | 82 | 1 | chevy s-10 | . 398 rows Ã— 9 columns . ê¹ƒí—™ì— ì—…ë¡œë“œ í•œ csvíŒŒì¼ì„ ì˜ ì½ì–´ì˜¤ëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/02/upload.html",
            "relUrl": "/python/2022/03/02/upload.html",
            "date": " â€¢ Mar 2, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "(6ì£¼ì°¨) 2ì›”18ì¼ (3)",
            "content": "- íŒŒì¼ê³¼ ê²½ë¡œ . - í…ìŠ¤íŠ¸ íŒŒì¼ ì—´ê¸°, ì“°ê¸°, ì½ê¸° . - Tkinter íŒŒì¼ ë‹¤ì´ì–¼ë¡œê·¸ë¥¼ ì´ìš©í•œ ì˜ˆì œ . &#54028;&#51068; . ëª©ì  ìë£Œë¥¼ ì˜êµ¬íˆ ë³´ê´€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë¨ | . | . ì¢…ë¥˜: ì €ì¥ëœ ë°ì´í„°ì— ë”°ë¼ í…ìŠ¤íŠ¸ íŒŒì¼ ì¼ë°˜ì ì¸ ë¬¸ì ì½”ë“œ | . | ì´ì§„ íŒŒì¼ ì‚¬ì§„, ìŒì•…, ë¹„ë””ì˜¤ | . | . | . íŒŒì¼ì˜ ìœ„ì¹˜ í´ë”ì— ì¡´ì¬ | í´ë”ëŠ” ë‹¤ë¥¸ í´ë”ì— í¬í•¨ë˜ì–´ ìˆìŒ | ê²½ë¡œ : ì–´ë–¤ í´ë”ë¡œë¶€í„° ê·¸ íŒŒì¼ì— ì´ë¥´ëŠ” ë°©ë²• | . | . - &#54028;&#51068; &#44221;&#47196; . * ê²½ë¡œì˜ ì¢…ë¥˜ . ì ˆëŒ€ ê²½ë¡œ: ë£¨íŠ¸ í´ë”ë¡œíˆ¬í„° ì‹œì‘ ex) c: users user documents hello.py | . | . ìƒëŒ€ ê²½ë¡œ: í˜„ì¬ í´ë”ë¡œë¶€í„° ì‹œì‘ | . * í´ë”ë¥¼ í‘œì‹œí•˜ëŠ” íŠ¹ìˆ˜í•œ ê¸°í˜¸ . . : í˜„ì¬ í´ë”ë¥¼ ì˜ë¯¸í•¨ | .. : í˜„ì¬ í´ë”ì˜ ë¶€ëª¨ (ì¦‰, ìƒìœ„í´ë”ë¥¼ ì˜ë¯¸í•¨) | . &gt; &gt;&gt; import os &gt;&gt;&gt; os.getcwd() ## í˜„ì¬ í´ë” ê²½ë¡œ &#39;C: USERS USER .... python3.7&#39;&gt; &gt;&gt; os.chdir(&quot;C: Users Users Documents&quot;) ## í˜„ì¬í´ë” ê²½ë¡œ ë³€ê²½&gt; &gt;&gt; os.getcwd() ## í˜„ì¬ í´ë” ê²½ë¡œ &quot;C: Users Users Documents&quot; ## ë°”ë€ ê²½ë¡œë¡œ ì¶œë ¥ëœ ê²ƒ í™•ì¸ . - &#44221;&#47196; &#48516;&#47532; &#47928;&#51088; . Windowsì—ì„œ ê²½ë¡œ ë¶„ë¦¬ ë¬¸ìëŠ” ë¬¸ì œëŠ” Escape-Sequenceë¥¼ ë‚˜íƒ€ë‚¼ ë•Œ ì‚¬ìš©ë¨ | ê·¸ëƒ¥ ë¬¸ìë¥¼ í‘œì‹œí•˜ê¸° ìœ„í•´ì„œëŠ” ë¥¼ ì‚¬ìš© | . | . Unix, Linux ê³„ì—´ì—ì„œ ê²½ë¡œ ë¶„ë¦¬ ë¬¸ìëŠ” / Windows ìœ„ì—ì„œ ì‹¤í–‰ë˜ëŠ” íŒŒì´ì¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥ | ì•ì˜ ì˜ˆëŠ” &quot;C:/Users/Users/Documents&quot;ë¡œ ì¨ë„ ê°€ëŠ¥! | . | . Raw ë¬¸ìì—´ ì‚¬ìš©ë°©ë²• r&quot;ë¬¸ìì—´&quot;ì€ ë¬¸ìì—´ ë‚´ ëª¨ë“  íŠ¹ìˆ˜ë¬¸ìë¥¼ ë¬´ì‹œí•˜ê³  ì¼ë°˜ ë¬¸ìë¡œ ì·¨ê¸‰í•¨ | r&quot;C: Users Users Documents&quot;ë¡œ ì¨ë„ ê°€ëŠ¥! | . | . - &#54028;&#51068; &#50676;&#44592; . open() ì´ë¼ëŠ” ë‚´ì¥ í•¨ìˆ˜ë¥¼ ì‚¬ìš© | . fileVar = open(filename, mode) . open() í•¨ìˆ˜ëŠ” íŒŒì¼ ì—´ê¸°ë¥¼ ì„±ê³µí•˜ë©´ íŒŒì¼ì„ ë‚˜íƒ€ë‚´ëŠ” ê°ì²´ë¥¼ ë°˜í™˜í•¨ _io.TextIoWrapper í´ë˜ìŠ¤ ê°ì²´ì„ | . | . . - &#54028;&#51068; &#50676;&#44592; &#47784;&#46300; . íŒŒì¼ì—´ê¸°ëª¨ë“œ ì„¤ëª… . r (ì½ê¸°ëª¨ë“œ) | íŒŒì¼ì„ ì½ê¸°ë§Œ í•  ë•Œ ì‚¬ìš©í•œë‹¤ | . w (ì“°ê¸°ëª¨ë“œ) | íŒŒì¼ì— ë‚´ìš©ì„ ì“¸ ë•Œ ì‚¬ìš©í•˜ë©° ê¸°ì¡´ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë‚´ìš©ì´ ëª¨ë‘ ì´ˆê¸°í™”ë˜ê³  &lt;/br&gt; ì£¼ì–´ì§„ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ íŒŒì¼ì„ ë§Œë“ ë‹¤ | . a (ì¶”ê°€ëª¨ë“œ) | ê¸°ì¡´ íŒŒì¼ì˜ ë§ˆì§€ë§‰ì— ìƒˆë¡œìš´ ë‚´ìš©ì„ ì¶”ê°€ ì‹œí‚¬ ë•Œ ì‚¬ìš©í•œë‹¤ | . rb, wb | ê°ê° ì´ì§„ íŒŒì¼ì„ ì½ê¸° ìœ„í•´ í˜¹ì€ ì“°ê¸° ìœ„í•´ ì—´ë•Œ ì‚¬ìš©í•œë‹¤ | . - &#54028;&#51068;&#50640; &#45936;&#51060;&#53552; &#50416;&#44592; . write() ë©”ì„œë“œ ì‚¬ìš© | . ofile = open(&quot;snowwhite.txt&quot;, &quot;w&quot;) # 1 ofile.write(&quot;Once upon a time, long, long ago n&quot;) # 2 ofile.write(&quot;a king and queen ruled over n&quot;) ofile.write(&quot;a distant land&quot;) ofile.close() . - &#54028;&#51068;&#51060; &#51316;&#51116;&#54616;&#45716;&#51648; &#44160;&#49324;&#54616;&#44592; . os.path.exist(ê²½ë¡œ) . íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ True, ì•„ë‹ˆë©´ Falseë¥¼ ë°˜í™˜ | . | os.path.isdir(ê²½ë¡œ) . ì§€ì •ëœ íŒŒì¼ì´ í´ë”ì´ë©´ True, ì•„ë‹ˆë©´ Falseë¥¼ ë°˜í™˜ | . | os.path.isfile(ê²½ë¡œ) . ì§€ì •ëœ íŒŒì¼ì´ ì¼ë°˜ íŒŒì¼ì´ë©´ True, ì•„ë‹ˆë©´ Falseë¥¼ ë°˜í™˜ | . | . - &#54028;&#51068; &#51088;&#47308; &#51069;&#44592; . íŒŒì´ì¬ì—ëŠ” ì™¸ë¶€íŒŒì¼ì„ ì½ì–´ ë“¤ì—¬ í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤. . ì „ì²´ ë°ì´í„°ë¥¼ ì½ëŠ” ë©”ì„œë“œ : read(), reaadlines() . | í•œ ì¤„ì„ ì½ëŠ” ë©”ì„œë“œ : readline() . | ì£¼ì–´ì§„ ê¸¸ì´ë¥¼ ì½ëŠ” ë©”ì„œë“œ: read(n) . | . - &#51204;&#52404; &#51069;&#44592; . - ë°©ë²•1: read() í•¨ìˆ˜ ì‚¬ìš©í•˜ê¸° . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) ## ì½ê¸° readResult = ifile.read() print(&quot;Read Result:&quot;) print(repr(readResult)) ## repr(): ì¤„ë°”ê¿ˆ ë¬¸ìë„ ê·¸ëŒ€ë¡œ ì¶œë ¥ ifile.close() . Read Result: &#39;Once upon a time, long, long ago na king and queen ruled over na distant land&#39; . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) ## ì½ê¸° readResult = ifile.read() print(&quot;Read Result:&quot;) print(readResult) ifile.close() . Read Result: Once upon a time, long, long ago a king and queen ruled over a distant land . read() ëŠ” íŒŒì¼ì˜ ë‚´ìš© ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ëŒë ¤ì¤€ë‹¤. | . - ë°©ë²•2: readlines() í•¨ìˆ˜ ì‚¬ìš©í•˜ê¸° . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) readLinesResult = ifile.readlines() print(&quot;Read Lines Result:&quot;) print(readLinesResult) ifile.close() . Read Lines Result: [&#39;Once upon a time, long, long ago n&#39;, &#39;a king and queen ruled over n&#39;, &#39;a distant land&#39;] . readline() í•¨ìˆ˜ëŠ” íŒŒì¼ì˜ ëª¨ë“  ì¤„ì„ ì½ì–´ì„œ ê°ê°ì˜ ì¤„ì„ ìš”ì†Œë¡œ ê°–ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ëŒë ¤ì¤€ë‹¤. | . - ë°©ë²•2 + ì¤„ë°”ê¿ˆ( n) ë¬¸ì ì œê±°í•˜ê¸° . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) lines = ifile.readlines() for line in lines: line = line.strip() # ì¤„ ëì˜ ì¤„ ë°”ê¿ˆ ë¬¸ìë¥¼ ì œê±° print(line) ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . - &#51648;&#51221;&#46108; &#44600;&#51060;&#47564;&#53372; &#51069;&#44592; . file.read(n) : í˜„ì¬ file pointerë¡œë¶€í„° nê°œì˜ ê¸€ìë¥¼ ì½ì–´ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜ | . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) str1 = ifile.read(4) print(&quot;Read(4) Result:&quot;) print(repr(str1)) str2 = ifile.read(10) print(&quot;Read(10) Result:&quot;) print(repr(str2)) ifile.close() . Read(4) Result: &#39;Once&#39; Read(10) Result: &#39; upon a ti&#39; . - &#54620; &#51460;&#50473; &#51069;&#44592; &#44208;&#44284; . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) ifile.readline() ## 1 . &#39;Once upon a time, long, long ago n&#39; . ifile.readline() ## 2 . &#39;a king and queen ruled over n&#39; . ifile.readline() ## 3 . &#39;a distant land&#39; . ifile.readline() ## 4 . &#39;&#39; . lineì´ ëì— ë‹¤ë‹¤ë¥´ë©´ ë¹ˆë¬¸ì(&#39;&#39;)ê°€ ì¶œë ¥ëœë‹¤. | . - &#54028;&#51068;&#50640; &#47336;&#54532; &#49324;&#50857;&#54616;&#44592; . ë£¨í”„ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ í•œ ì¤„ì”© ì²˜ë¦¬í•˜ê¸° . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) line = ifile.readline() while line != &#39;&#39;: # line ì²˜ë¦¬ print(line) line = ifile.readline() ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) while True: line = ifile.readline() if not line: break print(line) ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) lines = ifile.readlines() for line in lines: # line ì²˜ë¦¬ print(line) ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . - &#49707;&#51088;&#44032; &#46308;&#50612;&#44032; &#51080;&#45716; &#54028;&#51068; &#52376;&#47532; . ofile = open(&quot;num.txt&quot;, &quot;w&quot;) ofile.write(&quot;10 20 12 5 n&quot;) ofile.write(&quot;8 9 7 23 n&quot;) ofile.write(&quot;1 8 22 9&quot;) ofile.close() . num.txt ì•„ë˜ì™€ ê°™ì€ íŒŒì¼ì´ ìˆì„ ë–„ íŒŒì¼ì— ìˆëŠ” ìˆ«ìì˜ í•©ì„ êµ¬í•´ë³´ì. | . ofile = open(&quot;num.txt&quot;, &quot;r&quot;) print(ofile.read()) ofile.close() . 10 20 12 5 8 9 7 23 1 8 22 9 . ofile = open(&quot;num.txt&quot;, &quot;r&quot;) total = 0 for line in ofile: lineLst = line.split() numList = [eval(x) for x in lineLst] total += sum(numList) print(total) . 134 . 10+20+12+5+8+9+7+23+1+8+22+9 . 134 . ì˜ ê³„ì‚°ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/02/18/(3).html",
            "relUrl": "/python/2022/02/18/(3).html",
            "date": " â€¢ Feb 18, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "(6ì£¼ì°¨) 2ì›”18ì¼ (1)",
            "content": "- ì†Œê°œ . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ì™€ í•¨ìˆ˜ . - ì˜ˆì œ . - ë‹¤ì°¨ì› ë¦¬ìŠ¤íŠ¸ . &#49548;&#44060; . í…Œì´ë¸”ì´ë‚˜ í–‰ë ¬ì€ 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. . - ëŒ€í•œë¯¼êµ­ ë„ì‹œë“¤ ê°„ ê±°ë¦¬ . ì„œìš¸ ë¶€ì‚° ëŒ€êµ¬ ê´‘ì£¼ . ì„œìš¸ | 0 | 325 | 237 | 267 | . ë¶€ì‚° | 325 | 0 | 87 | 202 | . ëŒ€êµ¬ | 237 | 87 | 0 | 172 | . ê´‘ì£¼ | 267 | 202 | 172 | 0 | . distance = [[0, 325, 237, 267], [325, 0, 87, 202], [237, 87, 0, 172], [267, 202, 172, 0]] . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52376;&#47532;&#54616;&#44592; . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#54364;&#54788; . matrix_ = [[1,2,3,4,5], [6,7,8,9,10], [11,12,13,14,15]] . - ê° ìš”ì†ŒëŠ” ë‘ ê°œì˜ ì²¨ìë¥¼ ì´ìš©í•˜ì—¬ í‘œí˜„ . matrix_[0][2] . 3 . matrix_[2][3] . 14 . matrix_[1][1] . 7 . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52488;&#44592;&#54868; . - ì‚¬ìš©ì ì…ë ¥ ê°’ìœ¼ë¡œ ì´ˆê¸°í™” . - ë¬´ì‘ìœ„ ê°’ìœ¼ë¡œ ì´ˆê¸°í™” . matrix = [] for row in range(3): ## number of rows = 3 matrix.append([]) for col in range(2): ## number of columns = 2 value = eval(input(&quot;value:&quot;)) matrix[row].append(value) . matrix ## 3í–‰ 2ì—´ì˜ 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ . [[1, 2], [3, 4], [5, 6]] . import random matrix = [] numberOfRows=3 numberOfColumns=2 for row in range(numberOfRows): matrix.append([]) #print(matrix) for col in range(numberOfColumns): matrix[row].append(random.randint(0,99)) #print(matrix) . [[]] [[51]] [[51, 15]] [[51, 15], []] [[51, 15], [47]] [[51, 15], [47, 46]] [[51, 15], [47, 46], []] [[51, 15], [47, 46], [79]] [[51, 15], [47, 46], [79, 98]] . matrix . [[51, 15], [47, 46], [79, 98]] . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52636;&#47141;&#54616;&#44592;, &#49438;&#44592;, &#51221;&#47148; . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ . len(matrix), len(matrix[0]) . (3, 2) . for row in range(len(matrix)): for col in range(len(matrix[row])): print(matrix[row][col], end=&#39; &#39;) print() . 51 15 47 46 79 98 . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ ì„ê¸° . matrix . [[51, 15], [47, 46], [79, 98]] . for row in range(len(matrix)): for col in range(len(matrix[row])): i = random.randint(0, len(matrix)-1) j = random.randint(0, len(matrix[row])-1) matrix[row][col], matrix[i][j] = matrix[i][j], matrix[row][col] . matrix . [[79, 98], [46, 15], [47, 51]] . ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ì›ì†Œë“¤ì´ ì˜ ì„ì—¬ì§„ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. | . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52376;&#47532; . - ëª¨ë“  ì›ì†Œë“¤ì˜ í•© êµ¬í•˜ê¸° . matrix . [[79, 98], [46, 15], [47, 51]] . total = 0 for row in matrix: for value in row: total += value print(total) . 79 177 223 238 285 336 . total . 336 . - ê° ì—´ì˜ í•© êµ¬í•˜ê¸° . matrix . [[79, 98], [46, 15], [47, 51]] . for col in range(len(matrix[0])): total = 0 for row in range(len(matrix)): total += matrix[row][col] print(&quot;Sum of column&quot;, col, &quot;is&quot;, total) . Sum of column 0 is 172 Sum of column 1 is 164 . 79+46+47 # 1ì—´ í•© . 172 . 98+15+51 # 2ì—´ í•© . 164 . ê° ì—´ì˜ í•©ì´ ì˜ ê³„ì‚°ë˜ì—ˆë‹¤. | . - í•©ì´ ê°€ì¥ í° í–‰ êµ¬í•˜ê¸° . matrix . [[79, 98], [46, 15], [47, 51]] . maxRow = sum(matrix[0]) indexRow = 0 for row in range(1, len(matrix)): if sum(matrix[row]) &gt; maxRow: maxRow = sum(matrix[row]) indexRow = row print(&quot;Row&quot;, indexRow, &quot;has max sum of &quot; , maxRow) . Row 0 has max sum of 177 . - ë¦¬ìŠ¤íŠ¸ ì •ë ¬ . lst = [[1,2],[1,1],[3,1],[2,5]] lst . [[1, 2], [1, 1], [3, 1], [2, 5]] . lst.sort() lst . [[1, 1], [1, 2], [2, 5], [3, 1]] . 2&#52264;&#50896; &#47532;&#49828;&#53944;&#50752; &#54632;&#49688; . 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë„ ë‹¤ë¥¸ ê°ì²´ì™€ ë§ˆì°¬ê°€ì§€ë¡œ í•¨ìˆ˜ì— ì¸ìˆ˜ë¡œ ì „ë‹¬í•  ìˆ˜ë„ ìˆê³ , í•¨ìˆ˜ê°€ ë°˜í™˜ê°’ìœ¼ë¡œ ë°˜í™˜í•  ìˆ˜ë„ ìˆë‹¤. . def getMatrix(): matrix = [] numRows = eval(input(&quot;Number of Rows: &quot;)) numCols = eval(input(&quot;Number of Colunmns: &quot;)) for row in range(numRows): matrix.append([]) for col in range(numCols): value = eval(input(&quot;value:&quot;)) matrix[row].append(value) return matrix . getMatrix() . [[79, 98], [46, 15], [17, 51]] . def accumulate(m): total = 0 for row in m: total += sum(row) return total . accumulate(matrix) . 336 . matrixì˜ ëª¨ë“  ì›ì†Œì˜ í•©ì€ 336ìœ¼ë¡œ ìœ„ì—ì„œ êµ¬í•œ (2ì°¨ì› ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬: ëª¨ë“  ì›ì†Œì˜ í•©)ì—ì„œ êµ¬í•œ ê°’ê³¼ ê°™ë‹¤. | . &#50696;&#51228;1 | &#44032;&#51109; &#44032;&#44620;&#50868; &#46160; &#51216;&#51008;? . ì—¬ëŸ¬ ì ì— ëŒ€í•œ ì¢Œí‘œê°€ ìˆë‹¤. ì´ë“¤ ì  ì¤‘ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ë‘ ì ì„ ì°¾ì•„ë³´ì. . def distance(x1,y1,x2,y2): return((x1-x2)**2 + (y1-y2)**2)**0.5 def nearestPoint(points): p1, p2 = 0, 1 shortestDist = distance(points[p1][0], points[p1][1], points[p2][0], points[p2][1]) for i in range(len(points)): for j in range(i+1, len(points)): d = distance(points[i][0], points[i][1], points[j][0], points[j][1]) if d &lt; shortestDist: shortestDist = d p1, p2 = i, j return p1, p2 . nPoints = eval(input(&quot;ì ì˜ ìˆ˜:&quot;)) points = [] for i in range(nPoints): point = [0,0] point[0],point[1] = eval(input(&quot;ì¢Œí‘œ:&quot;)) points.append(point) p1, p2 = nearestPoint(points) print(&quot;(&quot;, points[p1][0], points[p1][1],&quot;)&quot;,&quot;(&quot;,points[p2][0], points[p2][1],&quot;)&quot;) . ( 0 0 ) ( 0 1 ) . nPoints = eval(input(&quot;ì ì˜ ìˆ˜:&quot;)) points = [] for i in range(nPoints): point = [0,0] point[0],point[1] = eval(input(&quot;ì¢Œí‘œ:&quot;)) points.append(point) p1, p2 = nearestPoint(points) print(&quot;(&quot;, points[p1][0], points[p1][1],&quot;)&quot;,&quot;(&quot;,points[p2][0], points[p2][1],&quot;)&quot;) . ( 2 5 ) ( 3 8 ) . &#50696;&#51228;2 | Sudoku . . [ê²Œì„ ê·œì¹™] . ê° ì—´, ê° í–‰ì— 1~9ê¹Œì§€ ìˆ«ìê°€ ë“¤ì–´ê°€ì•¼ í•œë‹¤. | $3 times 3$ ë¸”ë¡ì— 1~9ê°€ì§€ ìˆ«ìê°€ ë“¤ì–´ê°€ì•¼ í•œë‹¤. | . &#50612;&#46500; Sudoku &#54644;&#44208;&#48169;&#48277;&#51060; &#47582;&#45716;&#51648; &#44160;&#49324; . ë‘ê°€ì§€ ê²€ì‚¬ë°©ë²• . ê° í–‰, ì—´, ë¸”ë¡ì´ 1~9ê¹Œì§€ ìˆ«ìë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ ê²€ì‚¬ | | ê° ì…€ì— ëŒ€í•´ ê·¸ ì…€ì˜ ìˆ«ìê°€ í–‰, ì—´, ë¸”ë¡ì—ì„œ ìœ ì¼í•œì§€ ê²€ì‚¬ &lt; ì´ ë°©ë²• ì‚¬ìš©í•  ê²ƒì„! | | . | . def isValid(grid): for i in range(9): for j in range(9): if grid[i][j] &lt; 1 or grid[i][j] &gt; 9 or not isValidAt(i,j,grid): return False return True . def isValidAt(i,j,grid): for column in range(9): if column != j and grid[i][column] == grid[i][j]: return False for row in range(9): if row != i and grid[row][j] == grid[i][j]: return False for row in range((i//3)*3, (j//3)*3 + 3): if row != i and column != j and grid[row][column] == grid[i][j]: return False return True . &#45796;&#52264;&#50896; &#47532;&#49828;&#53944; . ì¼ë°˜ì ìœ¼ë¡œ $n$ê°œì˜ ì²¨ì ì‚¬ìš© | . m[i][j][k] . .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/02/18/(1).html",
            "relUrl": "/python/2022/02/18/(1).html",
            "date": " â€¢ Feb 18, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "test",
            "content": "import pandas as pd import altair as alt . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . selection = alt.selection_single(); alt.Chart(cars).mark_circle().add_selection( selection ).encode( x=&#39;Horsepower:Q&#39;, y=&#39;Miles_per_Gallon:Q&#39;, color=alt.condition(selection, &#39;Cylinders:O&#39;, alt.value(&#39;grey&#39;)), opacity=alt.condition(selection, alt.value(0.8), alt.value(0.1)) ) . def plot(selection): return alt.Chart(cars).mark_circle().add_selection( selection ).encode( x=&#39;Horsepower:Q&#39;, y=&#39;Miles_per_Gallon:Q&#39;, color=alt.condition(selection, &#39;Cylinders:O&#39;, alt.value(&#39;grey&#39;)), opacity=alt.condition(selection, alt.value(0.8), alt.value(0.1)) ).properties( width=240, height=180 ) . alt.hconcat( plot(alt.selection_single()).properties(title=&#39;Single (Click)&#39;), plot(alt.selection_multi()).properties(title=&#39;Multi (Shift-Click)&#39;), plot(alt.selection_interval()).properties(title=&#39;Interval (Drag)&#39;) ) . alt.hconcat( plot(alt.selection_single(on=&#39;mouseover&#39;)).properties(title=&#39;Single (Mouseover)&#39;), plot(alt.selection_multi(on=&#39;mouseover&#39;)).properties(title=&#39;Multi (Shift-Mouseover)&#39;) ) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/01/04/test.html",
            "relUrl": "/python/2022/01/04/test.html",
            "date": " â€¢ Jan 4, 2022"
        }
        
    
  
    
        ,"post20": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.â†© . 2. This is the other footnote. You can even have a link!â†© .",
            "url": "https://pinkocto.github.io/BP2022/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " â€¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post21": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a â€œlevel 1 headingâ€ in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Hereâ€™s a footnote 1. Hereâ€™s a horizontal rule: . . Lists . Hereâ€™s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes â€¦andâ€¦ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.Â &#8617; . |",
            "url": "https://pinkocto.github.io/BP2022/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " â€¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.Â &#8617; . |",
          "url": "https://pinkocto.github.io/BP2022/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ â€œsitemap.xmlâ€ | absolute_url }} | .",
          "url": "https://pinkocto.github.io/BP2022/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
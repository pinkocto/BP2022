{
  
    
        "post0": {
            "title": "note2",
            "content": "Machine Learning&#51032; &#51208;&#52264; . ë°ì´í„°ì˜ ê²°ì¸¡ì¹˜/ì´ìƒì¹˜ ì œê±°, ì²˜ë¦¬ (ì‹œê°í™”, ê°€ì„¤ê²€ì •, ...) | $X$(ì„¤ëª…ë³€ìˆ˜), $Y$(ëª©í‘œë³€ìˆ˜)ë¥¼ ì„ ì–¸ | í•™ìŠµë°ì´í„°ì™€ ê²€ì¦ë°ì´í„°ë¥¼ ë¶„í•  | í•™ìŠµë°ì´í„°ë¥¼ ê°€ì ¸ì™€, ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©í•´ í•™ìŠµ ì‹¤ì‹œ | ê²€ì¦ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬, í‰ê°€ì‘ì—… ì‹¤ì‹œ | Load Dataset . import pandas as pd . df1.shape . (51304, 18) . df1.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 51304 entries, 0 to 51303 Data columns (total 18 columns): # Column Non-Null Count Dtype -- -- 0 Unnamed: 0 51304 non-null int64 1 id 51304 non-null int64 2 type_of_contract 51300 non-null object 3 type_of_contract2 51303 non-null object 4 channel 51304 non-null object 5 datetime 51304 non-null object 6 Term 51304 non-null int64 7 payment_type 51304 non-null object 8 product 51303 non-null object 9 amount 51304 non-null int64 10 state 51304 non-null object 11 overdue_count 51304 non-null int64 12 overdue 51302 non-null object 13 credit rating 42521 non-null float64 14 bank 48544 non-null object 15 cancellation 51279 non-null object 16 age 40509 non-null float64 17 Mileage 40509 non-null float64 dtypes: float64(3), int64(5), object(10) memory usage: 7.0+ MB . df1.drop([&#39;Unnamed: 0&#39;], axis=1, inplace=True) . df1.isnull().sum() # ê° í•­ëª© ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜ . id 0 type_of_contract 4 type_of_contract2 1 channel 0 datetime 0 Term 0 payment_type 0 product 1 amount 0 state 0 overdue_count 0 overdue 2 credit rating 8783 bank 2760 cancellation 25 age 10795 Mileage 10795 dtype: int64 . &#44208;&#52769;&#52824; &#52376;&#47532; . # ê²°ì¸¡ì¹˜ ì œê±° df2 = df1.dropna() print(df2.shape) . (40480, 17) . import numpy as np . df1[&#39;age&#39;] . 0 43.0 1 62.0 2 60.0 3 60.0 4 51.0 ... 51299 NaN 51300 39.0 51301 51.0 51302 64.0 51303 53.0 Name: age, Length: 51304, dtype: float64 . df1[&#39;age(clean)&#39;] = df1[&#39;age&#39;].replace(np.nan, 0) . df1[&#39;age(clean)&#39;] = df1[&#39;age&#39;].fillna(0) print(df1.isnull().sum()) . id 0 type_of_contract 4 type_of_contract2 1 channel 0 datetime 0 Term 0 payment_type 0 product 1 amount 0 state 0 overdue_count 0 overdue 2 credit rating 8783 bank 2760 cancellation 25 age 10795 Mileage 10795 age(clean) 0 dtype: int64 . df1[&#39;age(clean_mean)&#39;] = df1[&#39;age&#39;].fillna(df1[&#39;age&#39;].mean()) print(df1[&#39;age&#39;].mean()) . 46.60828457873559 . df1[&#39;age(clean_median)&#39;] = df1[&#39;age&#39;].fillna(df1[&#39;age&#39;].median()) print(df1[&#39;age&#39;].median()) . 46.0 . df2[&#39;state&#39;].value_counts() . ê³„ì•½í™•ì • 39776 í•´ì•½í™•ì • 667 ê¸°ê°„ë§Œë£Œ 25 í•´ì•½ì§„í–‰ì¤‘ 12 Name: state, dtype: int64 . Y = df2[&#39;state&#39;].replace(&#39;ê³„ì•½í™•ì •&#39;,0).replace(&#39;ê¸°ê°„ë§Œë£Œ&#39;,0).replace(&#39;í•´ì•½í™•ì •&#39;,1).replace(&#39;í•´ì•½ì§„í–‰ì¤‘&#39;,1) X = df2[[&#39;Term&#39;, &#39;amount&#39;,&#39;age&#39;,&#39;overdue_count&#39;,&#39;credit rating&#39;]] . X.head() . Term amount age overdue_count credit rating . 0 60 | 96900 | 43.0 | 0 | 9.0 | . 1 60 | 102900 | 62.0 | 0 | 2.0 | . 2 60 | 96900 | 60.0 | 0 | 8.0 | . 3 12 | 66900 | 60.0 | 0 | 5.0 | . 4 12 | 66900 | 51.0 | 12 | 8.0 | . ê³„ì•½ê¸°ê°„, ê³„ì•½ê¸ˆì•¡, ê³ ê°ì˜ ì—°ë ¹, ì—°ì²´ê±´ìˆ˜, ê³ ê°ì˜ ì‹ ìš©ë“±ê¸‰ì„ ë„£ì—ˆì„ ë•Œ ì´ ê³ ê°ì´ í•´ì•½í•  ê³ ê°ì¸ì§€ ì•„ë‹Œì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ë§Œë“¤ì–´ë³´ì. | . # Scipy + Learning Tool kit # íŠ¹ì„±ê³µí•™ + ì•Œê³ ë¦¬ì¦˜ . from sklearn.model_selection import train_test_split # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í•  from sklearn.tree import DecisionTreeClassifier # ì•Œê³ ë¦¬ì¦˜ from sklearn.metrics import accuracy_score # ì •í™•ë„ í‰ê°€ì§€í‘œ . X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3) . model = DecisionTreeClassifier() model.fit(X_train, Y_train) . DecisionTreeClassifier() . In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeClassifierDecisionTreeClassifier() . # ê²€ì¦ì´ ì˜ ì´ë£¨ì–´ì§€ëŠ”ì§€ í™•ì¸ (ì¼ë°˜í™”) Y_train_pred = model.predict(X_train) Y_test_pred = model.predict(X_test) . accuracy_score(Y_train, Y_train_pred) . 0.9865542066629023 . accuracy_score(Y_test, Y_test_pred) . 0.980566534914361 .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/11/22/(2)-bigdata-note2.html",
            "relUrl": "/python/2022/11/22/(2)-bigdata-note2.html",
            "date": " â€¢ Nov 22, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "ğŸ¤£ Preparing for data analysis test",
            "content": "&#45936;&#51060;&#53552;&#47484; &#44288;&#52272;&#54616;&#44256; &#44032;&#44277;&#54616;&#44592;: &#51204;&#52376;&#47532;(preprocessing) . í˜„ì—…ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì „ì²˜ë¦¬ ì‘ì—…ì—ëŠ” ìˆ˜ì‹­ ê°€ì§€ê°€ ìˆì§€ë§Œ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ëª‡ê°€ì§€ ì „ì²˜ë¦¬ ì‘ì—…ì„ ì†Œê°œí•˜ê² ìŠµë‹ˆë‹¤. . í•„ìš”í•˜ì§€ ì•Šì€ ì—´ ì‚­ì œ | ëˆ„ë½ëœ ê°’ë“¤ì„ ë‹¤ë¥¸ ê°’ë“¤ë¡œ ë°”ê¾¸ê±°ë‚˜ ì‚­ì œ | ì˜ëª»ëœ ê°’ì„ ë°”ë¥´ê²Œìˆ˜ì • | ì¼ë°˜ì ì¸ ë²”ìœ„ì—ì„œ ë²—ì–´ë‚˜ëŠ” ì´ìƒê°’ ì¡°ì • | ê° ì—´ë“¤ì˜ ìˆ«ì ê°’ì„ ë™ì¼í•œ ë²”ìœ„ì˜ ìˆ«ìë¡œ ë³€ê²½ | ì˜ë„í•œ ë°ì´í„° íƒ€ì…ì´ ì•„ë‹ˆë¼ë©´ ì ì ˆí•œ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë³€ê²½ | ë¬¸ìë¡œ êµ¬ì„±ëœ ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ìˆ«ìí˜•ìœ¼ë¡œ ë³€ê²½ | ë¶„ì„ì— í•„ìš”í•œ ìƒˆë¡œìš´ ì—´ ìƒì„± | Data Load . import pandas as pd data = pd.read_csv(&#39;https://raw.githubusercontent.com/7ieon/bigData/main/mtcars.csv&#39;) . data.head() . Unnamed: 0 mpg cyl disp hp drat wt qsec vs am gear carb . 0 Mazda RX4 | 21.0 | 6.0 | 160.0 | 110 | 3.90 | 2.620 | 16.46 | 0 | manual | 4 | 4 | . 1 Mazda RX4 Wag | 21.0 | 6.0 | 160.0 | 110 | 3.90 | 2.875 | 17.02 | 0 | manual | 4 | 4 | . 2 Datsun 710 | 22.8 | 4.0 | 108.0 | 93 | 3.85 | 2.320 | 18.61 | 1 | manual | 4 | 1 | . 3 Hornet 4 Drive | 21.4 | 6.0 | 258.0 | 110 | 3.08 | 3.215 | 0.10 | 1 | auto | 3 | 1 | . 4 Hornet Sportabout | 18.7 | 8.0 | 360.0 | 175 | 3.15 | 3.440 | 17.02 | 0 | auto | 3 | 2 | . data.shape . (32, 12) . type(data) . pandas.core.frame.DataFrame . data.columns . Index([&#39;Unnamed: 0&#39;, &#39;mpg&#39;, &#39;cyl&#39;, &#39;disp&#39;, &#39;hp&#39;, &#39;drat&#39;, &#39;wt&#39;, &#39;qsec&#39;, &#39;vs&#39;, &#39;am&#39;, &#39;gear&#39;, &#39;carb&#39;], dtype=&#39;object&#39;) . data.describe() . mpg cyl disp hp drat wt qsec vs carb . count 32.000000 | 30.000000 | 32.000000 | 32.000000 | 32.000000 | 32.000000 | 31.000000 | 32.000000 | 32.0000 | . mean 20.090625 | 7.600000 | 230.721875 | 146.687500 | 3.596563 | 3.217250 | 19.866774 | 0.437500 | 2.8125 | . std 6.026948 | 8.194195 | 123.938694 | 68.562868 | 0.534679 | 0.978457 | 15.310469 | 0.504016 | 1.6152 | . min 10.400000 | 4.000000 | 71.100000 | 52.000000 | 2.760000 | 1.513000 | 0.100000 | 0.000000 | 1.0000 | . 25% 15.425000 | 4.000000 | 120.825000 | 96.500000 | 3.080000 | 2.581250 | 16.785000 | 0.000000 | 2.0000 | . 50% 19.200000 | 6.000000 | 196.300000 | 123.000000 | 3.695000 | 3.325000 | 17.600000 | 0.000000 | 2.0000 | . 75% 22.800000 | 8.000000 | 326.000000 | 180.000000 | 3.920000 | 3.610000 | 18.755000 | 1.000000 | 4.0000 | . max 33.900000 | 50.000000 | 472.000000 | 335.000000 | 4.930000 | 5.424000 | 100.000000 | 1.000000 | 8.0000 | . data[&#39;hp&#39;].describe() . count 32.000000 mean 146.687500 std 68.562868 min 52.000000 25% 96.500000 50% 123.000000 75% 180.000000 max 335.000000 Name: hp, dtype: float64 . print(data[&#39;am&#39;].unique()) # amì¹¼ëŸ¼ì—ì„œ ì¤‘ë³µ ì œê±° print(data[&#39;gear&#39;].unique()) print(data[&#39;vs&#39;].unique()) . [&#39;manual&#39; &#39;auto&#39;] [&#39;4&#39; &#39;3&#39; &#39;*3&#39; &#39;5&#39; &#39;*5&#39;] [0 1] . print(data.info()) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 Unnamed: 0 32 non-null object 1 mpg 32 non-null float64 2 cyl 30 non-null float64 3 disp 32 non-null float64 4 hp 32 non-null int64 5 drat 32 non-null float64 6 wt 32 non-null float64 7 qsec 31 non-null float64 8 vs 32 non-null int64 9 am 32 non-null object 10 gear 32 non-null object 11 carb 32 non-null int64 dtypes: float64(6), int64(3), object(3) memory usage: 3.1+ KB None . print(data.corr()) . mpg cyl disp hp drat wt qsec mpg 1.000000 -0.460227 -0.847551 -0.776168 0.681172 -0.867659 0.013668 cyl -0.460227 1.000000 0.544876 0.323293 -0.372671 0.533690 -0.012755 disp -0.847551 0.544876 1.000000 0.790949 -0.710214 0.887980 0.181810 hp -0.776168 0.323293 0.790949 1.000000 -0.448759 0.658748 0.010807 drat 0.681172 -0.372671 -0.710214 -0.448759 1.000000 -0.712441 -0.120283 wt -0.867659 0.533690 0.887980 0.658748 -0.712441 1.000000 0.093900 qsec 0.013668 -0.012755 0.181810 0.010807 -0.120283 0.093900 1.000000 vs 0.664039 -0.323960 -0.710416 -0.723097 0.440278 -0.554916 -0.112146 carb -0.550925 0.239980 0.394977 0.749812 -0.090790 0.427606 -0.120312 vs carb mpg 0.664039 -0.550925 cyl -0.323960 0.239980 disp -0.710416 0.394977 hp -0.723097 0.749812 drat 0.440278 -0.090790 wt -0.554916 0.427606 qsec -0.112146 -0.120312 vs 1.000000 -0.569607 carb -0.569607 1.000000 . ìš°ë¦¬ ëª©í‘œëŠ” mpg(ì—°ë¹„) ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒ . X = data.drop(columns = &#39;mpg&#39;) # dependent variables Y = data[&#39;mpg&#39;] # dependent variable . X.head() . Unnamed: 0 cyl disp hp drat wt qsec vs am gear carb . 0 Mazda RX4 | 6.0 | 160.0 | 110 | 3.90 | 2.620 | 16.46 | 0 | manual | 4 | 4 | . 1 Mazda RX4 Wag | 6.0 | 160.0 | 110 | 3.90 | 2.875 | 17.02 | 0 | manual | 4 | 4 | . 2 Datsun 710 | 4.0 | 108.0 | 93 | 3.85 | 2.320 | 18.61 | 1 | manual | 4 | 1 | . 3 Hornet 4 Drive | 6.0 | 258.0 | 110 | 3.08 | 3.215 | 0.10 | 1 | auto | 3 | 1 | . 4 Hornet Sportabout | 8.0 | 360.0 | 175 | 3.15 | 3.440 | 17.02 | 0 | auto | 3 | 2 | . Y.head() . 0 21.0 1 21.0 2 22.8 3 21.4 4 18.7 Name: mpg, dtype: float64 . ì˜ ë‚˜ëˆ ì§„ ê²ƒ ê°™ë‹¤. | . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . 1 &#48520;&#54596;&#50836;&#54620; &#50676; &#49325;&#51228; . X = X.iloc[:,1:] X.head() . cyl disp hp drat wt qsec vs am gear carb . 0 6.0 | 160.0 | 110 | 3.90 | 2.620 | 16.46 | 0 | manual | 4 | 4 | . 1 6.0 | 160.0 | 110 | 3.90 | 2.875 | 17.02 | 0 | manual | 4 | 4 | . 2 4.0 | 108.0 | 93 | 3.85 | 2.320 | 18.61 | 1 | manual | 4 | 1 | . 3 6.0 | 258.0 | 110 | 3.08 | 3.215 | 0.10 | 1 | auto | 3 | 1 | . 4 8.0 | 360.0 | 175 | 3.15 | 3.440 | 17.02 | 0 | auto | 3 | 2 | . 2 &#44208;&#52769;&#44050; &#52376;&#47532; . ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°ëŠ” í•´ë‹¹ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê±°ë‚˜ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ë°”ê¾¸ëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ë°”ê¾¸ëŠ” ë°ëŠ” ì „ì²´ ë°ì´í„°ì˜ í‰ê· ê°’, ì¤‘ìœ„ê°’ìœ¼ë¡œ ë°”ê¾¸ê±°ë‚˜, í•´ë‹¹ ë°ì´í„°ì™€ ìœ ì‚¬í•œ ê°’ì´ë‚˜ íŒ¨í„´ì„ ì°¸ê³ í•˜ì—¬ ë°”ê¾¸ëŠ” ë“±, ì—¬ëŸ¬ê°€ì§€ ë°©ë²•ì´ ì¡´ì¬í•©ë‹ˆë‹¤. . í•˜ì§€ë§Œ ê²°ì¸¡ì¹˜ë¥¼ ì‚­ì œí•˜ëŠ” ë°©ë²•ì€ ë¹…ë¶„ê¸° ì‹¤ê¸° ì‹œí—˜ì—ì„œëŠ” ì„ íƒí•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. . ê·¸ ì´ìœ ëŠ” ì£¼ì–´ì§„ ë¶„ì„ ë°ì´í„°ì˜ ê°œìˆ˜ ê·¸ëŒ€ë¡œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê±°ë‚˜ íŒŒì¼ë¡œ ì œì¶œí•´ì•¼í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. . X.isnull().head(3) . cyl disp hp drat wt qsec vs am gear carb . 0 False | False | False | False | False | False | False | False | False | False | . 1 False | False | False | False | False | False | False | False | False | False | . 2 False | False | False | False | False | False | False | False | False | False | . print(X.isnull().sum()) . cyl 2 disp 0 hp 0 drat 0 wt 0 qsec 1 vs 0 am 0 gear 0 carb 0 dtype: int64 . cylê³¼ qsecì—´ì— ê²°ì¸¡ì¹˜ê°€ ê°ê° 2ê°œ, 1ê°œ ìˆìŒì„ í™•ì¸ . - &#54217;&#44512;&#44050;&#51004;&#47196; &#45824;&#52824;&#54616;&#44592; (cyl) . X_cyl_mean = X[&#39;cyl&#39;].mean() # X_cyl_mean ë³€ìˆ˜ í™•ì¸ print(X_cyl_mean) . 7.6 . X[&#39;cyl&#39;] = X[&#39;cyl&#39;].fillna(X_cyl_mean) . X.isnull().sum() . cyl 0 disp 0 hp 0 drat 0 wt 0 qsec 1 vs 0 am 0 gear 0 carb 0 dtype: int64 . cylì˜ ê²°ì¸¡ê°’ì´ ì˜ ì²˜ë¦¬ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. | . - &#51473;&#50948;&#44050;&#51004;&#47196; &#45824;&#52824;&#54616;&#44592; (qsec) . X_qsec_median = X[&#39;qsec&#39;].median() # X1_qsec_median X_qsec_median . 17.6 . X[&#39;qsec&#39;] = X[&#39;qsec&#39;].fillna(X_qsec_median) . X.isnull().sum() . cyl 0 disp 0 hp 0 drat 0 wt 0 qsec 0 vs 0 am 0 gear 0 carb 0 dtype: int64 . ê²°ì¸¡ì¹˜ê°€ ëª¨ë‘ ì²˜ë¦¬ë˜ì—ˆë‹¤. cylì€ í‰ê· ìœ¼ë¡œ ê²°ì¸¡ê°’ì„ ëŒ€ì¹˜í•˜ì˜€ê³ , qsecëŠ” ì¤‘ì•™ê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ëŒ€ì¹˜í•˜ì˜€ë‹¤. | . 3 &#51096;&#47803;&#46108; &#44050;&#51012; &#50732;&#48148;&#47476;&#44172; &#48320;&#44221; . gearì—´ì— ì˜ë„ì¹˜ ì•Šì€ íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆê³ , ë°ì´í„° íƒ€ì… ë˜í•œ objectë¡œ ì¸ì‹ë¨ì„ ì•Œ ìˆ˜ ìˆë‹¤. . X[&#39;gear&#39;].unique() . array([&#39;4&#39;, &#39;3&#39;, &#39;*3&#39;, &#39;5&#39;, &#39;*5&#39;], dtype=object) . X[&#39;gear&#39;].value_counts() . 3 14 4 12 5 4 *3 1 *5 1 Name: gear, dtype: int64 . *3, *5 ì˜ëª»ë“¤ì–´ê°„ ì• ë“¤..! | $*3 to 3, *5 to 5$ ë¡œ ìˆ˜ì •í•˜ì. (2ê°œë§Œ ì²˜ë¦¬í•˜ë©´ ë  ë“¯í•˜ë‹¤..) | . X[&#39;gear&#39;] = X[&#39;gear&#39;].replace(&#39;*3&#39;,&#39;3&#39;).replace(&#39;*5&#39;,&#39;5&#39;) X[&#39;gear&#39;].value_counts() . 3 15 4 12 5 5 Name: gear, dtype: int64 . ì˜ ë³€í™˜ë˜ì—ˆë‹¤..ã…ã… | . 4 &#51060;&#49345;&#44050; &#52376;&#47532; . ì´ìƒê°’ì€ ì •ìƒì ì¸ ë°ì´í„°ì˜ ë²”ìœ„ë¥¼ ë„˜ì–´ì„œëŠ” ë¹„ì •ìƒì¸ ê°’ìœ¼ë¡œ, data scalingë³´ë‹¤ ì„ í–‰ë˜ì–´ì•¼ í•œë‹¤. data scaling ì´í›„ì— ì´ìƒê°’ì„ ì²˜ë¦¬í•œë‹¤ë©´, ë°ì´í„°ì˜ ë¶„í¬ê°€ ì™œê³¡ë˜ê±°ë‚˜ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ì˜ ìˆ˜í–‰ì´ ë‹¤ì‹œ í•„ìš”í• ìˆ˜ë„ ìˆë‹¤. . ë¹…ë¶„ê¸° ì‹œí—˜ì—ì„œëŠ” ì´ìƒê°’ì˜ ì²˜ë¦¬ë°©ì‹ì„ ë°ì´í„° ì‚­ì œê°€ ì•„ë‹Œ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ êµì²´í•  ê²ƒì„ ì¶”ì²œí•œë‹¤. . ë§Œì•½, ì´ìƒê°’ì„ ì œê±°í•˜ë¼ê³  ëª…ì‹œë˜ì–´ìˆë‹¤ë©´, ë¬¸ì œì˜ ìš”êµ¬ëŒ€ë¡œ ì²˜ë¦¬í•˜ë©´ ëœë‹¤. . - &#49324;&#48516;&#50948;&#49688; &#54876;&#50857; . ì™¼ìª½ì— ìœ„ì¹˜í•œ ì´ìƒê°’ (ì‘ì€) : $Q1 - 1.5 * IQR$ ì˜¤ë¥¸ìª½ì— ìœ„ì¹˜í•œ ì´ìƒê°’ (í°) : $Q3 + 1.5 * IQR$ . X_describe = X.describe() print(X_describe) . cyl disp hp drat wt qsec count 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 mean 7.600000 230.721875 146.687500 3.596563 3.217250 19.795938 std 7.925459 123.938694 68.562868 0.534679 0.978457 15.066831 min 4.000000 71.100000 52.000000 2.760000 1.513000 0.100000 25% 4.000000 120.825000 96.500000 3.080000 2.581250 16.827500 50% 6.000000 196.300000 123.000000 3.695000 3.325000 17.600000 75% 8.000000 326.000000 180.000000 3.920000 3.610000 18.682500 max 50.000000 472.000000 335.000000 4.930000 5.424000 100.000000 vs carb count 32.000000 32.0000 mean 0.437500 2.8125 std 0.504016 1.6152 min 0.000000 1.0000 25% 0.000000 2.0000 50% 0.000000 2.0000 75% 1.000000 4.0000 max 1.000000 8.0000 . print(X_describe.loc[&#39;75%&#39;],X_describe.loc[&#39;25%&#39;]) . cyl 8.0000 disp 326.0000 hp 180.0000 drat 3.9200 wt 3.6100 qsec 18.6825 vs 1.0000 carb 4.0000 Name: 75%, dtype: float64 cyl 4.00000 disp 120.82500 hp 96.50000 drat 3.08000 wt 2.58125 qsec 16.82750 vs 0.00000 carb 2.00000 Name: 25%, dtype: float64 . x_iqr = X_describe.loc[&#39;75%&#39;] - X_describe.loc[&#39;25%&#39;] print(x_iqr) . cyl 4.00000 disp 205.17500 hp 83.50000 drat 0.84000 wt 1.02875 qsec 1.85500 vs 1.00000 carb 2.00000 dtype: float64 . print(&#39;[ q3 + 1.5 * iqr ]&#39;) print(X_describe.loc[&#39;75%&#39;] + (1.5 * x_iqr)) print() print(&#39;[ q1 - 1.5 * iqr ]&#39;) print(X_describe.loc[&#39;25%&#39;] - (1.5 * x_iqr)) . [ q3 + 1.5 * iqr ] cyl 14.000000 disp 633.762500 hp 305.250000 drat 5.180000 wt 5.153125 qsec 21.465000 vs 2.500000 carb 7.000000 dtype: float64 [ q1 - 1.5 * iqr ] cyl -2.000000 disp -186.937500 hp -28.750000 drat 1.820000 wt 1.038125 qsec 14.045000 vs -1.500000 carb -1.000000 dtype: float64 . print(X_describe.loc[&#39;max&#39;]) print() print(X_describe.loc[&#39;min&#39;]) . cyl 50.000 disp 472.000 hp 335.000 drat 4.930 wt 5.424 qsec 100.000 vs 1.000 carb 8.000 Name: max, dtype: float64 cyl 4.000 disp 71.100 hp 52.000 drat 2.760 wt 1.513 qsec 0.100 vs 0.000 carb 1.000 Name: min, dtype: float64 . X_describe.loc[&#39;max&#39;] &gt; X_describe.loc[&#39;75%&#39;] + (1.5 * x_iqr) . cyl True disp False hp True drat False wt True qsec True vs False carb True dtype: bool . X_describe.loc[&#39;min&#39;] &lt; X_describe.loc[&#39;25%&#39;] - (1.5 * x_iqr) . cyl False disp False hp False drat False wt False qsec True vs False carb False dtype: bool . cyl, hp, wt, qsec, carb ë³€ìˆ˜ì— ëŒ€í•´ì„œ ì´ìƒì¹˜ë¥¼ ì²˜ë¦¬í•´ì£¼ë©´ ë˜ê² ë‹¤.. | . X.loc[X[&#39;cyl&#39;] &gt; 14] . cyl disp hp drat wt qsec vs am gear carb . 14 50.0 | 472.0 | 205 | 2.93 | 5.25 | 17.98 | 0 | auto | 3 | 4 | . X.loc[X[&#39;hp&#39;] &gt; 305.25] . cyl disp hp drat wt qsec vs am gear carb . 30 8.0 | 301.0 | 335 | 3.54 | 3.57 | 14.6 | 0 | manual | 5 | 8 | . X.loc[14, &#39;cyl&#39;] = 14 X.loc[30, &#39;hp&#39;] = 305.25 . print(X.loc[14, &#39;cyl&#39;],X.loc[30, &#39;hp&#39;]) . 14.0 305.25 . - &#54217;&#44512;&#44284; &#54364;&#51456;&#54200;&#52264; &#54876;&#50857; . $ text{ìµœëŒ€ ê²½ê³„ê°’} = text{í‰ê· } + 1.5 * text{í‘œì¤€í¸ì°¨}$ $ text{ìµœì†Œ ê²½ê³„ê°’} = text{í‰ê· } - 1.5 * text{í‘œì¤€í¸ì°¨}$ . def outlier(data, column): mean = data[column].mean() std = data[column].std() lowest = mean - (std * 1.5) highest = mean + (std * 1.5) print(&#39;ìµœì†Œ ê²½ê³„ê°’: &#39;, lowest, &#39;ìµœëŒ€ê²½ê³„ê°’:&#39;, highest) outlier_index = data[column][(data[column]&lt;lowest) | (data[column] &gt; highest) ].index return outlier_index . print(outlier(X,&#39;qsec&#39;)) print() print(X.loc[24,&#39;qsec&#39;]) . ìµœì†Œ ê²½ê³„ê°’: -2.8043094560577657 ìµœëŒ€ê²½ê³„ê°’: 42.39618445605777 Int64Index([24], dtype=&#39;int64&#39;) 100.0 . X.loc[24, &#39;qsec&#39;] = 42.245 X.loc[24, &#39;qsec&#39;] . 42.245 . print(outlier(X,&#39;carb&#39;)) print() print(X.loc[[29,30],&#39;carb&#39;]) . ìµœì†Œ ê²½ê³„ê°’: 0.3897000335522218 ìµœëŒ€ê²½ê³„ê°’: 5.235299966447778 Int64Index([29, 30], dtype=&#39;int64&#39;) 29 6 30 8 Name: carb, dtype: int64 . X.loc[29, &#39;carb&#39;] = 5.235 X.loc[30, &#39;carb&#39;] = 5.235 X.loc[[29,30], &#39;carb&#39;] . 29 5.235 30 5.235 Name: carb, dtype: float64 . 5&#45936;&#51060;&#53552;&#47484; &#46041;&#51068;&#54620; &#48276;&#50948;&#47196; &#47582;&#52628;&#44592; : &#45936;&#51060;&#53552; &#49828;&#52992;&#51068;&#47553; . Standard Scaling | Min-Max Scaling | Robust Scaling | . from sklearn.preprocessing import StandardScaler temp = X[[&#39;qsec&#39;]] scaler = StandardScaler() scaler.fit_transform(temp)[:4] . array([[-0.27330047], [-0.17334038], [ 0.11047486], [-3.19356296]]) . qsec_s_scaler = pd.DataFrame(scaler.fit_transform(temp)) print(qsec_s_scaler.describe()) . 0 count 3.200000e+01 mean -2.207436e-16 std 1.016001e+00 min -3.193563e+00 25% -2.077017e-01 50% -6.981029e-02 75% 1.234161e-01 max 4.329326e+00 . from sklearn.preprocessing import MinMaxScaler temp = X[[&#39;qsec&#39;]] scaler = MinMaxScaler() qsec_m_scaler = pd.DataFrame(scaler.fit_transform(temp)) print(qsec_m_scaler.describe()) . 0 count 32.000000 mean 0.424513 std 0.135055 min 0.000000 25% 0.396904 50% 0.415233 75% 0.440918 max 1.000000 . from sklearn.preprocessing import RobustScaler temp = X[[&#39;qsec&#39;]] scaler = RobustScaler() qsec_r_scaler = pd.DataFrame(scaler.fit_transform(temp)) print(qsec_r_scaler.describe()) . 0 count 32.000000 mean 0.210832 std 3.068398 min -9.433962 25% -0.416442 50% 0.000000 75% 0.583558 max 13.285714 . 6 &#45936;&#51060;&#53552; &#53440;&#51077; &#48320;&#44221; . X ë°ì´í„°ì˜ ìš”ì•½ì •ë³´ë¥¼ í†µí•´ì„œ ê° ì—´ë³„ë¡œ ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ë°ì´í„° íƒ€ì…(object, string)ê³¼ ì—°ì†í˜• ë³€ìˆ˜ì˜ ë°ì´í„° íƒ€ì…(int64, float64)ìœ¼ë¡œ ì í•©í•˜ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ë§Œì•½ ë²”ì£¼í˜• ë³€ìˆ˜ê°€ ì—°ì†í˜• íƒ€ì…ìœ¼ë¡œ ë˜ì–´ìˆê±°ë‚˜, ê·¸ ë°˜ëŒ€ì˜ ê²½ìš°ê°€ ìˆë‹¤ë©´ astype() í•¨ìˆ˜ë¥¼ í†µí•´ì„œ ë°ì´í„° íƒ€ì…ì„ ì¬ì„¤ì • í•©ë‹ˆë‹¤. . print(X.info()) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 cyl 32 non-null float64 1 disp 32 non-null float64 2 hp 32 non-null float64 3 drat 32 non-null float64 4 wt 32 non-null float64 5 qsec 32 non-null float64 6 vs 32 non-null int64 7 am 32 non-null object 8 gear 32 non-null object 9 carb 32 non-null float64 dtypes: float64(7), int64(1), object(2) memory usage: 2.6+ KB None . X[&#39;gear&#39;].value_counts() . 3 15 4 12 5 5 Name: gear, dtype: int64 . í™•ì¸ ê²°ê³¼ ì „ì§„ê¸°ì–´ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•˜ëŠ” gear ì—´ì´ object íƒ€ì…ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ìˆ˜ì¹˜í˜• (int64)ìœ¼ë¡œ ë³€ê²½ | . 7 &#47928;&#51088;&#47196; &#44396;&#49457;&#46108; &#48276;&#51452;&#54805; &#45936;&#51060;&#53552;&#47484; &#49707;&#51088;&#54805;&#51004;&#47196; &#48320;&#44221; . X[&#39;gear&#39;] = X[&#39;gear&#39;].astype(&#39;int64&#39;) X[&#39;gear&#39;].dtype . dtype(&#39;int64&#39;) . &#48276;&#51452;&#54805;&#51012; &#49688;&#52824;&#54805;&#51004;&#47196; &#48320;&#44221; : &#51064;&#53076;&#46377;(Encoding) . ë°ì´í„° ë¶„ì„ì€ ì»´í“¨í„°ì— ì˜í•´ ìˆ˜í–‰ë˜ê¸° ë•Œë¬¸ì—, ì£¼ì–´ì§„ ë°ì´í„°ëŠ” ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ í•œê¸€ì´ë‚˜ ì˜ë¬¸ ë“±ì˜ ë¬¸ìì—´ ë°ì´í„°ëŠ” ì»´í“¨í„°ê°€ ì´í•´í•˜ê¸° ì–´ë ¤ìš°ë¯€ë¡œ ìˆ«ìí˜•ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê³¼ì •ì„ ì¸ì½”ë”© ì´ë¼ê³  í•©ë‹ˆë‹¤. . One-Hot Encoding | Label Encoding | ìˆ˜ë™ ì¸ì½”ë”© (Replace) | . - &#50896;-&#54635; &#51064;&#53076;&#46377; . print(X.head()) print() # amì—´ì—ì„œ ì¤‘ë³µ ì œê±°í•œ ê°’ í™•ì¸ print(X[&#39;am&#39;].unique()) . cyl disp hp drat wt qsec vs am gear carb 0 6.0 160.0 110.0 3.90 2.620 16.46 0 manual 4 4.0 1 6.0 160.0 110.0 3.90 2.875 17.02 0 manual 4 4.0 2 4.0 108.0 93.0 3.85 2.320 18.61 1 manual 4 1.0 3 6.0 258.0 110.0 3.08 3.215 0.10 1 auto 3 1.0 4 8.0 360.0 175.0 3.15 3.440 17.02 0 auto 3 2.0 [&#39;manual&#39; &#39;auto&#39;] . pd.get_dummies(X[&#39;am&#39;]).head() . auto manual . 0 0 | 1 | . 1 0 | 1 | . 2 0 | 1 | . 3 1 | 0 | . 4 1 | 0 | . - í•˜ë‚˜ì˜ ì—´ë§Œìœ¼ë¡œ auto, manual ê°’ í‘œí˜„í•˜ë ¤ë©´? $ to$ drop_first=True ì˜µì…˜ì¶”ê°€ . pd.get_dummies(X[&#39;am&#39;], drop_first=True).head() . manual . 0 1 | . 1 1 | . 2 1 | . 3 0 | . 4 0 | . pd.get_dummies(X, drop_first=True).head() . cyl disp hp drat wt qsec vs gear carb am_manual . 0 6.0 | 160.0 | 110.0 | 3.90 | 2.620 | 16.46 | 0 | 4 | 4.0 | 1 | . 1 6.0 | 160.0 | 110.0 | 3.90 | 2.875 | 17.02 | 0 | 4 | 4.0 | 1 | . 2 4.0 | 108.0 | 93.0 | 3.85 | 2.320 | 18.61 | 1 | 4 | 1.0 | 1 | . 3 6.0 | 258.0 | 110.0 | 3.08 | 3.215 | 0.10 | 1 | 3 | 1.0 | 0 | . 4 8.0 | 360.0 | 175.0 | 3.15 | 3.440 | 17.02 | 0 | 3 | 2.0 | 0 | . - &#46972;&#48296;&#51064;&#53076;&#46377; . print(X[&#39;am&#39;].head()) . 0 manual 1 manual 2 manual 3 auto 4 auto Name: am, dtype: object . from sklearn.preprocessing import LabelEncoder encoder = LabelEncoder() print(encoder.fit_transform(X[&#39;am&#39;])) . [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1] . fruit = [&#39;apple&#39;,&#39;bananas&#39;,&#39;grape&#39;] encoder = LabelEncoder() fruit_new = encoder.fit_transform(fruit) print(fruit) print(fruit_new) . [&#39;apple&#39;, &#39;bananas&#39;, &#39;grape&#39;] [0 1 2] . - &#49688;&#46041; &#51064;&#53076;&#46377; (Replace) . ë°ì´í„° ê°’ì˜ ì¢…ë¥˜ê°€ ë§ì§€ ì•Šì€ ê²½ìš°ëŠ” replace() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ì¸ì½”ë”©ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ í•©ê²©/ë¶ˆí•©ê²© ê°’, ì‹ ì²­/ë¯¸ì‹ ì²­ ê°’, ë°©ë¬¸/ë¯¸ë°©ë¬¸ ë“±ì˜ ì´ì§„ ë°ì´í„°ë¼ë©´ ìˆ˜ë™ìœ¼ë¡œ ì¸ì½”ë”© í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤. . X[&#39;am_new&#39;]=X[&#39;am&#39;].replace(&#39;manual&#39;,0).replace(&#39;auto&#39;,1) print(X.head()) . cyl disp hp drat wt qsec vs am gear carb am_new 0 6.0 160.0 110.0 3.90 2.620 16.46 0 manual 4 4.0 0 1 6.0 160.0 110.0 3.90 2.875 17.02 0 manual 4 4.0 0 2 4.0 108.0 93.0 3.85 2.320 18.61 1 manual 4 1.0 0 3 6.0 258.0 110.0 3.08 3.215 0.10 1 auto 3 1.0 1 4 8.0 360.0 175.0 3.15 3.440 17.02 0 auto 3 2.0 1 . X = X.drop(columns=[&#39;am&#39;]) print(X.head()) . cyl disp hp drat wt qsec vs gear carb am_new 0 6.0 160.0 110.0 3.90 2.620 16.46 0 4 4.0 0 1 6.0 160.0 110.0 3.90 2.875 17.02 0 4 4.0 0 2 4.0 108.0 93.0 3.85 2.320 18.61 1 4 1.0 0 3 6.0 258.0 110.0 3.08 3.215 0.10 1 3 1.0 1 4 8.0 360.0 175.0 3.15 3.440 17.02 0 3 2.0 1 . 8 &#54028;&#49373;&#48320;&#49688; &#47564;&#46308;&#44592; . íŠ¹ì •í•œ ì¡°ê±´ì´ë‚˜ í•¨ìˆ˜ì— ì˜í•´ì„œ ìƒˆë¡­ê²Œ ì˜ë¯¸ë¥¼ ë¶€ì—¬í•´ì„œ ë§Œë“œëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤. . ì²« ë²ˆì§¸ë¡œ ë§Œë“¤ íŒŒìƒë³€ìˆ˜ëŠ” ë¬´ê²Œë¥¼ ì˜ë¯¸í•˜ëŠ” wt ì—´ì— ë”°ë¼ì„œ ë“±ê¸‰ì„ êµ¬ë¶„í•˜ëŠ” wt_class(ë¬´ê²Œì— ë”°ë¥¸ êµ¬ë¶„)ì…ë‹ˆë‹¤. wtì—´ì˜ í‰ê· ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë¬´ê²Œì˜ ë“±ê¸‰ì„ ë‚˜ëˆŒ ê²ƒì…ë‹ˆë‹¤. . import numpy as np np.round(X[&#39;wt&#39;].mean(),2) . 3.22 . condition = X[&#39;wt&#39;] &lt; np.round(X[&#39;wt&#39;].mean(),2) # ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ 0 X.loc[condition, &#39;wt_class&#39;] = 0 # ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë©´ 1 X.loc[~condition, &#39;wt_class&#39;] = 1 . X[[&#39;wt&#39;, &#39;wt_class&#39;]].head() . wt wt_class . 0 2.620 | 0.0 | . 1 2.875 | 0.0 | . 2 2.320 | 0.0 | . 3 3.215 | 0.0 | . 4 3.440 | 1.0 | . X = X.drop(columns = [&#39;wt&#39;]) X.head() . cyl disp hp drat qsec vs gear carb am_new wt_class . 0 6.0 | 160.0 | 110.0 | 3.90 | 16.46 | 0 | 4 | 4.0 | 0 | 0.0 | . 1 6.0 | 160.0 | 110.0 | 3.90 | 17.02 | 0 | 4 | 4.0 | 0 | 0.0 | . 2 4.0 | 108.0 | 93.0 | 3.85 | 18.61 | 1 | 4 | 1.0 | 0 | 0.0 | . 3 6.0 | 258.0 | 110.0 | 3.08 | 0.10 | 1 | 3 | 1.0 | 1 | 0.0 | . 4 8.0 | 360.0 | 175.0 | 3.15 | 17.02 | 0 | 3 | 2.0 | 1 | 1.0 | . ë‘ ë²ˆì§¸ë¡œ ë§Œë“¤ íŒŒìƒë³€ìˆ˜ëŠ” qsec ì—´(1/4mile ë„ë‹¬ ì‹œê°„) ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ qsec_4(1mileë„ë‹¬ ì‹œê°„ì„ ì˜ë¯¸)ì…ë‹ˆë‹¤. ì´ëŠ” qsec ì—´ ë‹¨ìœ„ë¥¼ 1/4mile ë‹¨ìœ„ì—ì„œ 1mile ë‹¨ìœ„ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ì„œ ìƒì„±í•˜ëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤. ì¦‰, í˜„ì¬ qsec ì—´ ê°’ì„ 4ë°° í•˜ì—¬ 1mile ë‹¹ ë„ë‹¬ ì‹œê°„ì„ ì˜ë¯¸í•˜ëŠ” qsec_4 ë³€ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. . X[&#39;qsec_4&#39;] = X[&#39;qsec&#39;] * 4 X[[&#39;qsec&#39;,&#39;qsec_4&#39;]].head() . qsec qsec_4 . 0 16.46 | 65.84 | . 1 17.02 | 68.08 | . 2 18.61 | 74.44 | . 3 0.10 | 0.40 | . 4 17.02 | 68.08 | . X = X.drop(columns=[&#39;qsec&#39;]) X.head() . cyl disp hp drat vs gear carb am_new wt_class qsec_4 . 0 6.0 | 160.0 | 110.0 | 3.90 | 0 | 4 | 4.0 | 0 | 0.0 | 65.84 | . 1 6.0 | 160.0 | 110.0 | 3.90 | 0 | 4 | 4.0 | 0 | 0.0 | 68.08 | . 2 4.0 | 108.0 | 93.0 | 3.85 | 1 | 4 | 1.0 | 0 | 0.0 | 74.44 | . 3 6.0 | 258.0 | 110.0 | 3.08 | 1 | 3 | 1.0 | 1 | 0.0 | 0.40 | . 4 8.0 | 360.0 | 175.0 | 3.15 | 0 | 3 | 2.0 | 1 | 1.0 | 68.08 | . &#47784;&#45944; &#49373;&#49457; &#48143; &#44160;&#51613; . &#54617;&#49845; &#45936;&#51060;&#53552;&#50752; &#53580;&#49828;&#53944; &#45936;&#51060;&#53552; &#48516;&#47532; . from sklearn.model_selection import train_test_split . X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=10) . print(X_train.shape, X_test.shape) print(y_train.shape, y_test.shape) . (22, 10) (10, 10) (22,) (10,) . X_train.head() . cyl disp hp drat vs gear carb am_new wt_class qsec_4 . 19 4.0 | 71.1 | 65.0 | 4.22 | 1 | 4 | 1.0 | 0 | 0.0 | 79.60 | . 14 14.0 | 472.0 | 205.0 | 2.93 | 0 | 3 | 4.0 | 1 | 1.0 | 71.92 | . 18 4.0 | 75.7 | 52.0 | 4.93 | 1 | 4 | 2.0 | 0 | 0.0 | 74.08 | . 6 8.0 | 360.0 | 245.0 | 3.21 | 0 | 3 | 4.0 | 1 | 1.0 | 63.36 | . 11 8.0 | 275.8 | 180.0 | 3.07 | 0 | 3 | 3.0 | 1 | 1.0 | 69.60 | . y_train.head() . 19 33.9 14 10.4 18 30.4 6 14.3 11 16.4 Name: mpg, dtype: float64 . X_test.head() . cyl disp hp drat vs gear carb am_new wt_class qsec_4 . 20 4.0 | 120.1 | 97.0 | 3.70 | 1 | 3 | 1.0 | 1 | 0.0 | 80.04 | . 7 7.6 | 146.7 | 62.0 | 3.69 | 1 | 4 | 2.0 | 1 | 0.0 | 80.00 | . 5 6.0 | 225.0 | 105.0 | 2.76 | 1 | 3 | 1.0 | 1 | 1.0 | 80.88 | . 2 4.0 | 108.0 | 93.0 | 3.85 | 1 | 4 | 1.0 | 0 | 0.0 | 74.44 | . 3 6.0 | 258.0 | 110.0 | 3.08 | 1 | 3 | 1.0 | 1 | 0.0 | 0.40 | . y_test.head() . 20 21.5 7 24.4 5 18.1 2 22.8 3 21.4 Name: mpg, dtype: float64 . &#47784;&#45944;&#47553; . &#49440;&#54805;&#54924;&#44480; (Linear Regression) . from sklearn.linear_model import LinearRegression # ì„ í˜•íšŒê·€ ë¶„ì„ì„ ìˆ˜í–‰í•  ê¸°ë³¸ì ì¸ ëª¨ë¸(model) ë§Œë“¤ê¸° model = LinearRegression() # ìƒì„±í•œ ëª¨ë¸ì— X_train, y_trainì„ ì „ë‹¬í•´ì„œ ì„ í˜•íšŒê·€ ë°©ë²•ìœ¼ë¡œ í•™ìŠµ model.fit(X_train, y_train) # í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ì— x_trainì„ ì „ë‹¬í•˜ì—¬ y_trian ê°’ ì˜ˆì¸¡ y_train_predicted = model.predict(X_train) # í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ì— X_testì„ ì „ë‹¬í•˜ì—¬ y_test ê°’ ì˜ˆì¸¡ y_test_predicted = model.predict(X_test) . print(model.intercept_) . 24.26181219199409 . print(model.coef_) . [-0.13817819 -0.01231325 -0.00409076 0.96656685 1.12173056 0.65741573 -1.9744834 -3.58098353 0.02124373 0.02402967] . print(model.score(X_train, y_train)) . 0.9063023662021511 . print(model.score(X_test, y_test)) . 0.10162785154970966 . ê²°ê³¼ë¡œ í•™ìŠµë°ì´í„°ì˜ ê²°ì •ê³„ìˆ˜ëŠ” 0.9ë¡œ ë§¤ìš° ë†’ê²Œë‚˜íƒ€ë‚¬ì§€ë§Œ í…ŒìŠ¤íŠ¸ ì…‹ì˜ ê²°ì •ê³„ìˆ˜ê°€ 0.1ë¡œ ë§¤ìš° ë‚®ê²Œ ë‚˜ì™”ë‹¤. (ê³¼ëŒ€ì í•©) . from sklearn.metrics import r2_score # MAEë¥¼ ê³„ì‚°í•˜ëŠ” mean_absolute_error í•¨ìˆ˜ from sklearn.metrics import mean_absolute_error # MSEë¥¼ ê³„ì‚°í•˜ëŠ” mean_squared_error í•¨ìˆ˜ from sklearn.metrics import mean_squared_error # ì œê³±ê·¼ ê³„ì‚°ì„ ìœ„í•˜ì—¬ numpy ë¼ì´ë¸ŒëŸ¬ë¦¬ import numpy as np . print(&#39;r2_score_train: &#39;,r2_score(y_train, y_train_predicted)) print(&#39;r2_score_test: &#39;,r2_score(y_test, y_test_predicted)) print(&#39;MSE_test: &#39;,mean_squared_error(y_test, y_test_predicted)) print(&#39;RMSE_test: &#39;,np.sqrt(mean_squared_error(y_test, y_test_predicted))) print(&#39;MAE_test: &#39;, mean_absolute_error(y_test, y_test_predicted)) . r2_score_train: 0.9063023662021511 r2_score_test: 0.10162785154970966 MSE_test: 8.924428922705184 RMSE_test: 2.987378269102389 MAE_test: 2.3752487909100055 .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/11/14/bigdata-test-study.html",
            "relUrl": "/python/2022/11/14/bigdata-test-study.html",
            "date": " â€¢ Nov 14, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "(OpenCV - Chap6) í™”ì†Œì²˜ë¦¬2",
            "content": "",
            "url": "https://pinkocto.github.io/BP2022/python/2022/11/10/opencv.html",
            "relUrl": "/python/2022/11/10/opencv.html",
            "date": " â€¢ Nov 10, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Crack",
            "content": "import matplotlib.pyplot as plt import seaborn as sns import keras from keras.models import Sequential from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout from keras.preprocessing.image import ImageDataGenerator from keras.optimizers import Adam, RMSprop, Adagrad from keras.layers import BatchNormalization from sklearn.metrics import classification_report,confusion_matrix import tensorflow as tf import cv2 import os import time import numpy as np import warnings warnings.filterwarnings(&#39;ignore&#39;) . print(keras.__version__) print(cv2.__version__) print(sns.__version__) print(np.__version__) . 2.10.0 4.6.0 0.12.0 1.23.4 . os.getcwd() # í˜„ì¬ ì‘ì—… í´ë” . &#39;C: Users hanka Desktop dino BP2022 _notebooks&#39; . labels = [&#39;Negative_500&#39;, &#39;Positive_500&#39;] img_size = 120 # ì–´ë”” í´ë”ì˜ Nagative, Postiveë¥¼ ë¶ˆëŸ¬ì˜¤ê² ë‹¤. def read_images(data_dir): data = [] for label in labels: path = os.path.join(data_dir, label) class_num = labels.index(label) for img in os.listdir(path): try: img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # ì´ë¯¸ì§€ ë³€ê²½ resized_arr = cv2.resize(img_arr, (img_size, img_size)) data.append([resized_arr, class_num]) except Exception as e: print(e) return np.array(data) Dataset = read_images(&#39;./data/Surface_Crack_Detection_small&#39;) . print( Dataset.shape ) print( Dataset[0][0], Dataset[0][1]) # í”¼ì²˜ì™€ Target . (1000, 2) [[172 161 149 ... 183 182 184] [174 166 147 ... 176 175 177] [176 171 170 ... 180 176 176] ... [163 166 170 ... 175 175 173] [158 155 164 ... 172 173 171] [161 153 154 ... 170 172 170]] 0 . data_dir = &#39;./data/Surface_Crack_Detection_small&#39; path_negative = os.path.join(data_dir, &quot;Negative_500&quot;) path_positive = os.path.join(data_dir, &quot;Positive_500&quot;) # íŒŒì¼ ë° í´ë” ë‚´ìš© í™•ì¸ print( len(os.listdir(path_negative) )) print( len(os.listdir(path_positive) )) num_n = len(os.listdir(path_negative) ) num_p = len(os.listdir(path_positive) ) num = [num_n, num_p] . 500 500 . &#54028;&#51068; &#44060;&#49688; &#54869;&#51064; . Im = [&#39;Negative&#39;, &#39;Positive&#39;] num = [num_n, num_p] plt.figure(figsize=(10, 6)) x = np.arange(2) plt.bar(Im, num) . &lt;BarContainer object of 2 artists&gt; . Dataset[0] . array([array([[172, 161, 149, ..., 183, 182, 184], [174, 166, 147, ..., 176, 175, 177], [176, 171, 170, ..., 180, 176, 176], ..., [163, 166, 170, ..., 175, 175, 173], [158, 155, 164, ..., 172, 173, 171], [161, 153, 154, ..., 170, 172, 170]], dtype=uint8), 0], dtype=object) . print(Dataset.shape) . (1000, 2) . Dataset[0][0] # í”½ì…€ ë°ì´í„° . array([[172, 161, 149, ..., 183, 182, 184], [174, 166, 147, ..., 176, 175, 177], [176, 171, 170, ..., 180, 176, 176], ..., [163, 166, 170, ..., 175, 175, 173], [158, 155, 164, ..., 172, 173, 171], [161, 153, 154, ..., 170, 172, 170]], dtype=uint8) . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . x = [] y = [] for feature, label in Dataset: x.append(feature) y.append(label) x = np.array(x).reshape(-1, img_size, img_size, 1) x = x / 255 y = np.array(y) print(x.shape, y.shape) . (1000, 120, 120, 1) (1000,) . plt.subplot(1, 2, 1) plt.imshow(x[300].reshape(img_size, img_size), cmap=&#39;gray&#39;) plt.axis(&#39;off&#39;) . (-0.5, 119.5, 119.5, -0.5) . plt.subplot(1, 2, 2) plt.imshow(x[500].reshape(img_size, img_size), cmap=&#39;gray&#39;) plt.axis(&#39;off&#39;) . (-0.5, 119.5, 119.5, -0.5) . model = Sequential() model.add(Conv2D(64, 3,padding=&quot;same&quot;, activation=&quot;relu&quot;, input_shape = x.shape[1:])) model.add(MaxPool2D()) model.add(Conv2D(64, 3, padding=&quot;same&quot;, activation=&quot;relu&quot;)) model.add(MaxPool2D()) model.add(Conv2D(128, 3, padding=&quot;same&quot;, activation=&quot;relu&quot;)) model.add(MaxPool2D()) model.add(Flatten()) model.add(Dense(256,activation=&quot;relu&quot;)) model.add(Dropout(0.5)) model.add(BatchNormalization()) model.add(Dense(1, activation=&quot;sigmoid&quot;)) model.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 120, 120, 64) 640 max_pooling2d (MaxPooling2D (None, 60, 60, 64) 0 ) conv2d_1 (Conv2D) (None, 60, 60, 64) 36928 max_pooling2d_1 (MaxPooling (None, 30, 30, 64) 0 2D) conv2d_2 (Conv2D) (None, 30, 30, 128) 73856 max_pooling2d_2 (MaxPooling (None, 15, 15, 128) 0 2D) flatten (Flatten) (None, 28800) 0 dense (Dense) (None, 256) 7373056 dropout (Dropout) (None, 256) 0 batch_normalization (BatchN (None, 256) 1024 ormalization) dense_1 (Dense) (None, 1) 257 ================================================================= Total params: 7,485,761 Trainable params: 7,485,249 Non-trainable params: 512 _________________________________________________________________ . start = time.time() opt = Adam(lr=1e-5) model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;]) history = model.fit(x, y, epochs = 15, batch_size = 128, validation_split = 0.25, verbose=1) print(&quot;ì†Œìš”ì‹œê°„&quot;, time.time() - start ) . Epoch 1/15 6/6 [==============================] - 11s 2s/step - loss: 0.6236 - accuracy: 0.6627 - val_loss: 0.7916 - val_accuracy: 0.0000e+00 Epoch 2/15 6/6 [==============================] - 10s 2s/step - loss: 0.5544 - accuracy: 0.7147 - val_loss: 0.8501 - val_accuracy: 0.0000e+00 Epoch 3/15 6/6 [==============================] - 10s 2s/step - loss: 0.5201 - accuracy: 0.7573 - val_loss: 0.8742 - val_accuracy: 0.0000e+00 Epoch 4/15 6/6 [==============================] - 11s 2s/step - loss: 0.4800 - accuracy: 0.7827 - val_loss: 0.8732 - val_accuracy: 0.0000e+00 Epoch 5/15 6/6 [==============================] - 11s 2s/step - loss: 0.4774 - accuracy: 0.7960 - val_loss: 0.8605 - val_accuracy: 0.0000e+00 Epoch 6/15 6/6 [==============================] - 11s 2s/step - loss: 0.4546 - accuracy: 0.8027 - val_loss: 0.8374 - val_accuracy: 0.0000e+00 Epoch 7/15 6/6 [==============================] - 10s 2s/step - loss: 0.4381 - accuracy: 0.8173 - val_loss: 0.8102 - val_accuracy: 0.0000e+00 Epoch 8/15 6/6 [==============================] - 11s 2s/step - loss: 0.4358 - accuracy: 0.8133 - val_loss: 0.7829 - val_accuracy: 0.0000e+00 Epoch 9/15 6/6 [==============================] - 11s 2s/step - loss: 0.4164 - accuracy: 0.8227 - val_loss: 0.7499 - val_accuracy: 0.0080 Epoch 10/15 6/6 [==============================] - 12s 2s/step - loss: 0.3856 - accuracy: 0.8493 - val_loss: 0.7181 - val_accuracy: 0.2400 Epoch 11/15 6/6 [==============================] - 10s 2s/step - loss: 0.3797 - accuracy: 0.8533 - val_loss: 0.6935 - val_accuracy: 0.5760 Epoch 12/15 6/6 [==============================] - 11s 2s/step - loss: 0.3373 - accuracy: 0.8827 - val_loss: 0.6736 - val_accuracy: 0.7200 Epoch 13/15 6/6 [==============================] - 11s 2s/step - loss: 0.3323 - accuracy: 0.8747 - val_loss: 0.6644 - val_accuracy: 0.7480 Epoch 14/15 6/6 [==============================] - 11s 2s/step - loss: 0.3101 - accuracy: 0.8920 - val_loss: 0.6438 - val_accuracy: 0.8880 Epoch 15/15 6/6 [==============================] - 11s 2s/step - loss: 0.3218 - accuracy: 0.8747 - val_loss: 0.6266 - val_accuracy: 0.9560 ì†Œìš”ì‹œê°„ 162.9058222770691 . plt.figure(figsize=(12, 12)) plt.style.use(&#39;ggplot&#39;) plt.subplot(2,2,1) plt.plot(history.history[&#39;accuracy&#39;]) plt.plot(history.history[&#39;val_accuracy&#39;]) plt.title(&#39;Accuracy of the Model&#39;) plt.ylabel(&#39;Accuracy&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train accuracy&#39;, &#39;validation accuracy&#39;], loc=&#39;lower right&#39;, prop={&#39;size&#39;: 12}) plt.subplot(2,2,2) plt.plot(history.history[&#39;loss&#39;]) plt.plot(history.history[&#39;val_loss&#39;]) plt.title(&#39;Loss of the Model&#39;) . Text(0.5, 1.0, &#39;Loss of the Model&#39;) . í•œ ì—í­ ë‹¹ 6ë²ˆë°–ì— í•™ìŠµì„ ëª»í•˜ë‹ˆê¹Œ 8ì—í­ê¹Œì§€ ì„±ëŠ¥ë³€í™”ê°€ ì—†ë‹¤ê°€ ê·¸ ì´í›„ì— ì˜¬ë¼ê°€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. | . &#49884;&#46020; 1. barch size&#47484; &#51460;&#50668;&#49436; &#54620; &#50640;&#54253; &#45817; &#54617;&#49845;&#54943;&#49688;&#47484; &#45720;&#47536;&#45796;. . start = time.time() opt = Adam(lr=1e-5) model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;]) history = model.fit(x, y, epochs = 15, batch_size = 16, validation_split = 0.25, verbose=1) print(&quot;ì†Œìš”ì‹œê°„&quot;, time.time() - start ) . Epoch 1/15 47/47 [==============================] - 13s 256ms/step - loss: 0.2841 - accuracy: 0.8987 - val_loss: 0.5707 - val_accuracy: 0.9680 Epoch 2/15 47/47 [==============================] - 13s 279ms/step - loss: 0.2494 - accuracy: 0.9227 - val_loss: 0.5101 - val_accuracy: 0.9760 Epoch 3/15 47/47 [==============================] - 13s 273ms/step - loss: 0.2229 - accuracy: 0.9387 - val_loss: 0.4406 - val_accuracy: 0.9880 Epoch 4/15 47/47 [==============================] - 12s 264ms/step - loss: 0.1932 - accuracy: 0.9427 - val_loss: 0.3940 - val_accuracy: 0.9680 Epoch 5/15 47/47 [==============================] - 12s 260ms/step - loss: 0.1846 - accuracy: 0.9480 - val_loss: 0.2834 - val_accuracy: 0.9920 Epoch 6/15 47/47 [==============================] - 13s 269ms/step - loss: 0.1569 - accuracy: 0.9573 - val_loss: 0.2352 - val_accuracy: 0.9840 Epoch 7/15 47/47 [==============================] - 12s 261ms/step - loss: 0.1490 - accuracy: 0.9600 - val_loss: 0.1286 - val_accuracy: 0.9960 Epoch 8/15 47/47 [==============================] - 13s 271ms/step - loss: 0.1649 - accuracy: 0.9587 - val_loss: 0.1572 - val_accuracy: 0.9560 Epoch 9/15 47/47 [==============================] - 12s 259ms/step - loss: 0.1393 - accuracy: 0.9680 - val_loss: 0.0991 - val_accuracy: 0.9760 Epoch 10/15 47/47 [==============================] - 12s 259ms/step - loss: 0.1247 - accuracy: 0.9680 - val_loss: 0.0710 - val_accuracy: 0.9720 Epoch 11/15 47/47 [==============================] - 12s 259ms/step - loss: 0.1239 - accuracy: 0.9680 - val_loss: 0.0948 - val_accuracy: 0.9560 Epoch 12/15 47/47 [==============================] - 12s 258ms/step - loss: 0.1100 - accuracy: 0.9773 - val_loss: 0.0291 - val_accuracy: 0.9920 Epoch 13/15 47/47 [==============================] - 12s 258ms/step - loss: 0.1277 - accuracy: 0.9720 - val_loss: 0.0438 - val_accuracy: 0.9800 Epoch 14/15 47/47 [==============================] - 12s 258ms/step - loss: 0.1024 - accuracy: 0.9760 - val_loss: 0.0409 - val_accuracy: 0.9840 Epoch 15/15 47/47 [==============================] - 12s 258ms/step - loss: 0.0855 - accuracy: 0.9853 - val_loss: 0.0356 - val_accuracy: 0.9880 ì†Œìš”ì‹œê°„ 185.70813751220703 . plt.figure(figsize=(12, 12)) plt.style.use(&#39;ggplot&#39;) plt.subplot(2,2,1) plt.plot(history.history[&#39;accuracy&#39;]) plt.plot(history.history[&#39;val_accuracy&#39;]) plt.title(&#39;Accuracy of the Model&#39;) plt.ylabel(&#39;Accuracy&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train accuracy&#39;, &#39;validation accuracy&#39;], loc=&#39;lower right&#39;, prop={&#39;size&#39;: 12}) plt.subplot(2,2,2) plt.plot(history.history[&#39;loss&#39;]) plt.plot(history.history[&#39;val_loss&#39;]) plt.title(&#39;Loss of the Model&#39;) . Text(0.5, 1.0, &#39;Loss of the Model&#39;) . &#49884;&#46020; 2. &#50640;&#54253;&#51012; &#45720;&#47536;&#45796;. . start = time.time() opt = Adam(lr=1e-5) model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;]) history = model.fit(x, y, epochs = 30, batch_size = 128, validation_split = 0.25, verbose=1) print(&quot;ì†Œìš”ì‹œê°„&quot;, time.time() - start ) . Epoch 1/30 6/6 [==============================] - 9s 1s/step - loss: 0.0658 - accuracy: 0.9813 - val_loss: 0.0301 - val_accuracy: 0.9920 Epoch 2/30 6/6 [==============================] - 9s 1s/step - loss: 0.0662 - accuracy: 0.9853 - val_loss: 0.0309 - val_accuracy: 0.9920 Epoch 3/30 6/6 [==============================] - 9s 2s/step - loss: 0.0661 - accuracy: 0.9867 - val_loss: 0.0340 - val_accuracy: 0.9880 Epoch 4/30 6/6 [==============================] - 9s 1s/step - loss: 0.0650 - accuracy: 0.9840 - val_loss: 0.0298 - val_accuracy: 0.9920 Epoch 5/30 6/6 [==============================] - 9s 1s/step - loss: 0.0633 - accuracy: 0.9867 - val_loss: 0.0222 - val_accuracy: 0.9960 Epoch 6/30 6/6 [==============================] - 9s 2s/step - loss: 0.0618 - accuracy: 0.9867 - val_loss: 0.0239 - val_accuracy: 0.9960 Epoch 7/30 6/6 [==============================] - 9s 2s/step - loss: 0.0608 - accuracy: 0.9880 - val_loss: 0.0283 - val_accuracy: 0.9920 Epoch 8/30 6/6 [==============================] - 9s 1s/step - loss: 0.0638 - accuracy: 0.9880 - val_loss: 0.0290 - val_accuracy: 0.9920 Epoch 9/30 6/6 [==============================] - 9s 1s/step - loss: 0.0539 - accuracy: 0.9893 - val_loss: 0.0252 - val_accuracy: 0.9920 Epoch 10/30 6/6 [==============================] - 9s 1s/step - loss: 0.0631 - accuracy: 0.9853 - val_loss: 0.0396 - val_accuracy: 0.9800 Epoch 11/30 6/6 [==============================] - 9s 1s/step - loss: 0.0568 - accuracy: 0.9867 - val_loss: 0.0223 - val_accuracy: 0.9960 Epoch 12/30 6/6 [==============================] - 9s 1s/step - loss: 0.0562 - accuracy: 0.9853 - val_loss: 0.0232 - val_accuracy: 0.9960 Epoch 13/30 6/6 [==============================] - 9s 1s/step - loss: 0.0558 - accuracy: 0.9853 - val_loss: 0.0290 - val_accuracy: 0.9880 Epoch 14/30 6/6 [==============================] - 9s 1s/step - loss: 0.0568 - accuracy: 0.9867 - val_loss: 0.0269 - val_accuracy: 0.9920 Epoch 15/30 6/6 [==============================] - 9s 1s/step - loss: 0.0501 - accuracy: 0.9880 - val_loss: 0.0386 - val_accuracy: 0.9800 Epoch 16/30 6/6 [==============================] - 9s 1s/step - loss: 0.0542 - accuracy: 0.9853 - val_loss: 0.0350 - val_accuracy: 0.9800 Epoch 17/30 6/6 [==============================] - 9s 1s/step - loss: 0.0478 - accuracy: 0.9893 - val_loss: 0.0237 - val_accuracy: 0.9960 Epoch 18/30 6/6 [==============================] - 9s 1s/step - loss: 0.0520 - accuracy: 0.9893 - val_loss: 0.0174 - val_accuracy: 1.0000 Epoch 19/30 6/6 [==============================] - 9s 1s/step - loss: 0.0501 - accuracy: 0.9867 - val_loss: 0.0186 - val_accuracy: 0.9960 Epoch 20/30 6/6 [==============================] - 9s 1s/step - loss: 0.0520 - accuracy: 0.9893 - val_loss: 0.0270 - val_accuracy: 0.9840 Epoch 21/30 6/6 [==============================] - 9s 1s/step - loss: 0.0528 - accuracy: 0.9880 - val_loss: 0.0177 - val_accuracy: 1.0000 Epoch 22/30 6/6 [==============================] - 9s 1s/step - loss: 0.0532 - accuracy: 0.9880 - val_loss: 0.0278 - val_accuracy: 0.9840 Epoch 23/30 6/6 [==============================] - 9s 1s/step - loss: 0.0449 - accuracy: 0.9893 - val_loss: 0.0273 - val_accuracy: 0.9840 Epoch 24/30 6/6 [==============================] - 9s 1s/step - loss: 0.0509 - accuracy: 0.9893 - val_loss: 0.0188 - val_accuracy: 1.0000 Epoch 25/30 6/6 [==============================] - 9s 1s/step - loss: 0.0472 - accuracy: 0.9907 - val_loss: 0.0212 - val_accuracy: 0.9960 Epoch 26/30 6/6 [==============================] - 9s 1s/step - loss: 0.0466 - accuracy: 0.9893 - val_loss: 0.0254 - val_accuracy: 0.9880 Epoch 27/30 6/6 [==============================] - 9s 1s/step - loss: 0.0426 - accuracy: 0.9920 - val_loss: 0.0262 - val_accuracy: 0.9840 Epoch 28/30 6/6 [==============================] - 9s 1s/step - loss: 0.0437 - accuracy: 0.9907 - val_loss: 0.0321 - val_accuracy: 0.9800 Epoch 29/30 6/6 [==============================] - 9s 1s/step - loss: 0.0473 - accuracy: 0.9893 - val_loss: 0.0176 - val_accuracy: 1.0000 Epoch 30/30 6/6 [==============================] - 9s 1s/step - loss: 0.0432 - accuracy: 0.9907 - val_loss: 0.0303 - val_accuracy: 0.9840 ì†Œìš”ì‹œê°„ 260.3884177207947 . plt.figure(figsize=(12, 12)) plt.style.use(&#39;ggplot&#39;) plt.subplot(2,2,1) plt.plot(history.history[&#39;accuracy&#39;]) plt.plot(history.history[&#39;val_accuracy&#39;]) plt.title(&#39;Accuracy of the Model&#39;) plt.ylabel(&#39;Accuracy&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train accuracy&#39;, &#39;validation accuracy&#39;], loc=&#39;lower right&#39;, prop={&#39;size&#39;: 12}) plt.subplot(2,2,2) plt.plot(history.history[&#39;loss&#39;]) plt.plot(history.history[&#39;val_loss&#39;]) plt.title(&#39;Loss of the Model&#39;) . Text(0.5, 1.0, &#39;Loss of the Model&#39;) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/25/crack.html",
            "relUrl": "/python/2022/10/25/crack.html",
            "date": " â€¢ Oct 25, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "(221025) MNIST",
            "content": "- CNNì˜ ê¸°ë³¸ ì´í•´ - CNNì„ ì‹¤ìŠµì„ í†µí•´ ì•Œì•„ë³´ê¸° . from IPython.display import display, Image import os, warnings warnings.filterwarnings(action=&#39;ignore&#39;) . import tensorflow as tf from tensorflow.keras import models from tensorflow.keras import layers # from tensorflow.keras import models import Sequential print(tf.__version__) . 2.10.0 . ì´ë¯¸ì§€ - Conv - Pooling - Conv - Polling - FCL (filter)3x3 2x2 (f)3x3 2x2 32ê°œ 64ê°œ . Conv: 3x3 í•„í„°, 32ê°œì˜ í•„í„°ê°œìˆ˜, ì…ë ¥ ì´ë¯¸ì§€(28,28,,1) | Maxpooling (2,2) | Conv: 3x3 í•„í„°, 64ê°œì˜ í•„í„°ê°œìˆ˜ | Maxpooling (2,2) | Fully Conneted Layer | . model = models.Sequential() model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation=&#39;relu&#39;, input_shape=(28,28,1) )) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=&#39;relu&#39; )) model.add(layers.MaxPooling2D((2, 2))) model.summary() . Model: &#34;sequential_4&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_1 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_2 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_2 (MaxPooling (None, 5, 5, 64) 0 2D) ================================================================= Total params: 18,816 Trainable params: 18,816 Non-trainable params: 0 _________________________________________________________________ . model.add( layers.Flatten() ) model.add( layers.Dense(64, activation=&#39;relu&#39;)) model.add( layers.Dense(10, activation=&#39;softmax&#39;)) . model.summary() . Model: &#34;sequential_4&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_1 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_2 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_2 (MaxPooling (None, 5, 5, 64) 0 2D) flatten (Flatten) (None, 1600) 0 dense (Dense) (None, 64) 102464 dense_1 (Dense) (None, 10) 650 ================================================================= Total params: 121,930 Trainable params: 121,930 Non-trainable params: 0 _________________________________________________________________ . from tensorflow.keras.datasets import mnist from tensorflow.keras.utils import to_categorical (train_images, train_labels), (test_images, test_labels) = mnist.load_data() . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz 11490434/11490434 [==============================] - 1s 0us/step . train_images = train_images.reshape((60000, 28, 28, 1)) train_images = train_images.astype(&#39;float32&#39;) / 255 test_images = test_images.reshape((10000, 28, 28, 1)) test_images = test_images.astype(&#39;float32&#39;) / 255 . train_labels = to_categorical(train_labels) test_labels = to_categorical(test_labels) . print(&quot;ì…ë ¥ì¸µ ë°ì´í„°(X) : &quot;,train_images.shape, test_images.shape ) print(&quot;ì¶œë ¥ì¸µ ë°ì´í„°(y) : &quot;,train_labels.shape, test_labels.shape ) . ì…ë ¥ì¸µ ë°ì´í„°(X) : (60000, 28, 28, 1) (10000, 28, 28, 1) ì¶œë ¥ì¸µ ë°ì´í„°(y) : (60000, 10) (10000, 10) . %%time model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5, batch_size=64) . Epoch 1/5 938/938 [==============================] - 19s 20ms/step - loss: 0.1647 - accuracy: 0.9501 - val_loss: 0.0481 - val_accuracy: 0.9834 Epoch 2/5 938/938 [==============================] - 19s 21ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.0359 - val_accuracy: 0.9879 Epoch 3/5 938/938 [==============================] - 20s 21ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0369 - val_accuracy: 0.9881 Epoch 4/5 938/938 [==============================] - 19s 20ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0255 - val_accuracy: 0.9912 Epoch 5/5 938/938 [==============================] - 19s 20ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.0236 - val_accuracy: 0.9924 CPU times: total: 7min 15s Wall time: 1min 36s . &lt;keras.callbacks.History at 0x20e4747ed00&gt; . test_loss, test_acc = model.evaluate(test_images, test_labels) print(test_acc) . 313/313 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9924 0.9923999905586243 . Conv &#44228;&#52789; &#52628;&#44032;&#54644;&#48372;&#44592; . model = models.Sequential() model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation=&#39;relu&#39;, input_shape=(28,28,1) )) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=&#39;relu&#39; )) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=&#39;relu&#39; )) model.add(layers.MaxPooling2D((2, 2))) model.summary() . Model: &#34;sequential_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_3 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_3 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_4 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_4 (MaxPooling (None, 5, 5, 64) 0 2D) conv2d_5 (Conv2D) (None, 3, 3, 64) 36928 max_pooling2d_5 (MaxPooling (None, 1, 1, 64) 0 2D) ================================================================= Total params: 55,744 Trainable params: 55,744 Non-trainable params: 0 _________________________________________________________________ . model.add( layers.Flatten() ) model.add( layers.Dense(64, activation=&#39;relu&#39;)) model.add( layers.Dense(10, activation=&#39;softmax&#39;)) . model.summary() . Model: &#34;sequential_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_3 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_3 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_4 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_4 (MaxPooling (None, 5, 5, 64) 0 2D) conv2d_5 (Conv2D) (None, 3, 3, 64) 36928 max_pooling2d_5 (MaxPooling (None, 1, 1, 64) 0 2D) flatten_1 (Flatten) (None, 64) 0 dense_2 (Dense) (None, 64) 4160 dense_3 (Dense) (None, 10) 650 ================================================================= Total params: 60,554 Trainable params: 60,554 Non-trainable params: 0 _________________________________________________________________ . from tensorflow.keras.datasets import mnist from tensorflow.keras.utils import to_categorical (train_images, train_labels), (test_images, test_labels) = mnist.load_data() . train_images = train_images.reshape((60000, 28, 28, 1)) train_images = train_images.astype(&#39;float32&#39;) / 255 test_images = test_images.reshape((10000, 28, 28, 1)) test_images = test_images.astype(&#39;float32&#39;) / 255 . train_labels = to_categorical(train_labels) test_labels = to_categorical(test_labels) . print(&quot;ì…ë ¥ì¸µ ë°ì´í„°(X) : &quot;,train_images.shape, test_images.shape ) print(&quot;ì¶œë ¥ì¸µ ë°ì´í„°(y) : &quot;,train_labels.shape, test_labels.shape ) . ì…ë ¥ì¸µ ë°ì´í„°(X) : (60000, 28, 28, 1) (10000, 28, 28, 1) ì¶œë ¥ì¸µ ë°ì´í„°(y) : (60000, 10) (10000, 10) . %%time model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5, batch_size=64) . Epoch 1/5 938/938 [==============================] - 20s 21ms/step - loss: 0.2627 - accuracy: 0.9182 - val_loss: 0.0972 - val_accuracy: 0.9697 Epoch 2/5 938/938 [==============================] - 21s 22ms/step - loss: 0.0785 - accuracy: 0.9762 - val_loss: 0.0790 - val_accuracy: 0.9775 Epoch 3/5 938/938 [==============================] - 22s 23ms/step - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.0549 - val_accuracy: 0.9833 Epoch 4/5 938/938 [==============================] - 22s 23ms/step - loss: 0.0432 - accuracy: 0.9871 - val_loss: 0.0490 - val_accuracy: 0.9853 Epoch 5/5 938/938 [==============================] - 21s 23ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0620 - val_accuracy: 0.9818 CPU times: total: 7min 49s Wall time: 1min 45s . &lt;keras.callbacks.History at 0x20e4879fe20&gt; . test_loss, test_acc = model.evaluate(test_images, test_labels) print(test_acc) . 313/313 [==============================] - 1s 4ms/step - loss: 0.0620 - accuracy: 0.9818 0.9818000197410583 . ì¶”ê°€ ì „ : 0.9923999905586243 | ì¶”ê°€ í›„ : 0.9818000197410583 | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/25/DNN.html",
            "relUrl": "/python/2022/10/25/DNN.html",
            "date": " â€¢ Oct 25, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "(22/10/24) ğŸ˜ Cross Validation",
            "content": "import time import gc import os, warnings import numpy as np # ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œí•˜ê±°ë‚˜ ìˆ¨ê¸¸ë•Œ(ignore), ë‹¤ì‹œë³´ì´ê²Œ(default) # warnings.filterwarnings(action=&#39;default&#39;) warnings.filterwarnings(action=&#39;ignore&#39;) . import mglearn mglearn.plots.plot_cross_validation() . from sklearn.datasets import load_iris from sklearn.neighbors import KNeighborsClassifier from sklearn.linear_model import LogisticRegression from sklearn.model_selection import cross_val_score . 00. Base . iris = load_iris() logreg = LogisticRegression() . scores = cross_val_score(logreg, iris.data, iris.target) print(scores) . [0.96666667 1. 0.93333333 0.96666667 1. ] . 01. CV=10 . scores_cv = cross_val_score(logreg, iris.data, iris.target, cv=10) print(scores_cv) . [1. 0.93333333 1. 1. 0.93333333 0.93333333 0.93333333 1. 1. 1. ] . 02. Kfold (n_splits = 3) . iris.target . array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) . from sklearn.model_selection import KFold # ê°ì²´ë¥¼ ì‚¬ìš©í•´ì„œ ë„£ì–´ì¤„ ìˆ˜ë„ ìˆë‹¤. kfold = KFold(n_splits = 3) print(&#39;êµì°¨ ê²€ì¦ ì ìˆ˜ : n{}&#39;.format(cross_val_score(logreg, iris.data, iris.target, cv=kfold))) . êµì°¨ ê²€ì¦ ì ìˆ˜ : [0. 0. 0.] . ë¬¸ì œ ë°œìƒ! | shuffle=True ì˜µì…˜ì„ ì§€ì •í•´ì£¼ì§€ ì•Šìœ¼ë©´ ì•ì—ì„œë¶€í„° 3ë“±ë¶„ ë‚˜ëˆ ì§„ë‹¤. | ê·¸ë ‡ê²Œë˜ë©´ ì²«ë²ˆì§¸ foldëŠ” 0ë§Œ, ë‘ë²ˆì§¸ foldëŠ” 1ë§Œ, ì„¸ë²ˆì§¸ foldëŠ” 2ë§Œ ìˆê²Œë˜ëŠ”ë° | . kfold_random = KFold(n_splits = 3, shuffle=True, random_state=0) print(&#39;êµì°¨ ê²€ì¦ ì ìˆ˜ : n{}&#39;.format(cross_val_score(logreg, iris.data, iris.target, cv=kfold_random))) . êµì°¨ ê²€ì¦ ì ìˆ˜ : [0.98 0.96 0.96] . ë¬¸ì œ í•´ê²°! | . 03. Boston Houst Price . from sklearn.model_selection import cross_val_score from sklearn.datasets import load_boston from sklearn.linear_model import LinearRegression import sklearn import pandas as pd import mglearn print(sklearn.__version__) . 1.1.2 . boston = load_boston() df = pd.DataFrame(boston.data, columns=boston.feature_names) df[&#39;price&#39;] = boston.target print(df.shape) . (506, 14) . X = df.drop([&#39;price&#39;], axis=1) y = df[&#39;price&#39;] . cv=5 . lr_model = LinearRegression() msescores = cross_val_score(lr_model, X, y, scoring=&#39;neg_mean_squared_error&#39;, cv=5) . rmse = np.sqrt(-1 * msescores) print(rmse) . [3.52991509 5.10378498 5.75101191 8.9867887 5.77179405] . print(&#39;í‰ê·  RMSE : {0:.3f}&#39;.format(np.mean(rmse))) . í‰ê·  RMSE : 5.829 . cv=10 . lr_model = LinearRegression() msescores = cross_val_score(lr_model, X, y, scoring=&#39;neg_mean_squared_error&#39;, cv=10) . rmse = np.sqrt(-1 * msescores) print(rmse) . [ 3.04744921 3.76181913 3.75148053 5.93354231 5.64669077 4.45374875 3.15392917 12.9759539 5.77319193 3.3106511 ] . print(&#39;í‰ê·  RMSE : {0:.3f}&#39;.format(np.mean(rmse))) . í‰ê·  RMSE : 5.181 . cvë¥¼ $5 to10$ìœ¼ë¡œ ë³€ê²½í›„ RMSEì˜ í‰ê· ì„ êµ¬í•œ ê²°ê³¼ | ì ìˆ˜ê°€ $5.829 to 5.181$ë¡œ ë–¨ì–´ì¡Œë‹¤. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/24/Cross_Validation_Class_For_Amex.html",
            "relUrl": "/python/2022/10/24/Cross_Validation_Class_For_Amex.html",
            "date": " â€¢ Oct 24, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "(OpenCV - Chap6) í™”ì†Œì²˜ë¦¬1",
            "content": "&#54868;&#49548;&#51032; &#44060;&#45392; . í™”ì†Œë€ í™”ë©´(ì˜ìƒ)ì„ êµ¬ì„±í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” ë‹¨ìœ„ë¥¼ ë§í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì˜ìƒì²˜ë¦¬ ì…ë¬¸ì—ì„œ ê°€ì¥ ë¨¼ì € ë‹¤ë£¨ëŠ” ë‚´ìš©ì´ í™”ì†Œê°’ ê¸°ë°˜ ì²˜ë¦¬ì´ë‹¤. ì´ê²ƒì€ ì˜ìƒ êµ¬ì¡°ì— ëŒ€í•´ ì•Œê¸° ìœ„í•´ ê°€ì¥ ë¨¼ì € ì´í•´í•´ì•¼ í•˜ëŠ” ê²ƒì´ í™”ì†Œì— ëŒ€í•œ ê¸°ë³¸ ê°œë…ì´ê¸° ë•Œë¬¸ì´ë‹¤. . ë””ì§€í„¸ ì˜ìƒì€ ì´ í™”ì†Œë“¤ì˜ ì§‘í•©ì„ ì˜ë¯¸í•˜ë©°, ì´ í™”ì†Œë“¤ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì—°ì‚°ì„ í•˜ëŠ” ê²ƒì´ ì˜ìƒì²˜ë¦¬ì´ë‹¤. . 6.1 &#50689;&#49345;&#54868;&#49548;&#51032; &#51217;&#44540; . ì˜ìƒì²˜ë¦¬ë¥¼ ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ ë§í•´ë³´ë©´, 2ì°¨ì› ë°ì´í„°ì— ëŒ€í•œ í–‰ë ¬ ì—°ì‚°ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì˜ìƒì„ ë‹¤ë£¨ë ¤ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ì˜ìƒì˜ í™”ì†Œì— ì ‘ê·¼í•˜ê³ , ê·¸ ê°’ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ìƒˆë¡œ ë§Œë“¤ ìˆ˜ ìˆì–´ì•¼ í•œë‹¤. . ê³¼ê±° OpenCVì™€ ê°™ì€ ëŒ€ì¤‘ì ì¸ ì˜ìƒì²˜ë¦¬ APIê°€ ì—†ì—ˆì„ ë•Œ, ì˜ìƒ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ì €ì¥í•˜ëŠ” ê²ƒì´ ì‰½ì§€ë§Œì€ ì•Šì€ ì¼ì´ì—ˆë‹¤. í•˜ì§€ë§Œ íŒŒì´ì¬ì—ì„œëŠ” í–‰ë ¬ ë°ì´í„° ì²˜ë¦¬ì— ìœ ìš©í•œ ë„˜íŒŒì´(Numpy) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì§€ì›í•˜ê³  ìˆìœ¼ë©°, OpenCV APIë„ numpy.ndarray ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ìƒ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•œë‹¤. . 6.1.1 &#54868;&#49548;(&#54665;&#47148; &#50896;&#49548;) &#51217;&#44540; . ë‹¤ìŒì€ ëª¨ë“  ì›ì†Œë¥¼ ìˆœíšŒí•˜ì—¬ ì›ì†Œê°’ì„ 2ë°°ë¡œ ë³€ê²½í•˜ëŠ” ì˜ˆì œì´ë‹¤. . - ë°©ë²•1 . í–‰ë ¬ì˜ ì›ì†Œë¥¼ ìˆœíšŒí•˜ë©° ì§ì ‘ ì›ì†Œê°’ì„ ê°€ì ¸ì™€ì„œ ê³„ì‚° . import numpy as np def mat_access1(mat): for i in range(mat.shape[0]): for j in range(mat.shape[1]): k = mat[i, j] mat[i, j] = k * 2 . mat1 = np.arange(10).reshape(2,5) mat1 . array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) . print(&#39;ì›ì†Œ ì²˜ë¦¬ ì „: n%s n&#39; % mat1) mat_access1(mat1) print(&#39;ì›ì†Œ ì²˜ë¦¬ í›„: n%s n&#39; % mat1) . ì›ì†Œ ì²˜ë¦¬ ì „: [[0 1 2 3 4] [5 6 7 8 9]] ì›ì†Œ ì²˜ë¦¬ í›„: [[ 0 2 4 6 8] [10 12 14 16 18]] . - ë°©ë²•2 . í–‰ë ¬ ì›ì†Œë¥¼ ìˆœíšŒí•˜ë©°, ndarray í´ë˜ìŠ¤ì˜ ë‚´ë¶€ ë©”ì„œë“œì¸ item() í•¨ìˆ˜ì™€ itemset() í•¨ìˆ˜ë¡œ ê°€ì ¸ì™€ì„œ ê°’ì„ ë³€ê²½ . def mat_access2(mat): for i in range(mat.shape[0]): for j in range(mat.shape[1]): k = mat.item(i, j) # mat.itemset((i, j), k*2) . mat2 = np.arange(10).reshape(2, 5) mat2 . array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) . print(&#39;ì›ì†Œ ì²˜ë¦¬ ì „: n%s n&#39; % mat2) mat_access2(mat2) print(&#39;ì›ì†Œ ì²˜ë¦¬ í›„: n%s n&#39; % mat2) . ì›ì†Œ ì²˜ë¦¬ ì „: [[0 1 2 3 4] [5 6 7 8 9]] ì›ì†Œ ì²˜ë¦¬ í›„: [[ 0 2 4 6 8] [10 12 14 16 18]] . 6.1.2 &#50689;&#49345; &#48152;&#51204;&#51012; &#49688;&#54665;&#54616;&#45716; &#45796;&#50577;&#54620; &#48169;&#48277;&#46308; . í–‰ë ¬ì„ ì²˜ë¦¬í•˜ì—¬ ì˜ìƒì˜ ë°˜ì „ì„ ìˆ˜í–‰í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì„ í•¨ìˆ˜ë¡œ ë§Œë“¤ê³ , ê° ë°©ë²•ì˜ ìˆ˜í–‰ì†ë„ë¥¼ ê³„ì‚°í•´ë³´ì. . import numpy as np, cv2, time ## í™”ì†Œ ì§ì ‘ì ‘ê·¼ def pixel_access1(image): image1 = np.zeros(image.shape[:2], image.dtype) for i in range(image.shape[0]): for j in range(image.shape[1]): pixel = image[i,j] # í™”ì†Œì ‘ê·¼ image1[i, j] = 255 - pixel # í™”ì†Œí• ë‹¹ return image1 ## item() í•¨ìˆ˜ def pixel_access2(image): # item() í•¨ìˆ˜ ì ‘ê·¼ ë°©ë²• image2 = np.zeros(image.shape[:2], image.dtype) for i in range(image.shape[0]): for j in range(image.shape[1]): pixel = image.item(i, j) # í™”ì†Œì ‘ê·¼ image2.itemset((i, j), 255 - pixel) # í™”ì†Œí• ë‹¹ return image2 ## ë£©ì—…í…Œì´ë¸” def pixel_access3(image): lut = [255 - i for i in range(256)] lut = np.array(lut, np.uint8) image3 = lut[image] return image3 ## openCV def pixel_access4(image): image4 = cv2.subtract(255, image) return image4 ## ndarray ì‚°ìˆ ì—°ì‚° def pixel_access5(image): image5 = 255 - image return image5 . image = cv2.imread(&#39;./ghtop_images/chap06_images/bright.jpg&#39;, cv2.IMREAD_GRAYSCALE) . image.shape . (450, 360) . def time_check(func, msg): start_time = time.perf_counter() ret_img = func(image) elapsed = (time.perf_counter() - start_time) * 1000 print(msg, &quot;ìˆ˜í–‰ì‹œê°„ : %0.2f ms&quot; % elapsed ) return ret_img . image1 = time_check(pixel_access1, &quot;[ë°©ë²•1] ì§ì ‘ ì ‘ê·¼ ë°©ì‹&quot;) image2 = time_check(pixel_access2, &quot;[ë°©ë²•2] item() ì ‘ê·¼ ë°©ì‹&quot;) image3 = time_check(pixel_access3, &quot;[ë°©ë²•3] ë£©ì—…í…Œì´ë¸” ë°©ì‹&quot;) image4 = time_check(pixel_access4, &quot;[ë°©ë²•4] OpenCV í•¨ìˆ˜ ë°©ì‹&quot;) image5 = time_check(pixel_access5, &quot;[ë°©ë²•5] ndarray ë°©ì‹&quot;) . [ë°©ë²•1] ì§ì ‘ ì ‘ê·¼ ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 228.04 ms [ë°©ë²•2] item() ì ‘ê·¼ ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 26.00 ms [ë°©ë²•3] ë£©ì—…í…Œì´ë¸” ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 1.54 ms [ë°©ë²•4] OpenCV í•¨ìˆ˜ ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 2.38 ms [ë°©ë²•5] ndarray ë°©ì‹ ìˆ˜í–‰ì‹œê°„ : 0.11 ms . ì‹¤í–‰ê²°ê³¼ë¥¼ ë³´ë©´, OpenCV ë˜ëŠ” ndarray ë°©ì‹ìœ¼ë¡œ í™”ì†Œì— ì ‘ê·¼í•˜ëŠ” ê²½ìš° ì†ë„ê°€ ë¹ ë¥¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. . ë”°ë¼ì„œ í™”ì†Œ ì§ì ‘ ì ‘ê·¼ ë°©ë²•ë³´ë‹¤ëŠ” OpenCVì—ì„œ ì œê³µí•˜ëŠ” í•¨ìˆ˜ë“¤ì„ ì¡°í•©í•˜ê±°ë‚˜ ndarray ê°ì²´ì˜ ì›ì†Œê°„ ì—°ì‚°ìœ¼ë¡œ êµ¬í˜„ ë‚´ìš©ì„ ë§Œë“œëŠ” ê²ƒì´ ì¢‹ë‹¤. . 6.2 &#54868;&#49548; &#48157;&#44592; &#48320;&#54872; . 6.2.1 &#44536;&#47112;&#51060; &#49828;&#52992;&#51068; (&#47749;&#50516;&#46020;) &#50689;&#49345; . ì¼ë°˜ì ìœ¼ë¡œ ì´í•´í•˜ëŠ” ì»¬ëŸ¬ê°€ ì•„ë‹Œ ì˜ìƒì„ ìš°ë¦¬ëŠ” í‘ë°±ì˜ìƒì´ë¼ê³  ì‰½ê²Œ ë¶€ë¥´ì§€ë§Œ, ì—„ë°€í•œ ì˜ë¯¸ì—ì„œ í‘ë°± ì˜ìƒì´ë¼ëŠ” ê²ƒì€ ê²€ì€ìƒ‰ê³¼ í°ìƒ‰ìœ¼ë¡œ êµ¬ì„±ëœ ì˜ìƒì„ ì˜ë¯¸í•˜ê¸° ë•Œë¬¸ì— ë‹¨ì¼ì±„ë„ ì˜ìƒì— ì´ ì´ë¦„ì„ ë¶™ì´ëŠ” ê²ƒì´ ë§ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤. . ë””ì§€í„¸ ì˜ìƒì²˜ë¦¬ì—ì„œ ë³´í†µ ë‹¨ì¼ì±„ë„ì˜ ì˜ìƒì„ ê·¸ë ˆì´ ìŠ¤ì¼€ì¼(gray-scale)ì˜ìƒ í˜¹ì€ ëª…ì•”ë„ ì˜ìƒì´ë¼ê³  í•œë‹¤. . ê·¸ë ˆì´ ìŠ¤ì¼€ì¼ ì˜ìƒ . 0~255ì˜ ê°’ì„ ê°€ì§€ëŠ” í™”ì†Œë“¤ì´ ëª¨ì—¬ì„œ êµ¬ì„±ëœ ì˜ìƒ | 0ì€ ê²€ì€ìƒ‰, 255ëŠ” í°ìƒ‰ì„ ì˜ë¯¸ | 0~255 ì‚¬ì´ ê°’ë“¤ì€ ì§„í•œ íšŒìƒ‰ì—ì„œ ì—°í•œ íšŒìƒ‰ê¹Œì§€ë¥¼ ë‚˜íƒ€ëƒ„ | . | . import numpy as np import cv2 . image1 = np.zeros((50,512), np.uint8) # 50x512 ì˜ìƒ ìƒì„± image2 = np.zeros((50,512), np.uint8) rows, cols = image1.shape[:2] for i in range(rows): for j in range(cols): image1.itemset((i,j), j//2) # í™”ì†Œê°’ ì ì§„ì  ì¦ê°€ image2.itemset((i,j), j // 20*10) # ê³„ë‹¨ í˜„ìƒ ì¦ê°€ . print(&#39;image1.shape:&#39;,image1.shape) print(&#39;image2.shape:&#39;,image2.shape) # 0ê°’ìœ¼ë¡œ ì±„ì›Œì§„ 50x512 í–‰ë ¬ print(&quot;image1&#39;s rows: &quot;, rows) print(&quot;image1&#39;s cols: &quot;, cols) . image1.shape: (50, 512) image2.shape: (50, 512) image1&#39;s rows: 50 image1&#39;s cols: 512 . cv2.imshow(&quot;image1&quot;, image1) cv2.imshow(&quot;image2&quot;, image2) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/image1_226.png&#39;, image1) # ì´ë¯¸ì§€ ì €ì¥ cv2.imwrite(&#39;./prac_image/image2_226.png&#39;, image2) # ì´ë¯¸ì§€ ì €ì¥ cv2.destroyAllWindows() . . - ì‹¤í–‰ê²°ê³¼ . image1 . ë‚˜ëˆ—ì…ˆ ëª« ì—°ì‚°ìë¡œ 2ë¡œ ë‚˜ëˆˆ ëª«ì„ ì €ì¥í•˜ëŠ” ê²ƒì€ ê°€ë¡œ ì¸ë±ìŠ¤ì˜ ì ˆë°˜ ê°’ìœ¼ë¡œ jì—´ ì›ì†Œì˜ í™”ì†Œê°’ì„ ì„¤ì •í•œ ê²ƒì´ë‹¤. ë”°ë¼ì„œ í™”ì†Œê°’ì€ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ 0ì—ì„œ 255ì˜ ê°’ê¹Œì§€ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•œë‹¤. | . image2 . (j // 20 * 10) ì€ ëª« ì—°ì‚°ìë¡œ ì¸í•´ì„œ ê³„ì‚° ê°’ì˜ ì†Œìˆ˜ ë¶€ë¶„ì€ ë‚ ë¼ê°„ë‹¤. ë”°ë¼ì„œ 20í™”ì†Œì”© ê°™ì€ ê°’ì„ ê°–ê²Œ ë˜ì–´ ê³„ë‹¨ í˜„ìƒì„ ë‚˜íƒ€ë‚´ë©° ì¦ê°€í•œë‹¤. | . 6.2.2 &#50689;&#49345;&#51032; &#54868;&#49548; &#54364;&#54788; . ì˜ìƒíŒŒì¼ì„ ì½ì–´ ë“¤ì—¬ ê·¸ ì˜ìƒì˜ íŠ¹ì • ë¶€ë¶„ì˜ í™”ì†Œë“¤ì„ í™•ì¸í•´ë³´ì. ì˜ìƒíŒŒì¼ì„ í–‰ë ¬ì— ì €ì¥í•˜ê³ , ê´€ì‹¬ ì˜ì—­ì„ ì§€ì •í•´ì„œ ì¶œë ¥í•˜ë©´ ê°„ë‹¨íˆ ì˜ìƒ ë°ì´í„°ì¸ í™”ì†Œë“¤ì˜ ê°’ì„ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤. . # ì˜ìƒ í™”ì†Œê°’ í™•ì¸ (pixel_value) import cv2 image = cv2.imread(&#39;./ghtop_images/chap06_images/pixel.jpg&#39;, cv2.IMREAD_GRAYSCALE) (x, y), (w, h) = (180, 37), (15, 10) roi_img = image[y:y+h, x:x+w] # í–‰ì€ ì‹œì‘ yì¢Œí‘œì—ì„œ y+hê¹Œì§€, ì—´ì€ ì‹œì‘ xì¢Œí‘œì—ì„œ x+wê¹Œì§€ #print(&quot;[roi img] = n&quot;, roi_img) . $(x, y)$ëŠ” ì‚¬ê°í˜•ì˜ ì‹œì‘ì¢Œí‘œ | $(w, h)$ëŠ” ì‚¬ê°í˜•ì˜ í¬ê¸° | ì¦‰, ì‚¬ê°í˜•ì˜ ì‹œì‘ì¢Œí‘œì™€ í¬ê¸°ë¡œ ê´€ì‹¬ì˜ì—­ì„ ì§€ì •í•œë‹¤. | . print(&quot;[roi_img] =&quot;) for row in roi_img: for p in row: print(&quot;%4d&quot; % p, end=&quot;&quot;) print() . [roi_img] = 56 51 59 66 84 104 154 206 220 208 203 207 205 204 204 75 57 53 53 72 71 100 152 195 214 212 201 209 207 205 88 76 65 53 51 60 73 96 143 200 219 200 206 204 202 91 92 80 63 53 59 59 61 89 144 195 222 205 200 205 89 94 90 82 63 54 51 56 65 92 149 203 223 209 196 89 91 90 89 84 64 54 55 51 56 94 140 208 223 203 91 86 84 85 97 86 72 59 50 53 66 81 148 211 216 92 86 85 88 92 95 88 70 55 53 59 64 89 155 211 88 85 86 90 87 87 89 86 72 56 50 53 59 88 175 87 85 86 88 87 84 86 90 86 70 53 44 51 56 111 . cv2.rectangle(image, (x,y,w,h) , 255, 1) # ê´€ì‹¬ ì˜ì—­ì— ì‚¬ê°í˜• í‘œì‹œ cv2.imshow(&quot;image&quot;, image) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/image_227.png&#39;, image) # ì´ë¯¸ì§€ ì €ì¥ cv2.destroyAllWindows() . . ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³´ë©´, ì˜ìƒì˜ ìš°ìƒë‹¨ì— í°ìƒ‰ì˜ ì‘ì€ ì‚¬ê°í˜•ì´ ê·¸ë ¤ì ¸ ìˆë‹¤. ì´ ì‚¬ê°í˜•ì´ ê´€ì‹¬ ì˜ì—­ì´ë©°, ì´ ì˜ì—­ì˜ í™”ì†Œê°’ê³¼ ë¹„êµí•´ë³´ì. | . print(&quot;[roi img] = n&quot;, roi_img) . [roi img] = [[255 255 255 255 255 255 255 255 255 255 255 255 255 255 255] [255 57 53 53 72 71 100 152 195 214 212 201 209 207 255] [255 76 65 53 51 60 73 96 143 200 219 200 206 204 255] [255 92 80 63 53 59 59 61 89 144 195 222 205 200 255] [255 94 90 82 63 54 51 56 65 92 149 203 223 209 255] [255 91 90 89 84 64 54 55 51 56 94 140 208 223 255] [255 86 84 85 97 86 72 59 50 53 66 81 148 211 255] [255 86 85 88 92 95 88 70 55 53 59 64 89 155 255] [255 85 86 90 87 87 89 86 72 56 50 53 59 88 255] [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255]] . ê´€ì‹¬ì˜ì—­ ì¦‰, í°ìƒ‰ ì‚¬ê°í˜•ì´ ê·¸ë ¤ì ¸ ìˆëŠ” ë¶€ë¶„ì„ ë³´ë©´ ì£¼ëŒ€ê°ì„  ìœ— ë¶€ë¶„ì€ í°ìƒ‰(ë°ì€ìƒ‰)ì´ê³  ì•„ë«ë¶€ë¶„ì€ ì§„í•œíšŒìƒ‰(ì–´ë‘ìš´ìƒ‰)ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤. | í™”ì†Œ ê°’ì„ ë³´ë©´ ì£¼ëŒ€ê°ì„  ê¸°ì¤€ ìœ—ë¶€ë¶„ì€ í™”ì†Œê°’ì€ ëŒ€ëµ $200 sim225$ë²”ìœ„ì˜ ê°’ì„ ë‚˜íƒ€ë‚´ê³ , ê·¸ ì•„ë˜ë¶€ë¶„ì€ ëŒ€ëµ $50 sim80$ë²”ìœ„ì˜ ê°’ì„ì„ í™•ì¸ | ì¦‰, í°ìƒ‰ë¶€ë¶„ì€ í™”ì†Œê°’ì´ 255ì™€ ê°€ê¹ê³ , ì–´ë‘ìš´ ë¶€ë¶„ì€ 0ì— ê°€ê¹Œìš´ ê°’ì„ ê°–ëŠ”ë‹¤. | . 6.2.3 &#50689;&#49345; &#48157;&#44592;&#51032; &#44032;&#44048;&#50689;&#49345; . í™”ì†Œê°’ì´ ì˜ìƒì˜ ë°ê¸°ë¥¼ ë‚˜íƒ€ë‚´ê¸° ë•Œë¬¸ì— ì´ í™”ì†Œê°’ì„ ë³€ê²½í•˜ë©´ ì˜ìƒì˜ ë°ê¸°ë¥¼ ë°”ê¿€ ìˆ˜ ìˆë‹¤. . ì˜ˆë¥¼ ë“¤ì–´ ì˜ìƒì˜ í™”ì†Œì— íŠ¹ì •í•œ ìƒìˆ«ê°’ì„ ë”í•˜ë©´ ì˜ìƒì´ ë°ì•„ì§€ê³ , ìƒìˆ«ê°’ì„ ë¹¼ë©´ ì˜ìƒì´ ì–´ë‘ì›Œì§„ë‹¤. | ë˜í•œ, í™”ì†Œê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìµœëŒ“ê°’(ì˜ˆë¡œ 255)ì—ì„œ ê·¸ í™”ì†Œì˜ ê°’ì„ ë¹¼ë©´ ë°˜ì „ ì˜ìƒì´ ë§Œë“¤ì–´ì§„ë‹¤. | . 6.2.4 &#54665;&#47148; &#45927;&#49480; &#48143; &#44273;&#49480;&#51012; &#51060;&#50857;&#54620; &#50689;&#49345; &#54633;&#49457; . ì˜ìƒì— ìƒìˆ˜ë¥¼ ë”í•˜ê±°ë‚˜ ë¹¼ëŠ” ì—°ì‚°ì„ í™•ì¥í•˜ë©´ ë‘ ê°œì˜ ì˜ìƒì„ ë”í•˜ê±°ë‚˜ ë¹¼ëŠ” ì—°ì‚°ì„ ìƒê°í•´ ë³¼ ìˆ˜ ìˆë‹¤. ë‘ ì˜ìƒì„ í•©í•˜ë©´ ì˜ìƒ í•©ì„±ì´ ë˜ë©°, ë‘ ì˜ìƒì„ ë¹¼ë©´ ì°¨ì˜ìƒ(difference image)ì´ ëœë‹¤. . ë‹¤ìŒì€ ì•Œë ‰ì‚°ë” ëŒ€ì™• ë™ìƒ ì˜ìƒ($A$)ê³¼ ì‚¬ë„ì˜ ê±´ë¬¼ ì˜ìƒ($B$), ë‘ ì˜ìƒì„ í•©ì„±í•œ ì˜ìƒ($A+B$)ì„ êµ¬í•˜ëŠ” ì˜ˆì œì´ë‹¤. . . . &#54665;&#47148; &#54633;&#44284; &#44273; &#50672;&#49328;&#51012; &#53685;&#54620; &#50689;&#49345; &#54633;&#49457; . import numpy as np, cv2 image1 = cv2.imread(&#39;./ghtop_images/chap06_images/add1.jpg&#39;, cv2.IMREAD_GRAYSCALE) # ì˜ìƒ ì½ê¸° image2 = cv2.imread(&#39;./ghtop_images/chap06_images/add2.jpg&#39;, cv2.IMREAD_GRAYSCALE) . alpha, beta = 0.6, 0.7 # ê³±ì…ˆ ë¹„ìœ¨ add_img1 = cv2.add(image1, image2) # ë‘ ì˜ìƒ ë‹¨ìˆœ ë”í•˜ê¸° add_img2 = cv2.add(image1 * alpha, image2 * beta) # ë‘ ì˜ìƒ ë¹„ìœ¨ì— ë”°ë¥¸ ë”í•˜ê¸° add_img2 = np.clip(add_img2, 0, 255).astype(&#39;uint8&#39;) # saturation ì²˜ë¦¬ add_img3 = cv2.addWeighted(image1, alpha, image2, beta, 0) # ë‘ ì˜ìƒ ë¹„ìœ¨ì— ë”°ë¥¸ ë”í•˜ê¸° titles = [&#39;image1&#39;, &#39;image2&#39;,&#39;add_img1&#39;,&#39;add_img2&#39;,&#39;add_img3&#39;] # ìœˆë„ìš° ì´ë¦„ for t in titles: cv2.imshow(t, eval(t)) # ì˜ìƒ í‘œì‹œ cv2.waitKey(0) cv2.destroyAllWindows() . titles = [&#39;image1&#39;, &#39;image2&#39;,&#39;add_img1&#39;,&#39;add_img2&#39;,&#39;add_img3&#39;] eval(titles[1]) . array([[110, 122, 118, ..., 165, 166, 166], [143, 159, 168, ..., 165, 166, 166], [115, 117, 140, ..., 165, 166, 166], ..., [ 32, 41, 45, ..., 34, 32, 30], [ 27, 35, 40, ..., 110, 109, 108], [ 41, 36, 31, ..., 146, 148, 149]], dtype=uint8) . íŒŒì´ì¬ ë‚´ì¥í•¨ìˆ˜ eval()í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ë¦¬ìŠ¤íŠ¸ ì›ì†Œì˜ ë¬¸ìì—´ì„ í–‰ë ¬ ë³€ìˆ˜ë¡œ ì‚¬ìš©í•˜ì—¬ í–‰ë ¬ì„ ì¶œë ¥í•´ì£¼ë©°, cv2.imshow()ì— ì§‘ì–´ë„£ì–´ ìœˆë„ìš°ì— í‘œì‹œí•œë‹¤. | . import os path_save = &#39;./prac_image&#39; os.chdir(path_save) file_name = [] for i in range(len(titles)): file_name.append(path_save + &#39;/&#39; + titles[i] +&#39;_233.png&#39;) #, eval(titles[i])) print(file_name) os.chdir(&#39;../&#39;) . [&#39;./prac_image/image1_233.png&#39;, &#39;./prac_image/image2_233.png&#39;, &#39;./prac_image/add_img1_233.png&#39;, &#39;./prac_image/add_img2_233.png&#39;, &#39;./prac_image/add_img3_233.png&#39;] . for i in range(len(file_name)): cv2.imwrite(file_name[i], eval(titles[i])) print(os.listdir(&#39;./prac_image&#39;)) . [&#39;add_img1_233.png&#39;, &#39;add_img2_233.png&#39;, &#39;add_img3_233.png&#39;, &#39;blue.png&#39;, &#39;green.png&#39;, &#39;image.png&#39;, &#39;image1.png&#39;, &#39;image1_226.png&#39;, &#39;image1_233.png&#39;, &#39;image2_226.png&#39;, &#39;image2_233.png&#39;, &#39;image_227.png&#39;, &#39;img1_plus_img2.PNG&#39;, &#39;img_basic.png&#39;, &#39;img_gray.png&#39;, &#39;problem_box.PNG&#39;, &#39;red.png&#39;, &#39;repeat.png&#39;, &#39;solution_box.PNG&#39;, &#39;trans.png&#39;, &#39;xaxis.png&#39;, &#39;xyaxis.png&#39;, &#39;yaxis.png&#39;] . . add_img1 = cv2.add(image1, image2) # ë‘ ì˜ìƒ ë‹¨ìˆœ ë”í•˜ê¸° . . add_img2 = cv2.add(image1 * alpha, image2 * beta) # ë‘ ì˜ìƒ ë¹„ìœ¨ì— ë”°ë¥¸ ë”í•˜ê¸° add_img2 = np.clip(add_img2, 0, 255).astype(&#39;uint8&#39;) # saturation ì²˜ë¦¬ . . add_img3 = cv2.addWeighted(image1, alpha, image2, beta, 0) # ë‘ ì˜ìƒ ë¹„ìœ¨ì— ë”°ë¥¸ ë”í•˜ê¸° . .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/15/opencv.html",
            "relUrl": "/python/2022/10/15/opencv.html",
            "date": " â€¢ Oct 15, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "(OpenCV - Chap5) 10ì›” 13ì¼(2)",
            "content": "5.3.1 &#49324;&#52825; &#50672;&#49328; (&#54665;&#47148; &#49328;&#49696; &#50672;&#49328;) . ì‚¬ì¹™ì—°ì‚°ì„ ìœ„í•œ OpenCVí•¨ìˆ˜ì— ëŒ€í•´ ì•Œì•„ë³´ì. . cv2.add(src1, src2[, mask[, dtype]]]) -&gt; dst . ë‘ ê°œì˜ ë°°ì—´ í˜¹ì€ ë°°ì—´ê³¼ ìŠ¤ì¹¼ë¼ì˜ ê° ì›ì†Œ ê°„ í•©ì„ ê³„ì‚°í•œë‹¤. ì…ë ¥ì¸ìˆ˜ src1, src2 ì¤‘ í•˜ë‚˜ëŠ” ìŠ¤ì¹¼ë¼ê°’ì¼ ìˆ˜ ìˆë‹¤. . $dst(i) = saturate(src1(i) + src2(i)) quad text{if } mask(i) neq 0$ | $dst(i) = saturate(src1 + src2(i)) quad text{if } mask(i) neq 0$ | $dst(i) = saturate(src1(i) + src2) quad text{if } mask(i) neq 0$ | . | . | . cv2.addWeighted(src1, alpha1, src2, beta, gamma[,[dst[,dtype]]) -&gt; dst ë‘ ë°°ì—´ì˜ ê° ì›ì†Œì— ê°€ì¤‘ì¹˜ë¥¼ ê³±í•œ í›„ì— ê° ì›ì†Œ ê°„ í•© ì¦‰, ê°€ì¤‘ëœ(weighted) í•©ì„ ê³„ì‚°í•œë‹¤. | ìˆ˜ì‹: $dst(i) = saturate(src1(i) cdot alpha + src2(i) cdot beta + gamma)$ | . | . [ ì°¸ê³  ] OpenCVì—ì„œ **saturate()** ëŠ” 0ì´í•˜ëŠ” 0ìœ¼ë¡œ, 255ì´ìƒì€ 255ë¡œ ë²”ìœ„ë¥¼ í•œì •ì‹œí‚¤ëŠ” ì—°ì‚°ì´ë‹¤. import numpy as np, cv2 m1 = np.full((3,6), 10, np.uint8) # ë‹¨ì¼ì±„ë„ ìƒì„± ë° ì´ˆê¸°í™” m2 = np.full((3,6), 50, np.uint8) m_mask = np.zeros(m1.shape, np.uint8) # ë§ˆìŠ¤í¬ ìƒì„± m_mask[:,3:] = 1 # ê´€ì‹¬ ì˜ì—­(ëª¨ë“ í–‰, 3ì—´ë¶€í„°)ì„ ì§€ì •í•œ í›„, 1ì„ í• ë‹¹ . . m1 . array([[10, 10, 10, 10, 10, 10], [10, 10, 10, 10, 10, 10], [10, 10, 10, 10, 10, 10]], dtype=uint8) . m2 . array([[50, 50, 50, 50, 50, 50], [50, 50, 50, 50, 50, 50], [50, 50, 50, 50, 50, 50]], dtype=uint8) . m_mask . array([[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1]], dtype=uint8) . - í–‰ë ¬ ë§ì…ˆ . m_add1 = cv2.add(m1, m2) m_add1 . array([[60, 60, 60, 60, 60, 60], [60, 60, 60, 60, 60, 60], [60, 60, 60, 60, 60, 60]], dtype=uint8) . m_add2 = cv2.add(m1, m2, mask=m_mask) m_add2 . array([[ 0, 0, 0, 60, 60, 60], [ 0, 0, 0, 60, 60, 60], [ 0, 0, 0, 60, 60, 60]], dtype=uint8) . ë§ˆìŠ¤í¬ ì˜ì—­ (ê´€ì‹¬ì˜ì—­)ë§Œ ë§ì…ˆ ì—°ì‚°ì´ ëœ ê²ƒì„ í™•ì¸! | . - í–‰ë ¬ ë‚˜ëˆ—ì…ˆ . m_div1 = cv2.divide(m1, m2) m_div1 . array([[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], dtype=uint8) . ì „ë¶€ 0ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤? 0.2ê°€ ë‚˜ì™€ì•¼ í•˜ëŠ”ë°?? (ì†Œìˆ˜ ë¶€ë¶„ì´ ìƒì‹¤ë˜ì—ˆë‹¤.) | . - ì†Œìˆ˜ë¶€ë¶„ ì†Œì‹¤ ë°©ì§€ . í–‰ë ¬ ì›ì†Œ ìë£Œí˜•ì„ 32ë¹„íŠ¸ ì‹¤ìˆ˜í˜•(np.float32)ë¡œ ë³€í™˜ . m1 = m1.astype(np.float32) # ì†Œìˆ˜ë¶€ë¶„ ë³´ì¡´ìœ„í•´ í–‰ë³€í™˜ m2 = np.float32(m2) # í˜• ë³€í™˜ ë°©ë²•2 m_div2 = cv2.divide(m1, m2) m_div2 . array([[0.2, 0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.2, 0.2, 0.2, 0.2, 0.2]], dtype=float32) . ì†Œìˆ˜ë¶€ë¶„ ì†Œì‹¤ ë¬¸ì œê°€ ì˜ í•´ê²°ë˜ì—ˆë‹¤. | . 5.3.2 &#51648;&#49688;, &#47196;&#44536;, &#51228;&#44273;&#44540; &#44288;&#47144; &#54632;&#49688; . import numpy as np, cv2 ## ndarray ìƒì„± v1 = np.array([1,2,3], np.float32) # 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ í–‰ë ¬ ìƒì„± v2 = np.array([[1],[2],[3]], np.float32) # 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ (3í–‰, 1ì—´) - ì—´ë²¡í„° v3 = np.array([[1,2,3]],np.float32) # 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ (1í–‰, 3ì—´) - í–‰ë²¡í„° . . v1 # 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ í–‰ë ¬ ìƒì„± . array([1., 2., 3.], dtype=float32) . v2 # 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ (3í–‰, 1ì—´) - ì—´ë²¡í„° . array([[1.], [2.], [3.]], dtype=float32) . v3 # 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ (1í–‰, 3ì—´) - í–‰ë²¡í„° . array([[1., 2., 3.]], dtype=float32) . v_exp = cv2.exp(v1) # 1ì°¨ì› í–‰ë ¬ì— ëŒ€í•œ ì§€ìˆ˜ m_exp = cv2.exp(v2) # í–‰ë²¡í„° (1*3)ì— ëŒ€í•œ ì§€ìˆ˜ê³„ì‚° m_exp = cv2.exp(v3) # ì—´ë²¡í„° (3*1)ì— ëŒ€í•œ ì§€ìˆ˜ ê³„ì‚° v_log = cv2.log(v1) # ë¡œê·¸ ê³„ì‚° m_sqrt = cv2.sqrt(v2) # ì œê³±ê·¼ ê³„ì‚° m_pow = cv2.pow(v3, 3) # 3ì˜ ê±°ë“­ì œê³± ê³„ì‚° . . v_exp . array([[ 2.718282 ], [ 7.3890557], [20.085539 ]], dtype=float32) . np.array([[np.exp(1)], [np.exp(2)],[np.exp(3)]]) . array([[ 2.71828183], [ 7.3890561 ], [20.08553692]]) . ì˜ ê³„ì‚°ë˜ëŠ”êµ¬ë§Œ! | . m_exp . array([[ 2.718282 , 7.3890557, 20.085539 ]], dtype=float32) . v_log . array([[0. ], [0.6931472], [1.0986123]], dtype=float32) . m_sqrt . array([[1. ], [1.4142135], [1.7320508]], dtype=float32) . m_pow . array([[ 1., 8., 27.]], dtype=float32) . &#54665;&#48289;&#53552;&#47484; &#50676;&#48289;&#53552;&#47196;, &#50676;&#48289;&#53552;&#47484; &#54665;&#48289;&#53552;&#47196; (Transpose) . print( v_log.T) . [[0. 0.6931472 1.0986123]] . print(m_sqrt.T) . [[1. 1.4142135 1.7320508]] . print(m_pow.T) . [[ 1.] [ 8.] [27.]] . ì—´ë²¡í„°ëŠ” í–‰ë²¡í„°ë¡œ, í–‰ë²¡í„°ëŠ” ì—´ë²¡í„°ë¡œ ë³€í™˜í•˜ì˜€ë‹¤! | . 2&#52264;&#50896; &#54665;&#47148;&#51012; &#48289;&#53552;(1&#52264;&#50896;)&#47196; &#48320;&#54872; . np.ravel | .flatten() | . print(m_sqrt) . [[1. ] [1.4142135] [1.7320508]] . print(np.ravel(m_sqrt)) . [1. 1.4142135 1.7320508] . Numpy ëª¨ë“ˆì˜ ravel() í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ 2ì°¨ì› í–‰ë ¬ì„ ë²¡í„°(1ì°¨ì›)ìœ¼ë¡œ ë³€í™˜. | ravel() í•¨ìˆ˜ëŠ” ë¦¬ìŠ¤íŠ¸ë‚˜ ë„˜íŒŒì´ ë°°ì—´ë¿ë§Œ ì•„ë‹ˆë¼ ëª¨ë“  ë‹¤ì°¨ì› ë°°ì—´ì„ ë²¡í„°(1ì°¨ì›)ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤. | . print(m_pow, type(m_pow)) print(m_pow.flatten(), type(m_pow.flatten())) . [[ 1. 8. 27.]] &lt;class &#39;numpy.ndarray&#39;&gt; [ 1. 8. 27.] &lt;class &#39;numpy.ndarray&#39;&gt; . ndarray í´ë˜ìŠ¤ì˜ ë‚´ë¶€ ë©”ì†Œë“œì¸ flatten() í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ë²¡í„°ë¡œ ë³€í™˜í•œë‹¤. | . &#54665;&#47148; &#53356;&#44592; &#48143; &#50948;&#49345; &#50672;&#49328; . ë‹¤ìŒì€ cv2.magnitude()ì™€ cv2.phase() í•¨ìˆ˜ì˜ ì˜ˆì‹œì´ë‹¤. OpenCV í•¨ìˆ˜ì—ì„œ ì—°ì‚°ì˜ ê²°ê³¼ê°€ ì‹¤ìˆ˜ê°’ì„ ê°–ëŠ” ê²½ìš° ëŒ€ë¶€ë¶„ ì…ë ¥ í–‰ë ¬ ì›ì†Œì˜ ìë£Œí˜•ë„ np.float32í˜•ì´ì—¬ì•¼ í•œë‹¤. . import numpy as np, cv2 . . x = np.array([1,2,3,5,10], np.float32) # ë¦¬ìŠ¤íŠ¸ë¡œ ndarray ê°ì²´ ìƒì„± y = np.array([2,5,7,2,9]).astype(&#39;float32&#39;) # í–‰ë ¬ ìƒì„± í›„ ì‹¤ìˆ˜í˜• ë³€í™˜ . x . array([ 1., 2., 3., 5., 10.], dtype=float32) . y . array([2., 5., 7., 2., 9.], dtype=float32) . - í¬ê¸° ê³„ì‚° . mag = cv2.magnitude(x, y) mag . array([[ 2.236068 ], [ 5.3851647], [ 7.615773 ], [ 5.3851647], [13.453624 ]], dtype=float32) . - ê°ë„(ë°©í–¥) ê³„ì‚° . ang = cv2.phase(x, y) ang . array([[1.1071129], [1.1902124], [1.1658309], [0.3805839], [0.7329612]], dtype=float32) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/14/operations_func.html",
            "relUrl": "/python/2022/10/14/operations_func.html",
            "date": " â€¢ Oct 14, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "(OpenCV - Chap5) 10ì›” 13ì¼",
            "content": "05. &#44592;&#48376; &#48176;&#50676; &#50672;&#49328; &#54632;&#49688; . OpenCVëŠ” ìˆ˜í•™ê³¼ ê³¼í•™ ì—°ì‚°ì„ ìœ„í•œ íŒŒì´ì¬ íŒ¨í‚¤ì§€ì¸ ë„˜íŒŒì´(numpy)ì™€ ì—°ë™í•´ ë°°ì—´ì„ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŸ° ë°°ì—´ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì—°ì‚°í•¨ìˆ˜ë¥¼ ì§€ì›í•œë‹¤. . íŒŒì´ì¬ì—ì„œëŠ” ë°°ì—´ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìë£Œí˜•ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ì‚¬ì „ ë“±ì˜ ì—´ê±°í˜•(sequence) ê°ì²´ê°€ ìˆë‹¤. ë¦¬ìŠ¤íŠ¸ëŠ” ë‹¤ì°¨ì›ì˜ ë°°ì—´ì„ ë§Œë“¤ê³  ì›ì†Œë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìœ¼ë©°, íŠœí”Œì€ ë‹¤ì°¨ì›ì˜ ë°°ì—´ì„ ë§Œë“¤ ìˆ˜ ìˆì§€ë§Œ, ìˆ˜ì •ì´ ë¶ˆê°€ëŠ¥í•œ ìë£Œí˜•ì´ë‹¤. OpenCV ëª¨ë“ˆì˜ í•¨ìˆ˜ë“¤ì€ ë„˜íŒŒì´ ëª¨ë“ˆì˜ ë°°ì—´(ndarray) ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì…ë ¥ ë°°ì—´ê³¼ ì¶œë ¥ ë°°ì—´ì„ ì‚¬ìš©í•œë‹¤. . ì´ ì¥ì—ì„œëŠ” OpenCVì—ì„œ ì§€ì›í•˜ëŠ” ì—¬ëŸ¬ ë°°ì—´ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì‚´í´ë³¸ë‹¤. . 5.1 &#44592;&#48376; &#48176;&#50676; (Array) &#54632;&#49688; . OpenCVì—ì„œëŠ” ë°°ì—´ì„ ì˜µì…˜ì— ë”°ë¼ ì—¬ëŸ¬ ë°©í–¥ìœ¼ë¡œ ë’¤ì§‘ê±°ë‚˜ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•˜ëŠ” ë“± ë°°ì—´ ìì²´ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì œê³µí•˜ê³  ìˆë‹¤. . ë‹¤ìŒ ì˜ˆì œëŠ” ì˜ìƒíŒŒì¼ì„ ì½ì€ í›„, cv2.flip(), cv2.repeat, cv2.transpose() í•¨ìˆ˜ë¥¼ í™œìš©í•´ì„œ ìƒí•˜ì¢Œìš°ë¡œ ë’¤ì§‘ëŠ” ì˜ˆì‹œì´ë‹¤. . import cv2 image = cv2.imread(&#39;./ghtop_images/chap05_images/flip_test.jpg&#39;, cv2.IMREAD_COLOR) if image is None: raise Exception(&quot;ì˜ìƒíŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ë°œìƒ&quot;) # ì˜ˆì™¸ ì²˜ë¦¬ . . - &#50896;&#48376; &#51060;&#48120;&#51648; . image = cv2.imshow(&#39;image&#39;, image) cv2.waitKey(0) cv2.destroyAllWindows() . . ì›ë³¸ ì´ë¯¸ì§€ . . - x&#52629; &#44592;&#51456;&#51004;&#47196; &#46244;&#51665;&#51008; &#51060;&#48120;&#51648; . x_axis = cv2.flip(image, 0) # xì¶• ê¸°ì¤€ ìƒí•˜ ë’¤ì§‘ê¸° cv2.imshow(&#39;x_axis&#39;, x_axis) cv2.waitKey(0) cv2.destroyAllWindows() . . x-axis flip . . - y&#52629; &#44592;&#51456;&#51004;&#47196; &#46244;&#51665;&#51008; &#51060;&#48120;&#51648; . y_axis = cv2.flip(image, 1) # yì¶• ê¸°ì¤€ ì¢Œìš° ë’¤ì§‘ê¸° cv2.imshow(&#39;y_axis&#39;, y_axis) cv2.waitKey(0) cv2.destroyAllWindows() . . y_axis flip . . - x, y&#52629; &#44592;&#51456; &#49345;&#54616;&#51340;&#50864; &#46244;&#51665;&#44592; . xy_axis = cv2.flip(image, -1) # ì–‘ì¶•(x,yì¶•) ê¸°ì¤€ ìƒí•˜ì¢Œìš° ë’¤ì§‘ê¸° cv2.imshow(&#39;xy_axis&#39;, xy_axis) cv2.waitKey(0) cv2.destroyAllWindows() . . xy_axis flip . . - &#48373;&#49324;&#48376; &#47564;&#46308;&#44592; . cv.repeat(src, ny, nx[,dst[) -&gt; dst . src, dst : ì…ë ¥, ì¶œë ¥ ë°°ì—´ . | ny, nx : ìˆ˜ì§, ìˆ˜í‰ë°©í–¥ ë°˜ë³µ íšŸìˆ˜ . | . | . ì…ë ¥ ë°°ì—´ì˜ ë°˜ë³µëœ ë³µì‚¬ë³¸ìœ¼ë¡œ ì¶œë ¥ ë°°ì—´ì„ ì±„ìš´ë‹¤. | . rep_image = cv2.repeat(image, 1, 2) # ë°˜ë³µ ë³µì‚¬ cv2.imshow(&#39;rep_image&#39;, rep_image) cv2.waitKey(0) cv2.destroyAllWindows() . . repeat_image . . - &#51204;&#52824; &#51060;&#48120;&#51648; . ì…ë ¥ í–‰ë ¬ì˜ ì „ì¹˜ í–‰ë ¬ì„ ì¶œë ¥ìœ¼ë¡œ ë°˜í™˜í•œë‹¤. | . trans_image = cv2.transpose(image) # í–‰ë ¬ ì „ì¹˜ cv2.imshow(&#39;trans_image&#39;, trans_image) cv2.waitKey(0) cv2.destroyAllWindows() . . trans_image . . image.shape . . (267, 360, 3) . trans_image.shape . . (360, 267, 3) . $267 times 360 times 3 to 360 times 267 times 3$ìœ¼ë¡œ ì „ì¹˜ëœ ê²ƒ í™•ì¸! . 5.2 &#52292;&#45328; &#52376;&#47532; &#54632;&#49688; . ì»¬ëŸ¬ ì˜ìƒì€ íŒŒë€ìƒ‰(B), ë…¹ìƒ‰(G), ë¹¨ê°„ìƒ‰(R)ì˜ ê°ê¸° ë…ë¦½ì ì¸ 2ì°¨ì› ì •ë³´ë¥¼ í•©ì³ ë†“ì€ ë°°ì—´ì´ë¼ê³  ì •ì˜í•  ìˆ˜ ìˆë‹¤. ìš”ì¦ˆìŒ ì˜ìƒì²˜ë¦¬ APIì—ì„œëŠ” ì»¬ëŸ¬ ì˜ìƒì„ í‘œí˜„í•˜ê¸° ìœ„í•´ ì±„ë„(Channel)ì´ë¼ëŠ” ê°œë…ì„ ë„ì…í•œë‹¤. ì¦‰, ë¹¨ê°„ìƒ‰, ë…¹ìƒ‰, íŒŒë€ìƒ‰ì˜ ë…ë¦½ì ì¸ 2ì°¨ì› ì •ë³´ëŠ” ê°ê° Blueì±„ë„, Greenì±„ë„, Red ì±„ë„ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í‘œí˜„ëœë‹¤. . ë‹¤ìŒì€ ë‹¨ì¼ì±„ë„ í–‰ë ¬ì„ ì—¬ëŸ¬ ê°œ í•©ì¹˜ê±°ë‚˜, ë‹¤ì±„ë„ì„ ë¶„ë¦¬í•˜ëŠ” ë“± ì±„ë„ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ì— ëŒ€í•œ ì„¤ëª…ì´ë‹¤. . ê°„ë‹¨í•œ ì˜ˆì œë¡œ ì±„ë„ì— ëŒ€í•œ ê°œë…ì„ ì•Œì•„ë³´ì. . 1. ë‹¨ì¼ì±„ë„ í–‰ë ¬ 3ê°œë¥¼ ìƒì„± | 2. 3ê°œì˜ ì±„ë„ì„ í•©ì³ í•˜ë‚˜ì˜ ë‹¤ì±„ë„ í–‰ë ¬ë¡œ ìƒì„± | 3. ê·¸ í›„ í•©ì³ì§„ ë‹¤ì±„ë„ í–‰ë ¬ì„ ë‹¤ì‹œ ë‹¨ì¼ì±„ë„ë¡œ ë¶„ë¦¬ | . import numpy as np import cv2 . . ## numpy.ndarrayë¥¼ ì´ìš©í•´ í–‰ë ¬ ìƒì„± ë° ì´ˆê¸°í™” ë°©ë²• ch0 = np.zeros((2,4), np.uint8) + 10 # 0ì›ì†Œ í–‰ë ¬ ì„ ì–¸ í›„ 10 ë”í•˜ê¸° ch1 = np.ones((2,4), np.uint8) * 20 # 1ì›ì†Œ í–‰ë ¬ ì„ ì–¸ í›„ 20 ê³±í•˜ê¸° ch2 = np.full((2,4), 30, np.uint8) # í–‰ë ¬ì„ ìƒì„±í•˜ë©° 30ìœ¼ë¡œ ì´ˆê¸°í™” list_bgr = [ch0, ch1, ch2] # ë‹¨ì¼ì±„ë„ í–‰ë ¬ë“¤ì„ ëª¨ì•„ ë¦¬ìŠ¤íŠ¸ êµ¬ì„± merge_bgr = cv2.merge(list_bgr) # ì±„ë„ í•©ì„± split_bgr = cv2.split(merge_bgr) # ì±„ë„ ë¶„ë¦¬ : ì»¬ëŸ¬ì˜ìƒ &gt; 3ì±„ë„ ë¶„ë¦¬ . . ch0 . . array([[10, 10, 10, 10], [10, 10, 10, 10]], dtype=uint8) . ch1 . . array([[20, 20, 20, 20], [20, 20, 20, 20]], dtype=uint8) . ch2 . . array([[30, 30, 30, 30], [30, 30, 30, 30]], dtype=uint8) . # ë‹¨ì¼ ì±„ë„ í–‰ë ¬ 3ê°œ (ch0, ch1, ch2) list_bgr . . [array([[10, 10, 10, 10], [10, 10, 10, 10]], dtype=uint8), array([[20, 20, 20, 20], [20, 20, 20, 20]], dtype=uint8), array([[30, 30, 30, 30], [30, 30, 30, 30]], dtype=uint8)] . print(&#39;merge_bgr í–‰ë ¬ í˜•íƒœ: &#39;, merge_bgr.shape) print(&#39; &#39;) print(merge_bgr) . . merge_bgr í–‰ë ¬ í˜•íƒœ: (2, 4, 3) [[[10 20 30] [10 20 30] [10 20 30] [10 20 30]] [[10 20 30] [10 20 30] [10 20 30] [10 20 30]]] . print(&#39;split_bar í–‰ë ¬ í˜•íƒœ: &#39;, np.array(split_bgr).shape) # numpyì˜ shape() í•¨ìˆ˜ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ ndarrayê°ì²´ë¡œ ë³€ê²½í•˜ì—¬ í–‰ë ¬ í˜•íƒœë¡œ ì¶œë ¥ print(&#39; &#39;) print(split_bgr[0]) print(&#39; &#39;) print(split_bgr[1]) print(&#39; &#39;) print(split_bgr[2]) . . split_bar í–‰ë ¬ í˜•íƒœ: (3, 2, 4) [[10 10 10 10] [10 10 10 10]] [[20 20 20 20] [20 20 20 20]] [[30 30 30 30] [30 30 30 30]] . 2ì—´ 3í–‰ ê¹Šì´ê°€ 4 | . split_bgr . . (array([[10, 10, 10, 10], [10, 10, 10, 10]], dtype=uint8), array([[20, 20, 20, 20], [20, 20, 20, 20]], dtype=uint8), array([[30, 30, 30, 30], [30, 30, 30, 30]], dtype=uint8)) . np.array(split_bgr) . . array([[[10, 10, 10, 10], [10, 10, 10, 10]], [[20, 20, 20, 20], [20, 20, 20, 20]], [[30, 30, 30, 30], [30, 30, 30, 30]]], dtype=uint8) . &#50696;&#51228; &#49892;&#49845; . import cv2 . . image = cv2.imread(&#39;./ghtop_images/chap05_images/color.jpg&#39;, cv2.IMREAD_COLOR) # ì˜ìƒ ì½ê¸° if image is None: raise Exception(&#39;ì˜ìƒíŒŒì¼ ì½ê¸° ì˜¤ë¥˜&#39;) # ì˜ˆì™¸ì²˜ë¦¬ if image.ndim != 3: raise Exception(&quot;ì»¬ëŸ¬ ì˜ìƒ ì•„ë‹˜&quot;) # ì˜ˆì™¸ ì²˜ë¦¬ - ì»¬ëŸ¬ ì˜ìƒ í™•ì¸ . bgr = cv2.split(image) # blue, green, red = cv2.split(image) ## 3ê°œ ë³€ìˆ˜ë¡œ ë°˜í™˜ë°›ê¸° ê°€ëŠ¥! print(&#39;bgr ìë£Œí˜•:&#39;,type(bgr), type(bgr[0]), type(bgr[0][0][0])) . bgr ìë£Œí˜•: &lt;class &#39;tuple&#39;&gt; &lt;class &#39;numpy.ndarray&#39;&gt; &lt;class &#39;numpy.uint8&#39;&gt; . ## ê° ì±„ë„ì„ ìœˆë„ìš°ì— ë„ìš°ê¸° cv2.imshow(&#39;image&#39;, image) cv2.imshow(&#39;Blue chnnel&#39;, bgr[0]) cv2.imshow(&#39;Green chnnel&#39;, bgr[1]) cv2.imshow(&#39;Red chnnel&#39;, bgr[2]) cv2.waitKey(0) cv2.destroyAllWindows() . . original image vs. Blue channel . Blue Channel ì•„ë˜ìª½ íŒŒë€ìƒ‰ ë§ˆí¬ ë¶€ë¶„ì´ Blue channelì—ì„œëŠ” ë°ê²Œ ë‚˜íƒ€ë‚œë‹¤. | . original image vs. Green channel . ì›ë³¸ì´ë¯¸ì§€ ì•„ë˜ìª½ì— ë…¹ìƒ‰ì„ ë„ëŠ” ì§„ì—´ëŒ€ ë¶€ë¶„ì´ Green Channelì—ì„œ ë°ê²Œ ë‚˜íƒ€ë‚œë‹¤. | . original image vs. red channel . ì›ë³¸ì´ë¯¸ì§€ì˜ ì™¼ìª½ ëƒ‰ì¥ ì „ì‹œë¬¼ì˜ ë¶‰ì€ìª½ ë¬¸ ë¶€ë¶„ì´ Red Chnnelì—ì„œ ë°ê²Œ ë‚˜íƒ€ë‚œë‹¤. | . 5.3.0 &#49328;&#49696; &#50672;&#49328; &#54632;&#49688; . í–‰ë ¬ì—°ì‚°ì€ ì£¼ë¡œ ì²« ë²ˆì§¸ ë°°ì—´ì˜ ië²ˆì§¸ ì›ì†Œì™€ ë‘ ë²ˆì§¸ ë°°ì—´ì˜ ië²ˆì§¸ ì›ì†Œ ê°„ì— ì—°ì‚°ì„ ìˆ˜í–‰í•´ì„œ ê²°ê³¼ ë°°ì—´ì˜ ië²ˆì§¸ ì›ì†Œì— ì €ì¥í•˜ëŠ” ë°©ì‹ì„ ì·¨í•œë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì„ ì›ì†Œê°„ (per-element, element-wise) ì—°ì‚°ì´ë¼ í•œë‹¤. . 5.3.1 &#49324;&#52825;&#50672;&#49328; . OpenCVì—ì„œ ë°°ì—´ì— ëŒ€í•œ ì‚¬ì¹™ ì—°ì‚°ì€ ë‘ ë°°ì—´ì˜ ì›ì†Œê°„(per-element) ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤. . 5.3.2 &#51648;&#49688;, &#47196;&#44536;, &#51228;&#44273;&#44540; &#44288;&#47144; &#54632;&#49688; . OpenCVëŠ” ë°°ì—´ ì›ì†Œì˜ ì§€ìˆ˜ì™€ ë¡œê·¸ ë° ì œê³±ê·¼ ê´€ë ¨ í•¨ìˆ˜ë¥¼ ì§€ì›í•œë‹¤. .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/13/operatios_func.html",
            "relUrl": "/python/2022/10/13/operatios_func.html",
            "date": " â€¢ Oct 13, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "note",
            "content": "&#44592;&#44228;&#54617;&#49845; . í•™ìŠµ Train / ê²€ì¦ Test $ to$ í‰ê°€ | . íŠ¹ì„±ê³µí•™ : ë°ì´í„° ì „ì²˜ë¦¬ . - Scaling : ìˆ«ì ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ ì¡°ì • (Standard / MinMax / Robust) . - Encoding: ìˆ«ì ë°ì´í„°ë¥¼ ë¬¸ìë¡œ ë³€í™˜ (Label / One hot) . - Cross Validation: êµì°¨ ê²€ì¦ì„ í†µí•´, ì—¬ëŸ¬ê°œì˜ ëª¨ë¸ . - Model Hyperparameter Tunning: ì•Œê³ ë¦¬ì¦˜ ë‚´ êµ¬ì¡°ë¥¼ Tunning . ì§€ë„ í•™ìŠµ ($Y$) . - $Y$ ì—°ì†í˜• (ìˆ«ì) : Regression íšŒê·€ / ì˜ˆì¸¡ . - $Y$ ë²”ì£¼í˜• (ë¬¸ì) : Classification ë¶„ë¥˜ . ë¹„ì§€ë„ í•™ìŠµ . - êµ°ì§‘ë¶„ì„ (Clustering) . - ì°¨ì›ì¶•ì†Œ / ì—°ê´€ë¶„ì„ . Load Dataset . import pandas as pd . df1 = pd.read_csv(&#39;./data/Breast_Cancer/data1.csv&#39;) . df1.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 569 entries, 0 to 568 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 id 569 non-null int64 1 diagnosis 569 non-null object 2 radius_mean 569 non-null float64 3 texture_mean 569 non-null float64 4 perimeter_mean 569 non-null float64 5 area_mean 569 non-null float64 6 smoothness_mean 569 non-null float64 7 compactness_mean 569 non-null float64 8 concavity_mean 569 non-null float64 9 concave_points_mean 569 non-null float64 10 symmetry_mean 569 non-null float64 11 fractal_dimension_mean 569 non-null float64 12 radius_se 569 non-null float64 13 texture_se 569 non-null float64 14 perimeter_se 569 non-null float64 15 area_se 569 non-null float64 16 smoothness_se 569 non-null float64 17 compactness_se 569 non-null float64 18 concavity_se 569 non-null float64 19 concave_points_se 569 non-null float64 20 symmetry_se 569 non-null float64 21 fractal_dimension_se 569 non-null float64 22 radius_worst 569 non-null float64 23 texture_worst 569 non-null float64 24 perimeter_worst 569 non-null float64 25 area_worst 569 non-null float64 26 smoothness_worst 569 non-null float64 27 compactness_worst 569 non-null float64 28 concavity_worst 569 non-null float64 29 concave_points_worst 569 non-null float64 30 symmetry_worst 569 non-null float64 31 fractal_dimension_worst 569 non-null float64 dtypes: float64(30), int64(1), object(1) memory usage: 142.4+ KB . df1[&#39;diagnosis&#39;] # Target . 0 M 1 M 2 M 3 M 4 M .. 564 M 565 M 566 M 567 M 568 B Name: diagnosis, Length: 569, dtype: object . df1[&#39;Target&#39;] = df1[&#39;diagnosis&#39;].replace(&#39;M&#39;,1).replace(&#39;B&#39;,0) . df1[&#39;diagnosis&#39;].unique() . array([&#39;M&#39;, &#39;B&#39;], dtype=object) . 01. Logistic Rgression . Y = df1[&#39;diagnosis&#39;] X = df1[[&#39;radius_mean&#39;, &#39;perimeter_mean&#39;, &#39;area_mean&#39;]] . from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report . X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3) . model = LogisticRegression() model.fit(X_train, Y_train) . LogisticRegression() . In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression() . Y_test_pred = model.predict(X_test) Y_test_pred . array([&#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;M&#39;, &#39;B&#39;, &#39;B&#39;], dtype=object) . print(classification_report(Y_test, Y_test_pred)) . precision recall f1-score support B 0.89 0.90 0.90 110 M 0.82 0.80 0.81 61 accuracy 0.87 171 macro avg 0.85 0.85 0.85 171 weighted avg 0.87 0.87 0.87 171 . Mê³¼ Bì˜ ì°¨ì´ê°€ í¬ì§€ ì•Šì•„ì•¼í•˜ê³ , ë§Œì•½ ì°¨ì´ê°€ í¬ë‹¤ë©´ ëª¨ë¸ì„ ë‹¤ì‹œ ë§Œë“¤ì–´ì•¼ í•œë‹¤. | macro avgë¥¼ ë³´ê³  ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ìƒì„±ë˜ì—ˆëŠ”ì§€ íŒë‹¨ì„ í•˜ë©´ ëœë‹¤. | . 02. &#53945;&#49457;&#44277;&#54617; . import pandas as pd . df1 = pd.read_csv(&#39;./data/Breast_Cancer/data1.csv&#39;) df1.head(2) . id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave_points_mean ... radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave_points_worst symmetry_worst fractal_dimension_worst . 0 842302 | M | 17.99 | 10.38 | 122.8 | 1001.0 | 0.11840 | 0.27760 | 0.3001 | 0.14710 | ... | 25.38 | 17.33 | 184.6 | 2019.0 | 0.1622 | 0.6656 | 0.7119 | 0.2654 | 0.4601 | 0.11890 | . 1 842517 | M | 20.57 | 17.77 | 132.9 | 1326.0 | 0.08474 | 0.07864 | 0.0869 | 0.07017 | ... | 24.99 | 23.41 | 158.8 | 1956.0 | 0.1238 | 0.1866 | 0.2416 | 0.1860 | 0.2750 | 0.08902 | . 2 rows Ã— 32 columns . print(df1.shape) . (569, 32) . print(df1.columns) # ë°ì´í„° í”„ë ˆì„ ë‚´ í•­ëª©ë“¤ì„ í™•ì¸ . Index([&#39;id&#39;, &#39;diagnosis&#39;, &#39;radius_mean&#39;, &#39;texture_mean&#39;, &#39;perimeter_mean&#39;, &#39;area_mean&#39;, &#39;smoothness_mean&#39;, &#39;compactness_mean&#39;, &#39;concavity_mean&#39;, &#39;concave_points_mean&#39;, &#39;symmetry_mean&#39;, &#39;fractal_dimension_mean&#39;, &#39;radius_se&#39;, &#39;texture_se&#39;, &#39;perimeter_se&#39;, &#39;area_se&#39;, &#39;smoothness_se&#39;, &#39;compactness_se&#39;, &#39;concavity_se&#39;, &#39;concave_points_se&#39;, &#39;symmetry_se&#39;, &#39;fractal_dimension_se&#39;, &#39;radius_worst&#39;, &#39;texture_worst&#39;, &#39;perimeter_worst&#39;, &#39;area_worst&#39;, &#39;smoothness_worst&#39;, &#39;compactness_worst&#39;, &#39;concavity_worst&#39;, &#39;concave_points_worst&#39;, &#39;symmetry_worst&#39;, &#39;fractal_dimension_worst&#39;], dtype=&#39;object&#39;) . print(df1.info()) # ë°ì´í„°ì˜ ìš”ì•½ì„ í™•ì¸ . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 569 entries, 0 to 568 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 id 569 non-null int64 1 diagnosis 569 non-null object 2 radius_mean 569 non-null float64 3 texture_mean 569 non-null float64 4 perimeter_mean 569 non-null float64 5 area_mean 569 non-null float64 6 smoothness_mean 569 non-null float64 7 compactness_mean 569 non-null float64 8 concavity_mean 569 non-null float64 9 concave_points_mean 569 non-null float64 10 symmetry_mean 569 non-null float64 11 fractal_dimension_mean 569 non-null float64 12 radius_se 569 non-null float64 13 texture_se 569 non-null float64 14 perimeter_se 569 non-null float64 15 area_se 569 non-null float64 16 smoothness_se 569 non-null float64 17 compactness_se 569 non-null float64 18 concavity_se 569 non-null float64 19 concave_points_se 569 non-null float64 20 symmetry_se 569 non-null float64 21 fractal_dimension_se 569 non-null float64 22 radius_worst 569 non-null float64 23 texture_worst 569 non-null float64 24 perimeter_worst 569 non-null float64 25 area_worst 569 non-null float64 26 smoothness_worst 569 non-null float64 27 compactness_worst 569 non-null float64 28 concavity_worst 569 non-null float64 29 concave_points_worst 569 non-null float64 30 symmetry_worst 569 non-null float64 31 fractal_dimension_worst 569 non-null float64 dtypes: float64(30), int64(1), object(1) memory usage: 142.4+ KB None . &#49828;&#52992;&#51068;&#47553; . ì—°ì†í˜• ë°ì´í„° ê°„ ìŠ¤ì¼€ì¼ì„ ë§ì¶”ê¸° ìœ„í•´ | Standard Scaler : í‰ê· ì´ 0, í‘œì¤€í¸ì°¨ 1 | MinMax Scaler : ìµœì†Ÿê°’ 0, ìµœëŒ“ê°’ 1 | Robust Scaler : ì¤‘ì•™ê°’ 0, IQR 1 (25% ~ 75%) | . from sklearn.preprocessing import StandardScaler . df2= df1[[&#39;radius_mean&#39;, &#39;perimeter_mean&#39;,&#39;area_mean&#39;]] . print(df2.describe()) . radius_mean perimeter_mean area_mean count 569.000000 569.000000 569.000000 mean 14.127292 91.969033 654.889104 std 3.524049 24.298981 351.914129 min 6.981000 43.790000 143.500000 25% 11.700000 75.170000 420.300000 50% 13.370000 86.240000 551.100000 75% 15.780000 104.100000 782.700000 max 28.110000 188.500000 2501.000000 . model = StandardScaler() model.fit(df2) # ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ìˆ˜ì‹ì„ ì ìš© . StandardScaler() . In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.StandardScalerStandardScaler() . pd.DataFrame(model.transform(df2)).describe() # transformìœ¼ë¡œ ë°ì´í„°ë¥¼ ë°”ê¿”ì¤ë‹ˆë‹¤. . 0 1 2 . count 5.690000e+02 | 5.690000e+02 | 5.690000e+02 | . mean -1.256562e-16 | -1.272171e-16 | -1.900452e-16 | . std 1.000880e+00 | 1.000880e+00 | 1.000880e+00 | . min -2.029648e+00 | -1.984504e+00 | -1.454443e+00 | . 25% -6.893853e-01 | -6.919555e-01 | -6.671955e-01 | . 50% -2.150816e-01 | -2.359800e-01 | -2.951869e-01 | . 75% 4.693926e-01 | 4.996769e-01 | 3.635073e-01 | . max 3.971288e+00 | 3.976130e+00 | 5.250529e+00 | . MinMax Scaling . ì˜ˆì œ1) data1.csv íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ raidus_mean ê°’ì„ MinMaxScalerë¥¼ ì´ìš©í•´ Scalingì„ ì‹¤ì‹œí•˜ì‹œì˜¤. (ìµœì†Ÿê°’ê³¼ ìµœëŒ“ê°’ì´ ì–´ë–»ê²Œ ë³€í–ˆëŠ”ì§€ í™•ì¸) . print(df1[&#39;radius_mean&#39;].mean()) . 14.127291739894563 . print(df1[&#39;radius_mean&#39;].max()) . 28.11 . print(df1[&#39;radius_mean&#39;].min()) . 6.981 . from sklearn.preprocessing import MinMaxScaler . model = MinMaxScaler() # scalerë¥¼ ë¶ˆëŸ¬ì™€ì„œ model.fit(df1[[&#39;radius_mean&#39;]]) # radius_meanì´ë¼ëŠ” ë°ì´í„°ë¥¼ í•™ìŠµ . MinMaxScaler() . In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.MinMaxScalerMinMaxScaler() . df1[&#39;Mean Radius(scaler)&#39;] = model.transform(df1[[&#39;radius_mean&#39;]]) # ë³€í™˜ì‘ì—… . print(df1[&#39;Mean Radius(scaler)&#39;].min()) . 0.0 . print(df1[&#39;Mean Radius(scaler)&#39;].max()) . 1.0 . ìµœì†Ÿê°’ì´ 0, ìµœëŒ“ê°’ì´ 1ì¸ í˜•íƒœë¡œ ì˜ ë°”ë€ ê²ƒì„ í™•ì¸ | . Robust Scaling . ì˜ˆì œ2. data1.csvíŒŒì¼ì—ì„œ Mean Area ê°’ì„ Robust Scalerë¥¼ ì´ìš©í•˜ì—¬, ìŠ¤ì¼€ì¼ë§ì„ ì‹¤ì‹œí•˜ê³ , ìµœëŒ“ê°’ê³¼ ì¤‘ì•™ê°’ì„ ê³„ì‚°í•˜ì‹œì˜¤. . from sklearn.preprocessing import RobustScaler . print(df1[&#39;area_mean&#39;].median()) . 551.1 . model = RobustScaler() model.fit(df1[[&#39;area_mean&#39;]]) . RobustScaler() . In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RobustScalerRobustScaler() . df1[&#39;Mean Area(scale)&#39;] = model.transform(df1[[&#39;area_mean&#39;]]) . df1[&#39;Mean Area(scale)&#39;].median() . 0.0 . Scaling + Modeling (Pipeline) . ì˜ˆì œ3. data1.csvíŒŒì¼ì—ì„œ diagnosisë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“¤ê³ ì í•œë‹¤. ì´ë•Œ, ì„¤ëª…ë³€ìˆ˜ë¥¼ MinMax Scalingì„ ì‹¤ì‹œí•˜ì—¬, Modelingì„ í•˜ë ¤ê³  í•œë‹¤. ëª¨ë¸ì„ êµ¬ì„±í•œ ë’¤ Test setì˜ ì •í™•ë„ë¥¼ ê³„ì‚° . Scaling + Modeling : Pipeline | . from sklearn.model_selection import train_test_split # ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©í•´ í•™ìŠµ from sklearn.tree import DecisionTreeClassifier # ìŠ¤ì¼€ì¼ë§ê³¼ ëª¨ë¸ì„ ë™ì‹œì— ì²˜ë¦¬ from sklearn.pipeline import Pipeline # ìŠ¤ì¼€ì¼ë§ì„ í•´ì£¼ëŠ” í•¨ìˆ˜ from sklearn.preprocessing import MinMaxScaler # ë¶„ë¥˜ëª¨ë¸ í‰ê°€ from sklearn.metrics import classification_report . X / Y ì„¤ì • | Train / Test Set êµ¬ì„± | Modelì„ ì´ìš©í•´ í•™ìŠµ | í‰ê°€ | . df1 = pd.read_csv(&#39;./data/Breast_Cancer/data1.csv&#39;) df1.head(2) . id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave_points_mean ... radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave_points_worst symmetry_worst fractal_dimension_worst . 0 842302 | M | 17.99 | 10.38 | 122.8 | 1001.0 | 0.11840 | 0.27760 | 0.3001 | 0.14710 | ... | 25.38 | 17.33 | 184.6 | 2019.0 | 0.1622 | 0.6656 | 0.7119 | 0.2654 | 0.4601 | 0.11890 | . 1 842517 | M | 20.57 | 17.77 | 132.9 | 1326.0 | 0.08474 | 0.07864 | 0.0869 | 0.07017 | ... | 24.99 | 23.41 | 158.8 | 1956.0 | 0.1238 | 0.1866 | 0.2416 | 0.1860 | 0.2750 | 0.08902 | . 2 rows Ã— 32 columns . df1[&#39;Target&#39;] = df1[&#39;diagnosis&#39;].replace(&#39;M&#39;,1).replace(&#39;B&#39;,0) . Y = df1[&#39;Target&#39;] X = df1[[&#39;radius_mean&#39;, &#39;perimeter_mean&#39;,&#39;area_mean&#39;]] . X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3) print(X_train.shape) print(X_test.shape) print(Y_train.shape) print(Y_test.shape) . (398, 3) (171, 3) (398,) (171,) . MinMax + DT . model = Pipeline( [(&#39;scaler&#39;, MinMaxScaler()), (&#39;model&#39;, DecisionTreeClassifier())] ) . model.fit(X_train, Y_train) . Pipeline(steps=[(&amp;#x27;scaler&amp;#x27;, MinMaxScaler()), (&amp;#x27;model&amp;#x27;, DecisionTreeClassifier())]) . In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[(&amp;#x27;scaler&amp;#x27;, MinMaxScaler()), (&amp;#x27;model&amp;#x27;, DecisionTreeClassifier())]) . MinMaxScalerMinMaxScaler() . DecisionTreeClassifierDecisionTreeClassifier() . Y_train_pred = model.predict(X_train) Y_test_pred = model.predict(X_test) . print(classification_report(Y_train, Y_train_pred)) . precision recall f1-score support 0 1.00 1.00 1.00 246 1 1.00 1.00 1.00 152 accuracy 1.00 398 macro avg 1.00 1.00 1.00 398 weighted avg 1.00 1.00 1.00 398 . print(classification_report(Y_test, Y_test_pred)) . precision recall f1-score support 0 0.92 0.89 0.90 111 1 0.81 0.85 0.83 60 accuracy 0.88 171 macro avg 0.86 0.87 0.87 171 weighted avg 0.88 0.88 0.88 171 . íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ê¹Œì§€ í•  ìˆ˜ ìˆë‹¤. | . MinMax + Logistic Regreesion . from sklearn.linear_model import LogisticRegression . model = Pipeline( [(&#39;scaler&#39;, MinMaxScaler()), (&#39;model&#39;, LogisticRegression())] ) . model.fit(X_train, Y_train) . Pipeline(steps=[(&amp;#x27;scaler&amp;#x27;, MinMaxScaler()), (&amp;#x27;model&amp;#x27;, LogisticRegression())]) . In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[(&amp;#x27;scaler&amp;#x27;, MinMaxScaler()), (&amp;#x27;model&amp;#x27;, LogisticRegression())]) . MinMaxScalerMinMaxScaler() . LogisticRegressionLogisticRegression() . Y_train_pred = model.predict(X_train) Y_test_pred = model.predict(X_test) . print(classification_report(Y_train, Y_train_pred)) . precision recall f1-score support 0 0.85 0.97 0.91 246 1 0.94 0.73 0.82 152 accuracy 0.88 398 macro avg 0.90 0.85 0.87 398 weighted avg 0.89 0.88 0.88 398 . print(classification_report(Y_test, Y_test_pred)) . precision recall f1-score support 0 0.87 0.99 0.92 111 1 0.98 0.72 0.83 60 accuracy 0.89 171 macro avg 0.92 0.85 0.88 171 weighted avg 0.91 0.89 0.89 171 . DecisionTreeì™€ ë¹„êµí•´ ë´¤ì„ ë•Œ ì¼ë°˜í™”ëŠ” Logistic Regressionì´ ë” ì˜ë˜ëŠ” ê²ƒ ê°™ë‹¤. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/09/13/bigdata-note.html",
            "relUrl": "/python/2022/09/13/bigdata-note.html",
            "date": " â€¢ Sep 13, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "(OpenCV - Chap5) OpenCV ì¸í„°í˜ì´ìŠ¤",
            "content": "4.1 &#50952;&#46020;&#50864; &#51228;&#50612; . ì˜ìƒì²˜ë¦¬ë¥¼ ê°„ë‹¨íˆ ë§í•˜ë©´, 2ì°¨ì› í–‰ë ¬ì— ëŒ€í•œ ì—°ì‚°ì´ë¼ í•  ìˆ˜ ìˆë‹¤. ì—¬ê¸°ì„œ í–‰ë ¬ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì—°ì‚° ê³¼ì •ì—ì„œ í–‰ë ¬ ì›ì†Œì˜ ê°’ì´ ë³€í•œë‹¤. ì´ ë•Œ ë³€í™”ëœ í–‰ë ¬ì˜ í™”ì†Œë“¤ì„ ìœˆë„ìš°ì— ì˜ìƒìœ¼ë¡œ ë°”ë¡œ í‘œì‹œí•  ìˆ˜ ìˆë‹¤ë©´ ì ìš©ëœ í–‰ë ¬ ì—°ì‚°ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸°ê°€ í›¨ì”¬ ë” ì‰¬ìš¸ ê²ƒì´ë‹¤. . OpenCVì—ì„œëŠ” ìœˆë„ìš°(window, ì°½)ê°€ í™œì„±í™”ëœ ìƒíƒœì—ì„œë§Œ ë§ˆìš°ìŠ¤ë‚˜ í‚¤ë³´ë“œ ì´ë²¤íŠ¸ë¥¼ ê°ì§€í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì´ëŸ° ì´ë²¤íŠ¸ë¥¼ ê°ì§€í•´ì„œ ì²˜ë¦¬í•˜ë ¤ë©´ ìœˆë„ìš°ë¥¼ ìƒì„±í•˜ê³  ì œì–´í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤. . import numpy as np import cv2 image = np.zeros((200, 400), np.uint8) # í–‰ë ¬ ìƒì„± image[:] = 200 # ë°ì€ íšŒìƒ‰(200) ë°”íƒ• ì˜ìƒ ìƒì„± title1, title2 = &#39;Position1&#39;, &#39;Position2&#39; # ìœˆë„ìš° ì´ë¦„ cv2.namedWindow(title1, cv2.WINDOW_AUTOSIZE) # ìœˆë„ìš° ìƒì„± ë° í¬ê¸°ì¡°ì ˆ ì˜µì…˜ cv2.namedWindow(title2) cv2.moveWindow(title1, 150, 150) cv2.moveWindow(title2, 400, 50) cv2.imshow(title1, image) cv2.imshow(title2, image) cv2.waitKey(0) cv2.destroyAllWindows() . image . array([[200, 200, 200, ..., 200, 200, 200], [200, 200, 200, ..., 200, 200, 200], [200, 200, 200, ..., 200, 200, 200], ..., [200, 200, 200, ..., 200, 200, 200], [200, 200, 200, ..., 200, 200, 200], [200, 200, 200, ..., 200, 200, 200]], dtype=uint8) . import numpy as np import cv2 image = np.zeros((200,300), np.uint8) # ndarray í–‰ë ¬ ìƒì„± image.fill(255) # ëª¨ë“  ì›ì†Œì— 255(í°ìƒ‰) ì§€ì • image, image.shape title1, title2 = &#39;AUTOSIZE&#39;, &#39;NORMAL&#39; cv2.namedWindow(title1, cv2.WINDOW_AUTOSIZE) cv2.namedWindow(title2, cv2.WINDOW_NORMAL) # cv2.moveWindow(title1, 150, 150) # ìœˆë„ìš° ì´ë™ - ìœ„ì¹˜ ì§€ì • # cv2.moveWindow(title2, 400, 50) cv2.imshow(&#39;image&#39;, image) # ì›ë³¸ ì´ë¯¸ì§€ cv2.imshow(title1, image) # AUTOSIZE cv2.imshow(title2, image) # NORMAL cv2.resizeWindow(title1, 400, 300) # ìœˆë„ìš° í¬ê¸° ë³€ê²½ cv2.resizeWindow(title2, 400, 300) cv2.waitKey(0) # í‚¤ ì´ë²¤íŠ¸ ëŒ€ê¸° cv2.destroyAllWindows() # ì—´ë¦° ëª¨ë“  ìœˆë„ìš° ë‹«ê¸° . ì‹¤í–‰ê²°ê³¼, í–‰ë ¬ì„ ë‘ ìœˆë„ìš°ì— ì˜ìƒì„ í‘œì‹œí•œ í›„ì— cv2.resizeWindow() ì˜ìƒì˜ í¬ê¸°ë¥¼ ê°€ë¡œ 400í™”ì†Œ, ì„¸ë¡œ 300í™”ì†Œë¡œ ë³€ê²½í•œë‹¤. ì—¬ê¸°ì„œ ë‘ ìœˆë„ìš°ì— ë‚˜íƒ€ë‚˜ëŠ” ì˜ìƒ(image í–‰ë ¬)ì˜ í˜•íƒœê°€ ë‹¤ë¥´ë‹¤. | ì¦‰, AUTOSIZE ìœˆë„ìš°ëŠ” í–‰ë ¬ì˜ í¬ê¸° ë³€ê²½ ì—†ì´ ìœˆë„ìš°ì˜ í¬ê¸°ë§Œ ë°”ê¾¸ë©°, | NORMAL ìœˆë„ìš°ëŠ” ë³€ê²½ëœ ìœˆë„ìš°ì™€ ë™ì¼í•˜ê²Œ í–‰ë ¬ì˜ í¬ê¸°ë„ ë°”ë€ë‹¤. ë‹¨, image í–‰ë ¬ì˜ ì‹¤ì œ í¬ê¸°ë¥¼ ë°”ê¾¸ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë³´ì—¬ì§€ëŠ” í˜•íƒœë§Œ ë°”ê¾¸ëŠ” ê²ƒ | . 4.1 &#51060;&#48292;&#53944; &#52376;&#47532; &#54632;&#49688; . OpenCVì—ì„œ ì§€ì›í•˜ëŠ” ì´ë²¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ì— ëŒ€í•´ ë°°ì›Œë³¸ë‹¤. . ëŒ€í‘œì ì¸ ì´ë²¤íŠ¸ ë°œìƒì€ ì‚¬ìš©ìê°€ ë§ˆìš°ìŠ¤ë¥¼ ì›€ì§ì¸ë‹¤ê±°ë‚˜ í‚¤ë³´ë“œì˜ í‚¤ë¥¼ ëˆ„ë¥´ëŠ” ê²ƒ ë“±ì´ ëŒ€í‘œì ì´ë‹¤. ìœˆë„ìš° ìš´ì˜ì²´ì œì—ì„œëŠ” ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ë©°, ì´ëŸ¬í•œ ì´ë²¤íŠ¸ ì²˜ë¦¬ë¥¼ í†µí•´ ì‚¬ìš©í•˜ê¸° í¸ë¦¬í•œ ëŒ€í™”í˜• í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤. . ì¼ë°˜ì ìœ¼ë¡œ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì½œë°±(callback) í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤. ì½œë°± í•¨ìˆ˜ëŠ” ê°œë°œìê°€ ì‹œìŠ¤í…œ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ë°©ì‹ì´ ì•„ë‹ˆë¼, ì–´ë–¤ ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ê±°ë‚˜ íŠ¹ì • ì‹œì ì— ë„ë‹¬í–ˆì„ ë•Œ ì‹œìŠ¤í…œì´ ê°œë°œìê°€ ë“±ë¡í•œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒ. . OpenCVì—ì„œë„ ê¸°ë³¸ì ì¸ ì´ë²¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì§€ì›í•œë‹¤. ëŒ€í‘œì ìœ¼ë¡œ í‚¤ë³´ë“œ ì´ë²¤íŠ¸, ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸, íŠ¸ë™ë°”(trackbar) ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ë“¤ì´ ìˆë‹¤. . 4.2.1 &#53412;&#48372;&#46300; &#51060;&#48292;&#53944; &#51228;&#50612; . - cv2.waitKey([, delay) . delay $ leq 0 $ : í‚¤ ì´ë²¤íŠ¸ ë°œìƒê¹Œì§€ ë¬´í•œëŒ€ê¸° | delay &gt; $0$ : ì§€ì—° ì‹œê°„ ë™ì•ˆ í‚¤ ì…ë ¥ ëŒ€ê¸°, ì§€ì—° ì‹œê°„ ì•ˆì— í‚¤ ì´ë²¤íŠ¸ ì—†ìœ¼ë©´ -1 ë°˜í™˜ | . import numpy as np import cv2 # switch caseë¬¸ì„ ì‚¬ì „ìœ¼ë¡œ êµ¬í˜„ switch_case { ord(&#39;a&#39;): &quot;aí‚¤ ì…ë ¥&quot;, # ord()í•¨ìˆ˜: ë¬¸ìë¥¼ ì•„ìŠ¤í‚¤ì½”ë“œë¡œ ë³€í™˜ ord(&#39;b&#39;): &quot;bí‚¤ ì…ë ¥&quot; 0x41: &quot;Aí‚¤ ì…ë ¥&quot;, int(&#39;ox42&#39;, 16): &quot;Bí‚¤ ì…ë ¥&quot;, 2424832: &quot;ì™¼ìª½ í™”ì‚´í‘œí‚¤ ì…ë ¥&quot;, 2490368: &quot;ìœ—ìª½ í™”ì‚´í‘œí‚¤ ì…ë ¥&quot;, 2555904: &quot;ì˜¤ë¥¸ìª½ í™”ì‚´í‘œí‚¤ ì…ë ¥&quot;, 2621440: &quot;ì•„ë˜ìª½ í™”ì‚´í‘œí‚¤ ì…ë ¥&quot; } image = np.ones((200,300), np.float) # ì›ì†Œê°’ì´ 1ì¸ í–‰ë ¬ ìƒì„± cv2.namedWindow(&quot;Keyboard Event&quot;) cv2.imshow(&quot;Keyboard Event&quot;, image) while True: # ë¬´í•œ ë°˜ë³µ key = cv2.waitKeyEx(100) # 100ms ë™ì•ˆ í‚¤ ì´ë²¤íŠ¸ ëŒ€ê¸° if key == 27: break # ESC í‚¤ ëˆ„ë¥´ë©´ ì¢…ë£Œ try: result = switch_cas[key] print(result) except keyError: result = -1 cv2.destroyAllWindows() # ì—´ë¥¸ ëª¨ë“  ìœˆë„ìš° ì œê±° . Cell In [5], line 5 switch_case { ^ SyntaxError: invalid syntax . 4.2.2 &#47560;&#50864;&#49828; &#51060;&#48292;&#53944; &#51228;&#50612; . import numpy as np import cv2 def onMouse(event, x, y, flags, param): if event == cv2.EVENT_LBUTTONDOWN: print(&#39;ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ëˆ„ë¥´ê¸°&#39;) elif event == cv2.EVENT_RBUTTONDOWN: print(&#39;ë§ˆìš°ìŠ¤ ì˜¤ë¥¸ìª½ ë²„íŠ¼ ëˆ„ë¥´ê¸°&#39;) elif event == cv2.EVENT_LBUTTONUP: print(&#39;ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ë–¼ê¸°&#39;) elif event == cv2.EVENT_RBUTTONUP: print(&#39;ë§ˆìš°ìŠ¤ ì˜¤ë¥¸ìª½ ë²„íŠ¼ ë–¼ê¸°&#39;) elif event == cv2.EVENT_LBUTTONDBLCLK: print(&#39;ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ë”ë¸” í´ë¦­&#39;) image = np.full((200, 300), 255, np.uint8) # ì´ˆê¸° ì˜ìƒ ìƒì„± title1, title2 = &quot;Mouse Event1&quot;, &quot;Mouse Event2&quot; # ìœˆë„ìš° ì´ë¦„ cv2.imshow(title1, image) # ì˜ìƒ ë³´ê¸° cv2.imshow(title2, image) cv2.setMouseCallback(title1, onMouse) # ë§ˆìš°ìŠ¤ ì½œë°± í•¨ìˆ˜ cv2.waitKey(0) cv2.destroyAllWindows() . ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ëˆ„ë¥´ê¸° ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ë–¼ê¸° ë§ˆìš°ìŠ¤ ì˜¤ë¥¸ìª½ ë²„íŠ¼ ëˆ„ë¥´ê¸° ë§ˆìš°ìŠ¤ ì˜¤ë¥¸ìª½ ë²„íŠ¼ ë–¼ê¸° ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ëˆ„ë¥´ê¸° ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ë–¼ê¸° ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ë”ë¸” í´ë¦­ ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ëˆ„ë¥´ê¸° ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ë–¼ê¸° . 4.2.3 &#53944;&#47001;&#48148; &#51060;&#48292;&#53944; &#51228;&#50612; . import numpy as np import cv2 def onChange(value): # íŠ¸ë™ë°” ì½œë°± í•¨ìˆ˜ global image, title # ì „ì—­ ë³€ìˆ˜ ì°¸ì¡° add_value = value - int(image[0][0]) # íŠ¸ë™ë°” ê°’ê³¼ ì˜ìƒ í™”ì†Œê°’ ì°¨ë¶„ print(&#39;ì¶”ê°€ í™”ì†Œê°’:&#39;, add_value) image = image + add_value # í–‰ë ¬ê³¼ ìŠ¤ì¹¼ë¼ ë§ì…ˆ ìˆ˜í–‰ cv2.imshow(title,image) image = np.zeros((300, 500), np.uint8) # ì˜ìƒ ìƒì„± title = &#39;Trackbar Event&#39; cv2.imshow(title, image) cv2.createTrackbar(&#39;Brightness&#39;, title, image[0][0], 255, onChange) # íŠ¸ë™ë°” ì½œë°± í•¨ìˆ˜ ë“±ë¡ cv2.waitKey(0) cv2.destroyAllWindows() . ì¶”ê°€ í™”ì†Œê°’: 5 ì¶”ê°€ í™”ì†Œê°’: 4 ì¶”ê°€ í™”ì†Œê°’: 2 ì¶”ê°€ í™”ì†Œê°’: 2 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 2 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 3 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 2 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 1 ì¶”ê°€ í™”ì†Œê°’: 1 . 4.3 &#44536;&#47532;&#44592; &#54632;&#49688; .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/09/02/chap4.html",
            "relUrl": "/python/2022/09/02/chap4.html",
            "date": " â€¢ Sep 2, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "OpenCV intro",
            "content": "ref: https://www.youtube.com/watch?v=F2FRpmh9sQo . &#51060;&#48120;&#51648; &#51069;&#50612;&#49436; &#49332;&#54196;&#48372;&#44592; . 01. cv2.imread(file_name, flag) . cv2.imread(file_name, flag) : ì´ë¯¸ì§€ë¥¼ ì½ì–´ Numpy ê°ì²´ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜ file_name : ì½ê³ ì í•˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ | flag : ì´ë¯¸ì§€ë¥¼ ì½ëŠ” ë°©ë²• ì„¤ì • . IMREAD_COLOR : ì´ë¯¸ì§€ë¥¼ Colorë¡œ ì½ê³ , íˆ¬ëª…í•œ ë¶€ë¶„ì€ ë¬´ì‹œ | IMREAD_GRAYSCALE : ì´ë¯¸ì§€ë¥¼ Grayscaleë¡œ ì½ê¸° | IMREAD_UNCHANGED : ì´ë¯¸ì§€ë¥¼ Colorë¡œ ì½ê³ , íˆ¬ëª…í•œ ë¶€ë¶„ë„ ì½ê¸° (Alpha) | . | ë°˜í™˜ ê°’ : Numpy ê°ì²´ (í–‰, ì—´, ìƒ‰ìƒ: ê¸°ë³¸ BGR) . | . 02. cv2. imshow(title, image) . cv2.imshow(title, image) : íŠ¹ì •í•œ ì´ë¯¸ì§€ë¥¼ í™”ë©´ì— ì¶œë ¥ title: ìœˆë„ìš° ì°½ì˜ ì œëª© | image : ì¶œë ¥í•  ì´ë¯¸ì§€ ê°ì²´ | . 03. cv2.imwrite(file_name, image) . cv2.imwrite(file_name, image) : íŠ¹ì •í•œ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ file_name : ì €ì¥í•  ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ | image : ì €ì¥í•  ì´ë¯¸ì§€ ê°ì²´ | . 04. cv2.waitKey(time) . cv2.waitKey(time) : í‚¤ë³´ë“œ ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ time : ì…ë ¥ ëŒ€ê¸° ì‹œê°„ (ë¬´í•œëŒ€ê¸°: 0) . | ë°˜í™˜ ê°’: ì‚¬ìš©ìê°€ ì…ë ¥í•œ Ascii Code (ESC: 27) . | . 05. cv2.destroyAllWindows() . cv2.destroyAllWindows() : í™”ë©´ì˜ ëª¨ë“  ìœˆë„ìš°ë¥¼ ë‹«ëŠ” í•¨ìˆ˜ import cv2 img_basic = cv2.imread(&#39;./ghtop_images/chap05_images/color.jpg&#39;, cv2.IMREAD_COLOR) cv2.imshow(&#39;Image Basic&#39;, img_basic) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/img_basic.png&#39;, img_basic) # ì´ë¯¸ì§€ ì €ì¥ cv2.destroyAllWindows() . . img_gray = cv2.cvtColor(img_basic, cv2.COLOR_BGR2GRAY) cv2.imshow(&quot;Image Gray&quot;, img_gray) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/img_gray.png&#39;, img_gray) # ì´ë¯¸ì§€ ì €ì¥ cv2.destroyAllWindows() . .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/09/01/opencv-intro.html",
            "relUrl": "/python/2022/09/01/opencv-intro.html",
            "date": " â€¢ Sep 1, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "(1ì£¼ì°¨ ML2) 4ì›” 28ì¼",
            "content": "",
            "url": "https://pinkocto.github.io/BP2022/python/2022/04/28/ML.html",
            "relUrl": "/python/2022/04/28/ML.html",
            "date": " â€¢ Apr 28, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "OpenCV",
            "content": "https://www.youtube.com/watch?v=XK3eU9egll8 . &#54872;&#44221; &#49444;&#51221; . Anaconda promptì—ì„œ ë‹¤ìŒ ëª…ë ¹ ìˆ˜í–‰ . pip install opencv-pythoon . import cv2 cv2.__version__ . &#39;4.5.5&#39; . OpenCV (Computer Vision) . ë‹¤ì–‘í•œ ì˜ìƒ (ì´ë¯¸ì§€) / ë™ì˜ìƒ ì²˜ë¦¬ì— ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ . 1. &#51060;&#48120;&#51648; &#52636;&#47141; . import cv2 img = cv2.imread(&#39;./my_icons/img.jpg&#39;) # í•´ë‹¹ ê²½ë¡œì˜ íŒŒì¼ ì½ì–´ì˜¤ê¸° cv2.imshow(&#39;img&#39;, img) # img ë¼ëŠ” ì´ë¦„ì˜ ì°½ì— imgë¥¼ í‘œì‹œ cv2.waitKey(5000) # ì§€ì •ëœ ì‹œê°„(ms) ë™ì•ˆ ì‚¬ìš©ì í‚¤ ì…ë ¥ ëŒ€ê¸° print(key) cv2.destroyAllWindows() # ëª¨ë“  ì°½ ë‹«ê¸° . 98 . &#51069;&#44592; &#50741;&#49496; . cv2.IMREAD_COLOR : ì»¬ëŸ¬ ì´ë¯¸ì§€,. íˆ¬ëª… ì˜ì—­ì€ ë¬´ì‹œ (ê¸°ë³¸ê°’) | cv2.IMREAD_GRAYSCALE : í‘ë°±ì´ë¯¸ì§€ | cv2.IMREAD_UNCHANGED : íˆ¬ëª… ì˜ì—³ê¹Œì§€ í¬í•¨ | import cv2 img_color = cv2.imread(&#39;./my_icons/img.jpg&#39;, cv2.IMREAD_COLOR) img_gray = cv2.imread(&#39;./my_icons/img.jpg&#39;, cv2.IMREAD_GRAYSCALE) img_unchanged = cv2.imread(&#39;./my_icons/img.jpg&#39;, cv2.IMREAD_UNCHANGED) cv2.imshow(&#39;img_color&#39;, img_color) cv2.imshow(&#39;img_gray&#39;, img_gray) cv2.imshow(&#39;img_unchanged&#39;, img_unchanged) cv2.waitKey(0) cv2.destroyAllWindows() . Shape . ì´ë¯¸ì§€ì˜ height, width, channel ì •ë³´ . import cv2 img = cv2.imread(&#39;./my_icons/img.jpg&#39;) img.shape # ì„¸ë¡œ, ê°€ë¡œ, Channel . (390, 640, 3) . 2. &#46041;&#50689;&#49345; &#52636;&#47141; . &#46041;&#50689;&#49345; &#54028;&#51068; &#52636;&#47141; . import cv2 cap = cv2.VideoCapture(&#39;./my_icons/video.mp4&#39;) while cap.isOpened(): # ë™ì˜ìƒ íŒŒì¼ì´ ì˜¬ë°”ë¡œ ì—´ë ¸ëŠ”ì§€? ret, frame = cap.read() # ret : ì„±ê³µ ì—¬ë¶€, frame : ë°›ì•„ì˜¨ ì´ë¯¸ì§€ (í”„ë ˆì„) if not ret: print(&#39;ë” ì´ìƒ ê°€ì ¸ì˜¬ í”„ë ˆì„ì´ ì—†ì–´ìš”&#39;) break cv2.imshow(&#39;video&#39;, frame) if cv2.waitKey(1) == ord(&#39;q&#39;): print(&#39;ì‚¬ìš©ì ì…ë ¥ì— ì˜í•´ ì¢…ë£Œí•©ë‹ˆë‹¤&#39;) break cap.release() # ìì› í•´ì œ cv2.destroyAllWindows() # ëª¨ë“  ì°½ ë‹«ê¸° . ë” ì´ìƒ ê°€ì ¸ì˜¬ í”„ë ˆì„ì´ ì—†ì–´ìš” . &#52852;&#47700;&#46972; &#52636;&#47141; . import cv2 cap = cv2.VideoCapture(0) # 0ë²ˆì§¸ ì¹´ë©”ë¼ ì¥ì¹˜ (Device ID) if not cap.isOpened(): # ì¹´ë©”ë¼ê°€ ì˜ ì—´ë¦¬ì§€ ì•Šì€ ê²½ìš° exit() # í”„ë¡œê·¸ë¨ ì¢…ë£Œ while True: ret, frame = cap.read() if not ret: break cv2.imshow(&#39;camera&#39;, frame) if cv2.waitKey(1) == ord(&#39;q&#39;): # ì‚¬ìš©ìê°€ që¥¼ ì…ë ¥í•˜ë©´ break cap.release() cv2.destroyAllWindows() . 3. &#46020;&#54805; &#44536;&#47532;&#44592; . &#48712; &#49828;&#52992;&#52824;&#48513; &#47564;&#46308;&#44592; . import cv2 import numpy as np # ì„¸ë¡œ 480 X ê°€ë¡œ 640, 3 Channel (RGB) ì— í•´ë‹¹í•˜ëŠ” ìŠ¤ì¼€ì¹˜ë¶ ë§Œë“¤ê¸° img = np.zeros((480, 640, 3), dtype = np.uint8) # img[:] = (255, 255, 255) # ì „ì²´ ê³µê°„ì„ í°ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸° (B,G,R) # print(img) cv2.imshow(&#39;img&#39;, img) cv2.waitKey(0) cv2.destroyAllWindows() .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/04/26/opencv.html",
            "relUrl": "/python/2022/04/26/opencv.html",
            "date": " â€¢ Apr 26, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "(1ì£¼ì°¨ ML2) 4ì›” 26ì¼",
            "content": "import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns . import matplotlib.pyplot as plt ## íŒŒì´ì¬ ë‚´ì—ì„œ ê·¸ë˜í”„ ì¶œë ¥ì‹œ ë””í…Œì¼í•œ ì˜µì…˜ import matplotlib as mpl ## í•œê¸€í°íŠ¸ ì„¤ì •, ê¸€ì”¨ì²´ íë¦¿í•œ ê²ƒì„ ì„ ëª…í•˜ê²Œ (ì „ì²´ì ì¸ í° í‹€ì˜ ì˜µì…˜) . mpl.rc(&#39;font&#39;, family=&#39;Malgun Gothic&#39;) ## ë§‘ì€ ê³ ë”• . 1. Data . ìœ„ìŠ¤ì½˜ì‹  ìœ ë°©ì•” ë°ì´í„°(Wisconsin Breast Cancer data)ë¥¼ ë¶„ì„í•´ë³´ì. . ë¶„ì„ì˜ ëª©ì ì€ 30ê°œì˜ ì„¤ëª…ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ ì§„ë‹¨ê°’ì´ ì•…ì„±ì¸ì§€ ì–‘ì„±ì¸ì§€ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. . 1.1 Data Load . from sklearn.datasets import load_breast_cancer . cancer = load_breast_cancer() . cancer[&quot;feature_names&quot;] . array([&#39;mean radius&#39;, &#39;mean texture&#39;, &#39;mean perimeter&#39;, &#39;mean area&#39;, &#39;mean smoothness&#39;, &#39;mean compactness&#39;, &#39;mean concavity&#39;, &#39;mean concave points&#39;, &#39;mean symmetry&#39;, &#39;mean fractal dimension&#39;, &#39;radius error&#39;, &#39;texture error&#39;, &#39;perimeter error&#39;, &#39;area error&#39;, &#39;smoothness error&#39;, &#39;compactness error&#39;, &#39;concavity error&#39;, &#39;concave points error&#39;, &#39;symmetry error&#39;, &#39;fractal dimension error&#39;, &#39;worst radius&#39;, &#39;worst texture&#39;, &#39;worst perimeter&#39;, &#39;worst area&#39;, &#39;worst smoothness&#39;, &#39;worst compactness&#39;, &#39;worst concavity&#39;, &#39;worst concave points&#39;, &#39;worst symmetry&#39;, &#39;worst fractal dimension&#39;], dtype=&#39;&lt;U23&#39;) . Variable name Description . radius | ë°˜ì§€ë¦„ | . texture | ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ê°’ì˜ í‘œì¤€í¸ì°¨ | . perimeter | ë‘˜ë ˆ | . area | ë©´ì  | . smoothness | ë°˜ì§€ë¦„ì˜ êµ­ì†Œì  ë³€í™”ì •ë„(local variation) | . compactness | $ frac{ text{perimeter}^2}{area}-1.0$ | . concavity | ì˜¤ëª©í•œ ì •ë„(severity of concave portions of the contour) | . concave_points | ì˜¤ëª©í•œ ì ë“¤ì˜ ê°œìˆ˜(number of concave portions of contour) | . symmetry | ëŒ€ì¹­ë„ | . fractal dimension | í”„ë™íƒˆ ì°¨ì›($ text{&quot;coastline approximation&quot;} - 1$) | . cancer[&quot;target_names&quot;] . array([&#39;malignant&#39;, &#39;benign&#39;], dtype=&#39;&lt;U9&#39;) . malignant : ì•…ì„± ($0$) | benign : ì–‘ì„± ($1$) | . - ë°ì´í„°ì™€ ì •ë‹µì„ í™•ì¸í•´ë³´ì. . data, target = cancer[&quot;data&quot;], cancer[&quot;target&quot;] . data . array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01, 1.189e-01], [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01, 8.902e-02], [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01, 8.758e-02], ..., [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01, 7.820e-02], [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01, 1.240e-01], [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01, 7.039e-02]]) . target . array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]) . 1.2 EDA . df = pd.DataFrame(data, columns=cancer[&quot;feature_names&quot;]) df.describe() . mean radius mean texture mean perimeter mean area mean smoothness mean compactness mean concavity mean concave points mean symmetry mean fractal dimension ... worst radius worst texture worst perimeter worst area worst smoothness worst compactness worst concavity worst concave points worst symmetry worst fractal dimension . count 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | ... | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | . mean 14.127292 | 19.289649 | 91.969033 | 654.889104 | 0.096360 | 0.104341 | 0.088799 | 0.048919 | 0.181162 | 0.062798 | ... | 16.269190 | 25.677223 | 107.261213 | 880.583128 | 0.132369 | 0.254265 | 0.272188 | 0.114606 | 0.290076 | 0.083946 | . std 3.524049 | 4.301036 | 24.298981 | 351.914129 | 0.014064 | 0.052813 | 0.079720 | 0.038803 | 0.027414 | 0.007060 | ... | 4.833242 | 6.146258 | 33.602542 | 569.356993 | 0.022832 | 0.157336 | 0.208624 | 0.065732 | 0.061867 | 0.018061 | . min 6.981000 | 9.710000 | 43.790000 | 143.500000 | 0.052630 | 0.019380 | 0.000000 | 0.000000 | 0.106000 | 0.049960 | ... | 7.930000 | 12.020000 | 50.410000 | 185.200000 | 0.071170 | 0.027290 | 0.000000 | 0.000000 | 0.156500 | 0.055040 | . 25% 11.700000 | 16.170000 | 75.170000 | 420.300000 | 0.086370 | 0.064920 | 0.029560 | 0.020310 | 0.161900 | 0.057700 | ... | 13.010000 | 21.080000 | 84.110000 | 515.300000 | 0.116600 | 0.147200 | 0.114500 | 0.064930 | 0.250400 | 0.071460 | . 50% 13.370000 | 18.840000 | 86.240000 | 551.100000 | 0.095870 | 0.092630 | 0.061540 | 0.033500 | 0.179200 | 0.061540 | ... | 14.970000 | 25.410000 | 97.660000 | 686.500000 | 0.131300 | 0.211900 | 0.226700 | 0.099930 | 0.282200 | 0.080040 | . 75% 15.780000 | 21.800000 | 104.100000 | 782.700000 | 0.105300 | 0.130400 | 0.130700 | 0.074000 | 0.195700 | 0.066120 | ... | 18.790000 | 29.720000 | 125.400000 | 1084.000000 | 0.146000 | 0.339100 | 0.382900 | 0.161400 | 0.317900 | 0.092080 | . max 28.110000 | 39.280000 | 188.500000 | 2501.000000 | 0.163400 | 0.345400 | 0.426800 | 0.201200 | 0.304000 | 0.097440 | ... | 36.040000 | 49.540000 | 251.200000 | 4254.000000 | 0.222600 | 1.058000 | 1.252000 | 0.291000 | 0.663800 | 0.207500 | . 8 rows Ã— 30 columns . cancer[&quot;feature_names&quot;] . array([&#39;mean radius&#39;, &#39;mean texture&#39;, &#39;mean perimeter&#39;, &#39;mean area&#39;, &#39;mean smoothness&#39;, &#39;mean compactness&#39;, &#39;mean concavity&#39;, &#39;mean concave points&#39;, &#39;mean symmetry&#39;, &#39;mean fractal dimension&#39;, &#39;radius error&#39;, &#39;texture error&#39;, &#39;perimeter error&#39;, &#39;area error&#39;, &#39;smoothness error&#39;, &#39;compactness error&#39;, &#39;concavity error&#39;, &#39;concave points error&#39;, &#39;symmetry error&#39;, &#39;fractal dimension error&#39;, &#39;worst radius&#39;, &#39;worst texture&#39;, &#39;worst perimeter&#39;, &#39;worst area&#39;, &#39;worst smoothness&#39;, &#39;worst compactness&#39;, &#39;worst concavity&#39;, &#39;worst concave points&#39;, &#39;worst symmetry&#39;, &#39;worst fractal dimension&#39;], dtype=&#39;&lt;U23&#39;) . ì–‘ì„±ê³¼ ì•…ì„±ì˜ ë¹„ìœ¨ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. . pd.Series(cancer[&quot;target&quot;]).value_counts() . 1 357 0 212 dtype: int64 . ì¢…ì–‘ì§„ë‹¨ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” class ë³€ìˆ˜ì˜ ë„ìˆ˜ë¶„í¬ë¡œë¶€í„° 357 ëª…ì˜ ê´€ì¸¡ì¹˜ê°€ ì–‘ì„±(benign, class=0)ì— í•´ë‹¹í•˜ê³ , ì´ë³´ë‹¤ ì ì€ 212ëª…ì˜ ê´€ì¸¡ì¹˜ê°€ ì•…ì„±(malign, class=1)ì— í•´ë‹¹í•¨ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. . sns.countplot(x=target) plt.title(&quot;ì¢…ì–‘ì§„ë‹¨ classë³„ ë„ìˆ˜ë¶„í¬&quot;) plt.xlabel(&quot;class&quot;) plt.ylim([0, 450]) plt.text(-0.1, 220, &quot;ì•…ì„±&quot;) plt.text(.9, 370, &quot;ì–‘ì„±&quot;) plt.show() . sns.boxplot(x=target, y=df[&quot;mean concave points&quot;]) plt.xlabel(&quot;class&quot;) . Text(0.5, 0, &#39;class&#39;) . ì•…ì„± ì¢…ì–‘ì„¸í¬ì—ì„œ mean_concave_points ê°’ì´ í›¨ì”¬ ë†’ì€ í¸ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. | . sns.boxplot(x=target, y=df[&quot;mean radius&quot;]) . &lt;AxesSubplot:ylabel=&#39;mean radius&#39;&gt; . ì•…ì„± ì¢…ì–‘ì„¸í¬ì—ì„œ mean_radius ê°’ì´ í›¨ì”¬ ë†’ì€ í¸ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. | . plt.scatter(x=df[&quot;mean concave points&quot;], y=df[&quot;mean radius&quot;], alpha=.5) plt.xlabel(&quot;mean_concave_points&quot;) plt.ylabel(&quot;mean_radius&quot;) . Text(0, 0.5, &#39;mean_radius&#39;) . ìœ„ì˜ ê·¸ë¦¼ì€ mean_concave_pointsì™€ mean_radius ë³€ìˆ˜ ì‚¬ì´ì˜ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. | . 1.3 Data Split . ë°ì´í„°ë¥¼ $7:3$ì˜ ë¹„ìœ¨ë¡œ train/test setìœ¼ë¡œ ë‚˜ëˆ„ì . from sklearn.model_selection import train_test_split train_data, test_data, train_target, test_target = train_test_split( data, target, train_size= 0.7, random_state=1001, ) . print(&quot;train data ê°œìˆ˜:&quot;, len(train_data)) print(&quot;test data ê°œìˆ˜:&quot;, len(test_data)) . train data ê°œìˆ˜: 398 test data ê°œìˆ˜: 171 . 2. Linear Regression and Categorical Label . Logistic Regressionì„ í•™ìŠµí•˜ê¸°ì— ì•ì„œ Linear Regressionìœ¼ë¡œ í•™ìŠµí•  ê²½ìš° ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ë³´ì. . from sklearn.linear_model import LinearRegression linear_regressor = LinearRegression() . 2.1 &#54617;&#49845; . linear_regressor.fit(train_data, train_target) . LinearRegression() . 2.2 &#50696;&#52769; . train_pred = linear_regressor.predict(train_data) test_pred = linear_regressor.predict(test_data) . ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ë©´ $0 sim 1$ ì‚¬ì´ë¥¼ ë²—ì–´ë‚œ ì˜ˆì¸¡ê°’ì´ ë³´ì´ëŠ”ë°..? | ì¼ë‹¨ ë„˜ì–´ê°€ì.. | . 2.3 &#49884;&#44033;&#54868; . fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5)) preds = [ (&quot;Train&quot;, train_data, train_pred), (&quot;Test&quot;, test_data, test_pred), ] for idx, (name, d, pred) in enumerate(preds): ax = axes[idx] ax.scatter(x=d[:,0], y=pred) ax.axhline(0, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.axhline(1, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.set_xlabel(&#39;mean_radius&#39;) ax.set_ylabel(&#39;predict&#39;) ax.set_title(f&quot;{name} Data&quot;) plt.show() . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . 2.4 &#54217;&#44032;&#54616;&#44592; . Linear Regressionì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ì„œëŠ” ìš°ì„  ì˜ˆì¸¡ê°’ì„ 0ê³¼ 1ë¡œ ë³€í™˜ì‹œì¼œì¤˜ì•¼ í•©ë‹ˆë‹¤. . Youden&#39;s Indexë¥¼ ì´ìš©í•´ Best Thresholdë¥¼ ì°¾ì€ í›„, 0ê³¼ 1ë¡œ ë³€í™”ì‹œí‚¨ í›„ ì •í™•ë„ë¥¼ ë¹„êµí•´ë³´ì. . ($ star$)Youden&#39;s J statistic . ì°¸ê³ ë§í¬: https://en.wikipedia.org/wiki/Youden%27s_J_statistic . $$ J = text{sensitivity} + text{specificity} - 1$$ . $$ J = frac{ text{True positives}}{ text{True positives}+ text{False negatives}} + frac{ text{True negatives}}{ text{True negatives}+ text{False positives}} - 1$$ . . from sklearn.metrics import auc, roc_curve fpr, tpr, threshold = roc_curve(train_target, train_pred) auroc = auc(fpr, tpr) . fpr . array([0. , 0. , 0. , 0.00699301, 0.00699301, 0.01398601, 0.01398601, 0.02097902, 0.02097902, 0.02797203, 0.02797203, 0.04195804, 0.04195804, 0.06993007, 0.06993007, 0.12587413, 0.12587413, 1. ]) . tpr . array([0. , 0.00392157, 0.70980392, 0.70980392, 0.90980392, 0.90980392, 0.93333333, 0.93333333, 0.96862745, 0.96862745, 0.98431373, 0.98431373, 0.99215686, 0.99215686, 0.99607843, 0.99607843, 1. , 1. ]) . threshold . array([ 2.35725299, 1.35725299, 0.82521489, 0.82466702, 0.70119883, 0.69924511, 0.67546196, 0.67513605, 0.63707749, 0.63401065, 0.61560836, 0.59241528, 0.58134679, 0.50969629, 0.50796669, 0.43013177, 0.42764525, -0.53936311]) . AUROCë¥¼ ê·¸ë ¤ë³´ì. . plt.plot(fpr, tpr) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) . Text(0, 0.5, &#39;tpr&#39;) . AUROC ê°’ì„ ê³„ì‚°í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. . print(f&quot;AUROC : {auroc: .4f}&quot;) . AUROC : 0.9960 . ì´ì œ Best Thresholdë¥¼ ê³„ì‚°í•´ë³´ì. . np.argmax(tpr - fpr) . 10 . 10ì¸ index ì—ì„œ Best Thresholdë¥¼ ê°–ëŠ”ë‹¤ëŠ” ì˜ë¯¸ | . J = tpr - fpr idx = np.argmax(J) best_thresh = threshold[idx] print(f&quot;Best Threshold is {best_thresh:.4f}&quot;) print(f&quot;Best Threshold&#39;s sensitivity is {tpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s specificity is {1-fpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s J is {J[idx]:.4f}&quot;) . Best Threshold is 0.6156 Best Threshold&#39;s sensitivity is 0.9843 Best Threshold&#39;s specificity is 0.9720 Best Threshold&#39;s J is 0.9563 . Best ThresholdëŠ” AUROC ê·¸ë˜í”„ì—ì„œ ì§ì„ ì´ ê°€ì¥ ê¸´ ê³³ì…ë‹ˆë‹¤. . plt.plot(fpr, tpr) plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10)) plt.plot((fpr[idx], fpr[idx]), (fpr[idx], tpr[idx]), color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) plt.show() . ì˜ˆì¸¡ê°’ì—ì„œì˜ Best threshold ì˜ ìœ„ì¹˜ë¥¼ ê·¸ë ¤ë³´ì . fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5)) preds = [ (&quot;Train&quot;, train_data, train_pred), (&quot;Test&quot;, test_data, test_pred), ] for idx, (name, d, pred) in enumerate(preds): ax = axes[idx] ax.scatter(x=d[:,0], y=pred) ax.axhline(0, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.axhline(1, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.set_xlabel(&quot;mean_radius&quot;) ax.set_ylabel(&quot;predict&quot;) ax.set_title(f&quot;{name} Data&quot;) ax.axhline(best_thresh, color=&quot;blue&quot;) plt.show() . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . ì´ì œ Thresholdë¡œ ì˜ˆì¸¡ê°’ì„ $0,1$ë¡œ ë³€í™˜ í›„ ì •í™•ë„ë¥¼ ë³´ì . train_pred_label = list(map(int, (train_pred &gt; best_thresh))) test_pred_label = list(map(int, (test_pred &gt; best_thresh))) . from sklearn.metrics import accuracy_score linear_train_accuracy = accuracy_score(train_target, train_pred_label) linear_test_accuracy = accuracy_score(test_target, test_pred_label) . print(f&quot;Train accuracy is : {linear_train_accuracy:.2f}&quot;) print(f&quot;Test accuracy is : {linear_test_accuracy:.2f}&quot;) . Train accuracy is : 0.98 Test accuracy is : 0.96 . 3. Logistic Regression . ì´ë²ˆì—ëŠ” Logistic Regressionì„ ì´ìš©í•˜ì—¬ ì˜ˆì¸¡í•´ ë³´ì. . 3.1 Scaling . Logistic Regressionì€ í•™ìŠµí•˜ê¸°ì— ì•ì„œ í•™ìŠµì‹œí‚¬ ë°ì´í„°ë¥¼ ì •ê·œí™”í•´ì•¼ í•©ë‹ˆë‹¤. . Logistic Regressiondì—ëŠ” expê°€ ìˆëŠ”ë°, expëŠ” ê°’ì´ í´ ê²½ìš° overflowê°€ ì¼ì–´ë‚  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. . from sklearn.preprocessing import StandardScaler scaler = StandardScaler() . ì •ê·œí™”ëŠ” í•­ìƒ train dataë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµí•˜ê³  valid, test ë°ì´í„°ë¥¼ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. . ëª¨ë“  ë°ì´í„°ë¥¼ í•œë²ˆì— í•™ìŠµí•  ê²½ìš° ë³¸ì ì´ ì—†ëŠ” valiation dataì˜ í‰ê· ê³¼ ë¶„ì‚°ì´ ë°˜ì˜ë˜ê³  ì´ëŠ” overfittingì„ ì¼ìœ¼í‚¤ëŠ” ì›ì¸ì´ ë©ë‹ˆë‹¤. . scaler.fit(train_data) . StandardScaler() . í•™ìŠµëœ Scalerë¡œ train/test ë°ì´í„°ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤. . scaled_train_data = scaler.transform(train_data) scaled_test_data = scaler.transform(test_data) . train_data[0] . array([1.953e+01, 1.890e+01, 1.295e+02, 1.217e+03, 1.150e-01, 1.642e-01, 2.197e-01, 1.062e-01, 1.792e-01, 6.552e-02, 1.111e+00, 1.161e+00, 7.237e+00, 1.330e+02, 6.056e-03, 3.203e-02, 5.638e-02, 1.733e-02, 1.884e-02, 4.787e-03, 2.593e+01, 2.624e+01, 1.711e+02, 2.053e+03, 1.495e-01, 4.116e-01, 6.121e-01, 1.980e-01, 2.968e-01, 9.929e-02]) . scaled_train_data[0] . array([ 1.55665013, -0.08374209, 1.56894905, 1.61738288, 1.35230219, 1.15579113, 1.64920637, 1.53999266, -0.05508639, 0.36872483, 2.57200558, -0.10081561, 2.13099893, 1.96746196, -0.29563095, 0.3786633 , 0.72463661, 0.88545529, -0.19263957, 0.37716933, 2.07668666, 0.10014731, 1.96594854, 2.15156304, 0.75699447, 1.00247978, 1.60389716, 1.3188727 , 0.1245053 , 0.85035853]) . 3.2 &#54617;&#49845; . ì´ì œ í‘œì¤€í™”ëœ ë°ì´í„°ë¡œ Logistic Regressionì„ í•™ìŠµí•´ ë³´ì. . from sklearn.linear_model import LogisticRegression logit_regressor = LogisticRegression() . logit_regressor.fit(scaled_train_data, train_target) . LogisticRegression() . 3.3 &#50696;&#52769; . Classificationì„ í•˜ëŠ” ëª¨ë¸ì˜ ê²½ìš° ì˜ˆì¸¡ì„ í•˜ëŠ” ë°©ë²•ì€ ë‘ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. . predict . | predict_proba . | predictëŠ” í•´ë‹¹ ë°ì´í„°ê°€ ì–´ë–¤ classë¡œ ë¶„ë¥˜í• ì§€ ë°”ë¡œ ì•Œë ¤ì¤ë‹ˆë‹¤. . ë°˜ë©´, predict_probaëŠ” ê° classì— ì†í•  í™•ë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. . train_pred = logit_regressor.predict(scaled_train_data) test_pred = logit_regressor.predict(scaled_test_data) . train_pred[:10] . array([0, 1, 0, 0, 1, 0, 1, 0, 0, 1]) . train_pred_logit = logit_regressor.predict_proba(scaled_train_data) test_pred_logit = logit_regressor.predict_proba(scaled_test_data) . train_pred_logit[:10] . array([[9.99999984e-01, 1.62885674e-08], [1.30750892e-03, 9.98692491e-01], [9.93452400e-01, 6.54760017e-03], [6.39996411e-01, 3.60003589e-01], [5.71378493e-05, 9.99942862e-01], [9.96253495e-01, 3.74650484e-03], [5.02851011e-04, 9.99497149e-01], [9.95986445e-01, 4.01355535e-03], [9.99998296e-01, 1.70356931e-06], [7.13730423e-04, 9.99286270e-01]]) . ê° classì— ì†í•  í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. . í˜„ì¬ ë°ì´í„°ì˜ ê²½ìš° ì•…ì„±ê³¼ ì–‘ì„± 2ê°œì˜ í´ë˜ìŠ¤ê°€ ìˆê¸° ë•Œë¬¸ì— 2ê°œì˜ í™•ë¥ ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. . ë§Œì•½ ì²« ë²ˆì§¸ classì— ì†í•  í™•ë¥ ì´ í¬ë‹¤ë©´ ë°ì´í„°ëŠ” 0ë²ˆ í´ë˜ìŠ¤ì— ì†í•˜ê²Œ ë˜ëŠ” ê²ƒ..! . train_pred_logit[0] . array([9.99999984e-01, 1.62885674e-08]) . 3.4 &#54217;&#44032; . ë°ì´í„°ì˜ AUROCë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” 1ì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜ë  í™•ë¥  í•˜ë‚˜ë§Œ í•„ìš”í•©ë‹ˆë‹¤. ë°˜ë©´ ìš°ë¦¬ê°€ ê°–ê³  ìˆëŠ” ì˜ˆì¸¡ê°’ì€ 0ê³¼ 1ë¡œ ë¶„ë¥˜ë  í™•ë¥ ì„ ëª¨ë‘ í‘œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ 1ì— ì†í•  í™•ë¥ ë§Œ ë‚¨ê¸°ê² ìŠµë‹ˆë‹¤. . train_pred_logit = train_pred_logit[:, 1] test_pred_logit = test_pred_logit[:, 1] . train_pred_logit[0] . 1.628856736535896e-08 . from sklearn.metrics import auc, roc_curve fpr, tpr, threshold = roc_curve(train_target, train_pred_logit) auroc = auc(fpr, tpr) . plt.plot(fpr, tpr) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) . Text(0, 0.5, &#39;tpr&#39;) . print(f&quot;AUROC : {auroc:.4f}&quot;) . AUROC : 0.9971 . J = tpr - fpr idx = np.argmax(J) best_thresh = threshold[idx] print(f&quot;Best Threshold is {best_thresh:.4f}&quot;) print(f&quot;Best Threshold&#39;s sensitivity is {tpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s specificity is {1-fpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s J is {J[idx]:.4f}&quot;) . Best Threshold is 0.5692 Best Threshold&#39;s sensitivity is 0.9961 Best Threshold&#39;s specificity is 0.9790 Best Threshold&#39;s J is 0.9751 . plt.plot(fpr, tpr) plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10)) plt.plot((fpr[idx],fpr[idx]), (fpr[idx], tpr[idx]), color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) . Text(0, 0.5, &#39;tpr&#39;) . plt.scatter(x=scaled_train_data[:,0], y=train_pred_logit) plt.axhline(best_thresh, color=&quot;blue&quot;) plt.axhline(0, color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.axhline(1, color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.xlabel(&quot;mean radius&quot;) plt.ylabel(&quot;Probability&quot;) plt.show() . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . ì´ì œ Thresholdë¡œ ì˜ˆì¸¡ê°’ì„ 0,1ë¡œ ë³€í™˜ í›„ ì •í™•ë„ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤. . train_pred_label = list(map(int, (train_pred_logit &gt; best_thresh))) test_pred_label = list(map(int, (test_pred_logit &gt; best_thresh))) . proba_train_accuracy = accuracy_score(train_target, train_pred_label) proba_test_accuracy = accuracy_score(test_target, test_pred_label) . print(f&quot;Train accuracy is : {proba_train_accuracy:.2f}&quot;) print(f&quot;Test accuracy is : {proba_test_accuracy:.2f}&quot;) . Train accuracy is : 0.99 Test accuracy is : 0.98 . ì´ë²ˆì—ëŠ” predictì˜ ê²°ê³¼ê°’ìœ¼ë¡œ ì •í™•ë„ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤. . train_accuracy = accuracy_score(train_target, train_pred) test_accuracy = accuracy_score(test_target, test_pred) . print(f&quot;Train accuracy is : {train_accuracy:.2f}&quot;) print(f&quot;Test accuracy is : {test_accuracy:.2f}&quot;) . Train accuracy is : 0.99 Test accuracy is : 0.97 . predict_probaì˜ best_thresholdë¡œ ê³„ì‚°í•œ ê²°ê³¼ì™€ predictë¡œ ê³„ì‚°í•œ ê²°ê³¼ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‘ 0ê³¼ 1ë¡œ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ì„œ (0.49, 0.51)ì˜ í™•ë¥ ì´ ìˆì„ ë•Œ predictì˜ ê²½ìš° class 1ì˜ í™•ë¥ ì— ì†í•  í™•ë¥ ì´ í¬ê¸° ë•Œë¬¸ì— 1ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ best_thresholdê°€ 0.52ë¼ë©´ predict_probaì˜ ê²½ìš° classë¥¼ 0ìœ¼ë¡œ ë¶„ë¥˜í•˜ê²Œ ë©ë‹ˆë‹¤ . 4. &#47560;&#47924;&#47532; . ì„¸ê°œì˜ ëª¨ë¸ë“¤ì˜ ì •í™•ë„ë¥¼ ë¹„êµí•´ ë³´ê² ìŠµë‹ˆë‹¤. . print(f&quot;Linear Regression Test Accuracy: {linear_test_accuracy:.2f}&quot;) print(f&quot;Logistic Regression predict_proba Test Accuracy: {proba_test_accuracy:.2f}&quot;) print(f&quot;Logistic Regression predict Test Accuracy: {test_accuracy:.2f}&quot;) . Linear Regression Test Accuracy: 0.96 Logistic Regression predict_proba Test Accuracy: 0.98 Logistic Regression predict Test Accuracy: 0.97 .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/04/26/ML.html",
            "relUrl": "/python/2022/04/26/ML.html",
            "date": " â€¢ Apr 26, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "(3ì£¼ì°¨ ML) 3ì›” 24ì¼",
            "content": "&#45336;&#54028;&#51060;&#47196; &#45936;&#51060;&#53552; &#51456;&#48708; . import numpy as np . fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] . fish_data = np.column_stack((fish_length, fish_weight)) . fish_data[:5] . array([[ 25.4, 242. ], [ 26.3, 290. ], [ 26.5, 340. ], [ 29. , 363. ], [ 29. , 430. ]]) . fish_target = np.concatenate((np.ones(35), np.zeros(14))) . fish_target . array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) . &#49324;&#51060;&#53431;&#47088;&#51004;&#47196; &#45936;&#51060;&#53552; &#45208;&#45572;&#44592; . from sklearn.model_selection import train_test_split ## model selection ëª¨ë“ˆ ì•„ë˜ì— train_test_split í•¨ìˆ˜ . train_input, test_input, train_target, test_target = train_test_split( fish_data, fish_target, stratify = fish_target, random_state = 42) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/24/ML.html",
            "relUrl": "/python/2022/03/24/ML.html",
            "date": " â€¢ Mar 24, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "(3ì£¼ì°¨ DV) 3ì›” 23ì¼",
            "content": "- How to upload your CSV file online for data analysis . https://evidencen.com/how-to-upload-your-csv-file-online/ . &#45800;&#51068;&#48320;&#49688; . import seaborn as sns import pandas as pd . df1 = pd.read_csv(&#39;https://raw.githubusercontent.com/pinkocto/BP2022/master/_notebooks/Data03.csv&#39;) df1.head() . id type_of_contract type_of_contract2 channel datetime Term payment_type product amount state overdue_count overdue credit rating bank cancellation age Mileage . 0 66758234 | ë Œíƒˆ | Normal | ì„œë¹„ìŠ¤ ë°©ë¬¸ | 2019-10-20 | 60 | CMS | K1 | 96900 | ê³„ì•½í™•ì • | 0 | ì—†ìŒ | 9.0 | ìƒˆë§ˆì„ê¸ˆê³  | ì •ìƒ | 43.0 | 1862.0 | . 1 66755948 | ë Œíƒˆ | Extension_Rental | ì„œë¹„ìŠ¤ ë°©ë¬¸ | 2019-10-20 | 60 | ì¹´ë“œì´ì²´ | K1 | 102900 | ê³„ì•½í™•ì • | 0 | ì—†ìŒ | 2.0 | í˜„ëŒ€ì¹´ë“œ | ì •ìƒ | 62.0 | 2532.0 | . 2 66756657 | ë Œíƒˆ | Normal | í™ˆì‡¼í•‘/ë°©ì†¡ | 2019-10-20 | 60 | CMS | K1 | 96900 | ê³„ì•½í™•ì • | 0 | ì—†ìŒ | 8.0 | ìš°ë¦¬ì€í–‰ | ì •ìƒ | 60.0 | 2363.0 | . 3 66423450 | ë©¤ë²„ì‹­ | TAS | ë Œíƒˆì¬ê³„ì•½ | 2019-10-20 | 12 | CMS | K1 | 66900 | ê³„ì•½í™•ì • | 0 | ì—†ìŒ | 5.0 | ë†í˜‘ì€í–‰ | ì •ìƒ | 60.0 | 2449.0 | . 4 66423204 | ë©¤ë²„ì‹­ | TAS | ë Œíƒˆì¬ê³„ì•½ | 2019-10-20 | 12 | CMS | K1 | 66900 | í•´ì•½í™•ì • | 12 | ìˆìŒ | 8.0 | ë†í˜‘ì€í–‰ | í•´ì•½ | 51.0 | 1942.0 | . 1 &#48276;&#51452;&#54805; &#48320;&#49688; . df1[&#39;type_of_contract&#39;].value_counts() . ë Œíƒˆ 46481 ë©¤ë²„ì‹­ 4819 Name: type_of_contract, dtype: int64 . sns.countplot(data=df1, x=&#39;type_of_contract&#39;) . &lt;AxesSubplot:xlabel=&#39;type_of_contract&#39;, ylabel=&#39;count&#39;&gt; . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 47116 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 53448 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 47716 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 48260 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 49901 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 47116 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 53448 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 47716 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 48260 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 49901 missing from current font. font.set_text(s, 0, flags=flags) . í•œê¸€ ê¸€ì”¨ì²´ ì„¤ì •ì´ í•„ìš”í•´ ë³´ì¸ë‹¤. | . df1[&#39;product&#39;].value_counts() . K1 39134 K2 8995 K3 2082 K5 645 K4 327 K6 120 Name: product, dtype: int64 . sns.countplot(data=df1, x=&#39;product&#39;, hue=&#39;type_of_contract2&#39;) . &lt;AxesSubplot:xlabel=&#39;product&#39;, ylabel=&#39;count&#39;&gt; . ë²”ë¡€ì™€ ê·¸ë˜í”„ê°€ ê²¹ì³ë‚˜ì˜¤ëŠ” ë¬¸ì œê°€ ë°œìƒ $ to$ matplotlib ì˜µì…˜ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥ | . &#54620;&#44544; &#44648;&#51664; &#54644;&#44208; . import matplotlib.pyplot as plt ## íŒŒì´ì¬ ë‚´ì—ì„œ ê·¸ë˜í”„ ì¶œë ¥ì‹œ ë””í…Œì¼í•œ ì˜µì…˜ import matplotlib as mpl ## í•œê¸€í°íŠ¸ ì„¤ì •, ê¸€ì”¨ì²´ íë¦¿í•œ ê²ƒì„ ì„ ëª…í•˜ê²Œ (ì „ì²´ì ì¸ í° í‹€ì˜ ì˜µì…˜) . mpl.rc(&#39;font&#39;, family=&#39;Malgun Gothic&#39;) ## ë§‘ì€ ê³ ë”• . Cë“œë¼ì´ë¸Œ $ to$ Windows $ to$ Fonts $ to$ Malgun Gothic | . sns.countplot(data=df1, x=&#39;type_of_contract&#39;) . &lt;AxesSubplot:xlabel=&#39;type_of_contract&#39;, ylabel=&#39;count&#39;&gt; . &#45936;&#51060;&#53552; &#44536;&#47000;&#54532; &#44217;&#52840;&#47928;&#51228; . - ê·¸ë˜í”„ ì‚¬ì´ì¦ˆ í‚¤ìš°ê¸° . plt.figure(figsize=[10,5]) ## Size ì¡°ì • sns.countplot(data=df1, x=&#39;product&#39;, hue=&#39;type_of_contract2&#39;) plt.legend(loc=&#39;right&#39;) ## ë²”ë¡€ ì˜¤ë¥¸ìª½ì— ìœ„ì¹˜ plt.savefig(&#39;img1.png&#39;) ## ì´ë¯¸ì§€ íŒŒì¼ í˜•íƒœë¡œ ì €ì¥ # plt.savefig(&#39;img1.pdf&#39;) . 2 &#50672;&#49549;&#54805; &#48320;&#49688; . sns.histplot(data=df1, x=&#39;age&#39;) . &lt;AxesSubplot:xlabel=&#39;age&#39;, ylabel=&#39;Count&#39;&gt; . - kde = True ì˜µì…˜ ì¶”ê°€ . plt.title(&#39;ê³„ì•½ ìœ í˜• ë³„. ê³ ê° ì—°ë ¹ ë¶„í¬&#39;) sns.histplot(data=df1, x=&#39;age&#39;, kde = True, hue=&#39;type_of_contract&#39;) ## í™•ë¥ ë¶„í¬ì„  (kde=True) plt.show() . 3 &#44536; &#50808; &#52628;&#44032; &#50741;&#49496;&#46308; . - ê·¸ë˜í”„ ì¶•ì— ìˆëŠ” ê¸€ì”¨ ê²¹ì¹¨ . sns.countplot(data=df1, x=&#39;bank&#39;) . &lt;AxesSubplot:xlabel=&#39;bank&#39;, ylabel=&#39;count&#39;&gt; . plt.figure(figsize=[5, 10]) sns.countplot(data=df1, y=&#39;bank&#39;) . &lt;AxesSubplot:xlabel=&#39;count&#39;, ylabel=&#39;bank&#39;&gt; . bank columnì— ë°ì´í„°ê°€ êµ‰ì¥íˆ ë§ë‹¤. ë¹ˆë„ìˆ˜ê°€ ë†’ì€ ìƒìœ„ 10ê°œ ë°ì´í„°ë§Œ ë½‘ì•„ì„œ ì‹œê°í™”ë¥¼ í•´ë³´ì. | . - ë¹ˆë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ . df1[&#39;bank&#39;].value_counts() ## ë¹ˆë„ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì¶œë ¥ . êµ­ë¯¼ì€í–‰ 9901 ë¡¯ë°ì¹´ë“œ 9518 ë†í˜‘ì€í–‰ 6278 ì‹ í•œì€í–‰ 3522 ìš°ë¦¬ì€í–‰ 3386 ê¸°ì—…ì€í–‰ 1963 ì‹ í•œì¹´ë“œ 1533 í•˜ë‚˜ì€í–‰ 1446 êµ­ë¯¼ì¹´ë“œ 1311 BCì¹´ë“œ 1264 ìƒˆë§ˆì„ê¸ˆê³  964 ë¶€ì‚°ì€í–‰ 888 ì‚¼ì„±ì¹´ë“œ 884 í˜„ëŒ€ì¹´ë“œ 876 ëŒ€êµ¬ì€í–‰ 746 ìš°ì²´êµ­ 717 ì™¸í™˜ì€í–‰ 586 ì™¸í™˜ì¹´ë“œ 530 ê²½ë‚¨ì€í–‰ 442 SCì œì¼ì€í–‰ 439 ê´‘ì£¼ì€í–‰ 347 ì‹ í˜‘ì¤‘ì•™íšŒ 341 ì „ë¶ì€í–‰ 195 ì”¨í‹°ì€í–‰ 162 ìˆ˜í˜‘ì¤‘ì•™íšŒ 160 ì œì£¼ì€í–‰ 40 ìœ ì•ˆíƒ€ì¦ê¶Œ 27 ì‚°ì—…ì€í–‰ 23 í˜„ëŒ€ì¦ê¶Œ 11 ì‚¼ì„±ì¦ê¶Œ 7 í•˜ë‚˜SK 6 ë¯¸ë˜ì—ì…‹ì¦ê¶Œ 5 NHë†í˜‘ì¹´ë“œ 4 í•œêµ­íˆ¬ìì¦ê¶Œ 4 ì‹ í•œê¸ˆìœµíˆ¬ì 4 ìš°ë¦¬ì¹´ë“œ 3 ëŒ€ìš°ì¦ê¶Œ 2 í•˜ì´íˆ¬ìì¦ê¶Œ 1 ë©”ë¦¬ì¸ ì¢…í•©ê¸ˆìœµì¦ê¶Œ 1 ìˆ˜í˜‘ì¹´ë“œ 1 ìƒí˜¸ì €ì¶•ì€í–‰ 1 SKì¦ê¶Œ 1 í•˜ë‚˜ëŒ€íˆ¬ì¦ê¶Œ 1 ì‚°ë¦¼ì¡°í•©ì¤‘ì•™íšŒ 1 ëŒ€ì‹ ì¦ê¶Œ 1 ì”¨í‹°ì¹´ë“œ 1 Name: bank, dtype: int64 . sns.countplot(data=df1, x=&#39;bank&#39;, order=[&#39;êµ­ë¯¼ì€í–‰&#39;, &#39;ë¡¯ë°ì¹´ë“œ&#39;, &#39;ë†í˜‘ì€í–‰&#39;, &#39;ì‹ í•œì€í–‰&#39;]) . &lt;AxesSubplot:xlabel=&#39;bank&#39;, ylabel=&#39;count&#39;&gt; . - ë¹ˆë„ ìˆœ ì •ë ¬ . order_list = df1[&#39;bank&#39;].value_counts().index.tolist() ## ë¹ˆë„ ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì¸ë±ìŠ¤ ì¶œë ¥ . sns.countplot(data=df1, x=&#39;bank&#39;, order=order_list) . &lt;AxesSubplot:xlabel=&#39;bank&#39;, ylabel=&#39;count&#39;&gt; . - ìƒìœ„ 10ê°œë§Œ ì‹œê°í™” . plt.figure(figsize=[10,5]) ## figure size ì¡°ì •. sns.countplot(data=df1, x=&#39;bank&#39;, order=order_list[0:10]) plt.savefig(&#39;img10.pdf&#39;) ## ì´ë¯¸ì§€ pdf í˜•íƒœë¡œ ì €ì¥ . - ì´ë¯¸ì§€ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ . import os print(os.getcwd()) # print(os.listdir(os.getcwd())) . C: Users 82103 Desktop dino BP2022 _notebooks . os.path.exists(&#39;C:/Users/82103/Desktop/dino/BP2022/_notebooks/img10.pdf&#39;) . True . ë”°ë¼ì„œ ìœ„ì˜ ê²½ë¡œ(í˜„ì¬ ì‘ì—… í´ë”)ì— img10.pdf ì´ë¯¸ì§€ íŒŒì¼ì´ ì €ì¥ë˜ì–´ ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/23/DV.html",
            "relUrl": "/python/2022/03/23/DV.html",
            "date": " â€¢ Mar 23, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "(3ì£¼ì°¨ ML) 3ì›” 17ì¼",
            "content": "training set / test set . fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] . len(fish_length), len(fish_weight) . (49, 49) . fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)] fish_target = [1]*35 + [0]*14 . fish_data[0] . [25.4, 242.0] . KNN (&#52395;&#48264;&#51704; &#49884;&#46020;) . from sklearn.neighbors import KNeighborsClassifier kn = KNeighborsClassifier() . print(fish_data[4]) . [29.0, 430.0] . print(fish_data[0:5]) . [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0]] . print(fish_data[:5]) . [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0]] . print(fish_data[44:]) . [[12.2, 12.2], [12.4, 13.4], [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]] . train_input = fish_data[:35] ## index 0~34 train_target = fish_target[:35] test_input = fish_data[35:] ## index 35~48 test_target = fish_target[35:] . len(train_input), len(train_target) . (35, 35) . len(test_input), len(test_target) . (14, 14) . kn = kn.fit(train_input, train_target) kn.score(test_input, test_target) . 0.0 . ì •í™•ë„ê°€ 0% ì´ë‹¤? | test inputì— ìˆëŠ” ìƒ˜í”Œ 14ê°œë¥¼ ëª¨ë‘ ëª» ë§ì·„ë‹¤ëŠ” ê²ƒì´ë‹¤. | WHY ? $ Rightarrow$ ìƒ˜í”Œë§ í¸í–¥ | . &#49368;&#54540;&#47553; &#54200;&#54693; . ì™œê·¸ëŸ°ê°€ ë´¤ë”ë‹ˆ ì²˜ìŒì— fish_lengthì™€ fish_weightë¥¼ ë„ë¯¸ 35ê°œ, ë¹™ì–´ 14ê°œë¥¼ ì­‰ ëŠ˜ì–´ë†“ê³  ë‘ ë¦¬ìŠ¤íŠ¸ë¥¼ í•©ì³¤ë‹¤. | ë‘ ë¦¬ìŠ¤íŠ¸ë¥¼ í•©ì¹œ fish_dataì—ì„œ ì•ì— 35ê°œë¥¼ í›ˆë ¨ ë’¤ì— 14ê°œë¥¼ test setìœ¼ë¡œ ì˜ëë‹¤. | ì¦‰, í›ˆë ¨ì„¸íŠ¸ì—ëŠ” ë¹™ì–´ê°€ í•˜ë‚˜ë„ ì—†ê³ , í…ŒìŠ¤íŠ¸ì…‹ì—ëŠ” ë„ë¯¸ê°€ í•˜ë‚˜ë„ ì—†ê²Œ ëœë‹¤. $ Rightarrow$ ë¯¸ì ë¶„ ê³µë¶€í•˜ê³  í™•í†µì‹œí—˜ ë³¸ ê²©.. | . | train setê³¼ test setì„ ë‚˜ëˆŒ ë•Œì—ëŠ” ë¹™ì–´ì™€ ë„ë¯¸ ë‘ classê°€ ì˜ ì„ì—¬ìˆë„ë¡ ë§Œë“¤ì–´ì•¼ í•œë‹¤. | . Numpy . ì´ì œ Numpyë¥¼ ì´ìš©í•´ì„œ ì˜ ì„ì–´ì„œ train setê³¼ test setìœ¼ë¡œ ë‚˜ëˆ ë³´ì. | NumpyëŠ” íŒŒì´ì¬ì˜ ëŒ€í‘œì ì¸ ë°°ì—´ library | scikit-learnì´ë‚˜ matplotlib librayrë„ ë„˜íŒŒì´ì— í¬ê²Œ ì˜ì¡´í•˜ê³  ìˆê³ , ì…ë ¥ ë°ì´í„°ê°€ Numpyë¡œ ì „ë‹¬ë  ê±°ë¼ê³  ê°€ì •í•˜ê³  ìˆë‹¤. predict method ê²°ê³¼ê°’ì´ array([1])ì´ëŸ° í˜•íƒœë¡œ ì¶œë ¥ë˜ëŠ” ê²ƒë„ ì´ëŸ¬í•œ ì´ìœ .(ì‚¬ì´í‚·ëŸ°ì˜ predict ë©”ì„œë“œì˜ ë°˜í™˜ê°’ì„ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë¦¬í„´) | . | ë”¥ëŸ¬ë‹ TensorFlowë„ Numpyì™€ë„ íƒ€ì´íŠ¸í•œ ê´€ê³„ê°€ ìˆë‹¤. | . . 1ì°¨ì› ë°°ì—´(ë²¡í„°), 2ì°¨ì› ë°°ì—´(í–‰ë ¬), 3ì°¨ì› ë°°ì—´ | . training set / test set (using Numpy) . inputê³¼ targetì´ í•¨ê»˜ ì„ì—¬ì„œ ì´ë™ì„ í•´ì•¼í•œë‹¤. (ì„ì—¬ì•¼ í•œë‹¤) | ì§€ë„í•™ìŠµì—ì„œ ì…ë ¥ê³¼ íƒ€ê²Ÿì´ ìŒì„ ì´ë£¨ê³  ìˆê²Œ ë˜ëŠ”ë° ë”°ë¡œë”°ë¡œ ì„ì—¬ë²„ë¦¬ë©´ ì •ë‹µì„ ì œëŒ€ë¡œ ëª»ì£¼ê²Œ ë˜ì„œ ì—‰í„°ë¦¬ í›ˆë ¨ì´ ë˜ë²„ë¦°ë‹¤. | ì…ë ¥ë°ì´í„° íŠ¹ì„±ê°’ê³¼ íƒ€ê¹‚ê°’ì´ ìŒìœ¼ë¡œ ì˜ ë”°ë¼ì„œ ì„ì´ë„ë¡ ë§Œë“¤ì–´ì•¼ í•˜ëŠ”ê²ƒì´ ì¤‘ìš”!!! indexë¥¼ ì„ì–´ ë¶„ë¦¬í•˜ëŠ” ë°©ë²• | . | . import numpy as np . input_arr = np.array(fish_data) target_arr = np.array(fish_target) . print(input_arr) . [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ] [ 29.7 450. ] [ 29.7 500. ] [ 30. 390. ] [ 30. 450. ] [ 30.7 500. ] [ 31. 475. ] [ 31. 500. ] [ 31.5 500. ] [ 32. 340. ] [ 32. 600. ] [ 32. 600. ] [ 33. 700. ] [ 33. 700. ] [ 33.5 610. ] [ 33.5 650. ] [ 34. 575. ] [ 34. 685. ] [ 34.5 620. ] [ 35. 680. ] [ 35. 700. ] [ 35. 725. ] [ 35. 720. ] [ 36. 714. ] [ 36. 850. ] [ 37. 1000. ] [ 38.5 920. ] [ 38.5 955. ] [ 39.5 925. ] [ 41. 975. ] [ 41. 950. ] [ 9.8 6.7] [ 10.5 7.5] [ 10.6 7. ] [ 11. 9.7] [ 11.2 9.8] [ 11.3 8.7] [ 11.8 10. ] [ 11.8 9.9] [ 12. 9.8] [ 12.2 12.2] [ 12.4 13.4] [ 13. 12.2] [ 14.3 19.7] [ 15. 19.9]] . print(input_arr.shape) . (49, 2) . - 0~48ê¹Œì§€ ì •ìˆ˜ë¡œëœ index ë§Œë“¤ê¸° . index = np.arange(49) index . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]) . - indexë¥¼ ì„ì–´ì¤€ë‹¤. . np.random.seed(42) np.random.shuffle(index) . print(index) . [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] . ì˜ ì„ì˜€ë‹¤... | . input_arr[:5] . array([[ 25.4, 242. ], [ 26.3, 290. ], [ 26.5, 340. ], [ 29. , 363. ], [ 29. , 430. ]]) . print(input_arr[[1,3]]) . [[ 26.3 290. ] [ 29. 363. ]] . - ëœë¤í•˜ê²Œ ì„ì¸ ì¸ë±ìŠ¤ ë°°ì—´ì—ì„œ ì•ë¶€ë¶„ 35ê°œë¥¼ í›ˆë ¨ì…‹ìœ¼ë¡œ ë‘ê³ , ë’·ë¶€ë¶„ 14ê°œë¥¼ í…ŒìŠ¤íŠ¸ ì…‹ìœ¼ë¡œ ë‘”ë‹¤ . print(index) . [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] . train_input = input_arr[index[:35]] train_target = target_arr[index[:35]] . print(input_arr[13], train_input[0]) . [ 32. 340.] [ 32. 340.] . test_input = input_arr[index[35:]] test_target = target_arr[index[35:]] . import matplotlib.pyplot as plt plt.scatter(train_input[:,0], train_input[:,1]) plt.scatter(test_input[:,0], test_input[:,1]) plt.xlabel(&#39;length&#39;) plt.ylabel(&#39;weight&#39;) plt.show() . KNN (&#46160;&#48264;&#51704; &#49884;&#46020;) . kn = kn.fit(train_input, train_target) . kn.score(test_input, test_target) . 1.0 . ì˜ í›ˆë ¨ë˜ì—ˆë‹¤. | . kn.predict(test_input) . array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) . test_target . array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) . Summary . Numpyë¥¼ ì´ìš©í•´ì„œ ë°ì´í„°ë¥¼ ì„ì–´ì„œ ë§Œë“¤ë•Œ, ë°°ì—´ ìì²´ë¥¼ ì„ì§€ ì•Šê³  (íŠ¹ì„±ë°ì´í„°ì™€ íƒ€ê¹ƒí…Œì´í„°ê°€ ìŒì„ ì´ë£¨ì–´ì„œ ì„ì–´ì•¼ í•˜ë¯€ë¡œ) . | ë°°ì—´ì˜ ì¸ë±ìŠ¤ë°°ì—´ì„ ë§Œë“¤ì–´ì„œ ì¸ë±ìŠ¤ë¥¼ ì„ì€ í›„ì— . | ì„ì¸ ì¸ë±ìŠ¤ë¥¼ ê°€ì§€ê³  ë°°ì—´ ìŠ¬ë¼ì´ì‹±ì„ í•˜ì—¬ í›ˆë ¨ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ë‚˜ëˆˆë‹¤. . | ì´ë ‡ê²Œ ë‚˜ëˆˆ ê²ƒìœ¼ë¡œ KNNìœ¼ë¡œ ë‹¤ì‹œ í›ˆë ¨í•´ì„œ ëª¨ë¸ì„ í‰ê°€ . | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/19/ML.html",
            "relUrl": "/python/2022/03/19/ML.html",
            "date": " â€¢ Mar 19, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "(3ì£¼ì°¨ DV) 3ì›” 18ì¼",
            "content": "import pandas as pd . pd.read_csv(&#39;C:/Users/82103/Desktop/2022-1/ë¨¸ì‹ ëŸ¬ë‹/data/train.csv&#39;) . Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice . 0 1 | 60 | RL | 65.0 | 8450 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 2 | 2008 | WD | Normal | 208500 | . 1 2 | 20 | RL | 80.0 | 9600 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 5 | 2007 | WD | Normal | 181500 | . 2 3 | 60 | RL | 68.0 | 11250 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 9 | 2008 | WD | Normal | 223500 | . 3 4 | 70 | RL | 60.0 | 9550 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 2 | 2006 | WD | Abnorml | 140000 | . 4 5 | 60 | RL | 84.0 | 14260 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 12 | 2008 | WD | Normal | 250000 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1455 1456 | 60 | RL | 62.0 | 7917 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 8 | 2007 | WD | Normal | 175000 | . 1456 1457 | 20 | RL | 85.0 | 13175 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | MnPrv | NaN | 0 | 2 | 2010 | WD | Normal | 210000 | . 1457 1458 | 70 | RL | 66.0 | 9042 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | GdPrv | Shed | 2500 | 5 | 2010 | WD | Normal | 266500 | . 1458 1459 | 20 | RL | 68.0 | 9717 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 4 | 2010 | WD | Normal | 142125 | . 1459 1460 | 20 | RL | 75.0 | 9937 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 6 | 2008 | WD | Normal | 147500 | . 1460 rows Ã— 81 columns . df_train = pd.read_csv(&#39;C:/Users/82103/Desktop/2022-1/ë¨¸ì‹ ëŸ¬ë‹/data/train.csv&#39;) df_test = pd.read_csv(&#39;C:/Users/82103/Desktop/2022-1/ë¨¸ì‹ ëŸ¬ë‹/data/test.csv&#39;) . from pandas.core.groupby.generic import ScalarResult import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import numpy as np from scipy.stats import norm from sklearn.preprocessing import StandardScaler from scipy import stats import warnings warnings.filterwarnings(&#39;ignore&#39;) %matplotlib inline . df_train.columns . Index([&#39;Id&#39;, &#39;MSSubClass&#39;, &#39;MSZoning&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;Street&#39;, &#39;Alley&#39;, &#39;LotShape&#39;, &#39;LandContour&#39;, &#39;Utilities&#39;, &#39;LotConfig&#39;, &#39;LandSlope&#39;, &#39;Neighborhood&#39;, &#39;Condition1&#39;, &#39;Condition2&#39;, &#39;BldgType&#39;, &#39;HouseStyle&#39;, &#39;OverallQual&#39;, &#39;OverallCond&#39;, &#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;RoofStyle&#39;, &#39;RoofMatl&#39;, &#39;Exterior1st&#39;, &#39;Exterior2nd&#39;, &#39;MasVnrType&#39;, &#39;MasVnrArea&#39;, &#39;ExterQual&#39;, &#39;ExterCond&#39;, &#39;Foundation&#39;, &#39;BsmtQual&#39;, &#39;BsmtCond&#39;, &#39;BsmtExposure&#39;, &#39;BsmtFinType1&#39;, &#39;BsmtFinSF1&#39;, &#39;BsmtFinType2&#39;, &#39;BsmtFinSF2&#39;, &#39;BsmtUnfSF&#39;, &#39;TotalBsmtSF&#39;, &#39;Heating&#39;, &#39;HeatingQC&#39;, &#39;CentralAir&#39;, &#39;Electrical&#39;, &#39;1stFlrSF&#39;, &#39;2ndFlrSF&#39;, &#39;LowQualFinSF&#39;, &#39;GrLivArea&#39;, &#39;BsmtFullBath&#39;, &#39;BsmtHalfBath&#39;, &#39;FullBath&#39;, &#39;HalfBath&#39;, &#39;BedroomAbvGr&#39;, &#39;KitchenAbvGr&#39;, &#39;KitchenQual&#39;, &#39;TotRmsAbvGrd&#39;, &#39;Functional&#39;, &#39;Fireplaces&#39;, &#39;FireplaceQu&#39;, &#39;GarageType&#39;, &#39;GarageYrBlt&#39;, &#39;GarageFinish&#39;, &#39;GarageCars&#39;, &#39;GarageArea&#39;, &#39;GarageQual&#39;, &#39;GarageCond&#39;, &#39;PavedDrive&#39;, &#39;WoodDeckSF&#39;, &#39;OpenPorchSF&#39;, &#39;EnclosedPorch&#39;, &#39;3SsnPorch&#39;, &#39;ScreenPorch&#39;, &#39;PoolArea&#39;, &#39;PoolQC&#39;, &#39;Fence&#39;, &#39;MiscFeature&#39;, &#39;MiscVal&#39;, &#39;MoSold&#39;, &#39;YrSold&#39;, &#39;SaleType&#39;, &#39;SaleCondition&#39;, &#39;SalePrice&#39;], dtype=&#39;object&#39;) . df_test.columns . Index([&#39;Id&#39;, &#39;MSSubClass&#39;, &#39;MSZoning&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;Street&#39;, &#39;Alley&#39;, &#39;LotShape&#39;, &#39;LandContour&#39;, &#39;Utilities&#39;, &#39;LotConfig&#39;, &#39;LandSlope&#39;, &#39;Neighborhood&#39;, &#39;Condition1&#39;, &#39;Condition2&#39;, &#39;BldgType&#39;, &#39;HouseStyle&#39;, &#39;OverallQual&#39;, &#39;OverallCond&#39;, &#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;RoofStyle&#39;, &#39;RoofMatl&#39;, &#39;Exterior1st&#39;, &#39;Exterior2nd&#39;, &#39;MasVnrType&#39;, &#39;MasVnrArea&#39;, &#39;ExterQual&#39;, &#39;ExterCond&#39;, &#39;Foundation&#39;, &#39;BsmtQual&#39;, &#39;BsmtCond&#39;, &#39;BsmtExposure&#39;, &#39;BsmtFinType1&#39;, &#39;BsmtFinSF1&#39;, &#39;BsmtFinType2&#39;, &#39;BsmtFinSF2&#39;, &#39;BsmtUnfSF&#39;, &#39;TotalBsmtSF&#39;, &#39;Heating&#39;, &#39;HeatingQC&#39;, &#39;CentralAir&#39;, &#39;Electrical&#39;, &#39;1stFlrSF&#39;, &#39;2ndFlrSF&#39;, &#39;LowQualFinSF&#39;, &#39;GrLivArea&#39;, &#39;BsmtFullBath&#39;, &#39;BsmtHalfBath&#39;, &#39;FullBath&#39;, &#39;HalfBath&#39;, &#39;BedroomAbvGr&#39;, &#39;KitchenAbvGr&#39;, &#39;KitchenQual&#39;, &#39;TotRmsAbvGrd&#39;, &#39;Functional&#39;, &#39;Fireplaces&#39;, &#39;FireplaceQu&#39;, &#39;GarageType&#39;, &#39;GarageYrBlt&#39;, &#39;GarageFinish&#39;, &#39;GarageCars&#39;, &#39;GarageArea&#39;, &#39;GarageQual&#39;, &#39;GarageCond&#39;, &#39;PavedDrive&#39;, &#39;WoodDeckSF&#39;, &#39;OpenPorchSF&#39;, &#39;EnclosedPorch&#39;, &#39;3SsnPorch&#39;, &#39;ScreenPorch&#39;, &#39;PoolArea&#39;, &#39;PoolQC&#39;, &#39;Fence&#39;, &#39;MiscFeature&#39;, &#39;MiscVal&#39;, &#39;MoSold&#39;, &#39;YrSold&#39;, &#39;SaleType&#39;, &#39;SaleCondition&#39;], dtype=&#39;object&#39;) . df_train[&#39;SalePrice&#39;].describe() ## ë¶€ë™ì‚° ê°€ê²©ì˜ ê¸°ìˆ í†µê³„ëŸ‰ . count 1460.000000 mean 180921.195890 std 79442.502883 min 34900.000000 25% 129975.000000 50% 163000.000000 75% 214000.000000 max 755000.000000 Name: SalePrice, dtype: float64 . sns.distplot(df_train[&#39;SalePrice&#39;]) ## line : kernel density plot ## ëª©í‘œë³€ìˆ˜ì— ëŒ€í•œ íˆìŠ¤í† ê·¸ë¨ê³¼ kernel density plot . print(&quot;Skewness: %f&quot; % df_train[&#39;SalePrice&#39;].skew()) print(&quot;Kurtosis: %f&quot; % df_train[&#39;SalePrice&#39;].kurt()) ## ê¼¬ë¦¬ê°€ ë‘í„°ìš´ ì •ë„ (ì´ìƒì¹˜ê°€ ë§ì„ìˆ˜ë¡ ë‘êº¼ì›€) . Skewness: 1.882876 Kurtosis: 6.536282 . $-2 sim2$ ì‚¬ì´ì˜ ê°’ì´ë¯€ë¡œ ì¹˜ìš°ì¹¨ì´ ì—†ëŠ” ë°ì´í„° (by. George &amp; Mallery, 2010) | ì²¨ë„ê°€ ë†’ìœ¼ë©´ (Kurtosis &gt; 3) ì´ìƒì¹˜ê°€ ë§ì´ ìˆë‹¤ëŠ” ê²ƒ. | . ë§ì€ í†µê³„ê¸°ë²•ë“¤ì´ ì •ê·œì„±ì„ ê°€ì •í•œë‹¤. | . positive skewness : ì˜¤ë¥¸ìª½ ê¼¬ë¦¬, ì™¼ìª½ì— ë°ì´í„°ê°€ ë§ë‹¤. | negative skewness : ì™¼ìª½ ê¼¬ë¦¬, ì˜¤ë¥¸ìª½ì— ë°ì´í„°ê°€ ë§ë‹¤. | . ì™œë„, ì²¨ë„ ì½ì–´ë³´ê¸° . . . var1 = &#39;GrLivArea&#39; # ì§€ìƒ ê±°ì‹¤ ë©´ì  í‰ë°©í”¼íŠ¸ data1 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var1]], axis=1) ## ì—´ë¡œ í•©ì¹˜ê¸°(axis=1) . data1.plot.scatter(x=var1, y=&#39;SalePrice&#39;, ylim=(0,800000)) . &lt;AxesSubplot:xlabel=&#39;GrLivArea&#39;, ylabel=&#39;SalePrice&#39;&gt; . linear relationship | . var2 = &#39;TotalBsmtSF&#39; # ì§€í•˜ ì´ í‰ë°© í”¼íŠ¸ data2 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var2]], axis=1) # ì—´ê¸°ì¤€ìœ¼ë¡œ ë¶™ì„ data2.plot.scatter(x=var2, y=&#39;SalePrice&#39;, ylim=(0,800000)) . &lt;AxesSubplot:xlabel=&#39;TotalBsmtSF&#39;, ylabel=&#39;SalePrice&#39;&gt; . ë” strong í•œ linear relationship ( ë” ê°€íŒŒë¥´ë‹¤. ) | . var1 = &#39;GrLivArea&#39; data1 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var1]], axis=1) plt.scatter(var1, y=&#39;SalePrice&#39;, data = data1) . &lt;matplotlib.collections.PathCollection at 0x24f2102bca0&gt; . var2 = &#39;TotalBsmtSF&#39; data2 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var2]], axis=1) plt.scatter(var2, y=&#39;SalePrice&#39;, data = data2) . &lt;matplotlib.collections.PathCollection at 0x24f21535ac0&gt; . data2 . SalePrice OverallQual . 0 208500 | 7 | . 1 181500 | 6 | . 2 223500 | 7 | . 3 140000 | 7 | . 4 250000 | 8 | . ... ... | ... | . 1455 175000 | 6 | . 1456 210000 | 6 | . 1457 266500 | 7 | . 1458 142125 | 5 | . 1459 147500 | 5 | . 1460 rows Ã— 2 columns . var3 = &#39;OverallQual&#39; # ì „ì²´ ì œë£Œ ë° ë§ˆê°í’ˆì§ˆ data3 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var3]], axis=1) # ì—´ë¡œ í•©ì¹˜ê¸° f, ax = plt.subplots(figsize=(8,6)) fig = sns.boxplot(x=var3, y=&quot;SalePrice&quot;, data=data3) fig.axis(ymin=0, ymax=800000) . (-0.5, 9.5, 0.0, 800000.0) . var4 = &#39;YearBuilt&#39; # ì›ë˜ ê±´ì„¤ ë‚ ì§œ data4 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var4]], axis=1) f, ax = plt.subplots(figsize=(16,8)) fig = sns.boxplot(x=var4, y=&quot;SalePrice&quot;, data=data4) fig.axis(ymin=0, ymax=800000) plt.xticks(rotation=90) # xì¶• ëˆˆê¸ˆ ê°’ 90ë„ íšŒì „. .",
            "url": "https://pinkocto.github.io/BP2022/2022/03/18/DV.html",
            "relUrl": "/2022/03/18/DV.html",
            "date": " â€¢ Mar 18, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "(2ì£¼ì°¨ ML) 3ì›” 10ì¼",
            "content": "&#49373;&#49440; &#48516;&#47448; &#47928;&#51228; . &#46020;&#48120;(bream) &#45936;&#51060;&#53552; &#51456;&#48708;&#54616;&#44592; . bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0] bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0] . import matplotlib.pyplot as plt plt.scatter(bream_length, bream_weight) plt.xlabel(&#39;length&#39;) # ëª¸ ê¸¸ì´ plt.ylabel(&#39;weight&#39;) # ëª¸ ë¬´ê²Œ . Text(0, 0.5, &#39;weight&#39;) . &#48729;&#50612;(smelt) &#45936;&#51060;&#53552; &#51456;&#48708;&#54616;&#44592; . smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] . plt.scatter(bream_length, bream_weight, label=&#39;bream&#39;) ## ë„ë¯¸ plt.scatter(smelt_length, smelt_weight, label=&#39;smelt&#39;) ## ë¹™ì–´ plt.xlabel(&#39;length&#39;) plt.ylabel(&#39;weight&#39;) plt.legend() plt.show() . ë¹™ì–´ëŠ” ê¸¸ì´ê°€ ëŠ˜ì–´ë‚˜ë”ë¼ë„ ë¬´ê²Œê°€ ë§ì´ ëŠ˜ì§€ ì•ŠëŠ”ë‹¤. $ Rightarrow$ ë¹™ì–´ì˜ ì‚°ì ë„ ì—­ì‹œ ì„ í˜•ì ì´ì§€ë§Œ ë¬´ê²Œê°€ ê¸¸ì´ì— ì˜í–¥ì„ ëœ ë°›ëŠ”ë‹¤. | . binary classification (&#46020;&#48120;, &#48729;&#50612;) &#51456;&#48708; . ë‹¤ìŒìœ¼ë¡œ ë°ì´í„°ë§Œ ë³´ê³  ì–´ë–¤ ê²ƒì´ ë„ë¯¸ì´ê³  ì–´ë–¤ ê²ƒì´ ë¹™ì–´ì¸ì§€ ìŠ¤ìŠ¤ë¡œ êµ¬ë¶„í•˜ê¸° ìœ„í•´ í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ì–´ ë³´ì! | KNN(K-Nearest Neighbors) ë°©ë²•ì„ ì´ìš©í•  ê²ƒ. | . - ìš°ì„  KNN ì•Œê³ ë¦¬ì¦˜ì„ ì¨ë¨¹ìœ¼ë ¤ë©´ ë„ë¯¸ì™€ ë¹™ì–´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°ë¡œ í•©ì³ì•¼ í•œë‹¤. . length = bream_length + smelt_length weight = bream_weight + smelt_length . + ì—°ì‚°ìê°€ list ì¼ ê²½ìš°ì—ëŠ” í•©ì³ì§€ëŠ” ì—­í• ì„ í•˜ê³ , ì •ìˆ˜ì¼ ë•ŒëŠ” ìš°ë¦¬ê°€ ì¼ë°˜ì ìœ¼ë¡œ ì•Œê³ ìˆëŠ” ë§ì…ˆ ì—°ì‚°ì„ í•œë‹¤. | . len(bream_length), len(smelt_length), len(bream_weight), len(smelt_length) . (35, 14, 35, 14) . len(length), len(weight) . (49, 49) . ì˜ í•©ì³ì§„ ê²ƒ ê°™ë‹¤. | . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ ë³´ì. (Scikit-learnì„ ì‚¬ìš©í•˜ê¸°ìœ„í•´) . ## ì´ëŸ° ì‹ìœ¼ë¡œ 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê²ƒ! ê¸¸ì´ ë¬´ê²Œ [[25.4, 242.0], [26.3, 290.0]. . . . . . . [15.0, 19.9]] . fish_data = [[l,w] for l, w in zip(length, weight)] . - ì •ë‹µ ì¤€ë¹„ . ë„ë¯¸(bream)ë¥¼ 1ë¡œ ë†“ê³ , ë¹™ì–´(smelt)ë¥¼ 0ìœ¼ë¡œ ë†“ì. (0ê³¼ 1ë¡œ ë¶„ë¥˜í•˜ëŠ” ì´ì§„ë¶„ë¥˜) | . fish_target = [1]*35 + [0]*14 . K-&#52572;&#44540;&#51217; &#51060;&#50883; . from sklearn.neighbors import KNeighborsClassifier . kn = KNeighborsClassifier() # classì˜ instance(ê°ì²´) ë¥¼ ë§Œë“ ë‹¤. . kn.fit(fish_data, fish_target) ## knì„ ëª¨ë¸ì´ë¼ ë¶€ë¦„ . KNeighborsClassifier() . ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œê·¸ë¨ì˜ ì•Œê³ ë¦¬ì¦˜ì´ ê°ì²´í™” ëœê²ƒì„ ëª¨ë¸ì´ë¼ê³  ë¶€ë¥¸ë‹¤. | ì¢…ì¢… ê·¸ ì•Œê³ ë¦¬ì¦˜ ìì²´ë¥¼ ëª¨ë¸ì´ë¼ê³ ë„ ë¶€ë¦„. | . kn.score(fish_data, fish_target) . 1.0 . 100% ë‹¤ ë§ì·„ë‹¤! (100% ì •í™•ë„ ë‹¬ì„±!) | . &#49352;&#47196;&#50868; &#49373;&#49440; &#50696;&#52769; . ê·¸ë˜í”„ì— í‘œì‹œëœ ì´ˆë¡ìƒ‰ ì‚¼ê°í˜•ì€ ì–´ë–¤ ìƒì„ ì¼ê¹Œ? | . plt.scatter(bream_length, bream_weight, label=&#39;bream&#39;) plt.scatter(smelt_length, smelt_weight, label=&#39;smelt&#39;) plt.scatter(30, 600, marker=&#39;^&#39;) plt.xlabel(&#39;length&#39;) plt.ylabel(&#39;weight&#39;) plt.legend() plt.show() . ì§ê´€ì ìœ¼ë¡œ ë´¤ì„ë•Œ ë„ë¯¸(bream) ì¼ ê²ƒ ê°™ë‹¤. | ì‹¤ì œë¡œë„ ê·¸ëŸ°ì§€ í™•ì¸í•´ë³´ì. | . kn.predict([[30, 600]]) ## predict method . array([1]) . predict method ì•ˆì— ë„£ì„ ë•Œë„ 2ì°¨ì› ë°°ì—´ ë°ì´í„°ë¥¼ ë„£ì–´ì¤€ë‹¤. (ì‚¬ì´í‚·ëŸ°ì´ ê¸°ëŒ€í•˜ëŠ” ê²ƒ) | n_neighbors=5ê°€ default, ì£¼ìœ„ì— ìˆëŠ” ì´ì›ƒì˜ ê°œìˆ˜(K)ë§Œí¼ ì£¼ë³€ ìƒ˜í”Œì˜ class ì¤‘ ê°€ì¥ ë§ì€ í´ë˜ìŠ¤ë¥¼ ì •ë‹µí´ë˜ìŠ¤ë¡œ ì‚¼ëŠ”ë‹¤. | . print(kn._fit_X) . [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ] [ 29.7 450. ] [ 29.7 500. ] [ 30. 390. ] [ 30. 450. ] [ 30.7 500. ] [ 31. 475. ] [ 31. 500. ] [ 31.5 500. ] [ 32. 340. ] [ 32. 600. ] [ 32. 600. ] [ 33. 700. ] [ 33. 700. ] [ 33.5 610. ] [ 33.5 650. ] [ 34. 575. ] [ 34. 685. ] [ 34.5 620. ] [ 35. 680. ] [ 35. 700. ] [ 35. 725. ] [ 35. 720. ] [ 36. 714. ] [ 36. 850. ] [ 37. 1000. ] [ 38.5 920. ] [ 38.5 955. ] [ 39.5 925. ] [ 41. 975. ] [ 41. 950. ] [ 9.8 9.8] [ 10.5 10.5] [ 10.6 10.6] [ 11. 11. ] [ 11.2 11.2] [ 11.3 11.3] [ 11.8 11.8] [ 11.8 11.8] [ 12. 12. ] [ 12.2 12.2] [ 12.4 12.4] [ 13. 13. ] [ 14.3 14.3] [ 15. 15. ]] . print(kn._y) . [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0] . &#47924;&#51312;&#44148; &#46020;&#48120; . Fish ë°ì´í„°ì˜ ì´ ê°œìˆ˜ëŠ” 49ê°œì´ë‹¤. ì´ë²ˆì—ëŠ” n_neighbors = 49ë¡œ ì§€ì • í•´ë³´ì. . kn49 = KNeighborsClassifier(n_neighbors=49) . kn49.fit(fish_data, fish_target) . KNeighborsClassifier(n_neighbors=49) . kn49.score(fish_data, fish_target) ## ì ìˆ˜ . 0.7142857142857143 . score method : í›ˆë ¨í•œ ëª¨ë¸ì„ ê°€ì§€ê³  ì–´ë–¤ ë°ì´í„°ë¥¼ ì§‘ì–´ ë„£ì–´ì„œ ì–¼ë§ˆë§Œí¼ ì˜ ë§ëŠ”ì§€ë¥¼ í™•ì¸í•´ ë³´ëŠ” ê²ƒì´ë‹¤. | ë¶„ë¥˜ë¬¸ì œì¼ ê²½ìš°ì—ëŠ” ì •í™•ë„ë¥¼ ì¶œë ¥ (ëª¨ë¸ì´ ì–´ëŠì •ë„ ì •í™•í•œì§€ë¥¼ ì•Œì•„ë³´ëŠ” ë©”ì„œë“œ.) | . print(35/49) . 0.7142857142857143 . ì´ë ‡ê²Œ ëª¨ë¸ì„ ë§Œë“¤ë©´ ì „ì²´ ìƒ˜í”Œì˜ ë‹¤ìˆ˜ëŠ” ë„ë¯¸ $ to$ ë¬´ì¡°ê±´ ë‹¤ ë„ë¯¸ | n_neighbors ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ìœ„ì˜ ìƒ˜í”Œê°œìˆ˜ë¥¼ ë°”ê¿”ë³¼ ìˆ˜ë„ ìˆë‹¤. ë°”ê¾¸ë©´ ì•Œê³ ë¦¬ì¦˜ì˜ ì •í™•ë„ê°€ ë†’ì„ìˆ˜ë¡, ë‚®ì„ìˆ˜ë„ ìˆë‹¤. | . &#54869;&#51064; &#47928;&#51228; . kn = KNeighborsClassifier() kn.fit(fish_data, fish_target) for n in range(5, 50): # ìµœê·¼ì ‘ ì´ì›ƒ ê°œìˆ˜ ì„¤ì • kn.n_neighbors = n #ì ‘ìˆ˜ ê³„ì‚° score = kn.score(fish_data, fish_target) # 100% ì •í™•ë„ì— ë¯¸ì¹˜ì§€ ëª»í•˜ëŠ” ì´ì›ƒ ê°œìˆ˜ ì¶œë ¥ if score &lt; 1: print(n, score) break . 18 0.9795918367346939 .",
            "url": "https://pinkocto.github.io/BP2022/2022/03/17/ML.html",
            "relUrl": "/2022/03/17/ML.html",
            "date": " â€¢ Mar 17, 2022"
        }
        
    
  
    
        ,"post20": {
            "title": "tips",
            "content": "1. csv&#54028;&#51068; upload . ì°¸ê³ ë§í¬ : https://evidencen.com/how-to-upload-your-csv-file-online/ . import pandas as pd . autompg.csv github notebooksì— upload | autommpg.csv íŒŒì¼ click | Raw / Blameì—ì„œ Raw ë²„íŠ¼ click | ìƒë‹¨ì˜ ë§í¬ ë³µì‚¬ | . ë³µì‚¬í•œ ì£¼ì†Œ : https://raw.githubusercontent.com/pinkocto/BP2022/master/_notebooks/autompg.csv . pd.read_csv(&quot;https://raw.githubusercontent.com/pinkocto/BP2022/master/_notebooks/autompg.csv&quot;) . mpg cyl disp hp wt accler year origin carname . 0 18.0 | 8 | 307.0 | 17 | 3504 | 12.0 | 70 | 1 | chevrolet chevelle malibu | . 1 15.0 | 8 | 350.0 | 35 | 3693 | 11.5 | 70 | 1 | buick skylark 320 | . 2 18.0 | 8 | 318.0 | 29 | 3436 | 11.0 | 70 | 1 | plymouth satellite | . 3 16.0 | 8 | 304.0 | 29 | 3433 | 12.0 | 70 | 1 | amc rebel sst | . 4 17.0 | 8 | 302.0 | 24 | 3449 | 10.5 | 70 | 1 | ford torino | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 393 27.0 | 4 | 140.0 | 82 | 2790 | 15.6 | 82 | 1 | ford mustang gl | . 394 44.0 | 4 | 97.0 | 53 | 2130 | 24.6 | 82 | 2 | vw pickup | . 395 32.0 | 4 | 135.0 | 80 | 2295 | 11.6 | 82 | 1 | dodge rampage | . 396 28.0 | 4 | 120.0 | 75 | 2625 | 18.6 | 82 | 1 | ford ranger | . 397 31.0 | 4 | 119.0 | 78 | 2720 | 19.4 | 82 | 1 | chevy s-10 | . 398 rows Ã— 9 columns . ê¹ƒí—™ì— ì—…ë¡œë“œ í•œ csvíŒŒì¼ì„ ì˜ ì½ì–´ì˜¤ëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/02/upload.html",
            "relUrl": "/python/2022/03/02/upload.html",
            "date": " â€¢ Mar 2, 2022"
        }
        
    
  
    
        ,"post21": {
            "title": "(6ì£¼ì°¨) 2ì›”18ì¼ (3)",
            "content": "- íŒŒì¼ê³¼ ê²½ë¡œ . - í…ìŠ¤íŠ¸ íŒŒì¼ ì—´ê¸°, ì“°ê¸°, ì½ê¸° . - Tkinter íŒŒì¼ ë‹¤ì´ì–¼ë¡œê·¸ë¥¼ ì´ìš©í•œ ì˜ˆì œ . &#54028;&#51068; . ëª©ì  ìë£Œë¥¼ ì˜êµ¬íˆ ë³´ê´€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë¨ | . | . ì¢…ë¥˜: ì €ì¥ëœ ë°ì´í„°ì— ë”°ë¼ í…ìŠ¤íŠ¸ íŒŒì¼ ì¼ë°˜ì ì¸ ë¬¸ì ì½”ë“œ | . | ì´ì§„ íŒŒì¼ ì‚¬ì§„, ìŒì•…, ë¹„ë””ì˜¤ | . | . | . íŒŒì¼ì˜ ìœ„ì¹˜ í´ë”ì— ì¡´ì¬ | í´ë”ëŠ” ë‹¤ë¥¸ í´ë”ì— í¬í•¨ë˜ì–´ ìˆìŒ | ê²½ë¡œ : ì–´ë–¤ í´ë”ë¡œë¶€í„° ê·¸ íŒŒì¼ì— ì´ë¥´ëŠ” ë°©ë²• | . | . - &#54028;&#51068; &#44221;&#47196; . * ê²½ë¡œì˜ ì¢…ë¥˜ . ì ˆëŒ€ ê²½ë¡œ: ë£¨íŠ¸ í´ë”ë¡œíˆ¬í„° ì‹œì‘ ex) c: users user documents hello.py | . | . ìƒëŒ€ ê²½ë¡œ: í˜„ì¬ í´ë”ë¡œë¶€í„° ì‹œì‘ | . * í´ë”ë¥¼ í‘œì‹œí•˜ëŠ” íŠ¹ìˆ˜í•œ ê¸°í˜¸ . . : í˜„ì¬ í´ë”ë¥¼ ì˜ë¯¸í•¨ | .. : í˜„ì¬ í´ë”ì˜ ë¶€ëª¨ (ì¦‰, ìƒìœ„í´ë”ë¥¼ ì˜ë¯¸í•¨) | . &gt; &gt;&gt; import os &gt;&gt;&gt; os.getcwd() ## í˜„ì¬ í´ë” ê²½ë¡œ &#39;C: USERS USER .... python3.7&#39;&gt; &gt;&gt; os.chdir(&quot;C: Users Users Documents&quot;) ## í˜„ì¬í´ë” ê²½ë¡œ ë³€ê²½&gt; &gt;&gt; os.getcwd() ## í˜„ì¬ í´ë” ê²½ë¡œ &quot;C: Users Users Documents&quot; ## ë°”ë€ ê²½ë¡œë¡œ ì¶œë ¥ëœ ê²ƒ í™•ì¸ . - &#44221;&#47196; &#48516;&#47532; &#47928;&#51088; . Windowsì—ì„œ ê²½ë¡œ ë¶„ë¦¬ ë¬¸ìëŠ” ë¬¸ì œëŠ” Escape-Sequenceë¥¼ ë‚˜íƒ€ë‚¼ ë•Œ ì‚¬ìš©ë¨ | ê·¸ëƒ¥ ë¬¸ìë¥¼ í‘œì‹œí•˜ê¸° ìœ„í•´ì„œëŠ” ë¥¼ ì‚¬ìš© | . | . Unix, Linux ê³„ì—´ì—ì„œ ê²½ë¡œ ë¶„ë¦¬ ë¬¸ìëŠ” / Windows ìœ„ì—ì„œ ì‹¤í–‰ë˜ëŠ” íŒŒì´ì¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥ | ì•ì˜ ì˜ˆëŠ” &quot;C:/Users/Users/Documents&quot;ë¡œ ì¨ë„ ê°€ëŠ¥! | . | . Raw ë¬¸ìì—´ ì‚¬ìš©ë°©ë²• r&quot;ë¬¸ìì—´&quot;ì€ ë¬¸ìì—´ ë‚´ ëª¨ë“  íŠ¹ìˆ˜ë¬¸ìë¥¼ ë¬´ì‹œí•˜ê³  ì¼ë°˜ ë¬¸ìë¡œ ì·¨ê¸‰í•¨ | r&quot;C: Users Users Documents&quot;ë¡œ ì¨ë„ ê°€ëŠ¥! | . | . - &#54028;&#51068; &#50676;&#44592; . open() ì´ë¼ëŠ” ë‚´ì¥ í•¨ìˆ˜ë¥¼ ì‚¬ìš© | . fileVar = open(filename, mode) . open() í•¨ìˆ˜ëŠ” íŒŒì¼ ì—´ê¸°ë¥¼ ì„±ê³µí•˜ë©´ íŒŒì¼ì„ ë‚˜íƒ€ë‚´ëŠ” ê°ì²´ë¥¼ ë°˜í™˜í•¨ _io.TextIoWrapper í´ë˜ìŠ¤ ê°ì²´ì„ | . | . . - &#54028;&#51068; &#50676;&#44592; &#47784;&#46300; . íŒŒì¼ì—´ê¸°ëª¨ë“œ ì„¤ëª… . r (ì½ê¸°ëª¨ë“œ) | íŒŒì¼ì„ ì½ê¸°ë§Œ í•  ë•Œ ì‚¬ìš©í•œë‹¤ | . w (ì“°ê¸°ëª¨ë“œ) | íŒŒì¼ì— ë‚´ìš©ì„ ì“¸ ë•Œ ì‚¬ìš©í•˜ë©° ê¸°ì¡´ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë‚´ìš©ì´ ëª¨ë‘ ì´ˆê¸°í™”ë˜ê³  &lt;/br&gt; ì£¼ì–´ì§„ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ íŒŒì¼ì„ ë§Œë“ ë‹¤ | . a (ì¶”ê°€ëª¨ë“œ) | ê¸°ì¡´ íŒŒì¼ì˜ ë§ˆì§€ë§‰ì— ìƒˆë¡œìš´ ë‚´ìš©ì„ ì¶”ê°€ ì‹œí‚¬ ë•Œ ì‚¬ìš©í•œë‹¤ | . rb, wb | ê°ê° ì´ì§„ íŒŒì¼ì„ ì½ê¸° ìœ„í•´ í˜¹ì€ ì“°ê¸° ìœ„í•´ ì—´ë•Œ ì‚¬ìš©í•œë‹¤ | . - &#54028;&#51068;&#50640; &#45936;&#51060;&#53552; &#50416;&#44592; . write() ë©”ì„œë“œ ì‚¬ìš© | . ofile = open(&quot;snowwhite.txt&quot;, &quot;w&quot;) # 1 ofile.write(&quot;Once upon a time, long, long ago n&quot;) # 2 ofile.write(&quot;a king and queen ruled over n&quot;) ofile.write(&quot;a distant land&quot;) ofile.close() . - &#54028;&#51068;&#51060; &#51316;&#51116;&#54616;&#45716;&#51648; &#44160;&#49324;&#54616;&#44592; . os.path.exist(ê²½ë¡œ) . íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ True, ì•„ë‹ˆë©´ Falseë¥¼ ë°˜í™˜ | . | os.path.isdir(ê²½ë¡œ) . ì§€ì •ëœ íŒŒì¼ì´ í´ë”ì´ë©´ True, ì•„ë‹ˆë©´ Falseë¥¼ ë°˜í™˜ | . | os.path.isfile(ê²½ë¡œ) . ì§€ì •ëœ íŒŒì¼ì´ ì¼ë°˜ íŒŒì¼ì´ë©´ True, ì•„ë‹ˆë©´ Falseë¥¼ ë°˜í™˜ | . | . - &#54028;&#51068; &#51088;&#47308; &#51069;&#44592; . íŒŒì´ì¬ì—ëŠ” ì™¸ë¶€íŒŒì¼ì„ ì½ì–´ ë“¤ì—¬ í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤. . ì „ì²´ ë°ì´í„°ë¥¼ ì½ëŠ” ë©”ì„œë“œ : read(), reaadlines() . | í•œ ì¤„ì„ ì½ëŠ” ë©”ì„œë“œ : readline() . | ì£¼ì–´ì§„ ê¸¸ì´ë¥¼ ì½ëŠ” ë©”ì„œë“œ: read(n) . | . - &#51204;&#52404; &#51069;&#44592; . - ë°©ë²•1: read() í•¨ìˆ˜ ì‚¬ìš©í•˜ê¸° . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) ## ì½ê¸° readResult = ifile.read() print(&quot;Read Result:&quot;) print(repr(readResult)) ## repr(): ì¤„ë°”ê¿ˆ ë¬¸ìë„ ê·¸ëŒ€ë¡œ ì¶œë ¥ ifile.close() . Read Result: &#39;Once upon a time, long, long ago na king and queen ruled over na distant land&#39; . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) ## ì½ê¸° readResult = ifile.read() print(&quot;Read Result:&quot;) print(readResult) ifile.close() . Read Result: Once upon a time, long, long ago a king and queen ruled over a distant land . read() ëŠ” íŒŒì¼ì˜ ë‚´ìš© ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ëŒë ¤ì¤€ë‹¤. | . - ë°©ë²•2: readlines() í•¨ìˆ˜ ì‚¬ìš©í•˜ê¸° . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) readLinesResult = ifile.readlines() print(&quot;Read Lines Result:&quot;) print(readLinesResult) ifile.close() . Read Lines Result: [&#39;Once upon a time, long, long ago n&#39;, &#39;a king and queen ruled over n&#39;, &#39;a distant land&#39;] . readline() í•¨ìˆ˜ëŠ” íŒŒì¼ì˜ ëª¨ë“  ì¤„ì„ ì½ì–´ì„œ ê°ê°ì˜ ì¤„ì„ ìš”ì†Œë¡œ ê°–ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ëŒë ¤ì¤€ë‹¤. | . - ë°©ë²•2 + ì¤„ë°”ê¿ˆ( n) ë¬¸ì ì œê±°í•˜ê¸° . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) lines = ifile.readlines() for line in lines: line = line.strip() # ì¤„ ëì˜ ì¤„ ë°”ê¿ˆ ë¬¸ìë¥¼ ì œê±° print(line) ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . - &#51648;&#51221;&#46108; &#44600;&#51060;&#47564;&#53372; &#51069;&#44592; . file.read(n) : í˜„ì¬ file pointerë¡œë¶€í„° nê°œì˜ ê¸€ìë¥¼ ì½ì–´ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜ | . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) str1 = ifile.read(4) print(&quot;Read(4) Result:&quot;) print(repr(str1)) str2 = ifile.read(10) print(&quot;Read(10) Result:&quot;) print(repr(str2)) ifile.close() . Read(4) Result: &#39;Once&#39; Read(10) Result: &#39; upon a ti&#39; . - &#54620; &#51460;&#50473; &#51069;&#44592; &#44208;&#44284; . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) ifile.readline() ## 1 . &#39;Once upon a time, long, long ago n&#39; . ifile.readline() ## 2 . &#39;a king and queen ruled over n&#39; . ifile.readline() ## 3 . &#39;a distant land&#39; . ifile.readline() ## 4 . &#39;&#39; . lineì´ ëì— ë‹¤ë‹¤ë¥´ë©´ ë¹ˆë¬¸ì(&#39;&#39;)ê°€ ì¶œë ¥ëœë‹¤. | . - &#54028;&#51068;&#50640; &#47336;&#54532; &#49324;&#50857;&#54616;&#44592; . ë£¨í”„ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ í•œ ì¤„ì”© ì²˜ë¦¬í•˜ê¸° . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) line = ifile.readline() while line != &#39;&#39;: # line ì²˜ë¦¬ print(line) line = ifile.readline() ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) while True: line = ifile.readline() if not line: break print(line) ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) lines = ifile.readlines() for line in lines: # line ì²˜ë¦¬ print(line) ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . - &#49707;&#51088;&#44032; &#46308;&#50612;&#44032; &#51080;&#45716; &#54028;&#51068; &#52376;&#47532; . ofile = open(&quot;num.txt&quot;, &quot;w&quot;) ofile.write(&quot;10 20 12 5 n&quot;) ofile.write(&quot;8 9 7 23 n&quot;) ofile.write(&quot;1 8 22 9&quot;) ofile.close() . num.txt ì•„ë˜ì™€ ê°™ì€ íŒŒì¼ì´ ìˆì„ ë–„ íŒŒì¼ì— ìˆëŠ” ìˆ«ìì˜ í•©ì„ êµ¬í•´ë³´ì. | . ofile = open(&quot;num.txt&quot;, &quot;r&quot;) print(ofile.read()) ofile.close() . 10 20 12 5 8 9 7 23 1 8 22 9 . ofile = open(&quot;num.txt&quot;, &quot;r&quot;) total = 0 for line in ofile: lineLst = line.split() numList = [eval(x) for x in lineLst] total += sum(numList) print(total) . 134 . 10+20+12+5+8+9+7+23+1+8+22+9 . 134 . ì˜ ê³„ì‚°ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/02/18/(3).html",
            "relUrl": "/python/2022/02/18/(3).html",
            "date": " â€¢ Feb 18, 2022"
        }
        
    
  
    
        ,"post22": {
            "title": "(6ì£¼ì°¨) 2ì›”18ì¼ (1)",
            "content": "- ì†Œê°œ . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ì™€ í•¨ìˆ˜ . - ì˜ˆì œ . - ë‹¤ì°¨ì› ë¦¬ìŠ¤íŠ¸ . &#49548;&#44060; . í…Œì´ë¸”ì´ë‚˜ í–‰ë ¬ì€ 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. . - ëŒ€í•œë¯¼êµ­ ë„ì‹œë“¤ ê°„ ê±°ë¦¬ . ì„œìš¸ ë¶€ì‚° ëŒ€êµ¬ ê´‘ì£¼ . ì„œìš¸ | 0 | 325 | 237 | 267 | . ë¶€ì‚° | 325 | 0 | 87 | 202 | . ëŒ€êµ¬ | 237 | 87 | 0 | 172 | . ê´‘ì£¼ | 267 | 202 | 172 | 0 | . distance = [[0, 325, 237, 267], [325, 0, 87, 202], [237, 87, 0, 172], [267, 202, 172, 0]] . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52376;&#47532;&#54616;&#44592; . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#54364;&#54788; . matrix_ = [[1,2,3,4,5], [6,7,8,9,10], [11,12,13,14,15]] . - ê° ìš”ì†ŒëŠ” ë‘ ê°œì˜ ì²¨ìë¥¼ ì´ìš©í•˜ì—¬ í‘œí˜„ . matrix_[0][2] . 3 . matrix_[2][3] . 14 . matrix_[1][1] . 7 . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52488;&#44592;&#54868; . - ì‚¬ìš©ì ì…ë ¥ ê°’ìœ¼ë¡œ ì´ˆê¸°í™” . - ë¬´ì‘ìœ„ ê°’ìœ¼ë¡œ ì´ˆê¸°í™” . matrix = [] for row in range(3): ## number of rows = 3 matrix.append([]) for col in range(2): ## number of columns = 2 value = eval(input(&quot;value:&quot;)) matrix[row].append(value) . matrix ## 3í–‰ 2ì—´ì˜ 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ . [[1, 2], [3, 4], [5, 6]] . import random matrix = [] numberOfRows=3 numberOfColumns=2 for row in range(numberOfRows): matrix.append([]) #print(matrix) for col in range(numberOfColumns): matrix[row].append(random.randint(0,99)) #print(matrix) . [[]] [[51]] [[51, 15]] [[51, 15], []] [[51, 15], [47]] [[51, 15], [47, 46]] [[51, 15], [47, 46], []] [[51, 15], [47, 46], [79]] [[51, 15], [47, 46], [79, 98]] . matrix . [[51, 15], [47, 46], [79, 98]] . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52636;&#47141;&#54616;&#44592;, &#49438;&#44592;, &#51221;&#47148; . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ . len(matrix), len(matrix[0]) . (3, 2) . for row in range(len(matrix)): for col in range(len(matrix[row])): print(matrix[row][col], end=&#39; &#39;) print() . 51 15 47 46 79 98 . - 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ ì„ê¸° . matrix . [[51, 15], [47, 46], [79, 98]] . for row in range(len(matrix)): for col in range(len(matrix[row])): i = random.randint(0, len(matrix)-1) j = random.randint(0, len(matrix[row])-1) matrix[row][col], matrix[i][j] = matrix[i][j], matrix[row][col] . matrix . [[79, 98], [46, 15], [47, 51]] . ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ì›ì†Œë“¤ì´ ì˜ ì„ì—¬ì§„ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. | . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52376;&#47532; . - ëª¨ë“  ì›ì†Œë“¤ì˜ í•© êµ¬í•˜ê¸° . matrix . [[79, 98], [46, 15], [47, 51]] . total = 0 for row in matrix: for value in row: total += value print(total) . 79 177 223 238 285 336 . total . 336 . - ê° ì—´ì˜ í•© êµ¬í•˜ê¸° . matrix . [[79, 98], [46, 15], [47, 51]] . for col in range(len(matrix[0])): total = 0 for row in range(len(matrix)): total += matrix[row][col] print(&quot;Sum of column&quot;, col, &quot;is&quot;, total) . Sum of column 0 is 172 Sum of column 1 is 164 . 79+46+47 # 1ì—´ í•© . 172 . 98+15+51 # 2ì—´ í•© . 164 . ê° ì—´ì˜ í•©ì´ ì˜ ê³„ì‚°ë˜ì—ˆë‹¤. | . - í•©ì´ ê°€ì¥ í° í–‰ êµ¬í•˜ê¸° . matrix . [[79, 98], [46, 15], [47, 51]] . maxRow = sum(matrix[0]) indexRow = 0 for row in range(1, len(matrix)): if sum(matrix[row]) &gt; maxRow: maxRow = sum(matrix[row]) indexRow = row print(&quot;Row&quot;, indexRow, &quot;has max sum of &quot; , maxRow) . Row 0 has max sum of 177 . - ë¦¬ìŠ¤íŠ¸ ì •ë ¬ . lst = [[1,2],[1,1],[3,1],[2,5]] lst . [[1, 2], [1, 1], [3, 1], [2, 5]] . lst.sort() lst . [[1, 1], [1, 2], [2, 5], [3, 1]] . 2&#52264;&#50896; &#47532;&#49828;&#53944;&#50752; &#54632;&#49688; . 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë„ ë‹¤ë¥¸ ê°ì²´ì™€ ë§ˆì°¬ê°€ì§€ë¡œ í•¨ìˆ˜ì— ì¸ìˆ˜ë¡œ ì „ë‹¬í•  ìˆ˜ë„ ìˆê³ , í•¨ìˆ˜ê°€ ë°˜í™˜ê°’ìœ¼ë¡œ ë°˜í™˜í•  ìˆ˜ë„ ìˆë‹¤. . def getMatrix(): matrix = [] numRows = eval(input(&quot;Number of Rows: &quot;)) numCols = eval(input(&quot;Number of Colunmns: &quot;)) for row in range(numRows): matrix.append([]) for col in range(numCols): value = eval(input(&quot;value:&quot;)) matrix[row].append(value) return matrix . getMatrix() . [[79, 98], [46, 15], [17, 51]] . def accumulate(m): total = 0 for row in m: total += sum(row) return total . accumulate(matrix) . 336 . matrixì˜ ëª¨ë“  ì›ì†Œì˜ í•©ì€ 336ìœ¼ë¡œ ìœ„ì—ì„œ êµ¬í•œ (2ì°¨ì› ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬: ëª¨ë“  ì›ì†Œì˜ í•©)ì—ì„œ êµ¬í•œ ê°’ê³¼ ê°™ë‹¤. | . &#50696;&#51228;1 | &#44032;&#51109; &#44032;&#44620;&#50868; &#46160; &#51216;&#51008;? . ì—¬ëŸ¬ ì ì— ëŒ€í•œ ì¢Œí‘œê°€ ìˆë‹¤. ì´ë“¤ ì  ì¤‘ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ë‘ ì ì„ ì°¾ì•„ë³´ì. . def distance(x1,y1,x2,y2): return((x1-x2)**2 + (y1-y2)**2)**0.5 def nearestPoint(points): p1, p2 = 0, 1 shortestDist = distance(points[p1][0], points[p1][1], points[p2][0], points[p2][1]) for i in range(len(points)): for j in range(i+1, len(points)): d = distance(points[i][0], points[i][1], points[j][0], points[j][1]) if d &lt; shortestDist: shortestDist = d p1, p2 = i, j return p1, p2 . nPoints = eval(input(&quot;ì ì˜ ìˆ˜:&quot;)) points = [] for i in range(nPoints): point = [0,0] point[0],point[1] = eval(input(&quot;ì¢Œí‘œ:&quot;)) points.append(point) p1, p2 = nearestPoint(points) print(&quot;(&quot;, points[p1][0], points[p1][1],&quot;)&quot;,&quot;(&quot;,points[p2][0], points[p2][1],&quot;)&quot;) . ( 0 0 ) ( 0 1 ) . nPoints = eval(input(&quot;ì ì˜ ìˆ˜:&quot;)) points = [] for i in range(nPoints): point = [0,0] point[0],point[1] = eval(input(&quot;ì¢Œí‘œ:&quot;)) points.append(point) p1, p2 = nearestPoint(points) print(&quot;(&quot;, points[p1][0], points[p1][1],&quot;)&quot;,&quot;(&quot;,points[p2][0], points[p2][1],&quot;)&quot;) . ( 2 5 ) ( 3 8 ) . &#50696;&#51228;2 | Sudoku . . [ê²Œì„ ê·œì¹™] . ê° ì—´, ê° í–‰ì— 1~9ê¹Œì§€ ìˆ«ìê°€ ë“¤ì–´ê°€ì•¼ í•œë‹¤. | $3 times 3$ ë¸”ë¡ì— 1~9ê°€ì§€ ìˆ«ìê°€ ë“¤ì–´ê°€ì•¼ í•œë‹¤. | . &#50612;&#46500; Sudoku &#54644;&#44208;&#48169;&#48277;&#51060; &#47582;&#45716;&#51648; &#44160;&#49324; . ë‘ê°€ì§€ ê²€ì‚¬ë°©ë²• . ê° í–‰, ì—´, ë¸”ë¡ì´ 1~9ê¹Œì§€ ìˆ«ìë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ ê²€ì‚¬ | | ê° ì…€ì— ëŒ€í•´ ê·¸ ì…€ì˜ ìˆ«ìê°€ í–‰, ì—´, ë¸”ë¡ì—ì„œ ìœ ì¼í•œì§€ ê²€ì‚¬ &lt; ì´ ë°©ë²• ì‚¬ìš©í•  ê²ƒì„! | | . | . def isValid(grid): for i in range(9): for j in range(9): if grid[i][j] &lt; 1 or grid[i][j] &gt; 9 or not isValidAt(i,j,grid): return False return True . def isValidAt(i,j,grid): for column in range(9): if column != j and grid[i][column] == grid[i][j]: return False for row in range(9): if row != i and grid[row][j] == grid[i][j]: return False for row in range((i//3)*3, (j//3)*3 + 3): if row != i and column != j and grid[row][column] == grid[i][j]: return False return True . &#45796;&#52264;&#50896; &#47532;&#49828;&#53944; . ì¼ë°˜ì ìœ¼ë¡œ $n$ê°œì˜ ì²¨ì ì‚¬ìš© | . m[i][j][k] . .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/02/18/(1).html",
            "relUrl": "/python/2022/02/18/(1).html",
            "date": " â€¢ Feb 18, 2022"
        }
        
    
  
    
        ,"post23": {
            "title": "test",
            "content": "import pandas as pd import altair as alt . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . selection = alt.selection_single(); alt.Chart(cars).mark_circle().add_selection( selection ).encode( x=&#39;Horsepower:Q&#39;, y=&#39;Miles_per_Gallon:Q&#39;, color=alt.condition(selection, &#39;Cylinders:O&#39;, alt.value(&#39;grey&#39;)), opacity=alt.condition(selection, alt.value(0.8), alt.value(0.1)) ) . def plot(selection): return alt.Chart(cars).mark_circle().add_selection( selection ).encode( x=&#39;Horsepower:Q&#39;, y=&#39;Miles_per_Gallon:Q&#39;, color=alt.condition(selection, &#39;Cylinders:O&#39;, alt.value(&#39;grey&#39;)), opacity=alt.condition(selection, alt.value(0.8), alt.value(0.1)) ).properties( width=240, height=180 ) . alt.hconcat( plot(alt.selection_single()).properties(title=&#39;Single (Click)&#39;), plot(alt.selection_multi()).properties(title=&#39;Multi (Shift-Click)&#39;), plot(alt.selection_interval()).properties(title=&#39;Interval (Drag)&#39;) ) . alt.hconcat( plot(alt.selection_single(on=&#39;mouseover&#39;)).properties(title=&#39;Single (Mouseover)&#39;), plot(alt.selection_multi(on=&#39;mouseover&#39;)).properties(title=&#39;Multi (Shift-Mouseover)&#39;) ) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/01/04/test.html",
            "relUrl": "/python/2022/01/04/test.html",
            "date": " â€¢ Jan 4, 2022"
        }
        
    
  
    
        ,"post24": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.â†© . 2. This is the other footnote. You can even have a link!â†© .",
            "url": "https://pinkocto.github.io/BP2022/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " â€¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post25": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a â€œlevel 1 headingâ€ in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Hereâ€™s a footnote 1. Hereâ€™s a horizontal rule: . . Lists . Hereâ€™s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes â€¦andâ€¦ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.Â &#8617; . |",
            "url": "https://pinkocto.github.io/BP2022/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " â€¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.Â &#8617; . |",
          "url": "https://pinkocto.github.io/BP2022/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ â€œsitemap.xmlâ€ | absolute_url }} | .",
          "url": "https://pinkocto.github.io/BP2022/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
{
  
    
        "post0": {
            "title": "Title",
            "content": "",
            "url": "https://pinkocto.github.io/BP2022/2023/02/15/%ED%8C%A8%ED%82%A4%EC%A7%80-%EC%A0%95%EB%A6%AC.html",
            "relUrl": "/2023/02/15/%ED%8C%A8%ED%82%A4%EC%A7%80-%EC%A0%95%EB%A6%AC.html",
            "date": " • Feb 15, 2023"
        }
        
    
  
    
        ,"post1": {
            "title": "ML Top5 Algorithm",
            "content": "01. Linear Regression . 가장 기본적인 기법 . | 해석하기 쉬움 . | 02. Logistic Regression . Binary Classification을 위한 가장 기본적인 기법 | 해석하기 쉬움 | Deep Learning의 Activation으로도 사용됨 | 03. Decision Tree . 1. 활용 범주가 넓음 . Linear Regression 같은 경우는 연속형변수를 예측하는데 사용하였고, Logistic Regression은 yes or no와 같은 Binary Classification에 쓴다. . | Decision Tree는 이 둘 다 활용이 가능하고 거기에 더해서 다중 클래스 classification 모델에서도 사용할 수 있다. . | . 2. Visulaization . 3. 최신 알고리즘 기반 모델 . 04. Random Forest . 활용 범주가 넓음 . | 앙상블 모델의 기본 . | 비교적 좋은 예측 능력 . | 05. Kmeans Clustering . Unsupervised Learning | Segmentation이 용이 | 어떤 식으로 segment가 뭉칠지 돌리는 사람도 모릅니다. . 클러스터링을 하고나서 나눠진 걸 보고 아 이런 애들끼리 뭉쳤구나..! . 클러스터링이 끝난 뒤에 알 수 있는게 바로 Unsupervised Learning의 특징 . 이처럼 이 알고리즘은 돌리는 사람이 미리 답을 정해 놓지 않는다는 겁니다. . 데이터는 일단 주어져 있고 알고리즘을 돌리는 사람은 이걸 3개의 세그먼트(클러스터)로 나눌지 5개로 나눌지 딱 그것만 정해주면 이 알고리즘은 데이터를 가장 비슷한 애들끼리 딱 그 숫자, 지정된 클러스터의 숫자만큼 나오도록 알아서 묶어주는 거에요. . 3개로 묶는 것도 여러가지 방법으로 묶을 수 있겠지만, 컴퓨터가 판단하기에 이렇게 묶었을 때 이 그룹간의 특징이 가장 잘 설명된다는 거죠. . 그룹내에 있는 애들끼리는 최대한 유사하고, 그룹 간의 성격은 최대한 좀 떨어져있는 . 그래서 Kmeans 클러스터링을 돌리면 어떤 식으로 결과가 나올지 예측이 불가능하고 그걸 돌리고 난 뒤에 클러스터 3개를 얻어 봤더니 A라는 특징은 이런 특징이 있고, B는 이렇고, C는 이렇다.이런식으로 해석 할 수 있는 거에요. . 그러기 때문에 이건 완전히 Unsupervised Learning입니다. . And. XGBoost . XGBoost는 앞에서 설명한 Decision Tree, Random Forest 같은 트리 모델 중의 하나이고, 나름 최신기법 중 하나입니다. 실제로 나온 시점은 수년이 지났지만, 여전히 많이 활발하게 사용되는 알고리즘이고 캐클 컴페티션에서 이미지 같은 거 아니고 그냥 Binary Classification 같은 문제면 거의 XGBoost 이것만 있으면 어느정도는 다룰 수 있어요. . 최신 기법이라고 할만한 트리 모델은 xgboost, LightGBM, 그리고 Cat Boost이렇게 3개가 있는데 xgboost가 가장 오래됐고, 그 다음으로 핫하게 뜨고 있는게 LightGBM, Cat Boost는 가장 마지막으로 나온 정말 최신 모델. .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/12/06/ML-top5-algorithm.html",
            "relUrl": "/python/2022/12/06/ML-top5-algorithm.html",
            "date": " • Dec 6, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Bias-Variance Tradeoff",
            "content": ". 위의 그림을 가지고 생각해보자. . 만약 내가 데이터를 10만개를 가지고 있다고 가정해보자. 모델링을 할 때 이 데이터 전체에 대해서 하는 것이 아니라 데이터의 부분집합 6개의 subset을 만들어서 (각각 다른 조합의 데이터들이 6개의 subset이 된다.) 이 6개의 subset에 대해서 트레이닝을 하고 예측을 해본다라고 하자. . 우리가 복잡한 모델과 덜 복잡한 모델을 사용했을 때 어떻게 달라지는가를 알아보자. . Decision Tree를 예를들어 봅시다. 트리가 Adaboost처럼 딱 한단계만 들어있으면 단순한 모델이 되고, 트리의 깊이가 20단계까지 내려가면 훨씬 복잡한 모델이 되겠죠! . 내가 가진 데이터의 독립변수의 개수가 20개라고 했을 때 이 얕은 트리에서는 20개의 변수 중에 가장 중요하다고 생각하는 변수를 하나밖에 사용을 안할것이고, 깊은 트리에서는 20개가 다 쓰일지 안쓰일지 모르겠으나 훨씬 많은 독립변수들이 이 트리를 만드는데 개입을 할 거에요. . . 단순한 모델의 경우 예측했을 때 값이 굉장히 비슷해 질 것이다. 반대로 깊이가 깊은 모델을 가지고 예측을 하면 각각의 training set(6개의 subset)에 대해서 결과값들이 들쭉날쭉한 그런 값들이 나올 겁니다. . 상식적으로 너무 단순하게 예측을 했기 때문에 실제값과 차이가 클 수 밖에 없어요. 그래서 BIas가 높은 것 입니다. 반대로, 이 결과값은 상당히 동일하게 유지가 되죠. 그래서 Variance가 낮은거에요. Variance가 낮다는 것은 다양한 Subset(data)을 가지고 돌려봤을 때 이걸 할때마다 예측값이 얼마나 다양하게 나오는지 아니면 동일하게 나오는지입니다. . 그래서 단순한 모델의 경우 Bias가 높고, Variance가 낮다. . 반대로 모델이 복잡한 경우 (트리가 깊은 경우)는 각가의 트레이닝 데이터셋을 최대한 잘 예측하게끔 모델링이 되기 때문에 Bias가 낮고, training set에 대해서 결과가 바뀌기 때문에 여기선 Variance가 높다라고 할 수 있습니다. . 그래서 모델이 얼마나 복잡하냐 복잡하지 않냐에 따라서 Bias와 Variance가 이런식으로 달라지는 거죠 . . High Bias / Low Variance : 즉, 20개의 subset을 예측했을 때 항상 비슷한 결과값을 보여주지만 실제 값이랑은 꽤 거리가 있다. 하지만 한 곳에 잘 뭉쳐있으니까 Variance는 낮다. . | 20개의 subset을 가지고 모델링 했을 때 매번 다른 결과값을 보여준다. 즉, 트레이닝 데이터 셋의 특성에 따라 나오는 결과값도 항상 다르기 때문에 Variance가 높은거고, 대신 bias는 training set에 대해서 좀 더 잘 예측을 하도록 모델링이 되기 때문에 bias는 낮게 예측이 되는거죠. . | . . 모델이 복잡할수록(오른쪽) 다양한 subset에 대해서 예측을 했을 때 매번 결과는 달라지니까 Variance가 높고, 대신 매번 그 subset에 대한 예측은 잘 하기 때문에 bias는 낮은 거에요. 그래서 이 경우는 오버피팅이 걱정이 되는것이고 . 반대로 모델의 복잡도가 낮은 경우는 여러개의 subset을 통해서 예측을 하더라도 그 결과값이 거의 동일하게 나오기 때문에 Variance는 굉장히 낮으나, 애초에 그 예측력이 떨어져서 bias가 높다. 그래서 언더피팅이 우려가 된다. . . Note: 바이어스는 에러라고 보면되고, Variance는 여러개의 subset data를 training set으로 썼을 때 매번 할때마다 얼마나 다양한 결과값이 나오느냐를 의미한다고 보면 됩니다. . . Tip: 즉, 복잡한 모델일수록 에러(바이어스)는 낮고, 결과값은 다이나믹하게 달라질 수 있기 때문에 Variance는 높다. 모델이 단순하면 그 반대다. .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/12/05/bias-variance-tradeoff.html",
            "relUrl": "/python/2022/12/05/bias-variance-tradeoff.html",
            "date": " • Dec 5, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "(OpenCV - Chap9) 변환영역 처리",
            "content": "9.1 &#44277;&#44036; &#51452;&#54028;&#49688;&#51032; &#51060;&#54644; . 공간주파수: 밝기의 변화 정도에 따라서 고주파 영역 / 저주파 영역으로 분류 . - 저주파 공간 영영 . 화소 밝기가 거의 변화가 없거나 점진적으로 변화하는 것 | 영상에서 배경 부분이나 객체의 내부에 많이 있음 | . - 고주파 공간 영역 . 화소 밝기가 급변하는 것 | 경계부분이나 객체의 모서리 부분 | . - 영상을 주파수 영역별로 분리 한다면? . 경계부분에 많은 고주파 성분 제거한 영상 $ to$ 경계 흐려진 영상 | 고주파 성분만 취한 영상 $ to$ 경계나 모서리만 포함하는 영상. 즉, 에지 영상 | . 9.2 &#51060;&#49328; &#54392;&#47532;&#50640; &#48320;&#54872; . &#49888;&#54840;&#51032; &#44592;&#48376; &#51204;&#51228; . 주기를 가진 신호는 정현파(사인파) / 여현파(코사인파)의 합으로 표현할 수 있다. . - 정현파 / 여현파 . 모든 파형 중에 가장 순수한 파형을 말하는 것으로 사인 또는 코사인 함수로 된 신호 | . - 예) 주기를 갖는 신호 $$g(t) = 0.3 cdot g_1(t) - 0.7 cdot g_2(t) + 0.6 cdot g_3(t)$$ . - 여러 사인 및 코사인 함수들로 분리 가능 . 분리된 신호(기저 함수): $g_1(t)=sin(2 pi cdot t), space g_2(t) = sin(2 pi cdot 3t), space g_3(t) = sin(2 pi cdot 5t)$ | . 기저 함수에 곱해지는 값(주파수 계수) : $0.3, -0.7, 0.5$) $ leftarrow$주파수 성분의 크기 | . &#51452;&#54028;&#49688; &#48320;&#54872; &#49688;&#49885; . $$g(t) = int_{- infty}^{ infty}G(f) cdot g_f(t)df$$ . $g_f(t)$ : f주파수에 대한 기저함수 | $G(t)$ 기저함수의 계수 | . 모든 주파수에 대한 기저함수와 그 계수들의 선형 조합 . &#47196;&#44536;&#51201;&#50857; &#51221;&#44508;&#54868; &#54632;&#49688; . def calc_spectrum(complex): if complex.ndim==2: dst = abs(complex) else: dst = cv2.magnitude(complex[:,:,0], complex[:,:,1]) dst = cv2.log(dst + 1) cv2.normalize(dst, dst, 0, 255, cv2.NORM_MINMAX) return cv2.convertScaleAbs(dst) . &#51452;&#54028;&#49688; &#49828;&#54169;&#53944;&#47100; &#50689;&#49345; . 저주파 영영이 모서리 부분에 위치, 고주파 부분이 중심부에 위치 | 사각형의 각 모서리를 중심으로 원형의 밴드를 형성하여 주파수 영역 분포 해당 주파수 영역 처리시 불편함 $ to$ 모양 변경 필요 | . | . &#54644;&#44208;&#48169;&#48277; - &#49492;&#54540;&#47553;(shuffling) / &#49884;&#54532;&#53944;(shift) &#50672;&#49328; . 좌측 상단이 1사분면, 우측상단이 2사분면, 우측 하단 3사분면, 좌픅 하당 4사분면 . 1사분면과 3사분면 맞교환, 2사분면과 4사분면 맞교환 | . def fftshift(img): dst = np.zeros(img.shape, img.dtype) h, w = dst.shape[:2] cy, cx = h//2, w//2 dst[h-cy:, w-cx:] = np.copy(img[0:cy, 0:cx]) #1사분면 -&gt; 3사분면 . 9.3 &#44256;&#49549; &#54392;&#47532;&#50640; &#48320;&#54872; . &#54392;&#47532;&#50640; &#48320;&#54872; &#49688;&#49885; - &#51677;&#49688;&#48512;/&#54848;&#49688;&#48512; &#48516;&#47532; &#44032;&#45733; . $$G(k) = sum_{n=0}^{L-1}g[2n] cdot e^{-j2 pi k frac{2n}{2L}} + sum_{n=0}^{L-1}g[2n+1] cdot e^{-j2 pi k frac{2n+1}{2L}}$$ .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/11/25/opencv-chap09.html",
            "relUrl": "/python/2022/11/25/opencv-chap09.html",
            "date": " • Nov 25, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "(OpenCV - Chap8) 기하학 처리",
            "content": "- 기하학적 처리의 기본 . 화소들의 배치 변경 $ to$ 사상(mapping)의 의미 이해 | . - 사상 . 화소들의 배치를 변경할 때, 입력영상의 좌표에 해당하는 해당 목적영상의 좌표를 찾아서 화소값을 옮기는 과정 | . - 순방향 사상(forward mapping) . 원본 영상의 좌표를 중심으로 목적영상의 좌표를 계산하여 화소의 위치를 반환하는 방식 $ to$ 입력 영상과 출력 영상의 클기가 같을 때 유용 . | 두 영상의 크기가 달라지면, 홀(HOLE)이나 오버랩(OVERLAP)의 문제가 발생 . | . - 역방향 사상 (reverse mapping) . 목적 영상의 좌표를 중심으로 역변환을 계산하여 해당하는 입력 영상의 좌표를 찾아서 화소값을 옮기는 과정 . | 홀이나 오버랩은 발생하지 않음 . | 입력영상의 한 화소를 목적영상의 여러 화소에서 사용하게 되면 결과 영상의 품질 저하 | . 8.2 &#53356;&#44592; &#48320;&#44221; (&#54869;&#45824; / &#52629;&#49548;) . &#53356;&#44592; &#48320;&#44221; (Scaling) . 입력영상의 가로와 세로로 크기를 변경해서 목적 영상을 만드는 방법 | 입력영상보다 변경하고자 하는 영상의 크기가 커지면 확대, 작아지면 축소 | . &#53356;&#44592;&#48320;&#44221; &#49688;&#49885; . 변경 비율 및 변경 크기 이용 . $x&#39; = x cdot ratio X$ | $y&#39; = y cdot ratio Y$ | . $$ ratio X = frac{dst_{width}}{org_{width}}, qquad ratio Y = frac{dst_{height}}{org_{height}}$$ . 8.3 &#48372;&#44036; . 알고있는 데이터를 기준으로 값을 추정하는 것. . 순방향 사상으로 영상 확대 - 홀이 많이 발생 | . . 역방향 사상을 통해서 홀의 화소들을 입력 영상에서 찾음 영상을 축소할 때에는 오버랩의 문제가 발생 | . | . 보간법 (interpolation) 필요 목적 영상에서 홀의 화소들을 채우고, 오버랩이 되지 않게 화소들을 배치하여 목적 영상을 만드는 기법 | . 8.3.1 &#52572;&#44540;&#51217; &#51060;&#50883; &#48372;&#44036;&#48277; (nearest neighbor interpolation) . . 8.3.2 &#50577;&#49440;&#54805; &#48372;&#44036;&#48277; . - &#52572;&#44540;&#51217; &#51060;&#50883; &#48372;&#44036;&#48277;&#51032; &#47928;&#51228; . 확대비율이 커지면, 모자이크 현상 혹은 경계부분에서 계단현상 발생 . $ to$ 양선형 보간 (bilinear interpolation)으로 해결 직선의 선상에 위치한 중간 화소들의 값은 직선의 수식을 이용해서 쉽게 계산 . - &#50577;&#49440;&#54805; &#48372;&#44036;&#48277; . 선형 보간을 두 번에 걸쳐서 수행하기에 붙여진 이름 . 목적영상 화소($P$)를 역변환으로 계산하여 가장 가까운 위치에 있는 입력영상의 4개 화소(A, B, C, D) 값 가져옴 . | 4개 화소를 두 개씩(AB, CD) 묶어서 두 화소를 화소값($P_1, P_2, P_3, P_4)$으로 잇는 직선 구성 . | . . 8.4 &#54217;&#54665;&#51060;&#46041; . 영상의 원점을 모든 화소를 동일하게 가로방향과 세로 방향으로 옮기는 것 | 가로 방향으로 $dx$만큼, 세로 방향으로 $dy$만큼 전체 영상의 모든 화소 이동한 예 | . . . 8.5 &#54924;&#51204; . 입력영상의 모든 화소를 영상의 원점을 기준으로 원하는 각도만큼 모든 화소에 대해서 회전 변환을 시키는 것 . . 8.6 &#54665;&#47148; &#50672;&#49328;&#51012; &#53685;&#54620; &#44592;&#54616;&#54617; &#48320;&#54872; - &#50612;&#54028;&#51064; &#48320;&#54872; . 기하학 변환 수식이 행렬의 곱으로 표현 가능 . - 회전 . $ begin{bmatrix}x&#39; y&#39; end{bmatrix} = begin{bmatrix}cos theta &amp; -sin theta sin theta &amp; cos theta end{bmatrix} begin{bmatrix}x y end{bmatrix}$ . - 평행이동 . $ begin{bmatrix}x&#39; y&#39; end{bmatrix} = begin{bmatrix}x y end{bmatrix} begin{bmatrix}t_x t_y end{bmatrix}$ . - 크기변경 . $ begin{bmatrix}x&#39; y&#39; end{bmatrix} = begin{bmatrix} alpha &amp; 0 0 &amp; beta end{bmatrix} begin{bmatrix}x y end{bmatrix}$ . 8.7 &#50896;&#44540; &#53804;&#49884;(&#53804;&#50689;) &#48320;&#54872; . &#50896;&#44540; &#53804;&#49884; &#48320;&#54872;(perspective projection transformation) . &#46041;&#52264; &#51340;&#54364;&#44228; (homogeneous coordinates) . 원근 투영 변환을 사용할 때에는 동차좌표계를 사용하는 것이 편리 | 모든 항의 차수가 동일하기 때문에 붙여진 이름으로서 $n$차원의 투영 공간을 $n+1$개의 좌표로 나타내는 좌표계 $ to$ 차원의 좌표를 1차원 증가시켜 표현 | . &#50896;&#44540; &#48320;&#54872;&#51012; &#49688;&#54665;&#54616;&#45716; &#54665;&#47148; . 입력 영상의 좌표를 목적 영상의 좌표로 변환하면 원근 변환 수행 . $w cdot begin{bmatrix}x&#39; y&#39; 1 end{bmatrix} = begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13} a_{21} &amp; a_{22} &amp; a_{23} a_{31} &amp; a_{32} &amp; a_{33} end{bmatrix} begin{bmatrix}x y 1 end{bmatrix}$ . OpenCV &#54632;&#49688; . function name Description . cv::getPerspectiveTransform() | 4개의 좌표쌍으로부터 원근변환 행렬 계산 | . cv::warpPerspective() | 원근변환 행렬에 따라서 원근변환 수행 | . cv::transform() | 입력영상의 4개 좌표와 원근 행렬을 인수로 입력하면 원근 변환된 좌표를 반환 | . Summary . 사상(mapping)은 화소들의 배치를 변경할 때, 입력영상의 좌표가 새롭게 배치될 해당 목적영상의 좌표를 찾아서 화소값을 옮기는 과정을 말한다. 순방향 사상(forward mapping)과 역방향 사상(reverse mapping)의 두 가지 방식이 있다. | . 사상의 과정에서 홀(hole)과 오버랩(overlap)이 발생할 수 있다. 홀은 입력영상의 좌표들로 목적영상의 좌표를 만드는 과정에서 사상되지 않은 화소이다. 오버랩은 원본 영상의 여러 화소가 목적영상의 한 화소로 사상되는 것을 말한다. | . 목적영상에서 홀의 화소들을 채우고, 오버랩이 되지 않게 화소들을 배치하여 목적영상을 만드는 기법을 보간법(interpolation)이라 하며, 그 종류에는 최근접 이웃 보간법, 양선형 보간법, 3차 회선 보간법 등 다양한 방법이 있다. | . 최근접 이웃 보간법은 목적영상을 만드는 과정에서 홀이 되어 할당 받지 못하는 화소들의 값을 찾을 때, 목적영상의 화소에 가장 가깝게 이웃한 입력영상의 화소값을 가져오는 방법이다. 양선형 보간법은 선형 보간을 두 번에 걸쳐서 수행하기에 붙여진 이름이다. | . OpneCV에서는 cv2.resize(), cv2.remap(), cv2.warpAffine(), cv2.warpPerspective() 등과 같이 영상을 변환하는 함수에서 보간을 위한 flag 옵션을 제공한다. 대표적으로‘INTER_NEAREST’는 최근접 이웃 보간이며, ‘INTER_LINEAR’는 양선형 보간이며, ‘INTER_CUBIC’는 바이큐빅 보간이다. | . 2×3 크기의 어파인 변환 행렬을 이용해서 회전, 크기변경, 평행이동 등을 복합적으로 수행할 수 있다. OpenCV에서는 cv2.getAffineTransform()와 cv2.getRotationMatrix2D() 함수로 어파인 변환 행렬을 만들며, cv2.warpAffine() 함수로 어파인 변환을 수행한다. | . 원근법은 눈에 보이는 3차원의 세계를 2차원의 평면으로 옮길 때에 관찰자가 보는 것 그대로 사물과의 거리를 반영하여 그리는 방법을 말한다. 그리고 이 원근법을 영상 좌표계에서 표현하는 것이 원근 투시 변환이다. 원근 변환에서는 주로 동차 좌표계를 사용하는 것이 편리하다. | . OpenCV에서는 cv2.getPerspectiveTransform() 함수로 원근 변환 행렬을 계산하며, cv2.warpPerspective() 함수는 원근변환 행렬에 따라서 원근변환을 수행한다. 또한 cv2.transform() 함수는 입력영상의 4개 좌표와 원근 행렬을 인수로 입력하면 원근변환된 좌표를 반환해 준다. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/11/24/opencv-chap8.html",
            "relUrl": "/python/2022/11/24/opencv-chap8.html",
            "date": " • Nov 24, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "(OpenCV - Chap7) 영역처리",
            "content": "7.1.2 &#48660;&#47084;&#47553; . 블러링은 영상에서 화소값이 급격하게 변하는 부분들을 감소시켜 점진적으로 변하게 함으로써 영상에서 전체적으로 부드러운 느낌이 나게 하는 기술이다. 교재에 따라서 스무딩(smoothing)이라 하기도 한다. . ((60+90+90+200+100+100)+300)/9 . 104.44444444444444 . import numpy as np, cv2 . def filter(image, mask): rows, cols = image.shape[:2] dst = np.zeros((rows, cols), np.float32) # 회선 결과 저장 행렬 ycenter, xcenter = rows//2, cols//2 # 마스크 중심 좌표 for i in range(ycenter, rows - ycenter): # 입력 행렬 반복 순회 for j in range(xcenter, cols - xcenter): y1, y2 = i - ycenter, i + ycenter + 1 # 관심 영역 높이 범위 x1, x2 = j - xcenter, j + xcenter + 1 # 관심 영역 너비 범위 roi = image[y1:y2, x1:x2].astype(&#39;float32&#39;) # 관심 영역 형변환 tmp = cv2.multiply(roi, mask) # 회선 적용 - 원소 간 곱셈 dst[i, j] = cv2.sumElems(tmp)[0] # 출력 화소 저장 return dst # 자료형 변환하여 반환 . def filter2(image, mask): rows, cols = image.shape[:2] dst = np.zeros((rows, cols), np.float32) # 회선 결과 저장 행렬 xcenter, ycenter = mask.shape[1]//2, mask.shape[0]//2 # 마스크 중심 좌표 for i in range(ycenter, rows - ycenter): # 입력 행렬 반복 순회 for j in range(xcenter, cols - xcenter): sum = 0.0 for u in range(mask.shape[0]): # 마스크 원소 순회 for v in range(mask.shape[1]): y, x = i + u - ycenter , j + v - xcenter sum += image[y, x] * mask[u, v] # 회선 수식 dst[i, j] = sum return dst . image = cv2.imread(&quot;./ghtop_images/chap07_images/filter_blur.jpg&quot;, cv2.IMREAD_GRAYSCALE) # 영상 읽기 if image is None: raise Exception(&quot;영상파일 읽기 오류&quot;) . data = [1/9, 1/9, 1/9, 1/9, 1/9, 1/9, 1/9, 1/9, 1/9] # 마스크 행렬 생성 mask = np.array(data, np.float32).reshape(3, 3) blur1 = filter(image, mask) # 회선 수행 - 행렬 처리 방식 blur2 = filter2(image, mask) # 회선 수행 - 화소 직접 접근 blur1 = blur1.astype(&#39;uint8&#39;) # 행렬 표시위해 uint8형 변환 blur2 = cv2.convertScaleAbs(blur2) . cv2.imshow(&#39;image&#39;, image) cv2.imshow(&#39;blur1&#39;, blur1) cv2.imshow(&#39;blur2&#39;, blur2) cv2.waitKey(0) cv2.destroyAllWindows() # 모든 창 닫기 . Summary . 1. 회선(convolution) 은 마스크 내의 원소값과 공간 영역에 있는 입력 영상의 화소값들을 대응되게 곱하여 출력 화소값을 계산하는 것을 말한다. 이때, 입력 영상에 곱해지는 이 마스크를 커널(kernel), 윈도우(window), 필터(filter)등의 용어로 부른다. . 2. 블러링(bluring) 은 회선 마스크의 원소를 모두 같은 값으로 지정해 수행하며, 전체 합이 1이 되어야 한다. 출력 영상에서 이웃하는 화소들이 비슷한 값을 갖기 때문에 부드러운 영상이 되며, 흐려지는 결과가 발생한다. . 3. 샤프닝(sharpening) 은 회선 마스크에서 중심 계수와 주변 계수의 차이를 크게 만들어 출력 화소가 도드라지게 함으로써 선명하고 날카로운 영상을 만드는 방법이다. 중심계수는 아주 큰 양수값을 갖게 하며, 주변 계수는 음수값을 갖게 해서 전체 합이 1이되게 한다. . 4. 영상처리에서 에지는 &quot;화소값이 급격하게 변화하는 부분&quot; 으로 정의한다. 이것은 객체에서 크기, 위치, 모양을 인지할 수 있으며, 그 뱡향성을 탐지할 수 있다. . 5. 에지는 이웃하는 두 화소의 차분으로 구할 수 있으며, 이것은 미분 공식과 유사하다. 따라서 미분 마스크로 회선을 수행하면 에지를 검출할 수 있다. 이것은 1차 미분 마스크라고 하며, 대표적으로 로버츠(Roberts), 소벨(Sobel), 프리윗(Prewitt) 등이 있다. . 6. 1차 미분 연산자는 점진적으로 변화하는 부분까지 민감하게 에지를 검출하여 너무 많은 에지가 나타날 수 있다. 이를 보완하는 방법으로 1차 미분한 결과에 미분을 한 번 더 하는 방법인 2차 미분 연산이 잇다. 대표적으로 라플라시안, LoG(Laplacian of Gaussian), DoG(Difference of Gaussian)등의 방법이 있다. . 12. 가우시안 블러링은 정규분포 곡선을 갖는 마스크를 가우시안 수식에 따라서 생성하고 이 마스크로 회선을 수행하는 방법이다. 표준편차로 정규분포 마스크를 생성할 수 있다. 표준편차가 클수록 많이 흐려진 영상을 생성한다. . 13. 모폴로지는 행태학적 방법을 여상처리에 적용한 것으로서 침식과 팽창 연산이 있다. . 침식 연산은 객체의 크기가 축소되기 때문에 영상 내에 존재하는 작은 크기의 잡음을 제거하는데에 효과적이다. | 팽창연산은 객체의 크기가 확대되어 객체 내부의 빈 공간을 메우는 역할을 한다. | . 14. 열림 연산은 침식 연산 수행 후에 팽창 연산을 수행한다. 침식 연산으로 객체는 축소되고, 배경의 잡음들은 제거되며, 팽창 연산으로 축소되었던 객체들이 원래 크기로 돌아간다. . 15. 닫힘 연산은 팽창 연산 수행 후에 침식 연산을 수행한다. 팽창 연산으로 객체가 확장되어 객체 내부의 빈 공간이 매워진다. 다음으로 침식 연산으로 확장되었던 객체의 크기가 원래대로 축소된다. . ref : https://pinkocto.github.io/BP2022/python/2022/10/15/opencv.html .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/11/24/opencv-chap7.html",
            "relUrl": "/python/2022/11/24/opencv-chap7.html",
            "date": " • Nov 24, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "🤣 Preparing for data analysis test",
            "content": "&#45936;&#51060;&#53552;&#47484; &#44288;&#52272;&#54616;&#44256; &#44032;&#44277;&#54616;&#44592;: &#51204;&#52376;&#47532;(preprocessing) . 현업에서 사용하는 전처리 작업에는 수십 가지가 있지만 주로 사용하는 몇가지 전처리 작업을 소개하겠습니다. . 필요하지 않은 열 삭제 | 누락된 값들을 다른 값들로 바꾸거나 삭제 | 잘못된 값을 바르게수정 | 일반적인 범위에서 벗어나는 이상값 조정 | 각 열들의 숫자 값을 동일한 범위의 숫자로 변경 | 의도한 데이터 타입이 아니라면 적절한 데이터 타입으로 변경 | 문자로 구성된 범주형 데이터를 숫자형으로 변경 | 분석에 필요한 새로운 열 생성 | Data Load . import pandas as pd data = pd.read_csv(&#39;https://raw.githubusercontent.com/7ieon/bigData/main/mtcars.csv&#39;) . data.head() . Unnamed: 0 mpg cyl disp hp drat wt qsec vs am gear carb . 0 Mazda RX4 | 21.0 | 6.0 | 160.0 | 110 | 3.90 | 2.620 | 16.46 | 0 | manual | 4 | 4 | . 1 Mazda RX4 Wag | 21.0 | 6.0 | 160.0 | 110 | 3.90 | 2.875 | 17.02 | 0 | manual | 4 | 4 | . 2 Datsun 710 | 22.8 | 4.0 | 108.0 | 93 | 3.85 | 2.320 | 18.61 | 1 | manual | 4 | 1 | . 3 Hornet 4 Drive | 21.4 | 6.0 | 258.0 | 110 | 3.08 | 3.215 | 0.10 | 1 | auto | 3 | 1 | . 4 Hornet Sportabout | 18.7 | 8.0 | 360.0 | 175 | 3.15 | 3.440 | 17.02 | 0 | auto | 3 | 2 | . data.shape . (32, 12) . type(data) . pandas.core.frame.DataFrame . data.columns . Index([&#39;Unnamed: 0&#39;, &#39;mpg&#39;, &#39;cyl&#39;, &#39;disp&#39;, &#39;hp&#39;, &#39;drat&#39;, &#39;wt&#39;, &#39;qsec&#39;, &#39;vs&#39;, &#39;am&#39;, &#39;gear&#39;, &#39;carb&#39;], dtype=&#39;object&#39;) . data.describe() . mpg cyl disp hp drat wt qsec vs carb . count 32.000000 | 30.000000 | 32.000000 | 32.000000 | 32.000000 | 32.000000 | 31.000000 | 32.000000 | 32.0000 | . mean 20.090625 | 7.600000 | 230.721875 | 146.687500 | 3.596563 | 3.217250 | 19.866774 | 0.437500 | 2.8125 | . std 6.026948 | 8.194195 | 123.938694 | 68.562868 | 0.534679 | 0.978457 | 15.310469 | 0.504016 | 1.6152 | . min 10.400000 | 4.000000 | 71.100000 | 52.000000 | 2.760000 | 1.513000 | 0.100000 | 0.000000 | 1.0000 | . 25% 15.425000 | 4.000000 | 120.825000 | 96.500000 | 3.080000 | 2.581250 | 16.785000 | 0.000000 | 2.0000 | . 50% 19.200000 | 6.000000 | 196.300000 | 123.000000 | 3.695000 | 3.325000 | 17.600000 | 0.000000 | 2.0000 | . 75% 22.800000 | 8.000000 | 326.000000 | 180.000000 | 3.920000 | 3.610000 | 18.755000 | 1.000000 | 4.0000 | . max 33.900000 | 50.000000 | 472.000000 | 335.000000 | 4.930000 | 5.424000 | 100.000000 | 1.000000 | 8.0000 | . data[&#39;hp&#39;].describe() . count 32.000000 mean 146.687500 std 68.562868 min 52.000000 25% 96.500000 50% 123.000000 75% 180.000000 max 335.000000 Name: hp, dtype: float64 . print(data[&#39;am&#39;].unique()) # am칼럼에서 중복 제거 print(data[&#39;gear&#39;].unique()) print(data[&#39;vs&#39;].unique()) . [&#39;manual&#39; &#39;auto&#39;] [&#39;4&#39; &#39;3&#39; &#39;*3&#39; &#39;5&#39; &#39;*5&#39;] [0 1] . print(data.info()) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 Unnamed: 0 32 non-null object 1 mpg 32 non-null float64 2 cyl 30 non-null float64 3 disp 32 non-null float64 4 hp 32 non-null int64 5 drat 32 non-null float64 6 wt 32 non-null float64 7 qsec 31 non-null float64 8 vs 32 non-null int64 9 am 32 non-null object 10 gear 32 non-null object 11 carb 32 non-null int64 dtypes: float64(6), int64(3), object(3) memory usage: 3.1+ KB None . print(data.corr()) . mpg cyl disp hp drat wt qsec mpg 1.000000 -0.460227 -0.847551 -0.776168 0.681172 -0.867659 0.013668 cyl -0.460227 1.000000 0.544876 0.323293 -0.372671 0.533690 -0.012755 disp -0.847551 0.544876 1.000000 0.790949 -0.710214 0.887980 0.181810 hp -0.776168 0.323293 0.790949 1.000000 -0.448759 0.658748 0.010807 drat 0.681172 -0.372671 -0.710214 -0.448759 1.000000 -0.712441 -0.120283 wt -0.867659 0.533690 0.887980 0.658748 -0.712441 1.000000 0.093900 qsec 0.013668 -0.012755 0.181810 0.010807 -0.120283 0.093900 1.000000 vs 0.664039 -0.323960 -0.710416 -0.723097 0.440278 -0.554916 -0.112146 carb -0.550925 0.239980 0.394977 0.749812 -0.090790 0.427606 -0.120312 vs carb mpg 0.664039 -0.550925 cyl -0.323960 0.239980 disp -0.710416 0.394977 hp -0.723097 0.749812 drat 0.440278 -0.090790 wt -0.554916 0.427606 qsec -0.112146 -0.120312 vs 1.000000 -0.569607 carb -0.569607 1.000000 . 우리 목표는 mpg(연비) 값을 예측하는 것 . X = data.drop(columns = &#39;mpg&#39;) # dependent variables Y = data[&#39;mpg&#39;] # dependent variable . X.head() . Unnamed: 0 cyl disp hp drat wt qsec vs am gear carb . 0 Mazda RX4 | 6.0 | 160.0 | 110 | 3.90 | 2.620 | 16.46 | 0 | manual | 4 | 4 | . 1 Mazda RX4 Wag | 6.0 | 160.0 | 110 | 3.90 | 2.875 | 17.02 | 0 | manual | 4 | 4 | . 2 Datsun 710 | 4.0 | 108.0 | 93 | 3.85 | 2.320 | 18.61 | 1 | manual | 4 | 1 | . 3 Hornet 4 Drive | 6.0 | 258.0 | 110 | 3.08 | 3.215 | 0.10 | 1 | auto | 3 | 1 | . 4 Hornet Sportabout | 8.0 | 360.0 | 175 | 3.15 | 3.440 | 17.02 | 0 | auto | 3 | 2 | . Y.head() . 0 21.0 1 21.0 2 22.8 3 21.4 4 18.7 Name: mpg, dtype: float64 . 잘 나눠진 것 같다. | . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . 1 &#48520;&#54596;&#50836;&#54620; &#50676; &#49325;&#51228; . X = X.iloc[:,1:] X.head() . cyl disp hp drat wt qsec vs am gear carb . 0 6.0 | 160.0 | 110 | 3.90 | 2.620 | 16.46 | 0 | manual | 4 | 4 | . 1 6.0 | 160.0 | 110 | 3.90 | 2.875 | 17.02 | 0 | manual | 4 | 4 | . 2 4.0 | 108.0 | 93 | 3.85 | 2.320 | 18.61 | 1 | manual | 4 | 1 | . 3 6.0 | 258.0 | 110 | 3.08 | 3.215 | 0.10 | 1 | auto | 3 | 1 | . 4 8.0 | 360.0 | 175 | 3.15 | 3.440 | 17.02 | 0 | auto | 3 | 2 | . 2 &#44208;&#52769;&#44050; &#52376;&#47532; . 결측치를 처리하는 데는 해당 데이터를 삭제하거나 다른 값으로 바꾸는 방법이 있습니다. 여기서 다른 값으로 바꾸는 데는 전체 데이터의 평균값, 중위값으로 바꾸거나, 해당 데이터와 유사한 값이나 패턴을 참고하여 바꾸는 등, 여러가지 방법이 존재합니다. . 하지만 결측치를 삭제하는 방법은 빅분기 실기 시험에서는 선택해서는 안 됩니다. . 그 이유는 주어진 분석 데이터의 개수 그대로 예측 결과를 출력하거나 파일로 제출해야하기 때문입니다. . X.isnull().head(3) . cyl disp hp drat wt qsec vs am gear carb . 0 False | False | False | False | False | False | False | False | False | False | . 1 False | False | False | False | False | False | False | False | False | False | . 2 False | False | False | False | False | False | False | False | False | False | . print(X.isnull().sum()) . cyl 2 disp 0 hp 0 drat 0 wt 0 qsec 1 vs 0 am 0 gear 0 carb 0 dtype: int64 . cyl과 qsec열에 결측치가 각각 2개, 1개 있음을 확인 . - &#54217;&#44512;&#44050;&#51004;&#47196; &#45824;&#52824;&#54616;&#44592; (cyl) . X_cyl_mean = X[&#39;cyl&#39;].mean() # X_cyl_mean 변수 확인 print(X_cyl_mean) . 7.6 . X[&#39;cyl&#39;] = X[&#39;cyl&#39;].fillna(X_cyl_mean) . X.isnull().sum() . cyl 0 disp 0 hp 0 drat 0 wt 0 qsec 1 vs 0 am 0 gear 0 carb 0 dtype: int64 . cyl의 결측값이 잘 처리된 것을 확인할 수 있다. | . - &#51473;&#50948;&#44050;&#51004;&#47196; &#45824;&#52824;&#54616;&#44592; (qsec) . X_qsec_median = X[&#39;qsec&#39;].median() # X1_qsec_median X_qsec_median . 17.6 . X[&#39;qsec&#39;] = X[&#39;qsec&#39;].fillna(X_qsec_median) . X.isnull().sum() . cyl 0 disp 0 hp 0 drat 0 wt 0 qsec 0 vs 0 am 0 gear 0 carb 0 dtype: int64 . 결측치가 모두 처리되었다. cyl은 평균으로 결측값을 대치하였고, qsec는 중앙값으로 결측치를 대치하였다. | . 3 &#51096;&#47803;&#46108; &#44050;&#51012; &#50732;&#48148;&#47476;&#44172; &#48320;&#44221; . gear열에 의도치 않은 특수문자가 포함되어 있고, 데이터 타입 또한 object로 인식됨을 알 수 있다. . X[&#39;gear&#39;].unique() . array([&#39;4&#39;, &#39;3&#39;, &#39;*3&#39;, &#39;5&#39;, &#39;*5&#39;], dtype=object) . X[&#39;gear&#39;].value_counts() . 3 14 4 12 5 4 *3 1 *5 1 Name: gear, dtype: int64 . *3, *5 잘못들어간 애들..! | $*3 to 3, *5 to 5$ 로 수정하자. (2개만 처리하면 될 듯하다..) | . X[&#39;gear&#39;] = X[&#39;gear&#39;].replace(&#39;*3&#39;,&#39;3&#39;).replace(&#39;*5&#39;,&#39;5&#39;) X[&#39;gear&#39;].value_counts() . 3 15 4 12 5 5 Name: gear, dtype: int64 . 잘 변환되었다..ㅎㅎ | . 4 &#51060;&#49345;&#44050; &#52376;&#47532; . 이상값은 정상적인 데이터의 범위를 넘어서는 비정상인 값으로, data scaling보다 선행되어야 한다. data scaling 이후에 이상값을 처리한다면, 데이터의 분포가 왜곡되거나 데이터 스케일링의 수행이 다시 필요할수도 있다. . 빅분기 시험에서는 이상값의 처리방식을 데이터 삭제가 아닌 다른 값으로 교체할 것을 추천한다. . 만약, 이상값을 제거하라고 명시되어있다면, 문제의 요구대로 처리하면 된다. . - &#49324;&#48516;&#50948;&#49688; &#54876;&#50857; . 왼쪽에 위치한 이상값 (작은) : $Q1 - 1.5 * IQR$ 오른쪽에 위치한 이상값 (큰) : $Q3 + 1.5 * IQR$ . X_describe = X.describe() print(X_describe) . cyl disp hp drat wt qsec count 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 mean 7.600000 230.721875 146.687500 3.596563 3.217250 19.795938 std 7.925459 123.938694 68.562868 0.534679 0.978457 15.066831 min 4.000000 71.100000 52.000000 2.760000 1.513000 0.100000 25% 4.000000 120.825000 96.500000 3.080000 2.581250 16.827500 50% 6.000000 196.300000 123.000000 3.695000 3.325000 17.600000 75% 8.000000 326.000000 180.000000 3.920000 3.610000 18.682500 max 50.000000 472.000000 335.000000 4.930000 5.424000 100.000000 vs carb count 32.000000 32.0000 mean 0.437500 2.8125 std 0.504016 1.6152 min 0.000000 1.0000 25% 0.000000 2.0000 50% 0.000000 2.0000 75% 1.000000 4.0000 max 1.000000 8.0000 . print(X_describe.loc[&#39;75%&#39;],X_describe.loc[&#39;25%&#39;]) . cyl 8.0000 disp 326.0000 hp 180.0000 drat 3.9200 wt 3.6100 qsec 18.6825 vs 1.0000 carb 4.0000 Name: 75%, dtype: float64 cyl 4.00000 disp 120.82500 hp 96.50000 drat 3.08000 wt 2.58125 qsec 16.82750 vs 0.00000 carb 2.00000 Name: 25%, dtype: float64 . x_iqr = X_describe.loc[&#39;75%&#39;] - X_describe.loc[&#39;25%&#39;] print(x_iqr) . cyl 4.00000 disp 205.17500 hp 83.50000 drat 0.84000 wt 1.02875 qsec 1.85500 vs 1.00000 carb 2.00000 dtype: float64 . print(&#39;[ q3 + 1.5 * iqr ]&#39;) print(X_describe.loc[&#39;75%&#39;] + (1.5 * x_iqr)) print() print(&#39;[ q1 - 1.5 * iqr ]&#39;) print(X_describe.loc[&#39;25%&#39;] - (1.5 * x_iqr)) . [ q3 + 1.5 * iqr ] cyl 14.000000 disp 633.762500 hp 305.250000 drat 5.180000 wt 5.153125 qsec 21.465000 vs 2.500000 carb 7.000000 dtype: float64 [ q1 - 1.5 * iqr ] cyl -2.000000 disp -186.937500 hp -28.750000 drat 1.820000 wt 1.038125 qsec 14.045000 vs -1.500000 carb -1.000000 dtype: float64 . print(X_describe.loc[&#39;max&#39;]) print() print(X_describe.loc[&#39;min&#39;]) . cyl 50.000 disp 472.000 hp 335.000 drat 4.930 wt 5.424 qsec 100.000 vs 1.000 carb 8.000 Name: max, dtype: float64 cyl 4.000 disp 71.100 hp 52.000 drat 2.760 wt 1.513 qsec 0.100 vs 0.000 carb 1.000 Name: min, dtype: float64 . X_describe.loc[&#39;max&#39;] &gt; X_describe.loc[&#39;75%&#39;] + (1.5 * x_iqr) . cyl True disp False hp True drat False wt True qsec True vs False carb True dtype: bool . X_describe.loc[&#39;min&#39;] &lt; X_describe.loc[&#39;25%&#39;] - (1.5 * x_iqr) . cyl False disp False hp False drat False wt False qsec True vs False carb False dtype: bool . cyl, hp, wt, qsec, carb 변수에 대해서 이상치를 처리해주면 되겠다.. | . X.loc[X[&#39;cyl&#39;] &gt; 14] . cyl disp hp drat wt qsec vs am gear carb . 14 50.0 | 472.0 | 205 | 2.93 | 5.25 | 17.98 | 0 | auto | 3 | 4 | . X.loc[X[&#39;hp&#39;] &gt; 305.25] . cyl disp hp drat wt qsec vs am gear carb . 30 8.0 | 301.0 | 335 | 3.54 | 3.57 | 14.6 | 0 | manual | 5 | 8 | . X.loc[14, &#39;cyl&#39;] = 14 X.loc[30, &#39;hp&#39;] = 305.25 . print(X.loc[14, &#39;cyl&#39;],X.loc[30, &#39;hp&#39;]) . 14.0 305.25 . - &#54217;&#44512;&#44284; &#54364;&#51456;&#54200;&#52264; &#54876;&#50857; . $ text{최대 경계값} = text{평균} + 1.5 * text{표준편차}$ $ text{최소 경계값} = text{평균} - 1.5 * text{표준편차}$ . def outlier(data, column): mean = data[column].mean() std = data[column].std() lowest = mean - (std * 1.5) highest = mean + (std * 1.5) print(&#39;최소 경계값: &#39;, lowest, &#39;최대경계값:&#39;, highest) outlier_index = data[column][(data[column]&lt;lowest) | (data[column] &gt; highest) ].index return outlier_index . print(outlier(X,&#39;qsec&#39;)) print() print(X.loc[24,&#39;qsec&#39;]) . 최소 경계값: -2.8043094560577657 최대경계값: 42.39618445605777 Int64Index([24], dtype=&#39;int64&#39;) 100.0 . X.loc[24, &#39;qsec&#39;] = 42.245 X.loc[24, &#39;qsec&#39;] . 42.245 . print(outlier(X,&#39;carb&#39;)) print() print(X.loc[[29,30],&#39;carb&#39;]) . 최소 경계값: 0.3897000335522218 최대경계값: 5.235299966447778 Int64Index([29, 30], dtype=&#39;int64&#39;) 29 6 30 8 Name: carb, dtype: int64 . X.loc[29, &#39;carb&#39;] = 5.235 X.loc[30, &#39;carb&#39;] = 5.235 X.loc[[29,30], &#39;carb&#39;] . 29 5.235 30 5.235 Name: carb, dtype: float64 . 5&#45936;&#51060;&#53552;&#47484; &#46041;&#51068;&#54620; &#48276;&#50948;&#47196; &#47582;&#52628;&#44592; : &#45936;&#51060;&#53552; &#49828;&#52992;&#51068;&#47553; . Standard Scaling | Min-Max Scaling | Robust Scaling | . from sklearn.preprocessing import StandardScaler temp = X[[&#39;qsec&#39;]] scaler = StandardScaler() scaler.fit_transform(temp)[:4] . array([[-0.27330047], [-0.17334038], [ 0.11047486], [-3.19356296]]) . qsec_s_scaler = pd.DataFrame(scaler.fit_transform(temp)) print(qsec_s_scaler.describe()) . 0 count 3.200000e+01 mean -2.207436e-16 std 1.016001e+00 min -3.193563e+00 25% -2.077017e-01 50% -6.981029e-02 75% 1.234161e-01 max 4.329326e+00 . from sklearn.preprocessing import MinMaxScaler temp = X[[&#39;qsec&#39;]] scaler = MinMaxScaler() qsec_m_scaler = pd.DataFrame(scaler.fit_transform(temp)) print(qsec_m_scaler.describe()) . 0 count 32.000000 mean 0.424513 std 0.135055 min 0.000000 25% 0.396904 50% 0.415233 75% 0.440918 max 1.000000 . from sklearn.preprocessing import RobustScaler temp = X[[&#39;qsec&#39;]] scaler = RobustScaler() qsec_r_scaler = pd.DataFrame(scaler.fit_transform(temp)) print(qsec_r_scaler.describe()) . 0 count 32.000000 mean 0.210832 std 3.068398 min -9.433962 25% -0.416442 50% 0.000000 75% 0.583558 max 13.285714 . 6 &#45936;&#51060;&#53552; &#53440;&#51077; &#48320;&#44221; . X 데이터의 요약정보를 통해서 각 열별로 범주형 변수의 데이터 타입(object, string)과 연속형 변수의 데이터 타입(int64, float64)으로 적합하게 설정되어 있는지 확인합니다. 만약 범주형 변수가 연속형 타입으로 되어있거나, 그 반대의 경우가 있다면 astype() 함수를 통해서 데이터 타입을 재설정 합니다. . print(X.info()) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 cyl 32 non-null float64 1 disp 32 non-null float64 2 hp 32 non-null float64 3 drat 32 non-null float64 4 wt 32 non-null float64 5 qsec 32 non-null float64 6 vs 32 non-null int64 7 am 32 non-null object 8 gear 32 non-null object 9 carb 32 non-null float64 dtypes: float64(7), int64(1), object(2) memory usage: 2.6+ KB None . X[&#39;gear&#39;].value_counts() . 3 15 4 12 5 5 Name: gear, dtype: int64 . 확인 결과 전진기어 개수를 의미하는 gear 열이 object 타입으로 설정되어 있음을 확인할 수 있다. 따라서 수치형 (int64)으로 변경 | . 7 &#47928;&#51088;&#47196; &#44396;&#49457;&#46108; &#48276;&#51452;&#54805; &#45936;&#51060;&#53552;&#47484; &#49707;&#51088;&#54805;&#51004;&#47196; &#48320;&#44221; . X[&#39;gear&#39;] = X[&#39;gear&#39;].astype(&#39;int64&#39;) X[&#39;gear&#39;].dtype . dtype(&#39;int64&#39;) . &#48276;&#51452;&#54805;&#51012; &#49688;&#52824;&#54805;&#51004;&#47196; &#48320;&#44221; : &#51064;&#53076;&#46377;(Encoding) . 데이터 분석은 컴퓨터에 의해 수행되기 때문에, 주어진 데이터는 컴퓨터가 이해할 수 있는 값이어야 합니다. 따라서 한글이나 영문 등의 문자열 데이터는 컴퓨터가 이해하기 어려우므로 숫자형으로 변경해야 합니다. 이러한 과정을 인코딩 이라고 합니다. . One-Hot Encoding | Label Encoding | 수동 인코딩 (Replace) | . - &#50896;-&#54635; &#51064;&#53076;&#46377; . print(X.head()) print() # am열에서 중복 제거한 값 확인 print(X[&#39;am&#39;].unique()) . cyl disp hp drat wt qsec vs am gear carb 0 6.0 160.0 110.0 3.90 2.620 16.46 0 manual 4 4.0 1 6.0 160.0 110.0 3.90 2.875 17.02 0 manual 4 4.0 2 4.0 108.0 93.0 3.85 2.320 18.61 1 manual 4 1.0 3 6.0 258.0 110.0 3.08 3.215 0.10 1 auto 3 1.0 4 8.0 360.0 175.0 3.15 3.440 17.02 0 auto 3 2.0 [&#39;manual&#39; &#39;auto&#39;] . pd.get_dummies(X[&#39;am&#39;]).head() . auto manual . 0 0 | 1 | . 1 0 | 1 | . 2 0 | 1 | . 3 1 | 0 | . 4 1 | 0 | . - 하나의 열만으로 auto, manual 값 표현하려면? $ to$ drop_first=True 옵션추가 . pd.get_dummies(X[&#39;am&#39;], drop_first=True).head() . manual . 0 1 | . 1 1 | . 2 1 | . 3 0 | . 4 0 | . pd.get_dummies(X, drop_first=True).head() . cyl disp hp drat wt qsec vs gear carb am_manual . 0 6.0 | 160.0 | 110.0 | 3.90 | 2.620 | 16.46 | 0 | 4 | 4.0 | 1 | . 1 6.0 | 160.0 | 110.0 | 3.90 | 2.875 | 17.02 | 0 | 4 | 4.0 | 1 | . 2 4.0 | 108.0 | 93.0 | 3.85 | 2.320 | 18.61 | 1 | 4 | 1.0 | 1 | . 3 6.0 | 258.0 | 110.0 | 3.08 | 3.215 | 0.10 | 1 | 3 | 1.0 | 0 | . 4 8.0 | 360.0 | 175.0 | 3.15 | 3.440 | 17.02 | 0 | 3 | 2.0 | 0 | . - &#46972;&#48296;&#51064;&#53076;&#46377; . print(X[&#39;am&#39;].head()) . 0 manual 1 manual 2 manual 3 auto 4 auto Name: am, dtype: object . from sklearn.preprocessing import LabelEncoder encoder = LabelEncoder() print(encoder.fit_transform(X[&#39;am&#39;])) . [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1] . fruit = [&#39;apple&#39;,&#39;bananas&#39;,&#39;grape&#39;] encoder = LabelEncoder() fruit_new = encoder.fit_transform(fruit) print(fruit) print(fruit_new) . [&#39;apple&#39;, &#39;bananas&#39;, &#39;grape&#39;] [0 1 2] . - &#49688;&#46041; &#51064;&#53076;&#46377; (Replace) . 데이터 값의 종류가 많지 않은 경우는 replace() 함수를 사용해서 인코딩을 수행할 수 있습니다. 예를 들어 합격/불합격 값, 신청/미신청 값, 방문/미방문 등의 이진 데이터라면 수동으로 인코딩 하기 쉽습니다. . X[&#39;am_new&#39;]=X[&#39;am&#39;].replace(&#39;manual&#39;,0).replace(&#39;auto&#39;,1) print(X.head()) . cyl disp hp drat wt qsec vs am gear carb am_new 0 6.0 160.0 110.0 3.90 2.620 16.46 0 manual 4 4.0 0 1 6.0 160.0 110.0 3.90 2.875 17.02 0 manual 4 4.0 0 2 4.0 108.0 93.0 3.85 2.320 18.61 1 manual 4 1.0 0 3 6.0 258.0 110.0 3.08 3.215 0.10 1 auto 3 1.0 1 4 8.0 360.0 175.0 3.15 3.440 17.02 0 auto 3 2.0 1 . X = X.drop(columns=[&#39;am&#39;]) print(X.head()) . cyl disp hp drat wt qsec vs gear carb am_new 0 6.0 160.0 110.0 3.90 2.620 16.46 0 4 4.0 0 1 6.0 160.0 110.0 3.90 2.875 17.02 0 4 4.0 0 2 4.0 108.0 93.0 3.85 2.320 18.61 1 4 1.0 0 3 6.0 258.0 110.0 3.08 3.215 0.10 1 3 1.0 1 4 8.0 360.0 175.0 3.15 3.440 17.02 0 3 2.0 1 . 8 &#54028;&#49373;&#48320;&#49688; &#47564;&#46308;&#44592; . 특정한 조건이나 함수에 의해서 새롭게 의미를 부여해서 만드는 변수입니다. . 첫 번째로 만들 파생변수는 무게를 의미하는 wt 열에 따라서 등급을 구분하는 wt_class(무게에 따른 구분)입니다. wt열의 평균값을 기준으로 무게의 등급을 나눌 것입니다. . import numpy as np np.round(X[&#39;wt&#39;].mean(),2) . 3.22 . condition = X[&#39;wt&#39;] &lt; np.round(X[&#39;wt&#39;].mean(),2) # 조건을 만족하면 0 X.loc[condition, &#39;wt_class&#39;] = 0 # 조건을 만족하지 않으면 1 X.loc[~condition, &#39;wt_class&#39;] = 1 . X[[&#39;wt&#39;, &#39;wt_class&#39;]].head() . wt wt_class . 0 2.620 | 0.0 | . 1 2.875 | 0.0 | . 2 2.320 | 0.0 | . 3 3.215 | 0.0 | . 4 3.440 | 1.0 | . X = X.drop(columns = [&#39;wt&#39;]) X.head() . cyl disp hp drat qsec vs gear carb am_new wt_class . 0 6.0 | 160.0 | 110.0 | 3.90 | 16.46 | 0 | 4 | 4.0 | 0 | 0.0 | . 1 6.0 | 160.0 | 110.0 | 3.90 | 17.02 | 0 | 4 | 4.0 | 0 | 0.0 | . 2 4.0 | 108.0 | 93.0 | 3.85 | 18.61 | 1 | 4 | 1.0 | 0 | 0.0 | . 3 6.0 | 258.0 | 110.0 | 3.08 | 0.10 | 1 | 3 | 1.0 | 1 | 0.0 | . 4 8.0 | 360.0 | 175.0 | 3.15 | 17.02 | 0 | 3 | 2.0 | 1 | 1.0 | . 두 번째로 만들 파생변수는 qsec 열(1/4mile 도달 시간) 값을 기반으로 만들 qsec_4(1mile도달 시간을 의미)입니다. 이는 qsec 열 단위를 1/4mile 단위에서 1mile 단위로 변환하기 위해서 생성하는 변수입니다. 즉, 현재 qsec 열 값을 4배 하여 1mile 당 도달 시간을 의미하는 qsec_4 변수를 생성합니다. . X[&#39;qsec_4&#39;] = X[&#39;qsec&#39;] * 4 X[[&#39;qsec&#39;,&#39;qsec_4&#39;]].head() . qsec qsec_4 . 0 16.46 | 65.84 | . 1 17.02 | 68.08 | . 2 18.61 | 74.44 | . 3 0.10 | 0.40 | . 4 17.02 | 68.08 | . X = X.drop(columns=[&#39;qsec&#39;]) X.head() . cyl disp hp drat vs gear carb am_new wt_class qsec_4 . 0 6.0 | 160.0 | 110.0 | 3.90 | 0 | 4 | 4.0 | 0 | 0.0 | 65.84 | . 1 6.0 | 160.0 | 110.0 | 3.90 | 0 | 4 | 4.0 | 0 | 0.0 | 68.08 | . 2 4.0 | 108.0 | 93.0 | 3.85 | 1 | 4 | 1.0 | 0 | 0.0 | 74.44 | . 3 6.0 | 258.0 | 110.0 | 3.08 | 1 | 3 | 1.0 | 1 | 0.0 | 0.40 | . 4 8.0 | 360.0 | 175.0 | 3.15 | 0 | 3 | 2.0 | 1 | 1.0 | 68.08 | . &#47784;&#45944; &#49373;&#49457; &#48143; &#44160;&#51613; . &#54617;&#49845; &#45936;&#51060;&#53552;&#50752; &#53580;&#49828;&#53944; &#45936;&#51060;&#53552; &#48516;&#47532; . from sklearn.model_selection import train_test_split . X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=10) . print(X_train.shape, X_test.shape) print(y_train.shape, y_test.shape) . (22, 10) (10, 10) (22,) (10,) . X_train.head() . cyl disp hp drat vs gear carb am_new wt_class qsec_4 . 19 4.0 | 71.1 | 65.0 | 4.22 | 1 | 4 | 1.0 | 0 | 0.0 | 79.60 | . 14 14.0 | 472.0 | 205.0 | 2.93 | 0 | 3 | 4.0 | 1 | 1.0 | 71.92 | . 18 4.0 | 75.7 | 52.0 | 4.93 | 1 | 4 | 2.0 | 0 | 0.0 | 74.08 | . 6 8.0 | 360.0 | 245.0 | 3.21 | 0 | 3 | 4.0 | 1 | 1.0 | 63.36 | . 11 8.0 | 275.8 | 180.0 | 3.07 | 0 | 3 | 3.0 | 1 | 1.0 | 69.60 | . y_train.head() . 19 33.9 14 10.4 18 30.4 6 14.3 11 16.4 Name: mpg, dtype: float64 . X_test.head() . cyl disp hp drat vs gear carb am_new wt_class qsec_4 . 20 4.0 | 120.1 | 97.0 | 3.70 | 1 | 3 | 1.0 | 1 | 0.0 | 80.04 | . 7 7.6 | 146.7 | 62.0 | 3.69 | 1 | 4 | 2.0 | 1 | 0.0 | 80.00 | . 5 6.0 | 225.0 | 105.0 | 2.76 | 1 | 3 | 1.0 | 1 | 1.0 | 80.88 | . 2 4.0 | 108.0 | 93.0 | 3.85 | 1 | 4 | 1.0 | 0 | 0.0 | 74.44 | . 3 6.0 | 258.0 | 110.0 | 3.08 | 1 | 3 | 1.0 | 1 | 0.0 | 0.40 | . y_test.head() . 20 21.5 7 24.4 5 18.1 2 22.8 3 21.4 Name: mpg, dtype: float64 . &#47784;&#45944;&#47553; . &#49440;&#54805;&#54924;&#44480; (Linear Regression) . from sklearn.linear_model import LinearRegression # 선형회귀 분석을 수행할 기본적인 모델(model) 만들기 model = LinearRegression() # 생성한 모델에 X_train, y_train을 전달해서 선형회귀 방법으로 학습 model.fit(X_train, y_train) # 학습 완료된 모델에 x_train을 전달하여 y_trian 값 예측 y_train_predicted = model.predict(X_train) # 학습 완료된 모델에 X_test을 전달하여 y_test 값 예측 y_test_predicted = model.predict(X_test) . print(model.intercept_) . 24.26181219199409 . print(model.coef_) . [-0.13817819 -0.01231325 -0.00409076 0.96656685 1.12173056 0.65741573 -1.9744834 -3.58098353 0.02124373 0.02402967] . print(model.score(X_train, y_train)) . 0.9063023662021511 . print(model.score(X_test, y_test)) . 0.10162785154970966 . 결과로 학습데이터의 결정계수는 0.9로 매우 높게나타났지만 테스트 셋의 결정계수가 0.1로 매우 낮게 나왔다. (과대적합) . from sklearn.metrics import r2_score # MAE를 계산하는 mean_absolute_error 함수 from sklearn.metrics import mean_absolute_error # MSE를 계산하는 mean_squared_error 함수 from sklearn.metrics import mean_squared_error # 제곱근 계산을 위하여 numpy 라이브러리 import numpy as np . print(&#39;r2_score_train: &#39;,r2_score(y_train, y_train_predicted)) print(&#39;r2_score_test: &#39;,r2_score(y_test, y_test_predicted)) print(&#39;MSE_test: &#39;,mean_squared_error(y_test, y_test_predicted)) print(&#39;RMSE_test: &#39;,np.sqrt(mean_squared_error(y_test, y_test_predicted))) print(&#39;MAE_test: &#39;, mean_absolute_error(y_test, y_test_predicted)) . r2_score_train: 0.9063023662021511 r2_score_test: 0.10162785154970966 MSE_test: 8.924428922705184 RMSE_test: 2.987378269102389 MAE_test: 2.3752487909100055 .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/11/14/bigdata-test-study.html",
            "relUrl": "/python/2022/11/14/bigdata-test-study.html",
            "date": " • Nov 14, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "(OpenCV - Chap6) 화소처리2",
            "content": "",
            "url": "https://pinkocto.github.io/BP2022/python/2022/11/10/opencv.html",
            "relUrl": "/python/2022/11/10/opencv.html",
            "date": " • Nov 10, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "Crack",
            "content": "import matplotlib.pyplot as plt import seaborn as sns import keras from keras.models import Sequential from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout from keras.preprocessing.image import ImageDataGenerator from keras.optimizers import Adam, RMSprop, Adagrad from keras.layers import BatchNormalization from sklearn.metrics import classification_report,confusion_matrix import tensorflow as tf import cv2 import os import time import numpy as np import warnings warnings.filterwarnings(&#39;ignore&#39;) . print(keras.__version__) print(cv2.__version__) print(sns.__version__) print(np.__version__) . 2.10.0 4.6.0 0.12.0 1.23.4 . os.getcwd() # 현재 작업 폴더 . &#39;C: Users hanka Desktop dino BP2022 _notebooks&#39; . labels = [&#39;Negative_500&#39;, &#39;Positive_500&#39;] img_size = 120 # 어디 폴더의 Nagative, Postive를 불러오겠다. def read_images(data_dir): data = [] for label in labels: path = os.path.join(data_dir, label) class_num = labels.index(label) for img in os.listdir(path): try: img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # 이미지 변경 resized_arr = cv2.resize(img_arr, (img_size, img_size)) data.append([resized_arr, class_num]) except Exception as e: print(e) return np.array(data) Dataset = read_images(&#39;./data/Surface_Crack_Detection_small&#39;) . print( Dataset.shape ) print( Dataset[0][0], Dataset[0][1]) # 피처와 Target . (1000, 2) [[172 161 149 ... 183 182 184] [174 166 147 ... 176 175 177] [176 171 170 ... 180 176 176] ... [163 166 170 ... 175 175 173] [158 155 164 ... 172 173 171] [161 153 154 ... 170 172 170]] 0 . data_dir = &#39;./data/Surface_Crack_Detection_small&#39; path_negative = os.path.join(data_dir, &quot;Negative_500&quot;) path_positive = os.path.join(data_dir, &quot;Positive_500&quot;) # 파일 및 폴더 내용 확인 print( len(os.listdir(path_negative) )) print( len(os.listdir(path_positive) )) num_n = len(os.listdir(path_negative) ) num_p = len(os.listdir(path_positive) ) num = [num_n, num_p] . 500 500 . &#54028;&#51068; &#44060;&#49688; &#54869;&#51064; . Im = [&#39;Negative&#39;, &#39;Positive&#39;] num = [num_n, num_p] plt.figure(figsize=(10, 6)) x = np.arange(2) plt.bar(Im, num) . &lt;BarContainer object of 2 artists&gt; . Dataset[0] . array([array([[172, 161, 149, ..., 183, 182, 184], [174, 166, 147, ..., 176, 175, 177], [176, 171, 170, ..., 180, 176, 176], ..., [163, 166, 170, ..., 175, 175, 173], [158, 155, 164, ..., 172, 173, 171], [161, 153, 154, ..., 170, 172, 170]], dtype=uint8), 0], dtype=object) . print(Dataset.shape) . (1000, 2) . Dataset[0][0] # 픽셀 데이터 . array([[172, 161, 149, ..., 183, 182, 184], [174, 166, 147, ..., 176, 175, 177], [176, 171, 170, ..., 180, 176, 176], ..., [163, 166, 170, ..., 175, 175, 173], [158, 155, 164, ..., 172, 173, 171], [161, 153, 154, ..., 170, 172, 170]], dtype=uint8) . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . x = [] y = [] for feature, label in Dataset: x.append(feature) y.append(label) x = np.array(x).reshape(-1, img_size, img_size, 1) x = x / 255 y = np.array(y) print(x.shape, y.shape) . (1000, 120, 120, 1) (1000,) . plt.subplot(1, 2, 1) plt.imshow(x[300].reshape(img_size, img_size), cmap=&#39;gray&#39;) plt.axis(&#39;off&#39;) . (-0.5, 119.5, 119.5, -0.5) . plt.subplot(1, 2, 2) plt.imshow(x[500].reshape(img_size, img_size), cmap=&#39;gray&#39;) plt.axis(&#39;off&#39;) . (-0.5, 119.5, 119.5, -0.5) . model = Sequential() model.add(Conv2D(64, 3,padding=&quot;same&quot;, activation=&quot;relu&quot;, input_shape = x.shape[1:])) model.add(MaxPool2D()) model.add(Conv2D(64, 3, padding=&quot;same&quot;, activation=&quot;relu&quot;)) model.add(MaxPool2D()) model.add(Conv2D(128, 3, padding=&quot;same&quot;, activation=&quot;relu&quot;)) model.add(MaxPool2D()) model.add(Flatten()) model.add(Dense(256,activation=&quot;relu&quot;)) model.add(Dropout(0.5)) model.add(BatchNormalization()) model.add(Dense(1, activation=&quot;sigmoid&quot;)) model.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 120, 120, 64) 640 max_pooling2d (MaxPooling2D (None, 60, 60, 64) 0 ) conv2d_1 (Conv2D) (None, 60, 60, 64) 36928 max_pooling2d_1 (MaxPooling (None, 30, 30, 64) 0 2D) conv2d_2 (Conv2D) (None, 30, 30, 128) 73856 max_pooling2d_2 (MaxPooling (None, 15, 15, 128) 0 2D) flatten (Flatten) (None, 28800) 0 dense (Dense) (None, 256) 7373056 dropout (Dropout) (None, 256) 0 batch_normalization (BatchN (None, 256) 1024 ormalization) dense_1 (Dense) (None, 1) 257 ================================================================= Total params: 7,485,761 Trainable params: 7,485,249 Non-trainable params: 512 _________________________________________________________________ . start = time.time() opt = Adam(lr=1e-5) model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;]) history = model.fit(x, y, epochs = 15, batch_size = 128, validation_split = 0.25, verbose=1) print(&quot;소요시간&quot;, time.time() - start ) . Epoch 1/15 6/6 [==============================] - 11s 2s/step - loss: 0.6236 - accuracy: 0.6627 - val_loss: 0.7916 - val_accuracy: 0.0000e+00 Epoch 2/15 6/6 [==============================] - 10s 2s/step - loss: 0.5544 - accuracy: 0.7147 - val_loss: 0.8501 - val_accuracy: 0.0000e+00 Epoch 3/15 6/6 [==============================] - 10s 2s/step - loss: 0.5201 - accuracy: 0.7573 - val_loss: 0.8742 - val_accuracy: 0.0000e+00 Epoch 4/15 6/6 [==============================] - 11s 2s/step - loss: 0.4800 - accuracy: 0.7827 - val_loss: 0.8732 - val_accuracy: 0.0000e+00 Epoch 5/15 6/6 [==============================] - 11s 2s/step - loss: 0.4774 - accuracy: 0.7960 - val_loss: 0.8605 - val_accuracy: 0.0000e+00 Epoch 6/15 6/6 [==============================] - 11s 2s/step - loss: 0.4546 - accuracy: 0.8027 - val_loss: 0.8374 - val_accuracy: 0.0000e+00 Epoch 7/15 6/6 [==============================] - 10s 2s/step - loss: 0.4381 - accuracy: 0.8173 - val_loss: 0.8102 - val_accuracy: 0.0000e+00 Epoch 8/15 6/6 [==============================] - 11s 2s/step - loss: 0.4358 - accuracy: 0.8133 - val_loss: 0.7829 - val_accuracy: 0.0000e+00 Epoch 9/15 6/6 [==============================] - 11s 2s/step - loss: 0.4164 - accuracy: 0.8227 - val_loss: 0.7499 - val_accuracy: 0.0080 Epoch 10/15 6/6 [==============================] - 12s 2s/step - loss: 0.3856 - accuracy: 0.8493 - val_loss: 0.7181 - val_accuracy: 0.2400 Epoch 11/15 6/6 [==============================] - 10s 2s/step - loss: 0.3797 - accuracy: 0.8533 - val_loss: 0.6935 - val_accuracy: 0.5760 Epoch 12/15 6/6 [==============================] - 11s 2s/step - loss: 0.3373 - accuracy: 0.8827 - val_loss: 0.6736 - val_accuracy: 0.7200 Epoch 13/15 6/6 [==============================] - 11s 2s/step - loss: 0.3323 - accuracy: 0.8747 - val_loss: 0.6644 - val_accuracy: 0.7480 Epoch 14/15 6/6 [==============================] - 11s 2s/step - loss: 0.3101 - accuracy: 0.8920 - val_loss: 0.6438 - val_accuracy: 0.8880 Epoch 15/15 6/6 [==============================] - 11s 2s/step - loss: 0.3218 - accuracy: 0.8747 - val_loss: 0.6266 - val_accuracy: 0.9560 소요시간 162.9058222770691 . plt.figure(figsize=(12, 12)) plt.style.use(&#39;ggplot&#39;) plt.subplot(2,2,1) plt.plot(history.history[&#39;accuracy&#39;]) plt.plot(history.history[&#39;val_accuracy&#39;]) plt.title(&#39;Accuracy of the Model&#39;) plt.ylabel(&#39;Accuracy&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train accuracy&#39;, &#39;validation accuracy&#39;], loc=&#39;lower right&#39;, prop={&#39;size&#39;: 12}) plt.subplot(2,2,2) plt.plot(history.history[&#39;loss&#39;]) plt.plot(history.history[&#39;val_loss&#39;]) plt.title(&#39;Loss of the Model&#39;) . Text(0.5, 1.0, &#39;Loss of the Model&#39;) . 한 에폭 당 6번밖에 학습을 못하니까 8에폭까지 성능변화가 없다가 그 이후에 올라가는 것을 볼 수 있다. | . &#49884;&#46020; 1. barch size&#47484; &#51460;&#50668;&#49436; &#54620; &#50640;&#54253; &#45817; &#54617;&#49845;&#54943;&#49688;&#47484; &#45720;&#47536;&#45796;. . start = time.time() opt = Adam(lr=1e-5) model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;]) history = model.fit(x, y, epochs = 15, batch_size = 16, validation_split = 0.25, verbose=1) print(&quot;소요시간&quot;, time.time() - start ) . Epoch 1/15 47/47 [==============================] - 13s 256ms/step - loss: 0.2841 - accuracy: 0.8987 - val_loss: 0.5707 - val_accuracy: 0.9680 Epoch 2/15 47/47 [==============================] - 13s 279ms/step - loss: 0.2494 - accuracy: 0.9227 - val_loss: 0.5101 - val_accuracy: 0.9760 Epoch 3/15 47/47 [==============================] - 13s 273ms/step - loss: 0.2229 - accuracy: 0.9387 - val_loss: 0.4406 - val_accuracy: 0.9880 Epoch 4/15 47/47 [==============================] - 12s 264ms/step - loss: 0.1932 - accuracy: 0.9427 - val_loss: 0.3940 - val_accuracy: 0.9680 Epoch 5/15 47/47 [==============================] - 12s 260ms/step - loss: 0.1846 - accuracy: 0.9480 - val_loss: 0.2834 - val_accuracy: 0.9920 Epoch 6/15 47/47 [==============================] - 13s 269ms/step - loss: 0.1569 - accuracy: 0.9573 - val_loss: 0.2352 - val_accuracy: 0.9840 Epoch 7/15 47/47 [==============================] - 12s 261ms/step - loss: 0.1490 - accuracy: 0.9600 - val_loss: 0.1286 - val_accuracy: 0.9960 Epoch 8/15 47/47 [==============================] - 13s 271ms/step - loss: 0.1649 - accuracy: 0.9587 - val_loss: 0.1572 - val_accuracy: 0.9560 Epoch 9/15 47/47 [==============================] - 12s 259ms/step - loss: 0.1393 - accuracy: 0.9680 - val_loss: 0.0991 - val_accuracy: 0.9760 Epoch 10/15 47/47 [==============================] - 12s 259ms/step - loss: 0.1247 - accuracy: 0.9680 - val_loss: 0.0710 - val_accuracy: 0.9720 Epoch 11/15 47/47 [==============================] - 12s 259ms/step - loss: 0.1239 - accuracy: 0.9680 - val_loss: 0.0948 - val_accuracy: 0.9560 Epoch 12/15 47/47 [==============================] - 12s 258ms/step - loss: 0.1100 - accuracy: 0.9773 - val_loss: 0.0291 - val_accuracy: 0.9920 Epoch 13/15 47/47 [==============================] - 12s 258ms/step - loss: 0.1277 - accuracy: 0.9720 - val_loss: 0.0438 - val_accuracy: 0.9800 Epoch 14/15 47/47 [==============================] - 12s 258ms/step - loss: 0.1024 - accuracy: 0.9760 - val_loss: 0.0409 - val_accuracy: 0.9840 Epoch 15/15 47/47 [==============================] - 12s 258ms/step - loss: 0.0855 - accuracy: 0.9853 - val_loss: 0.0356 - val_accuracy: 0.9880 소요시간 185.70813751220703 . plt.figure(figsize=(12, 12)) plt.style.use(&#39;ggplot&#39;) plt.subplot(2,2,1) plt.plot(history.history[&#39;accuracy&#39;]) plt.plot(history.history[&#39;val_accuracy&#39;]) plt.title(&#39;Accuracy of the Model&#39;) plt.ylabel(&#39;Accuracy&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train accuracy&#39;, &#39;validation accuracy&#39;], loc=&#39;lower right&#39;, prop={&#39;size&#39;: 12}) plt.subplot(2,2,2) plt.plot(history.history[&#39;loss&#39;]) plt.plot(history.history[&#39;val_loss&#39;]) plt.title(&#39;Loss of the Model&#39;) . Text(0.5, 1.0, &#39;Loss of the Model&#39;) . &#49884;&#46020; 2. &#50640;&#54253;&#51012; &#45720;&#47536;&#45796;. . start = time.time() opt = Adam(lr=1e-5) model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;]) history = model.fit(x, y, epochs = 30, batch_size = 128, validation_split = 0.25, verbose=1) print(&quot;소요시간&quot;, time.time() - start ) . Epoch 1/30 6/6 [==============================] - 9s 1s/step - loss: 0.0658 - accuracy: 0.9813 - val_loss: 0.0301 - val_accuracy: 0.9920 Epoch 2/30 6/6 [==============================] - 9s 1s/step - loss: 0.0662 - accuracy: 0.9853 - val_loss: 0.0309 - val_accuracy: 0.9920 Epoch 3/30 6/6 [==============================] - 9s 2s/step - loss: 0.0661 - accuracy: 0.9867 - val_loss: 0.0340 - val_accuracy: 0.9880 Epoch 4/30 6/6 [==============================] - 9s 1s/step - loss: 0.0650 - accuracy: 0.9840 - val_loss: 0.0298 - val_accuracy: 0.9920 Epoch 5/30 6/6 [==============================] - 9s 1s/step - loss: 0.0633 - accuracy: 0.9867 - val_loss: 0.0222 - val_accuracy: 0.9960 Epoch 6/30 6/6 [==============================] - 9s 2s/step - loss: 0.0618 - accuracy: 0.9867 - val_loss: 0.0239 - val_accuracy: 0.9960 Epoch 7/30 6/6 [==============================] - 9s 2s/step - loss: 0.0608 - accuracy: 0.9880 - val_loss: 0.0283 - val_accuracy: 0.9920 Epoch 8/30 6/6 [==============================] - 9s 1s/step - loss: 0.0638 - accuracy: 0.9880 - val_loss: 0.0290 - val_accuracy: 0.9920 Epoch 9/30 6/6 [==============================] - 9s 1s/step - loss: 0.0539 - accuracy: 0.9893 - val_loss: 0.0252 - val_accuracy: 0.9920 Epoch 10/30 6/6 [==============================] - 9s 1s/step - loss: 0.0631 - accuracy: 0.9853 - val_loss: 0.0396 - val_accuracy: 0.9800 Epoch 11/30 6/6 [==============================] - 9s 1s/step - loss: 0.0568 - accuracy: 0.9867 - val_loss: 0.0223 - val_accuracy: 0.9960 Epoch 12/30 6/6 [==============================] - 9s 1s/step - loss: 0.0562 - accuracy: 0.9853 - val_loss: 0.0232 - val_accuracy: 0.9960 Epoch 13/30 6/6 [==============================] - 9s 1s/step - loss: 0.0558 - accuracy: 0.9853 - val_loss: 0.0290 - val_accuracy: 0.9880 Epoch 14/30 6/6 [==============================] - 9s 1s/step - loss: 0.0568 - accuracy: 0.9867 - val_loss: 0.0269 - val_accuracy: 0.9920 Epoch 15/30 6/6 [==============================] - 9s 1s/step - loss: 0.0501 - accuracy: 0.9880 - val_loss: 0.0386 - val_accuracy: 0.9800 Epoch 16/30 6/6 [==============================] - 9s 1s/step - loss: 0.0542 - accuracy: 0.9853 - val_loss: 0.0350 - val_accuracy: 0.9800 Epoch 17/30 6/6 [==============================] - 9s 1s/step - loss: 0.0478 - accuracy: 0.9893 - val_loss: 0.0237 - val_accuracy: 0.9960 Epoch 18/30 6/6 [==============================] - 9s 1s/step - loss: 0.0520 - accuracy: 0.9893 - val_loss: 0.0174 - val_accuracy: 1.0000 Epoch 19/30 6/6 [==============================] - 9s 1s/step - loss: 0.0501 - accuracy: 0.9867 - val_loss: 0.0186 - val_accuracy: 0.9960 Epoch 20/30 6/6 [==============================] - 9s 1s/step - loss: 0.0520 - accuracy: 0.9893 - val_loss: 0.0270 - val_accuracy: 0.9840 Epoch 21/30 6/6 [==============================] - 9s 1s/step - loss: 0.0528 - accuracy: 0.9880 - val_loss: 0.0177 - val_accuracy: 1.0000 Epoch 22/30 6/6 [==============================] - 9s 1s/step - loss: 0.0532 - accuracy: 0.9880 - val_loss: 0.0278 - val_accuracy: 0.9840 Epoch 23/30 6/6 [==============================] - 9s 1s/step - loss: 0.0449 - accuracy: 0.9893 - val_loss: 0.0273 - val_accuracy: 0.9840 Epoch 24/30 6/6 [==============================] - 9s 1s/step - loss: 0.0509 - accuracy: 0.9893 - val_loss: 0.0188 - val_accuracy: 1.0000 Epoch 25/30 6/6 [==============================] - 9s 1s/step - loss: 0.0472 - accuracy: 0.9907 - val_loss: 0.0212 - val_accuracy: 0.9960 Epoch 26/30 6/6 [==============================] - 9s 1s/step - loss: 0.0466 - accuracy: 0.9893 - val_loss: 0.0254 - val_accuracy: 0.9880 Epoch 27/30 6/6 [==============================] - 9s 1s/step - loss: 0.0426 - accuracy: 0.9920 - val_loss: 0.0262 - val_accuracy: 0.9840 Epoch 28/30 6/6 [==============================] - 9s 1s/step - loss: 0.0437 - accuracy: 0.9907 - val_loss: 0.0321 - val_accuracy: 0.9800 Epoch 29/30 6/6 [==============================] - 9s 1s/step - loss: 0.0473 - accuracy: 0.9893 - val_loss: 0.0176 - val_accuracy: 1.0000 Epoch 30/30 6/6 [==============================] - 9s 1s/step - loss: 0.0432 - accuracy: 0.9907 - val_loss: 0.0303 - val_accuracy: 0.9840 소요시간 260.3884177207947 . plt.figure(figsize=(12, 12)) plt.style.use(&#39;ggplot&#39;) plt.subplot(2,2,1) plt.plot(history.history[&#39;accuracy&#39;]) plt.plot(history.history[&#39;val_accuracy&#39;]) plt.title(&#39;Accuracy of the Model&#39;) plt.ylabel(&#39;Accuracy&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train accuracy&#39;, &#39;validation accuracy&#39;], loc=&#39;lower right&#39;, prop={&#39;size&#39;: 12}) plt.subplot(2,2,2) plt.plot(history.history[&#39;loss&#39;]) plt.plot(history.history[&#39;val_loss&#39;]) plt.title(&#39;Loss of the Model&#39;) . Text(0.5, 1.0, &#39;Loss of the Model&#39;) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/25/crack.html",
            "relUrl": "/python/2022/10/25/crack.html",
            "date": " • Oct 25, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "(221025) MNIST",
            "content": "- CNN의 기본 이해 - CNN을 실습을 통해 알아보기 . from IPython.display import display, Image import os, warnings warnings.filterwarnings(action=&#39;ignore&#39;) . import tensorflow as tf from tensorflow.keras import models from tensorflow.keras import layers # from tensorflow.keras import models import Sequential print(tf.__version__) . 2.10.0 . 이미지 - Conv - Pooling - Conv - Polling - FCL (filter)3x3 2x2 (f)3x3 2x2 32개 64개 . Conv: 3x3 필터, 32개의 필터개수, 입력 이미지(28,28,,1) | Maxpooling (2,2) | Conv: 3x3 필터, 64개의 필터개수 | Maxpooling (2,2) | Fully Conneted Layer | . model = models.Sequential() model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation=&#39;relu&#39;, input_shape=(28,28,1) )) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=&#39;relu&#39; )) model.add(layers.MaxPooling2D((2, 2))) model.summary() . Model: &#34;sequential_4&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_1 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_2 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_2 (MaxPooling (None, 5, 5, 64) 0 2D) ================================================================= Total params: 18,816 Trainable params: 18,816 Non-trainable params: 0 _________________________________________________________________ . model.add( layers.Flatten() ) model.add( layers.Dense(64, activation=&#39;relu&#39;)) model.add( layers.Dense(10, activation=&#39;softmax&#39;)) . model.summary() . Model: &#34;sequential_4&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_1 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_2 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_2 (MaxPooling (None, 5, 5, 64) 0 2D) flatten (Flatten) (None, 1600) 0 dense (Dense) (None, 64) 102464 dense_1 (Dense) (None, 10) 650 ================================================================= Total params: 121,930 Trainable params: 121,930 Non-trainable params: 0 _________________________________________________________________ . from tensorflow.keras.datasets import mnist from tensorflow.keras.utils import to_categorical (train_images, train_labels), (test_images, test_labels) = mnist.load_data() . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz 11490434/11490434 [==============================] - 1s 0us/step . train_images = train_images.reshape((60000, 28, 28, 1)) train_images = train_images.astype(&#39;float32&#39;) / 255 test_images = test_images.reshape((10000, 28, 28, 1)) test_images = test_images.astype(&#39;float32&#39;) / 255 . train_labels = to_categorical(train_labels) test_labels = to_categorical(test_labels) . print(&quot;입력층 데이터(X) : &quot;,train_images.shape, test_images.shape ) print(&quot;출력층 데이터(y) : &quot;,train_labels.shape, test_labels.shape ) . 입력층 데이터(X) : (60000, 28, 28, 1) (10000, 28, 28, 1) 출력층 데이터(y) : (60000, 10) (10000, 10) . %%time model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5, batch_size=64) . Epoch 1/5 938/938 [==============================] - 19s 20ms/step - loss: 0.1647 - accuracy: 0.9501 - val_loss: 0.0481 - val_accuracy: 0.9834 Epoch 2/5 938/938 [==============================] - 19s 21ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.0359 - val_accuracy: 0.9879 Epoch 3/5 938/938 [==============================] - 20s 21ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0369 - val_accuracy: 0.9881 Epoch 4/5 938/938 [==============================] - 19s 20ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0255 - val_accuracy: 0.9912 Epoch 5/5 938/938 [==============================] - 19s 20ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.0236 - val_accuracy: 0.9924 CPU times: total: 7min 15s Wall time: 1min 36s . &lt;keras.callbacks.History at 0x20e4747ed00&gt; . test_loss, test_acc = model.evaluate(test_images, test_labels) print(test_acc) . 313/313 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9924 0.9923999905586243 . Conv &#44228;&#52789; &#52628;&#44032;&#54644;&#48372;&#44592; . model = models.Sequential() model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation=&#39;relu&#39;, input_shape=(28,28,1) )) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=&#39;relu&#39; )) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=&#39;relu&#39; )) model.add(layers.MaxPooling2D((2, 2))) model.summary() . Model: &#34;sequential_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_3 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_3 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_4 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_4 (MaxPooling (None, 5, 5, 64) 0 2D) conv2d_5 (Conv2D) (None, 3, 3, 64) 36928 max_pooling2d_5 (MaxPooling (None, 1, 1, 64) 0 2D) ================================================================= Total params: 55,744 Trainable params: 55,744 Non-trainable params: 0 _________________________________________________________________ . model.add( layers.Flatten() ) model.add( layers.Dense(64, activation=&#39;relu&#39;)) model.add( layers.Dense(10, activation=&#39;softmax&#39;)) . model.summary() . Model: &#34;sequential_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_3 (Conv2D) (None, 26, 26, 32) 320 max_pooling2d_3 (MaxPooling (None, 13, 13, 32) 0 2D) conv2d_4 (Conv2D) (None, 11, 11, 64) 18496 max_pooling2d_4 (MaxPooling (None, 5, 5, 64) 0 2D) conv2d_5 (Conv2D) (None, 3, 3, 64) 36928 max_pooling2d_5 (MaxPooling (None, 1, 1, 64) 0 2D) flatten_1 (Flatten) (None, 64) 0 dense_2 (Dense) (None, 64) 4160 dense_3 (Dense) (None, 10) 650 ================================================================= Total params: 60,554 Trainable params: 60,554 Non-trainable params: 0 _________________________________________________________________ . from tensorflow.keras.datasets import mnist from tensorflow.keras.utils import to_categorical (train_images, train_labels), (test_images, test_labels) = mnist.load_data() . train_images = train_images.reshape((60000, 28, 28, 1)) train_images = train_images.astype(&#39;float32&#39;) / 255 test_images = test_images.reshape((10000, 28, 28, 1)) test_images = test_images.astype(&#39;float32&#39;) / 255 . train_labels = to_categorical(train_labels) test_labels = to_categorical(test_labels) . print(&quot;입력층 데이터(X) : &quot;,train_images.shape, test_images.shape ) print(&quot;출력층 데이터(y) : &quot;,train_labels.shape, test_labels.shape ) . 입력층 데이터(X) : (60000, 28, 28, 1) (10000, 28, 28, 1) 출력층 데이터(y) : (60000, 10) (10000, 10) . %%time model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5, batch_size=64) . Epoch 1/5 938/938 [==============================] - 20s 21ms/step - loss: 0.2627 - accuracy: 0.9182 - val_loss: 0.0972 - val_accuracy: 0.9697 Epoch 2/5 938/938 [==============================] - 21s 22ms/step - loss: 0.0785 - accuracy: 0.9762 - val_loss: 0.0790 - val_accuracy: 0.9775 Epoch 3/5 938/938 [==============================] - 22s 23ms/step - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.0549 - val_accuracy: 0.9833 Epoch 4/5 938/938 [==============================] - 22s 23ms/step - loss: 0.0432 - accuracy: 0.9871 - val_loss: 0.0490 - val_accuracy: 0.9853 Epoch 5/5 938/938 [==============================] - 21s 23ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0620 - val_accuracy: 0.9818 CPU times: total: 7min 49s Wall time: 1min 45s . &lt;keras.callbacks.History at 0x20e4879fe20&gt; . test_loss, test_acc = model.evaluate(test_images, test_labels) print(test_acc) . 313/313 [==============================] - 1s 4ms/step - loss: 0.0620 - accuracy: 0.9818 0.9818000197410583 . 추가 전 : 0.9923999905586243 | 추가 후 : 0.9818000197410583 | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/25/DNN.html",
            "relUrl": "/python/2022/10/25/DNN.html",
            "date": " • Oct 25, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "(22/10/24) 😎 Cross Validation",
            "content": "import time import gc import os, warnings import numpy as np # 경고 메시지 무시하거나 숨길때(ignore), 다시보이게(default) # warnings.filterwarnings(action=&#39;default&#39;) warnings.filterwarnings(action=&#39;ignore&#39;) . import mglearn mglearn.plots.plot_cross_validation() . from sklearn.datasets import load_iris from sklearn.neighbors import KNeighborsClassifier from sklearn.linear_model import LogisticRegression from sklearn.model_selection import cross_val_score . 00. Base . iris = load_iris() logreg = LogisticRegression() . scores = cross_val_score(logreg, iris.data, iris.target) print(scores) . [0.96666667 1. 0.93333333 0.96666667 1. ] . 01. CV=10 . scores_cv = cross_val_score(logreg, iris.data, iris.target, cv=10) print(scores_cv) . [1. 0.93333333 1. 1. 0.93333333 0.93333333 0.93333333 1. 1. 1. ] . 02. Kfold (n_splits = 3) . iris.target . array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) . from sklearn.model_selection import KFold # 객체를 사용해서 넣어줄 수도 있다. kfold = KFold(n_splits = 3) print(&#39;교차 검증 점수 : n{}&#39;.format(cross_val_score(logreg, iris.data, iris.target, cv=kfold))) . 교차 검증 점수 : [0. 0. 0.] . 문제 발생! | shuffle=True 옵션을 지정해주지 않으면 앞에서부터 3등분 나눠진다. | 그렇게되면 첫번째 fold는 0만, 두번째 fold는 1만, 세번째 fold는 2만 있게되는데 | . kfold_random = KFold(n_splits = 3, shuffle=True, random_state=0) print(&#39;교차 검증 점수 : n{}&#39;.format(cross_val_score(logreg, iris.data, iris.target, cv=kfold_random))) . 교차 검증 점수 : [0.98 0.96 0.96] . 문제 해결! | . 03. Boston Houst Price . from sklearn.model_selection import cross_val_score from sklearn.datasets import load_boston from sklearn.linear_model import LinearRegression import sklearn import pandas as pd import mglearn print(sklearn.__version__) . 1.1.2 . boston = load_boston() df = pd.DataFrame(boston.data, columns=boston.feature_names) df[&#39;price&#39;] = boston.target print(df.shape) . (506, 14) . X = df.drop([&#39;price&#39;], axis=1) y = df[&#39;price&#39;] . cv=5 . lr_model = LinearRegression() msescores = cross_val_score(lr_model, X, y, scoring=&#39;neg_mean_squared_error&#39;, cv=5) . rmse = np.sqrt(-1 * msescores) print(rmse) . [3.52991509 5.10378498 5.75101191 8.9867887 5.77179405] . print(&#39;평균 RMSE : {0:.3f}&#39;.format(np.mean(rmse))) . 평균 RMSE : 5.829 . cv=10 . lr_model = LinearRegression() msescores = cross_val_score(lr_model, X, y, scoring=&#39;neg_mean_squared_error&#39;, cv=10) . rmse = np.sqrt(-1 * msescores) print(rmse) . [ 3.04744921 3.76181913 3.75148053 5.93354231 5.64669077 4.45374875 3.15392917 12.9759539 5.77319193 3.3106511 ] . print(&#39;평균 RMSE : {0:.3f}&#39;.format(np.mean(rmse))) . 평균 RMSE : 5.181 . cv를 $5 to10$으로 변경후 RMSE의 평균을 구한 결과 | 점수가 $5.829 to 5.181$로 떨어졌다. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/24/Cross_Validation_Class_For_Amex.html",
            "relUrl": "/python/2022/10/24/Cross_Validation_Class_For_Amex.html",
            "date": " • Oct 24, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "(OpenCV - Chap6) 화소처리1",
            "content": "&#54868;&#49548;&#51032; &#44060;&#45392; . 화소란 화면(영상)을 구성하는 가장 기본이 되는 단위를 말한다. 일반적으로 영상처리 입문에서 가장 먼저 다루는 내용이 화소값 기반 처리이다. 이것은 영상 구조에 대해 알기 위해 가장 먼저 이해해야 하는 것이 화소에 대한 기본 개념이기 때문이다. . 디지털 영상은 이 화소들의 집합을 의미하며, 이 화소들에 대해 다양한 연산을 하는 것이 영상처리이다. . 6.1 &#50689;&#49345;&#54868;&#49548;&#51032; &#51217;&#44540; . 영상처리를 아주 간단하게 말해보면, 2차원 데이터에 대한 행렬 연산이라고 할 수 있다. 따라서 영상을 다루려면 기본적으로 영상의 화소에 접근하고, 그 값을 수정하거나 새로 만들 수 있어야 한다. . 과거 OpenCV와 같은 대중적인 영상처리 API가 없었을 때, 영상 데이터를 처리하고 저장하는 것이 쉽지만은 않은 일이었다. 하지만 파이썬에서는 행렬 데이터 처리에 유용한 넘파이(Numpy) 라이브러리를 지원하고 있으며, OpenCV API도 numpy.ndarray 객체를 기반으로 영상 데이터를 처리한다. . 6.1.1 &#54868;&#49548;(&#54665;&#47148; &#50896;&#49548;) &#51217;&#44540; . 다음은 모든 원소를 순회하여 원소값을 2배로 변경하는 예제이다. . - 방법1 . 행렬의 원소를 순회하며 직접 원소값을 가져와서 계산 . import numpy as np def mat_access1(mat): for i in range(mat.shape[0]): for j in range(mat.shape[1]): k = mat[i, j] mat[i, j] = k * 2 . mat1 = np.arange(10).reshape(2,5) mat1 . array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) . print(&#39;원소 처리 전: n%s n&#39; % mat1) mat_access1(mat1) print(&#39;원소 처리 후: n%s n&#39; % mat1) . 원소 처리 전: [[0 1 2 3 4] [5 6 7 8 9]] 원소 처리 후: [[ 0 2 4 6 8] [10 12 14 16 18]] . - 방법2 . 행렬 원소를 순회하며, ndarray 클래스의 내부 메서드인 item() 함수와 itemset() 함수로 가져와서 값을 변경 . def mat_access2(mat): for i in range(mat.shape[0]): for j in range(mat.shape[1]): k = mat.item(i, j) # mat.itemset((i, j), k*2) . mat2 = np.arange(10).reshape(2, 5) mat2 . array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) . print(&#39;원소 처리 전: n%s n&#39; % mat2) mat_access2(mat2) print(&#39;원소 처리 후: n%s n&#39; % mat2) . 원소 처리 전: [[0 1 2 3 4] [5 6 7 8 9]] 원소 처리 후: [[ 0 2 4 6 8] [10 12 14 16 18]] . 6.1.2 &#50689;&#49345; &#48152;&#51204;&#51012; &#49688;&#54665;&#54616;&#45716; &#45796;&#50577;&#54620; &#48169;&#48277;&#46308; . 행렬을 처리하여 영상의 반전을 수행하는 다양한 방법들을 함수로 만들고, 각 방법의 수행속도를 계산해보자. . import numpy as np, cv2, time ## 화소 직접접근 def pixel_access1(image): image1 = np.zeros(image.shape[:2], image.dtype) for i in range(image.shape[0]): for j in range(image.shape[1]): pixel = image[i,j] # 화소접근 image1[i, j] = 255 - pixel # 화소할당 return image1 ## item() 함수 def pixel_access2(image): # item() 함수 접근 방법 image2 = np.zeros(image.shape[:2], image.dtype) for i in range(image.shape[0]): for j in range(image.shape[1]): pixel = image.item(i, j) # 화소접근 image2.itemset((i, j), 255 - pixel) # 화소할당 return image2 ## 룩업테이블 def pixel_access3(image): lut = [255 - i for i in range(256)] lut = np.array(lut, np.uint8) image3 = lut[image] return image3 ## openCV def pixel_access4(image): image4 = cv2.subtract(255, image) return image4 ## ndarray 산술연산 def pixel_access5(image): image5 = 255 - image return image5 . image = cv2.imread(&#39;./ghtop_images/chap06_images/bright.jpg&#39;, cv2.IMREAD_GRAYSCALE) . image.shape . (450, 360) . def time_check(func, msg): start_time = time.perf_counter() ret_img = func(image) elapsed = (time.perf_counter() - start_time) * 1000 print(msg, &quot;수행시간 : %0.2f ms&quot; % elapsed ) return ret_img . image1 = time_check(pixel_access1, &quot;[방법1] 직접 접근 방식&quot;) image2 = time_check(pixel_access2, &quot;[방법2] item() 접근 방식&quot;) image3 = time_check(pixel_access3, &quot;[방법3] 룩업테이블 방식&quot;) image4 = time_check(pixel_access4, &quot;[방법4] OpenCV 함수 방식&quot;) image5 = time_check(pixel_access5, &quot;[방법5] ndarray 방식&quot;) . [방법1] 직접 접근 방식 수행시간 : 228.04 ms [방법2] item() 접근 방식 수행시간 : 26.00 ms [방법3] 룩업테이블 방식 수행시간 : 1.54 ms [방법4] OpenCV 함수 방식 수행시간 : 2.38 ms [방법5] ndarray 방식 수행시간 : 0.11 ms . 실행결과를 보면, OpenCV 또는 ndarray 방식으로 화소에 접근하는 경우 속도가 빠른 것을 확인할 수 있었다. . 따라서 화소 직접 접근 방법보다는 OpenCV에서 제공하는 함수들을 조합하거나 ndarray 객체의 원소간 연산으로 구현 내용을 만드는 것이 좋다. . 6.2 &#54868;&#49548; &#48157;&#44592; &#48320;&#54872; . 6.2.1 &#44536;&#47112;&#51060; &#49828;&#52992;&#51068; (&#47749;&#50516;&#46020;) &#50689;&#49345; . 일반적으로 이해하는 컬러가 아닌 영상을 우리는 흑백영상이라고 쉽게 부르지만, 엄밀한 의미에서 흑백 영상이라는 것은 검은색과 흰색으로 구성된 영상을 의미하기 때문에 단일채널 영상에 이 이름을 붙이는 것이 맞지 않을 수도 있다. . 디지털 영상처리에서 보통 단일채널의 영상을 그레이 스케일(gray-scale)영상 혹은 명암도 영상이라고 한다. . 그레이 스케일 영상 . 0~255의 값을 가지는 화소들이 모여서 구성된 영상 | 0은 검은색, 255는 흰색을 의미 | 0~255 사이 값들은 진한 회색에서 연한 회색까지를 나타냄 | . | . import numpy as np import cv2 . image1 = np.zeros((50,512), np.uint8) # 50x512 영상 생성 image2 = np.zeros((50,512), np.uint8) rows, cols = image1.shape[:2] for i in range(rows): for j in range(cols): image1.itemset((i,j), j//2) # 화소값 점진적 증가 image2.itemset((i,j), j // 20*10) # 계단 현상 증가 . print(&#39;image1.shape:&#39;,image1.shape) print(&#39;image2.shape:&#39;,image2.shape) # 0값으로 채워진 50x512 행렬 print(&quot;image1&#39;s rows: &quot;, rows) print(&quot;image1&#39;s cols: &quot;, cols) . image1.shape: (50, 512) image2.shape: (50, 512) image1&#39;s rows: 50 image1&#39;s cols: 512 . cv2.imshow(&quot;image1&quot;, image1) cv2.imshow(&quot;image2&quot;, image2) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/image1_226.png&#39;, image1) # 이미지 저장 cv2.imwrite(&#39;./prac_image/image2_226.png&#39;, image2) # 이미지 저장 cv2.destroyAllWindows() . . - 실행결과 . image1 . 나눗셈 몫 연산자로 2로 나눈 몫을 저장하는 것은 가로 인덱스의 절반 값으로 j열 원소의 화소값을 설정한 것이다. 따라서 화소값은 왼쪽에서 오른쪽으로 0에서 255의 값까지 점진적으로 증가한다. | . image2 . (j // 20 * 10) 은 몫 연산자로 인해서 계산 값의 소수 부분은 날라간다. 따라서 20화소씩 같은 값을 갖게 되어 계단 현상을 나타내며 증가한다. | . 6.2.2 &#50689;&#49345;&#51032; &#54868;&#49548; &#54364;&#54788; . 영상파일을 읽어 들여 그 영상의 특정 부분의 화소들을 확인해보자. 영상파일을 행렬에 저장하고, 관심 영역을 지정해서 출력하면 간단히 영상 데이터인 화소들의 값을 출력할 수 있다. . # 영상 화소값 확인 (pixel_value) import cv2 image = cv2.imread(&#39;./ghtop_images/chap06_images/pixel.jpg&#39;, cv2.IMREAD_GRAYSCALE) (x, y), (w, h) = (180, 37), (15, 10) roi_img = image[y:y+h, x:x+w] # 행은 시작 y좌표에서 y+h까지, 열은 시작 x좌표에서 x+w까지 #print(&quot;[roi img] = n&quot;, roi_img) . $(x, y)$는 사각형의 시작좌표 | $(w, h)$는 사각형의 크기 | 즉, 사각형의 시작좌표와 크기로 관심영역을 지정한다. | . print(&quot;[roi_img] =&quot;) for row in roi_img: for p in row: print(&quot;%4d&quot; % p, end=&quot;&quot;) print() . [roi_img] = 56 51 59 66 84 104 154 206 220 208 203 207 205 204 204 75 57 53 53 72 71 100 152 195 214 212 201 209 207 205 88 76 65 53 51 60 73 96 143 200 219 200 206 204 202 91 92 80 63 53 59 59 61 89 144 195 222 205 200 205 89 94 90 82 63 54 51 56 65 92 149 203 223 209 196 89 91 90 89 84 64 54 55 51 56 94 140 208 223 203 91 86 84 85 97 86 72 59 50 53 66 81 148 211 216 92 86 85 88 92 95 88 70 55 53 59 64 89 155 211 88 85 86 90 87 87 89 86 72 56 50 53 59 88 175 87 85 86 88 87 84 86 90 86 70 53 44 51 56 111 . cv2.rectangle(image, (x,y,w,h) , 255, 1) # 관심 영역에 사각형 표시 cv2.imshow(&quot;image&quot;, image) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/image_227.png&#39;, image) # 이미지 저장 cv2.destroyAllWindows() . . 실행 결과를 보면, 영상의 우상단에 흰색의 작은 사각형이 그려져 있다. 이 사각형이 관심 영역이며, 이 영역의 화소값과 비교해보자. | . print(&quot;[roi img] = n&quot;, roi_img) . [roi img] = [[255 255 255 255 255 255 255 255 255 255 255 255 255 255 255] [255 57 53 53 72 71 100 152 195 214 212 201 209 207 255] [255 76 65 53 51 60 73 96 143 200 219 200 206 204 255] [255 92 80 63 53 59 59 61 89 144 195 222 205 200 255] [255 94 90 82 63 54 51 56 65 92 149 203 223 209 255] [255 91 90 89 84 64 54 55 51 56 94 140 208 223 255] [255 86 84 85 97 86 72 59 50 53 66 81 148 211 255] [255 86 85 88 92 95 88 70 55 53 59 64 89 155 255] [255 85 86 90 87 87 89 86 72 56 50 53 59 88 255] [255 255 255 255 255 255 255 255 255 255 255 255 255 255 255]] . 관심영역 즉, 흰색 사각형이 그려져 있는 부분을 보면 주대각선 윗 부분은 흰색(밝은색)이고 아랫부분은 진한회색(어두운색)임을 알 수 있다. | 화소 값을 보면 주대각선 기준 윗부분은 화소값은 대략 $200 sim225$범위의 값을 나타내고, 그 아래부분은 대략 $50 sim80$범위의 값임을 확인 | 즉, 흰색부분은 화소값이 255와 가깝고, 어두운 부분은 0에 가까운 값을 갖는다. | . 6.2.3 &#50689;&#49345; &#48157;&#44592;&#51032; &#44032;&#44048;&#50689;&#49345; . 화소값이 영상의 밝기를 나타내기 때문에 이 화소값을 변경하면 영상의 밝기를 바꿀 수 있다. . 예를 들어 영상의 화소에 특정한 상숫값을 더하면 영상이 밝아지고, 상숫값을 빼면 영상이 어두워진다. | 또한, 화소가 가질 수 있는 최댓값(예로 255)에서 그 화소의 값을 빼면 반전 영상이 만들어진다. | . 6.2.4 &#54665;&#47148; &#45927;&#49480; &#48143; &#44273;&#49480;&#51012; &#51060;&#50857;&#54620; &#50689;&#49345; &#54633;&#49457; . 영상에 상수를 더하거나 빼는 연산을 확장하면 두 개의 영상을 더하거나 빼는 연산을 생각해 볼 수 있다. 두 영상을 합하면 영상 합성이 되며, 두 영상을 빼면 차영상(difference image)이 된다. . 다음은 알렉산더 대왕 동상 영상($A$)과 사도의 건물 영상($B$), 두 영상을 합성한 영상($A+B$)을 구하는 예제이다. . . . &#54665;&#47148; &#54633;&#44284; &#44273; &#50672;&#49328;&#51012; &#53685;&#54620; &#50689;&#49345; &#54633;&#49457; . import numpy as np, cv2 image1 = cv2.imread(&#39;./ghtop_images/chap06_images/add1.jpg&#39;, cv2.IMREAD_GRAYSCALE) # 영상 읽기 image2 = cv2.imread(&#39;./ghtop_images/chap06_images/add2.jpg&#39;, cv2.IMREAD_GRAYSCALE) . alpha, beta = 0.6, 0.7 # 곱셈 비율 add_img1 = cv2.add(image1, image2) # 두 영상 단순 더하기 add_img2 = cv2.add(image1 * alpha, image2 * beta) # 두 영상 비율에 따른 더하기 add_img2 = np.clip(add_img2, 0, 255).astype(&#39;uint8&#39;) # saturation 처리 add_img3 = cv2.addWeighted(image1, alpha, image2, beta, 0) # 두 영상 비율에 따른 더하기 titles = [&#39;image1&#39;, &#39;image2&#39;,&#39;add_img1&#39;,&#39;add_img2&#39;,&#39;add_img3&#39;] # 윈도우 이름 for t in titles: cv2.imshow(t, eval(t)) # 영상 표시 cv2.waitKey(0) cv2.destroyAllWindows() . titles = [&#39;image1&#39;, &#39;image2&#39;,&#39;add_img1&#39;,&#39;add_img2&#39;,&#39;add_img3&#39;] eval(titles[1]) . array([[110, 122, 118, ..., 165, 166, 166], [143, 159, 168, ..., 165, 166, 166], [115, 117, 140, ..., 165, 166, 166], ..., [ 32, 41, 45, ..., 34, 32, 30], [ 27, 35, 40, ..., 110, 109, 108], [ 41, 36, 31, ..., 146, 148, 149]], dtype=uint8) . 파이썬 내장함수 eval()함수를 사용하면 리스트 원소의 문자열을 행렬 변수로 사용하여 행렬을 출력해주며, cv2.imshow()에 집어넣어 윈도우에 표시한다. | . import os path_save = &#39;./prac_image&#39; os.chdir(path_save) file_name = [] for i in range(len(titles)): file_name.append(path_save + &#39;/&#39; + titles[i] +&#39;_233.png&#39;) #, eval(titles[i])) print(file_name) os.chdir(&#39;../&#39;) . [&#39;./prac_image/image1_233.png&#39;, &#39;./prac_image/image2_233.png&#39;, &#39;./prac_image/add_img1_233.png&#39;, &#39;./prac_image/add_img2_233.png&#39;, &#39;./prac_image/add_img3_233.png&#39;] . for i in range(len(file_name)): cv2.imwrite(file_name[i], eval(titles[i])) print(os.listdir(&#39;./prac_image&#39;)) . [&#39;add_img1_233.png&#39;, &#39;add_img2_233.png&#39;, &#39;add_img3_233.png&#39;, &#39;blue.png&#39;, &#39;green.png&#39;, &#39;image.png&#39;, &#39;image1.png&#39;, &#39;image1_226.png&#39;, &#39;image1_233.png&#39;, &#39;image2_226.png&#39;, &#39;image2_233.png&#39;, &#39;image_227.png&#39;, &#39;img1_plus_img2.PNG&#39;, &#39;img_basic.png&#39;, &#39;img_gray.png&#39;, &#39;problem_box.PNG&#39;, &#39;red.png&#39;, &#39;repeat.png&#39;, &#39;solution_box.PNG&#39;, &#39;trans.png&#39;, &#39;xaxis.png&#39;, &#39;xyaxis.png&#39;, &#39;yaxis.png&#39;] . . add_img1 = cv2.add(image1, image2) # 두 영상 단순 더하기 . . add_img2 = cv2.add(image1 * alpha, image2 * beta) # 두 영상 비율에 따른 더하기 add_img2 = np.clip(add_img2, 0, 255).astype(&#39;uint8&#39;) # saturation 처리 . . add_img3 = cv2.addWeighted(image1, alpha, image2, beta, 0) # 두 영상 비율에 따른 더하기 . .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/15/opencv.html",
            "relUrl": "/python/2022/10/15/opencv.html",
            "date": " • Oct 15, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "(OpenCV - Chap5) 10월 13일(2)",
            "content": "5.3.1 &#49324;&#52825; &#50672;&#49328; (&#54665;&#47148; &#49328;&#49696; &#50672;&#49328;) . 사칙연산을 위한 OpenCV함수에 대해 알아보자. . cv2.add(src1, src2[, mask[, dtype]]]) -&gt; dst . 두 개의 배열 혹은 배열과 스칼라의 각 원소 간 합을 계산한다. 입력인수 src1, src2 중 하나는 스칼라값일 수 있다. . $dst(i) = saturate(src1(i) + src2(i)) quad text{if } mask(i) neq 0$ | $dst(i) = saturate(src1 + src2(i)) quad text{if } mask(i) neq 0$ | $dst(i) = saturate(src1(i) + src2) quad text{if } mask(i) neq 0$ | . | . | . cv2.addWeighted(src1, alpha1, src2, beta, gamma[,[dst[,dtype]]) -&gt; dst 두 배열의 각 원소에 가중치를 곱한 후에 각 원소 간 합 즉, 가중된(weighted) 합을 계산한다. | 수식: $dst(i) = saturate(src1(i) cdot alpha + src2(i) cdot beta + gamma)$ | . | . [ 참고 ] OpenCV에서 **saturate()** 는 0이하는 0으로, 255이상은 255로 범위를 한정시키는 연산이다. import numpy as np, cv2 m1 = np.full((3,6), 10, np.uint8) # 단일채널 생성 및 초기화 m2 = np.full((3,6), 50, np.uint8) m_mask = np.zeros(m1.shape, np.uint8) # 마스크 생성 m_mask[:,3:] = 1 # 관심 영역(모든행, 3열부터)을 지정한 후, 1을 할당 . . m1 . array([[10, 10, 10, 10, 10, 10], [10, 10, 10, 10, 10, 10], [10, 10, 10, 10, 10, 10]], dtype=uint8) . m2 . array([[50, 50, 50, 50, 50, 50], [50, 50, 50, 50, 50, 50], [50, 50, 50, 50, 50, 50]], dtype=uint8) . m_mask . array([[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1]], dtype=uint8) . - 행렬 덧셈 . m_add1 = cv2.add(m1, m2) m_add1 . array([[60, 60, 60, 60, 60, 60], [60, 60, 60, 60, 60, 60], [60, 60, 60, 60, 60, 60]], dtype=uint8) . m_add2 = cv2.add(m1, m2, mask=m_mask) m_add2 . array([[ 0, 0, 0, 60, 60, 60], [ 0, 0, 0, 60, 60, 60], [ 0, 0, 0, 60, 60, 60]], dtype=uint8) . 마스크 영역 (관심영역)만 덧셈 연산이 된 것을 확인! | . - 행렬 나눗셈 . m_div1 = cv2.divide(m1, m2) m_div1 . array([[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], dtype=uint8) . 전부 0으로 나온다? 0.2가 나와야 하는데?? (소수 부분이 상실되었다.) | . - 소수부분 소실 방지 . 행렬 원소 자료형을 32비트 실수형(np.float32)로 변환 . m1 = m1.astype(np.float32) # 소수부분 보존위해 행변환 m2 = np.float32(m2) # 형 변환 방법2 m_div2 = cv2.divide(m1, m2) m_div2 . array([[0.2, 0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.2, 0.2, 0.2, 0.2, 0.2]], dtype=float32) . 소수부분 소실 문제가 잘 해결되었다. | . 5.3.2 &#51648;&#49688;, &#47196;&#44536;, &#51228;&#44273;&#44540; &#44288;&#47144; &#54632;&#49688; . import numpy as np, cv2 ## ndarray 생성 v1 = np.array([1,2,3], np.float32) # 1차원 리스트로 행렬 생성 v2 = np.array([[1],[2],[3]], np.float32) # 2차원 리스트 (3행, 1열) - 열벡터 v3 = np.array([[1,2,3]],np.float32) # 2차원 리스트 (1행, 3열) - 행벡터 . . v1 # 1차원 리스트로 행렬 생성 . array([1., 2., 3.], dtype=float32) . v2 # 2차원 리스트 (3행, 1열) - 열벡터 . array([[1.], [2.], [3.]], dtype=float32) . v3 # 2차원 리스트 (1행, 3열) - 행벡터 . array([[1., 2., 3.]], dtype=float32) . v_exp = cv2.exp(v1) # 1차원 행렬에 대한 지수 m_exp = cv2.exp(v2) # 행벡터 (1*3)에 대한 지수계산 m_exp = cv2.exp(v3) # 열벡터 (3*1)에 대한 지수 계산 v_log = cv2.log(v1) # 로그 계산 m_sqrt = cv2.sqrt(v2) # 제곱근 계산 m_pow = cv2.pow(v3, 3) # 3의 거듭제곱 계산 . . v_exp . array([[ 2.718282 ], [ 7.3890557], [20.085539 ]], dtype=float32) . np.array([[np.exp(1)], [np.exp(2)],[np.exp(3)]]) . array([[ 2.71828183], [ 7.3890561 ], [20.08553692]]) . 잘 계산되는구만! | . m_exp . array([[ 2.718282 , 7.3890557, 20.085539 ]], dtype=float32) . v_log . array([[0. ], [0.6931472], [1.0986123]], dtype=float32) . m_sqrt . array([[1. ], [1.4142135], [1.7320508]], dtype=float32) . m_pow . array([[ 1., 8., 27.]], dtype=float32) . &#54665;&#48289;&#53552;&#47484; &#50676;&#48289;&#53552;&#47196;, &#50676;&#48289;&#53552;&#47484; &#54665;&#48289;&#53552;&#47196; (Transpose) . print( v_log.T) . [[0. 0.6931472 1.0986123]] . print(m_sqrt.T) . [[1. 1.4142135 1.7320508]] . print(m_pow.T) . [[ 1.] [ 8.] [27.]] . 열벡터는 행벡터로, 행벡터는 열벡터로 변환하였다! | . 2&#52264;&#50896; &#54665;&#47148;&#51012; &#48289;&#53552;(1&#52264;&#50896;)&#47196; &#48320;&#54872; . np.ravel | .flatten() | . print(m_sqrt) . [[1. ] [1.4142135] [1.7320508]] . print(np.ravel(m_sqrt)) . [1. 1.4142135 1.7320508] . Numpy 모듈의 ravel() 함수를 이용해서 2차원 행렬을 벡터(1차원)으로 변환. | ravel() 함수는 리스트나 넘파이 배열뿐만 아니라 모든 다차원 배열을 벡터(1차원)로 변환할 수 있다. | . print(m_pow, type(m_pow)) print(m_pow.flatten(), type(m_pow.flatten())) . [[ 1. 8. 27.]] &lt;class &#39;numpy.ndarray&#39;&gt; [ 1. 8. 27.] &lt;class &#39;numpy.ndarray&#39;&gt; . ndarray 클래스의 내부 메소드인 flatten() 함수를 이용해서 벡터로 변환한다. | . &#54665;&#47148; &#53356;&#44592; &#48143; &#50948;&#49345; &#50672;&#49328; . 다음은 cv2.magnitude()와 cv2.phase() 함수의 예시이다. OpenCV 함수에서 연산의 결과가 실수값을 갖는 경우 대부분 입력 행렬 원소의 자료형도 np.float32형이여야 한다. . import numpy as np, cv2 . . x = np.array([1,2,3,5,10], np.float32) # 리스트로 ndarray 객체 생성 y = np.array([2,5,7,2,9]).astype(&#39;float32&#39;) # 행렬 생성 후 실수형 변환 . x . array([ 1., 2., 3., 5., 10.], dtype=float32) . y . array([2., 5., 7., 2., 9.], dtype=float32) . - 크기 계산 . mag = cv2.magnitude(x, y) mag . array([[ 2.236068 ], [ 5.3851647], [ 7.615773 ], [ 5.3851647], [13.453624 ]], dtype=float32) . - 각도(방향) 계산 . ang = cv2.phase(x, y) ang . array([[1.1071129], [1.1902124], [1.1658309], [0.3805839], [0.7329612]], dtype=float32) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/14/operations_func.html",
            "relUrl": "/python/2022/10/14/operations_func.html",
            "date": " • Oct 14, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "(OpenCV - Chap5) 10월 13일",
            "content": "05. &#44592;&#48376; &#48176;&#50676; &#50672;&#49328; &#54632;&#49688; . OpenCV는 수학과 과학 연산을 위한 파이썬 패키지인 넘파이(numpy)와 연동해 배열을 생성할 수 있으며, 이런 배열을 처리할 수 있는 다양한 연산함수를 지원한다. . 파이썬에서는 배열을 처리하기 위한 자료형으로 리스트, 튜플, 사전 등의 열거형(sequence) 객체가 있다. 리스트는 다차원의 배열을 만들고 원소를 수정할 수 있으며, 튜플은 다차원의 배열을 만들 수 있지만, 수정이 불가능한 자료형이다. OpenCV 모듈의 함수들은 넘파이 모듈의 배열(ndarray) 객체를 기반으로 입력 배열과 출력 배열을 사용한다. . 이 장에서는 OpenCV에서 지원하는 여러 배열 처리 함수들을 살펴본다. . 5.1 &#44592;&#48376; &#48176;&#50676; (Array) &#54632;&#49688; . OpenCV에서는 배열을 옵션에 따라 여러 방향으로 뒤집거나 여러 번 반복하는 등 배열 자체를 처리하는 함수를 제공하고 있다. . 다음 예제는 영상파일을 읽은 후, cv2.flip(), cv2.repeat, cv2.transpose() 함수를 활용해서 상하좌우로 뒤집는 예시이다. . import cv2 image = cv2.imread(&#39;./ghtop_images/chap05_images/flip_test.jpg&#39;, cv2.IMREAD_COLOR) if image is None: raise Exception(&quot;영상파일 읽기 오류 발생&quot;) # 예외 처리 . . - &#50896;&#48376; &#51060;&#48120;&#51648; . image = cv2.imshow(&#39;image&#39;, image) cv2.waitKey(0) cv2.destroyAllWindows() . . 원본 이미지 . . - x&#52629; &#44592;&#51456;&#51004;&#47196; &#46244;&#51665;&#51008; &#51060;&#48120;&#51648; . x_axis = cv2.flip(image, 0) # x축 기준 상하 뒤집기 cv2.imshow(&#39;x_axis&#39;, x_axis) cv2.waitKey(0) cv2.destroyAllWindows() . . x-axis flip . . - y&#52629; &#44592;&#51456;&#51004;&#47196; &#46244;&#51665;&#51008; &#51060;&#48120;&#51648; . y_axis = cv2.flip(image, 1) # y축 기준 좌우 뒤집기 cv2.imshow(&#39;y_axis&#39;, y_axis) cv2.waitKey(0) cv2.destroyAllWindows() . . y_axis flip . . - x, y&#52629; &#44592;&#51456; &#49345;&#54616;&#51340;&#50864; &#46244;&#51665;&#44592; . xy_axis = cv2.flip(image, -1) # 양축(x,y축) 기준 상하좌우 뒤집기 cv2.imshow(&#39;xy_axis&#39;, xy_axis) cv2.waitKey(0) cv2.destroyAllWindows() . . xy_axis flip . . - &#48373;&#49324;&#48376; &#47564;&#46308;&#44592; . cv.repeat(src, ny, nx[,dst[) -&gt; dst . src, dst : 입력, 출력 배열 . | ny, nx : 수직, 수평방향 반복 횟수 . | . | . 입력 배열의 반복된 복사본으로 출력 배열을 채운다. | . rep_image = cv2.repeat(image, 1, 2) # 반복 복사 cv2.imshow(&#39;rep_image&#39;, rep_image) cv2.waitKey(0) cv2.destroyAllWindows() . . repeat_image . . - &#51204;&#52824; &#51060;&#48120;&#51648; . 입력 행렬의 전치 행렬을 출력으로 반환한다. | . trans_image = cv2.transpose(image) # 행렬 전치 cv2.imshow(&#39;trans_image&#39;, trans_image) cv2.waitKey(0) cv2.destroyAllWindows() . . trans_image . . image.shape . . (267, 360, 3) . trans_image.shape . . (360, 267, 3) . $267 times 360 times 3 to 360 times 267 times 3$으로 전치된 것 확인! . 5.2 &#52292;&#45328; &#52376;&#47532; &#54632;&#49688; . 컬러 영상은 파란색(B), 녹색(G), 빨간색(R)의 각기 독립적인 2차원 정보를 합쳐 놓은 배열이라고 정의할 수 있다. 요즈음 영상처리 API에서는 컬러 영상을 표현하기 위해 채널(Channel)이라는 개념을 도입한다. 즉, 빨간색, 녹색, 파란색의 독립적인 2차원 정보는 각각 Blue채널, Green채널, Red 채널이라는 이름으로 표현된다. . 다음은 단일채널 행렬을 여러 개 합치거나, 다채널을 분리하는 등 채널을 처리하는 함수에 대한 설명이다. . 간단한 예제로 채널에 대한 개념을 알아보자. . 1. 단일채널 행렬 3개를 생성 | 2. 3개의 채널을 합쳐 하나의 다채널 행렬로 생성 | 3. 그 후 합쳐진 다채널 행렬을 다시 단일채널로 분리 | . import numpy as np import cv2 . . ## numpy.ndarray를 이용해 행렬 생성 및 초기화 방법 ch0 = np.zeros((2,4), np.uint8) + 10 # 0원소 행렬 선언 후 10 더하기 ch1 = np.ones((2,4), np.uint8) * 20 # 1원소 행렬 선언 후 20 곱하기 ch2 = np.full((2,4), 30, np.uint8) # 행렬을 생성하며 30으로 초기화 list_bgr = [ch0, ch1, ch2] # 단일채널 행렬들을 모아 리스트 구성 merge_bgr = cv2.merge(list_bgr) # 채널 합성 split_bgr = cv2.split(merge_bgr) # 채널 분리 : 컬러영상 &gt; 3채널 분리 . . ch0 . . array([[10, 10, 10, 10], [10, 10, 10, 10]], dtype=uint8) . ch1 . . array([[20, 20, 20, 20], [20, 20, 20, 20]], dtype=uint8) . ch2 . . array([[30, 30, 30, 30], [30, 30, 30, 30]], dtype=uint8) . # 단일 채널 행렬 3개 (ch0, ch1, ch2) list_bgr . . [array([[10, 10, 10, 10], [10, 10, 10, 10]], dtype=uint8), array([[20, 20, 20, 20], [20, 20, 20, 20]], dtype=uint8), array([[30, 30, 30, 30], [30, 30, 30, 30]], dtype=uint8)] . print(&#39;merge_bgr 행렬 형태: &#39;, merge_bgr.shape) print(&#39; &#39;) print(merge_bgr) . . merge_bgr 행렬 형태: (2, 4, 3) [[[10 20 30] [10 20 30] [10 20 30] [10 20 30]] [[10 20 30] [10 20 30] [10 20 30] [10 20 30]]] . print(&#39;split_bar 행렬 형태: &#39;, np.array(split_bgr).shape) # numpy의 shape() 함수를 적용하기 위해 ndarray객체로 변경하여 행렬 형태로 출력 print(&#39; &#39;) print(split_bgr[0]) print(&#39; &#39;) print(split_bgr[1]) print(&#39; &#39;) print(split_bgr[2]) . . split_bar 행렬 형태: (3, 2, 4) [[10 10 10 10] [10 10 10 10]] [[20 20 20 20] [20 20 20 20]] [[30 30 30 30] [30 30 30 30]] . 2열 3행 깊이가 4 | . split_bgr . . (array([[10, 10, 10, 10], [10, 10, 10, 10]], dtype=uint8), array([[20, 20, 20, 20], [20, 20, 20, 20]], dtype=uint8), array([[30, 30, 30, 30], [30, 30, 30, 30]], dtype=uint8)) . np.array(split_bgr) . . array([[[10, 10, 10, 10], [10, 10, 10, 10]], [[20, 20, 20, 20], [20, 20, 20, 20]], [[30, 30, 30, 30], [30, 30, 30, 30]]], dtype=uint8) . &#50696;&#51228; &#49892;&#49845; . import cv2 . . image = cv2.imread(&#39;./ghtop_images/chap05_images/color.jpg&#39;, cv2.IMREAD_COLOR) # 영상 읽기 if image is None: raise Exception(&#39;영상파일 읽기 오류&#39;) # 예외처리 if image.ndim != 3: raise Exception(&quot;컬러 영상 아님&quot;) # 예외 처리 - 컬러 영상 확인 . bgr = cv2.split(image) # blue, green, red = cv2.split(image) ## 3개 변수로 반환받기 가능! print(&#39;bgr 자료형:&#39;,type(bgr), type(bgr[0]), type(bgr[0][0][0])) . bgr 자료형: &lt;class &#39;tuple&#39;&gt; &lt;class &#39;numpy.ndarray&#39;&gt; &lt;class &#39;numpy.uint8&#39;&gt; . ## 각 채널을 윈도우에 띄우기 cv2.imshow(&#39;image&#39;, image) cv2.imshow(&#39;Blue chnnel&#39;, bgr[0]) cv2.imshow(&#39;Green chnnel&#39;, bgr[1]) cv2.imshow(&#39;Red chnnel&#39;, bgr[2]) cv2.waitKey(0) cv2.destroyAllWindows() . . original image vs. Blue channel . Blue Channel 아래쪽 파란색 마크 부분이 Blue channel에서는 밝게 나타난다. | . original image vs. Green channel . 원본이미지 아래쪽에 녹색을 띄는 진열대 부분이 Green Channel에서 밝게 나타난다. | . original image vs. red channel . 원본이미지의 왼쪽 냉장 전시물의 붉은쪽 문 부분이 Red Chnnel에서 밝게 나타난다. | . 5.3.0 &#49328;&#49696; &#50672;&#49328; &#54632;&#49688; . 행렬연산은 주로 첫 번째 배열의 i번째 원소와 두 번째 배열의 i번째 원소 간에 연산을 수행해서 결과 배열의 i번째 원소에 저장하는 방식을 취한다. 이러한 방식을 원소간 (per-element, element-wise) 연산이라 한다. . 5.3.1 &#49324;&#52825;&#50672;&#49328; . OpenCV에서 배열에 대한 사칙 연산은 두 배열의 원소간(per-element) 연산을 수행한다. . 5.3.2 &#51648;&#49688;, &#47196;&#44536;, &#51228;&#44273;&#44540; &#44288;&#47144; &#54632;&#49688; . OpenCV는 배열 원소의 지수와 로그 및 제곱근 관련 함수를 지원한다. .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/10/13/operatios_func.html",
            "relUrl": "/python/2022/10/13/operatios_func.html",
            "date": " • Oct 13, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "(OpenCV - Chap5) OpenCV 인터페이스",
            "content": "4.1 &#50952;&#46020;&#50864; &#51228;&#50612; . 영상처리를 간단히 말하면, 2차원 행렬에 대한 연산이라 할 수 있다. 여기서 행렬에 대한 다양한 연산 과정에서 행렬 원소의 값이 변한다. 이 때 변화된 행렬의 화소들을 윈도우에 영상으로 바로 표시할 수 있다면 적용된 행렬 연산의 의미를 이해하기가 훨씬 더 쉬울 것이다. . OpenCV에서는 윈도우(window, 창)가 활성화된 상태에서만 마우스나 키보드 이벤트를 감지할 수 있다. 따라서 이런 이벤트를 감지해서 처리하려면 윈도우를 생성하고 제어할 수 있어야 한다. . import numpy as np import cv2 image = np.zeros((200, 400), np.uint8) # 행렬 생성 image[:] = 200 # 밝은 회색(200) 바탕 영상 생성 title1, title2 = &#39;Position1&#39;, &#39;Position2&#39; # 윈도우 이름 cv2.namedWindow(title1, cv2.WINDOW_AUTOSIZE) # 윈도우 생성 및 크기조절 옵션 cv2.namedWindow(title2) cv2.moveWindow(title1, 150, 150) cv2.moveWindow(title2, 400, 50) cv2.imshow(title1, image) cv2.imshow(title2, image) cv2.waitKey(0) cv2.destroyAllWindows() . image . array([[200, 200, 200, ..., 200, 200, 200], [200, 200, 200, ..., 200, 200, 200], [200, 200, 200, ..., 200, 200, 200], ..., [200, 200, 200, ..., 200, 200, 200], [200, 200, 200, ..., 200, 200, 200], [200, 200, 200, ..., 200, 200, 200]], dtype=uint8) . import numpy as np import cv2 image = np.zeros((200,300), np.uint8) # ndarray 행렬 생성 image.fill(255) # 모든 원소에 255(흰색) 지정 image, image.shape title1, title2 = &#39;AUTOSIZE&#39;, &#39;NORMAL&#39; cv2.namedWindow(title1, cv2.WINDOW_AUTOSIZE) cv2.namedWindow(title2, cv2.WINDOW_NORMAL) # cv2.moveWindow(title1, 150, 150) # 윈도우 이동 - 위치 지정 # cv2.moveWindow(title2, 400, 50) cv2.imshow(&#39;image&#39;, image) # 원본 이미지 cv2.imshow(title1, image) # AUTOSIZE cv2.imshow(title2, image) # NORMAL cv2.resizeWindow(title1, 400, 300) # 윈도우 크기 변경 cv2.resizeWindow(title2, 400, 300) cv2.waitKey(0) # 키 이벤트 대기 cv2.destroyAllWindows() # 열린 모든 윈도우 닫기 . 실행결과, 행렬을 두 윈도우에 영상을 표시한 후에 cv2.resizeWindow() 영상의 크기를 가로 400화소, 세로 300화소로 변경한다. 여기서 두 윈도우에 나타나는 영상(image 행렬)의 형태가 다르다. | 즉, AUTOSIZE 윈도우는 행렬의 크기 변경 없이 윈도우의 크기만 바꾸며, | NORMAL 윈도우는 변경된 윈도우와 동일하게 행렬의 크기도 바뀐다. 단, image 행렬의 실제 크기를 바꾸는 것이 아니라 보여지는 형태만 바꾸는 것 | . 4.1 &#51060;&#48292;&#53944; &#52376;&#47532; &#54632;&#49688; . OpenCV에서 지원하는 이벤트 처리 함수에 대해 배워본다. . 대표적인 이벤트 발생은 사용자가 마우스를 움직인다거나 키보드의 키를 누르는 것 등이 대표적이다. 윈도우 운영체제에서는 다양한 이벤트가 발생하며, 이러한 이벤트 처리를 통해 사용하기 편리한 대화형 프로그램을 만들 수 있다. . 일반적으로 이벤트를 처리하기 위해 콜백(callback) 함수를 사용한다. 콜백 함수는 개발자가 시스템 함수를 직접 호출하는 방식이 아니라, 어떤 이벤트가 발생하거나 특정 시점에 도달했을 때 시스템이 개발자가 등록한 함수를 호출하는 것. . OpenCV에서도 기본적인 이벤트 처리 함수들을 지원한다. 대표적으로 키보드 이벤트, 마우스 이벤트, 트랙바(trackbar) 이벤트를 처리하는 콜백 함수들이 있다. . 4.2.1 &#53412;&#48372;&#46300; &#51060;&#48292;&#53944; &#51228;&#50612; . - cv2.waitKey([, delay) . delay $ leq 0 $ : 키 이벤트 발생까지 무한대기 | delay &gt; $0$ : 지연 시간 동안 키 입력 대기, 지연 시간 안에 키 이벤트 없으면 -1 반환 | . import numpy as np import cv2 # switch case문을 사전으로 구현 switch_case { ord(&#39;a&#39;): &quot;a키 입력&quot;, # ord()함수: 문자를 아스키코드로 변환 ord(&#39;b&#39;): &quot;b키 입력&quot; 0x41: &quot;A키 입력&quot;, int(&#39;ox42&#39;, 16): &quot;B키 입력&quot;, 2424832: &quot;왼쪽 화살표키 입력&quot;, 2490368: &quot;윗쪽 화살표키 입력&quot;, 2555904: &quot;오른쪽 화살표키 입력&quot;, 2621440: &quot;아래쪽 화살표키 입력&quot; } image = np.ones((200,300), np.float) # 원소값이 1인 행렬 생성 cv2.namedWindow(&quot;Keyboard Event&quot;) cv2.imshow(&quot;Keyboard Event&quot;, image) while True: # 무한 반복 key = cv2.waitKeyEx(100) # 100ms 동안 키 이벤트 대기 if key == 27: break # ESC 키 누르면 종료 try: result = switch_cas[key] print(result) except keyError: result = -1 cv2.destroyAllWindows() # 열른 모든 윈도우 제거 . Cell In [5], line 5 switch_case { ^ SyntaxError: invalid syntax . 4.2.2 &#47560;&#50864;&#49828; &#51060;&#48292;&#53944; &#51228;&#50612; . import numpy as np import cv2 def onMouse(event, x, y, flags, param): if event == cv2.EVENT_LBUTTONDOWN: print(&#39;마우스 왼쪽 버튼 누르기&#39;) elif event == cv2.EVENT_RBUTTONDOWN: print(&#39;마우스 오른쪽 버튼 누르기&#39;) elif event == cv2.EVENT_LBUTTONUP: print(&#39;마우스 왼쪽 버튼 떼기&#39;) elif event == cv2.EVENT_RBUTTONUP: print(&#39;마우스 오른쪽 버튼 떼기&#39;) elif event == cv2.EVENT_LBUTTONDBLCLK: print(&#39;마우스 왼쪽 버튼 더블 클릭&#39;) image = np.full((200, 300), 255, np.uint8) # 초기 영상 생성 title1, title2 = &quot;Mouse Event1&quot;, &quot;Mouse Event2&quot; # 윈도우 이름 cv2.imshow(title1, image) # 영상 보기 cv2.imshow(title2, image) cv2.setMouseCallback(title1, onMouse) # 마우스 콜백 함수 cv2.waitKey(0) cv2.destroyAllWindows() . 마우스 왼쪽 버튼 누르기 마우스 왼쪽 버튼 떼기 마우스 오른쪽 버튼 누르기 마우스 오른쪽 버튼 떼기 마우스 왼쪽 버튼 누르기 마우스 왼쪽 버튼 떼기 마우스 왼쪽 버튼 더블 클릭 마우스 왼쪽 버튼 누르기 마우스 왼쪽 버튼 떼기 . 4.2.3 &#53944;&#47001;&#48148; &#51060;&#48292;&#53944; &#51228;&#50612; . import numpy as np import cv2 def onChange(value): # 트랙바 콜백 함수 global image, title # 전역 변수 참조 add_value = value - int(image[0][0]) # 트랙바 값과 영상 화소값 차분 print(&#39;추가 화소값:&#39;, add_value) image = image + add_value # 행렬과 스칼라 덧셈 수행 cv2.imshow(title,image) image = np.zeros((300, 500), np.uint8) # 영상 생성 title = &#39;Trackbar Event&#39; cv2.imshow(title, image) cv2.createTrackbar(&#39;Brightness&#39;, title, image[0][0], 255, onChange) # 트랙바 콜백 함수 등록 cv2.waitKey(0) cv2.destroyAllWindows() . 추가 화소값: 5 추가 화소값: 4 추가 화소값: 2 추가 화소값: 2 추가 화소값: 1 추가 화소값: 2 추가 화소값: 1 추가 화소값: 3 추가 화소값: 1 추가 화소값: 1 추가 화소값: 1 추가 화소값: 1 추가 화소값: 1 추가 화소값: 1 추가 화소값: 1 추가 화소값: 1 추가 화소값: 2 추가 화소값: 1 추가 화소값: 1 추가 화소값: 1 . 4.3 &#44536;&#47532;&#44592; &#54632;&#49688; .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/09/02/chap4.html",
            "relUrl": "/python/2022/09/02/chap4.html",
            "date": " • Sep 2, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "OpenCV intro",
            "content": "ref: https://www.youtube.com/watch?v=F2FRpmh9sQo . &#51060;&#48120;&#51648; &#51069;&#50612;&#49436; &#49332;&#54196;&#48372;&#44592; . 01. cv2.imread(file_name, flag) . cv2.imread(file_name, flag) : 이미지를 읽어 Numpy 객체로 만드는 함수 file_name : 읽고자 하는 이미지 파일 | flag : 이미지를 읽는 방법 설정 . IMREAD_COLOR : 이미지를 Color로 읽고, 투명한 부분은 무시 | IMREAD_GRAYSCALE : 이미지를 Grayscale로 읽기 | IMREAD_UNCHANGED : 이미지를 Color로 읽고, 투명한 부분도 읽기 (Alpha) | . | 반환 값 : Numpy 객체 (행, 열, 색상: 기본 BGR) . | . 02. cv2. imshow(title, image) . cv2.imshow(title, image) : 특정한 이미지를 화면에 출력 title: 윈도우 창의 제목 | image : 출력할 이미지 객체 | . 03. cv2.imwrite(file_name, image) . cv2.imwrite(file_name, image) : 특정한 이미지를 파일로 저장하는 함수 file_name : 저장할 이미지 파일 이름 | image : 저장할 이미지 객체 | . 04. cv2.waitKey(time) . cv2.waitKey(time) : 키보드 입력을 처리하는 함수 time : 입력 대기 시간 (무한대기: 0) . | 반환 값: 사용자가 입력한 Ascii Code (ESC: 27) . | . 05. cv2.destroyAllWindows() . cv2.destroyAllWindows() : 화면의 모든 윈도우를 닫는 함수 import cv2 img_basic = cv2.imread(&#39;./ghtop_images/chap05_images/color.jpg&#39;, cv2.IMREAD_COLOR) cv2.imshow(&#39;Image Basic&#39;, img_basic) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/img_basic.png&#39;, img_basic) # 이미지 저장 cv2.destroyAllWindows() . . img_gray = cv2.cvtColor(img_basic, cv2.COLOR_BGR2GRAY) cv2.imshow(&quot;Image Gray&quot;, img_gray) cv2.waitKey(0) cv2.imwrite(&#39;./prac_image/img_gray.png&#39;, img_gray) # 이미지 저장 cv2.destroyAllWindows() . .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/09/01/opencv-intro.html",
            "relUrl": "/python/2022/09/01/opencv-intro.html",
            "date": " • Sep 1, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "Autoencoder",
            "content": ".",
            "url": "https://pinkocto.github.io/BP2022/python/2022/06/12/autoencoder.html",
            "relUrl": "/python/2022/06/12/autoencoder.html",
            "date": " • Jun 12, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "군집분석",
            "content": "군집분석 . 군집화 수행 시 주요 고려사항 . 어떤 거리 척도를 사용하여 유사도를 측정할 것인가? | 어떤 군집화 알고리즘을 사용할 것인가? | 어떻게 최적의 군집 수를 결정할 것인가? | 어떻게 군집화 결과를 측정/평가할 것인가? | . #1.어떤 거리 척도를 사용하여 유사도를 측정할 것인가? . 유클리디안 거리 (Euclidean Distance) | 맨하탄 거리 (Manhattan Distance) | 마할라노비스 거리 (Mahalanobis Distance) | 상관계수 거리 (Correlation Distance) | . #2. 군집화: 알고리즘 . 1. 계층적 군집화 . 개체들을 가까운 집단부터 차근차근 묶어나가는 방식 | 군집화 결과 뿐만 아니라 유사한 개체들이 결합되는 dendrogram 생성 | . 2. 분리형 군집화 . 전체 데이터의 영역을 특정 기준에 의해 동시에 구분 | 각 개체들은 사전에 정의된 개수의 군집 중 하나에 속하게 됨 | . 3. 자기조직화 지도 . 2차원의 격자에 각 개체들이 대응하도록 인공신경망과 유사한 학습을 통해 군집 도출 | . 4. 분포 기반 군집화 . 데이터의 분포를 기반으로 높은 밀도를 갖는 세부 영역들로 전체 영역을 구분 | . 계층적 군집화 (Hierarchical Clustering) . 계층적 트리모형을 이용하여 개별 개체들을 순차적/계층적으로 유사한 개체/군집과 통합 | 덴드로그램(Dendrogram)을 통해 시각화 가능 덴드로그램 : 개체들이 결합되는 순서를 나타내는 트리 형태의 구조 | . | 사전에 군집의 수를 정하지 않아도 수행 가능 덴드로그램 생성 후 적절한 수준에서 자르면 그에 해당하는 군집화 결과 생성 | . | . 계층적 군집화 수행 예시 . 모든 개체들 사이의 거리에 대한 유사도 행렬 계산 | 거리가 인접한 관측치끼리 군집 형성 | 유사도 행렬 업데이트 | 위의 과정 반복 | . 핵심 수행 절차 : 두 군집 사이의 유사성/거리 측정 . Min(단일연결), max(완전연결), group average(평균연결), between centroid, Ward’s, … | . . - Ward’s method : Distance between two clusters, A and B, how much the sum of squares will increase when they are merged. . K-평균 군집화 (K-Means Clustering) . 대표적인 분리형 군집화 알고리즘 . 각 군집은 하나의 중심(centroid)을 가짐 | 각 개체는 가장 가까운 중심에 할당되며, 같은 중심에 할당된 개체들이 모여 하나의 군집을 형성 | 사전에 군집의 수 K가 정해져야 알고리즘을 실행할 수 있음 | . X=C1∪C2⋯∪Ck,Ci∩Cj=∅,i≠jX = C_1 cup C_2 dots cup C_k, quad C_i cap C_j= emptyset, quad i neq jX=C1​∪C2​⋯∪Ck​,Ci​∩Cj​=∅,i=j . arg⁡min⁡C∑i=1K∑xj∈Ci∣∣xj−cj∣∣2 underset{C}{ operatorname{ arg min}} sum_{i=1}^K sum_{x_j in C_i} ||x_j-c_j||^2Cargmin​i=1∑K​xj​∈Ci​∑​∣∣xj​−cj​∣∣2 . 무작위 초기 중심 설정의 위험을 피하고자 다양한 연구 존재 . 반복적으로 수행하여 가장 여러 번 나타나는 군집을 사용 | 전체 데이터 중 일부만 샘플링하여 계층적 군집화를 수행한 뒤 초기 군집 중심 설정 | 데이터 분포의 정보를 사용해서 초기 중심 설정 | 하지만 많은 경우 초기 중심 설정이 최종 결과에 큰 영향을 미치지는 않음. | . K-평균 군집화의 문제점 . 문제1 : 서로 다른 크기의 군집을 잘 찾아내지 못함 . | 문제2 : 서로 다른 밀도의 군집을 잘 찾아내지 못함 . | 문제3 : 지역적 패턴이 존재하는 군집을 판별하기 어려움 . (보는 위치마다 조금씩 다른 패턴이 보이는 것을 지역적 패턴이 존재한다고 한다.) | 지역적 패턴이 존재할 때 Geodesic distance를 이용한다. | . | . . #3. 군집화: 최적의 군집 수 결정 . 어떻게 최적의 군집 수를 결정할 것인가? . 예시) 20개의 관측치가 존재할 때, 최적의 군집 수는? . | 다양한 군집 수에 대해 성능 평가 지표를 도시하여 최적의 군집 수 선택 | Elbow point에서 최적 군집 수가 결정되는 경우가 일반적 | . . #4. 군집화: 결과 측정 및 평가 . 어떻게 군집화 결과를 측정/평가할 것인가? 분류 알고리즘처럼 모든 상황에 적용가능한 평가 지표 부재 . - 내부 평가지표 . Dunn Index, Silhouette, Sum of Squared Error,… | . - 외부 평가지표 . Rand Index, Jaccard Coefficient, Folks and Mallows Index,… | . 군집화 평가지표 1: Sum of Squared Error (SSE) . SSE=∑i=1k∑x∈Cidist(x,ci)2 text{SSE} = sum_{i=1}^k sum_{x in C_i}dist(x, c_i)^2SSE=∑i=1k​∑x∈Ci​​dist(x,ci​)2 . . 군집의 중심을 정의하고 군집을 중심으로부터 거리를 쭉 본것.. 차이의 제곱 . | 군집의 개수가 2개가 있다면 첫번째 군집으로 부터 SSE, 두번째 군집에서의 SSE(중심과 관측치 사이의 차이제곱)의 합을 대표적으로 하겠다는 것이다. . | . SSE=SSE1+SSE2SSE = SSE_1 + SSE_2SSE=SSE1​+SSE2​ . 각 군집의 c(중심)으로부터 거리의 제곱의 합을 계산하는데 군집이 $K$개가 있는것. $K$에 따라서 값이 달라지게된다. 당연한 소리지만,,ㅎ | . . 위의 경우 ‘2또는 3에서 최적의 군집이다’라고 할 수 있겠다. | . 군집화 평가지표 2: Silhouette 통계량 (SSE의 단점보완) . $a(i)$ 관측치 $i$로부터 같은 군집 내에 있는 모든 다른 개체들 사이의 평균 거리 | $b(i)$ 관측치 $i$로부터 다른 군집 내에 있는 개체들 사이의 평균 거리 중 최솟값 | 일반적으로 $ bar{S}$의 값 $0.5$보다 크면 군집 결과가 타당하다고 볼 수 있음 | $-1$에 가까우면 군집이 전혀 되지 않음 | . S(i)=b(i)−a(i)max{a(i),b(i)}, −1≤(i)≤1S(i) = frac{b(i)-a(i)}{ text{max} {a(i),b(i) }}, space -1 leq(i) leq1S(i)=max{a(i),b(i)}b(i)−a(i)​, −1≤(i)≤1 . Sˉ=1n∑i=1nS(i) bar{S} = frac{1}{n} sum_{i=1}^{n}S(i)Sˉ=n1​i=1∑n​S(i) . . S(i)=b(i)−a(i)max{a(i),b(i)}, −1≤(i)≤1S(i) = frac{b(i)-a(i)}{ text{max} {a(i),b(i) }}, space -1 leq(i) leq1S(i)=max{a(i),b(i)}b(i)−a(i)​, −1≤(i)≤1 . - 위의 식에서 분모의 역할 . $b(i)-a(i)$의 값은 무한대까지 갈 수 있기 때문에 스케일된 값을 만들어주기 위해서 $ text{max}{a(i),b(i)}$로 나눠준다. . | 따라서 실루엣 값은 $-1$과 $1$ 사이에 있다.($-1 leq S(i) leq 1$) . | 실루엣 계수는 $1$에가까울 수록 좋고 $-1$에 가까울수록 안좋다. . | . . Tip: 실루엣으로 평가를 할때는 K=2일 때가 많은 경우 가장 크게 나오니 K가 2인 것을 선택하는 것보다는 2번째로 큰 실루엣값(second best)이 해당하는 K의 군집을 사용하는 것이 좋다. . 실습예제 . https://www.kaggle.com/code/kashnitsky/topic-7-unsupervised-learning-pca-and-clustering .",
            "url": "https://pinkocto.github.io/BP2022/markdown/2022/06/11/clustering.html",
            "relUrl": "/markdown/2022/06/11/clustering.html",
            "date": " • Jun 11, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "Principal Component Analysis (PCA)",
            "content": "&#44256;&#52264;&#50896; &#45936;&#51060;&#53552; . . 변수의 수가 많은 $ to$ 불필요한 변수 존재 | 시각적으로 표현하기 어려움 | 계산 복잡도 증가 $ to$ 모델링 비효율적 | 중요한 변수만을 선택 $ to$ 차원축소 | . &#48320;&#49688; &#49440;&#53469; / &#52628;&#52636;&#51012; &#53685;&#54620; &#52264;&#50896;&#52629;&#49548; . &#48320;&#49688;&#49440;&#53469; (selection) : . 분석 목적에 부합하는 소수의 예측변수만을 선택 . 장점:선택한 변수 해석 용이- 단점: 변수간 상관관계 고려 어려움 | . &#48320;&#49688;&#52628;&#52636; (extraction) : . 예측변수의 변환을 통해 새로운 변수 추출 . 장점:변수 간 상관관계 고려, 일반적으로 변수의 개수를 많이 줄일 수 있음- 단점: 추출된 변수의 해석이 어려움 | . . Supervised feature selection: . Information gain, Stepwise regression, LASSO, Genetic Algorithm, $ dots$ . Supervised feature extraction: . Partial least squares (PLS) . Unsupervised feature selection: . PCA loading . Unsupervised feature extraction: . $Y$를 이용하지 않고 $X$들의 결합으로 변수를 추출하는 방법 Pincipal Component Analysis (PCA), Wavelets transformms, Autoencoder . PCA &#44060;&#50836; . 고차원 데이터를 효과적으로 분석하기 위한 대표적 분석 기법 | 차원축소, 시각화, 군집화, 압축 | PCA는 $n$개의 관측치와 $p$개의 변수로 구성된 데이터를 상관관계가 없는 $k$개의 변수로 구성된 데이터 ($n$개의 관측치)로 요약하는 방식으로, 이 때 요약된 변수는 기존 변수의 선형조합으로 생성됨. . | 원래 데이터의 분산을 최대한 보존하는 새로운 축을 찾고, 그 축에 데이터를 사영 ( Projection) 시키는 기법 . | 주요 목적 . 데이터 차원 축소 ($n times p to n times k, space where space k &lt;&lt; p)$ | 데이터 시각화 및 해석 | . | 일반적으로 PCA는 전체 분석 과정 충 초기에 사용 . | . . $Z_1,Z_2, Z_3$은 기존 변수인 $X_1, X_2, dots X_p$의 선형 조합으로 새롭게 생성된 변수 . $Z$ is linear combination (선형결합) of the original $p$ variables in $X$ . $$Z_1 = a_1^TX = a_{11}X_1 + a_{12}X_2 + dots a_{1p}X_p$$ $$Z_2 = a_2^TX = a_{21}X_1 + a_{22}X_2 + dots a_{2p}X_p$$ $$ vdots$$ . $$Z_p = a_p^TX = a_{p1}X_1 + a_{p2}X_2 + dots a_{pp}X_p$$ . $X_1, X_2, dots, X_p$: 원래 변수 (original variable) | $a_i = [a_{i1}, a_{i2}, dots, a_{ip}]$, $i$번째 기저(basis) 또는 계수(Loading) | $Z_1, Z_2, dots, Z_p$ 각 기저로 사영 변환 후 변수 (주성분 : Score) | . &#51452;&#49457;&#48516; &#48516;&#49437; . 아래 2차원 데이터를 좌측과 우측 두 개의 축에 사영시킬 경우 우측 기저(basis)가 좌측 기저에 비해 손실되는 정보의 양(분산의 크기)이 적으므로 상대적으로 선호되는 기저라고 할 수 있음 . . 1번축과 2번축에 이 데이터를 사영시킨 후에 그 데이터의 분산을 봤을 때 1번분산이 클까? 2번분산이 클까? | . 답 : 2번이 분산이 더 크다. . . 위의 그림의 경우 1번의 분산이 더 크다. | 주성분 분석의 관점에서 1번 축이 더 좋다. (원래 데이터의 분산을 최대화하는 1번 축이 더 좋다.) | . PCA &#49688;&#47532;&#51201; &#48176;&#44221; . $ bar{X} = begin{bmatrix} bar{x}_1 bar{x}_2 dots bar{x}_p end{bmatrix}, quad text{Mean Vector}$ . $C_n = begin{bmatrix} S_{11} &amp; dots &amp; S_{1p} vdots &amp; ddots &amp; vdots S_{p1} &amp; dots &amp; S_{pp} end{bmatrix}, quad text{Covariance Matrix}$ . $R = begin{bmatrix} 1 &amp; r_{12} &amp; dots &amp; r_{1p} r_{21} &amp; 1 &amp; dots &amp; r_{2p} vdots &amp; vdots &amp; ddots &amp; vdots r_{p1} &amp; r_{p2} &amp; dots &amp; 1 end{bmatrix}, quad text{Correlation Matrix}$ . &#44277;&#48516;&#49328;(Covariance)&#51032; &#49457;&#51656; . $ bf{X}$를 $p$개의 변수와 $n$개의 개체로 구성된 $n times p$행렬로 정의할 떄 $ bf{X}$의 공분산 행렬은 다음과 같음 | . $$Cov( bf{X}) = frac{1}{n}(X- bar{X})(X- bar{X})^ top$$ . 공분산 행렬의 대각 성분은 각 변수의 분산과 같으며, 비대각행렬은 대응하는 두 변수의 공분산과 같음 (변수 개수 : $p$) | . $$ C_x = Var[x] = begin{bmatrix} Var[x_1] &amp; Cov[x_1,x_2] &amp; dots &amp; Cov[x_1, x_p] Cov[x_2, x_1] &amp; Var[x_2] &amp; dots &amp; Cov[x_1,x_p] vdots &amp; vdots &amp; ddots &amp; vdots Cov[x_p,x_1] &amp; Cov[x_p,x_2] &amp; dots &amp; Var[x_p] end{bmatrix}$$$$= begin{bmatrix} sigma_{11} &amp; sigma_{12} &amp; dots &amp; sigma_{1p} sigma_{21} &amp; sigma_{22} &amp; dots &amp; sigma_{2p} vdots &amp; vdots &amp; ddots &amp; vdots sigma_{p1} &amp; sigma_{p2} &amp; dots&amp; sigma_{pp} end{bmatrix} = begin{bmatrix} sigma_1^2 &amp; sigma_{12} &amp; dots &amp; sigma_{1p} sigma_{21} &amp; sigma_{2}^2 &amp; dots &amp; sigma_{2p} vdots &amp; vdots &amp; ddots &amp; vdots sigma_{p1} &amp; sigma_{p2} &amp; dots&amp; sigma_{p}^2 end{bmatrix}$$ 데이터의 총분산은 공분산행렬의 대각성분들의 합으로 표현됨. | . $$tr[Cov(X)] = Cov(X)_{11} + Cov(X)_{22} + Cov(X)_{33} + dots Cov(X)_{pp}$$ . &#44256;&#50976;&#44050; &#48143; &#44256;&#50976;&#48289;&#53552; . 어떤 행렬 $ bf A$에 대해 상수 $ lambda$와 벡터 $ bf{x}$가 다음 식을 만족할 때, $ lambda$와 $ bf{x}$를 각각 행렬 $ bf{A}$의 고유값 및 고유벡터라고 함. | . $$ bf{A} bf{x} = lambda bf{x} to ( bf{A} - lambda I) bf{x} = 0$$ . 벡터에 행렬을 곱한다는 것은 해당 벡터를 선형변환 (linear transformation)한다는 의미 $ to$ 고유벡터는 이 변환에 의해 방향이 변하지 않는 벡터를 의미 | . PCA &#50508;&#44256;&#47532;&#51608; - &#51452;&#49457;&#48516; &#52628;&#52636; . . Assume that we have the centered data ($ text{i.e.}, bar{X}_i=0, space i=1, dots,p$) | Let $ bf{X}$ be an p-dimensional random vector with the covariance matrix $ Sigma$ | Let $ alpha$ be an p-dimensional vector of length one ($ text{i.e.}, alpha^ top alpha = 1)$ | Let $Z= alpha^ top bf{X}$ be the projection of $ bf{X}$ onto the direction $ alpha$ | . The main purpose in PCA is . to find $ alpha$ that produces the largest variance of $Z$ . $$ text{Max} space Var(Z) = Var( alpha^ top bf{X}) = alpha^ top Var( bf{X}) alpha = alpha^ top Sigma alpha$$ . $$ text{s.t.} space|| alpha||= alpha^ top alpha=1$$ . . 다시 전체적인 식을 정리해보자. . $ text{Max} space alpha^ top Sigma alpha = alpha^ top E Lambda E^ top alpha, quad Sigma_{m times m} = E Lambda E^ top$ . $ text{s.t.} || alpha|| = 1$ . $ text{Max} space beta^ top Lambda beta quad text{where} space beta=E^ top alpha$ . $ text{s.t.} || beta||=1$ . $ text{Max} space lambda_1 beta_1^2+ lambda_2 beta_2^2 + dots + lambda_m beta_m^2$ . $ text{s.t.} space beta_1^2 + beta_2^2 + dots + beta_m^2 = 1$ . $ qquad lambda_1 &gt; lambda_2 &gt; dots &gt; lambda_m$ . Thus, the optimal value is $ lambda_1$ and $ alpha=e_1$ PCA - &#50696;&#51228; . . $$ text{normalize } bf{X} text{ to } E(X_i)=0, Var(X_i)=1$$ . $$ lambda_3 &gt; lambda_2 &gt; lambda_1$$ . $Z_1 = e_1^ top bf{X} = 0.5699X_1 + 0.5765X_2 -0.5855X_3$ . $=0.5699 cdot begin{bmatrix}-1.1930 -0.0370 -0.5919 0.3792 1.4427 end{bmatrix} . 0.5765 cdot begin{bmatrix}-1.0300 -0.7647 -0.3257 1.0739 1.0464 end{bmatrix} -0.5855 cdot begin{bmatrix}1.5012 0.3540 -0.0910 -0.7140 -1.0502 end{bmatrix} = begin{bmatrix}-2.1527 -0.6692 -0.4718 1.2533 2.0404 end{bmatrix}$ | . $Z_2 = e_2^ top bf{X} = begin{bmatrix}-0.0615 0.4912 -0.2798 -0.4703 0.3204 end{bmatrix}$ . $Z_3 = e_3^ top bf{X} = begin{bmatrix}0.3160 -0.1493 -0.4047 0.1223 0.1157 end{bmatrix}$ . $$ therefore bf{Z} = begin{bmatrix}-2.1527 &amp; −0.0615 &amp; 0.3160 -0.6692 &amp; 0.4912&amp; −0.1493 -0.4718 &amp; −0.2798 &amp; −0.4047 1.2533 &amp; −0.4703 &amp; 0.1223 2.0404 &amp; 0.3204&amp; 0.1157 end{bmatrix}$$ $Z_1,Z_2,Z_3$는 오리지널 $X$들의 선형결합으로 얻어진 새로운 축(변수), 새롭게 추출된 변수라고 할 수 있다. . $$Cov(Z) = begin{bmatrix}2.7596 &amp; 0 &amp; 0 0 &amp; 0.1618 &amp; 0 0 &amp; 0 &amp; 0.0786 end{bmatrix}$$ $$Cov(Z_1, Z_2) = 0$$ $$Cov(Z_2, Z_3) = 0$$ $$Cov(Z_3, Z_1) = 0$$ $$Cov(Z_1, Z_1) = 2.7596$$ . $ Rightarrow$주성분(Z)들은 서로 독립!!! . # &#47751; &#44060;&#51032; &#51452;&#49457;&#48516;&#51012; &#49324;&#50857;&#54644;&#50556; &#54624;&#44620;? . . $$ text{Eigenvalues of the covariance matrix}= text{Variances of each principal component (각 주성분의 분산)}$$ . . $$ text{Eigenvalues of the covariance matrix} ( lambda_1, lambda_2, lambda_3)$$ . $$= text{Variances of each principal component (각 주성분의 분산)}$$ . $$Cov(Z) = begin{bmatrix}2.7596 &amp; 0 &amp; 0 0 &amp; 0.1618 &amp; 0 0 &amp; 0 &amp; 0.0786 end{bmatrix}$$ $Var(Z_1) = 2.7596 = lambda_3 ( text{Largest eigenvalues})$ . $Var(Z_2) = 0.1618 = lambda_2$ . $Var(Z_3) = 0.0786 = lambda_1$ . $$ text{[Proportion of total population variance due to the 1st principal component]} = frac{ lambda_3}{ lambda_1+ lambda_2 + lambda_3}= frac{2.7596}{0.0786+0.1618+2.7596} = 0.920$$ . 첫번째 주성분만 사용하면 원래 데이터의 약 $92 %$를 설명할 수 있다는 것!! . 굳이 두번째, 3번째 주성분을 사용하지 않아도 될 것 같다. . 1. &#49440;&#53469;&#48169;&#49885; 1 : &#44256;&#50976;&#44050; &#44048;&#49548;&#50984;&#51060; &#50976;&#51032;&#48120;&#54616;&#44172; &#45230;&#50500;&#51648;&#45716; Elbow Point&#50640; &#54644;&#45817;&#54616;&#45716; &#51452;&#49457;&#48516; &#49688;&#47484; &#49440;&#53469; . 2. &#49440;&#53469;&#48169;&#49885; 2: &#51068;&#51221; &#49688;&#51456; &#51060;&#49345;&#51032; &#48516;&#49328;&#48708;&#47484; &#48372;&#51316;&#54616;&#45716; &#52572;&#49548;&#51032; &#51452;&#49457;&#48516;&#51012; &#49440;&#53469; (&#48372;&#53685; 70% &#51060;&#49345;) . PCA Loading Plot - &#50696;&#51228; . PCA Loading : 실제 변수가 주성분 결정에 얼마나 많은 영향을 미쳤는지 . PCA &#50508;&#44256;&#47532;&#51608; - &#50836;&#50557; . step1. &#45936;&#51060;&#53552; &#51221;&#44508;&#54868; (mean centering) . step2. &#44592;&#51316; &#48320;&#49688;&#51032; covariance (correlation) matrix &#44228;&#49328; . step3. Covariance (correlation) matrix&#47196;&#48512;&#53552; eigenvalue &#48143; &#51060;&#50640; &#54644;&#45817;&#46104;&#45716; eigenvector&#47484; &#44228;&#49328; . step4. Eigenvalue &#48143; &#54644;&#45817;&#46104;&#45716; eigenvectors&#47484; &#49692;&#49436;&#45824;&#47196; &#45208;&#50676; . $ lambda(1) &gt; lambda(2) &gt; lambda(3) &gt; lambda(4) &gt; lambda(5)$ | $e(1) &gt; e(2) &gt; e(3) &gt; e(4) &gt; e(5), quad i=1, dots,5 text{ is a vector}$ | . step5. &#51221;&#47148;&#46108; eigenvector&#47484; &#53664;&#45824;&#47196; &#44592;&#51316; &#48320;&#49688;&#47484; &#48320;&#54872; . $Z_1 = e(1) bf{X} = e_{11} cdot X_1 + e_{12} cdot X_2 + dots + e_{15} cdot X_5$ | $Z_2 = e(1) bf{X} = e_{21} cdot X_1 + e_{22} cdot X_2 + dots + e_{25} cdot X_5$ | $ dots$ | $Z_5 = e(5) bf{X} = e_{51} cdot X_1 + e_{52} cdot X_2 + dots + e_{55} cdot X_5$ | . PCA &#54620;&#44228; . &#51452;&#49457;&#48516; &#48516;&#49437;&#51032; &#53945;&#51669; . 공분산 행렬의 고유벡터를 사용하므로 단일 가우시안(unimodal) 분포로 추정할 수 있는 데이터에 대해 서로 독립적인 축을 찾는데 사용할 수 있음 . &#54620;&#44228;&#51216;1 . 데이터의 분포가 가우시안이 아니거나 다중 가우시안(multimodal) 자료들에 대해서는 적용하기가 어려움 . | 대안: 커널PCA, LLE (Locally Linear Embedding) . | . . &#54620;&#44228;&#51216;2 . 분류/예측 문제에 대해서 데이터의 범주 정보를 고려하지 않기 때문에 범주간 구분이 잘 되도록 변환을 해주는 것은 아님 주성분분석은 단순히 변환된 축이 최대 분산방향과 정렬되도록 좌표회전을 수행함 | 대안: Partial Least Square (PLS) | . | . . 추출된 X변수들이 분류가 잘 되거나 예측이 잘되는 그런 방향으로 추출된 것은 아니다. 분산이 최대화 되는 방향으로 추출된 것. 그렇기 때문에 항상 분류문제와 예측문제에 우리가 추출된 변수를 사용하더라도 잘 된다는 보장은 없다! . PCA - &#49892;&#51228;&#50696;&#51228; (R) . IRIS 데이터에 대한 주성분 분석 . 150개의 IRIS에 대해 4개 입력변수, 1개 출력변수 (3클래스) | . | 실습예제 : https://www.kaggle.com/code/kashnitsky/topic-7-unsupervised-learning-pca-and-clustering . | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/06/10/pca.html",
            "relUrl": "/python/2022/06/10/pca.html",
            "date": " • Jun 10, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "Unbalanced Data",
            "content": "&#48520;&#44512;&#54805; &#45936;&#51060;&#53552;&#46976;? . **&quot;정상&quot;** 범주의 관측치 수와 **&quot;이상&quot;** 범주의 관측치 수의 차이가 크게 나타나는 경우 . . &#48520;&#44512;&#54805; &#45936;&#51060;&#53552; &#53945;&#51669; . &#50780; &#47928;&#51228;&#51064;&#44032;? . 정상(다수)을 정확히 분류 vs. 이상(소수)을 정확히 분류 . #1. 일반적으로 이상(소수)을 정확히 분류하는 것이 중요 . #2. 적절한 분류경계선이 형성되지 못함 $ to$ 이상(소수)을 정확히 찾아내지 못함 . #3. 높은 예측 정확도를 보임(?) 모델 성능에 대한 왜곡이 있을 수 있음. . . . . . 불균형 상황 하에서는 분류 경계선이 잘못 설정된다. . . 미래의 이상점이 나타났을 때(회색 점) 실제 분류경계선 옆 주황색 점들은 실제 이상임에도 불구하고 이 분류 경계선에 의하면 정상으로 오분류를 하게 된다. . $ to$ 이상을 잘 찾아내지 못하는 문제 발생 . &#49457;&#45733;&#54217;&#44032; . . . 이것만 봤을때는 정확도는 꽤 좋다. 그래서 우리 모델이 참 좋다! 라고 결론내릴 수 있는데 아마 이건 말이안된다고 생각할 것이다. . | 왜냐하면 정상데이터는 다 맞췄지만 우리가 관심있는 것은 이상이고, 이상관점에서만 봤을때는 반 밖에 못맞췄는데?? 이것이 어떻게 좋은 모델일까? . | . . Warning: 예측 정확도는 높게 나오지만 그것을 곧이곧대로 해석하면 안된다!! . &#54644;&#44208;&#48169;&#48277;&#51008;? . 불균형 데이터의 해결방안은 크게 두가지로 볼 수 있다. . 첫번째는 데이터를 조절해서 해결한다. . | 두번째는 분류모델 자체를 조절해서 해결한다. . | 세부적으로 불균형 데이터를 해결하는 방법은 3개가 있다고 볼 수 있다. . 샘플링 기법 (Sampling method) | 비용 기반 학습 (Cost sensitive leraning) | 단일 클래스 분류기법 (Novelty detection) | 이번 시간에는 샘플링 기법에 대해서 알아보자. . &#45936;&#51060;&#53552;&#47484; &#51312;&#51221;&#54644;&#49436; &#54644;&#44208; . . &#45936;&#51060;&#53552;&#47484; &#51312;&#51221;&#54644;&#49436; &#54644;&#44208; (Sampling) . . 샘플링 기법은 크게 언더 샘플링과 오버 샘플링으로 나눈다. . 언더샘플링은 다수 범주를 줄여서 소수범주의 개수와 비슷하게 만들자 . 오버샘플링은 소수범주의 개수를 증폭시켜 다수 범주의 개수와 비슷하게 만들자.. . - &#50616;&#45908; &#49368;&#54540;&#47553; . #1. Random undersampling . . . . . 또 이런식으로 샘플링 될 수도 있겠지.. 이런 경우에는 분류경계선이 다음과 같다. . . . 랜덤 언더샘플링은 무작위로 샘플링하기 때문에 할 때마다 다른 결과가 나올 수 있다. . 굉장히 쉬운방법이긴 하나 단점으로 작용할 수 있다. . 잘 작동할때도 많이 있지만(의외로 잘 작동한다.) 샘플링할 때마다 성능이 달라질 수 있다는 문제가 있다. . #2. Tomek links . 두 범주 사이를 탐지하고 정리를 통해 부정확한 분류경계선 방지 . 정의: $d(x_i,x_k) &lt; d(x_i, x_j) 또는 d(x_j,x_k) &lt; d(x_i, x_j)$가 되는 관측치 $x_k$가 없는 경우 . $ to$ 두 샘플 $x_i, x_j$는 Tomek links를 형성 . $ to$ 둘 중 하나는 노이즈 이거나 둘 다 경계선 근처에 있음 . . 두 점사이에는 k점이 없어야 한다. . k점은 뭐냐? 하면은 두 점사이(다수범주의 점1, 소수범주의 점1)에 어떠한 한점으로 각 점과 k점이 연결되었을 때 i와 j를 연결한 것보다 거리보다 작은 그런 중간에 있는 점이 없을 때 그 두 점을 연결한것을 tomek links라고 한다. . . 보라색으로 표시한 부분이 Tomek link . . Tomek links에 해당하는 다수 범주에 속한 관측치가 제거되었기떄문에 언더샘플링이 된 것! . . 샘플링 이전에는 분류경계선이 다수 범주에 편향된 분류경계선이 나온다면, . 샘플링 이후에는 일부를 지웠기때문에(다수범주를 언더샘플링 헀기때문에) 분류경계선이 조금 더 향상되게 나온다. . #3. CNN (condensed nearest neighbor) . 1-NN 알고리즘을 통해 원데이터를 분류 . . $k=1$ 이어야만 한다. | $k$가 1이 아니면? 모든 다수클래스가 이상으로된다. = CNN이 의미없다. | . #4. OSS (One-Side Selection) . Tomek links + CNN . . . Summary . [ &#127774; &#51109;&#51216; ] . 다수 범주 관측치 제거로 계산 시간 감소 | 데이터 클랜징으로 클래스 오버랩 감소 가능 | . [ &#127770; &#45800;&#51216; ] . 데이터 제거로 인한 정보 손실 방생 | . &#50724;&#48260; &#49368;&#54540;&#47553; . Resampling, SMOTE, Borderline-SMOTE, ADASYN . #1. Resampling . 소수 범주 내 관측치를 늘려보자. (단순히 증폭) 다수 범주의 관측치 수가 비슷해지도록 소수클래스 관측치 복제 . . . . . . 단점: 오히려 소수 클래스를 잡으려다 보니까 다수 클래스가 너무 안좋아지는 과적합이 발생할 수 있다. . 정상도 잘 분류하고 이상도 잘 분류하는게 우리의 궁긍적인 목표인데 이상은 제대로 하는데 정상이 너무 안좋아지는..그러한 경우 . 이를 보완하는 꽤 많은 방법들이 있는데 그 중 하나로 가상의 관측치를 생성하는 것이다. . 가상의 데이터를 생성하자. (빨간색을 그대로 카피하지 말고 그 주변에 생성을 하면 앞의 단점들이 보완되지 않을까..? $ to$ SMOTE . #2. SMOTE (synthetic minority oversampling technique) . 소수 범주에서 가상의 데이터를 생성하는 방법 . . . $$synthetic = X + u cdot (X(nn) - X)$$ . . . . . . K는 반드시 2이상을 설정해야 한다. . . . #3. Borderline - SMOTE . Borderline(경계선) 부분만 샘플링 정상과 이상의 경계부분만 오버샘플링을 하면 좋지 않을까? . . - safe 관측치 (Borderline X) . . - Danger 관측치 (Borderline O) . . - Noise 관측치 (Borderline X) . . 전체 중 다수가 몇개 있어야 safe이고, 몇개 있어야 노이즈인지 기준이 있어야 한다. . . 즉, Danger 관측치가 borderline에 있다고 할 수 있다. . . - Danger 관측치에 대해 SMOTE 적용 . . Danger 관측치를 하나 설정하고, $k$를 5라고 하면 그 주변의 5개 선정하고 그 중 하나를 랜덤하게 선택한다. . - Danger 관측치 5개 선정 ($k=5$) . . - 5개 중 1개를 랜덤으로 선택 . . - 다음과 같은 방법을 통해 복원 . . - Borderline - SMOTE . . original SMOTE 같은 경우 소수 관측치 전반에 걸쳐서 증폭이 됐다면, 이제는 경계선 위치에만 데이터가 샘플링 되는 효과를 얻을 수 있다. . - Borderline-SMOTE 전 / 후 비교 . . 샘플링 이전에는 다수 관측치에 분류경계선이 편향되서 나온다면, 샘플링 이후에는 (오버샘플링 되었기 때문에) 분류경계선이 약간 왼쪽으로 이동한다. . 새로 생성된 데이터들이 경계선 부분에 주로 생성이 된다 . - Borderline - SMOTE를 제안한 논문 . . (1) 검은색이 다수범주, 빨간색이 소수범주, 데이터는 눈사람 형태로 되어있다. . (2) 파란색 점이 Borderline주변에 Danger 관측치가 잘 선정이 됐다. . (3) 이 부분에 대해서만 SMOTE를 적용해서 오버샘플링 되었다. . #4. ADASYN (adaptive synthetic sampling approach) . 샘플링하는 개수를 위치에 따라 다르게 . . 각 소수 클래스 주변에 얼마나 많은 다수 클래스 관측치가 있는가를 정량화 한 지표 . - 예제1 . . - 예제2 . . - 예제3 . . . . . 괄호 안에 있는 개수만큼 개수를 증폭시키겠다는 말이다. 첫번째 소수클래스 주변에 14개를, 13번째 주변에는 40개를 생성해내겠다. . 소수 클래스 주변에 다수클래스가 몇 개 있느냐에 따라 비율이 ($r_i$) 결정되고, 그에 따라 증폭되는 오버샘플링한 데이터의 개수가 달라진다. . . . 소수 클래스 주변의 다수 클래스의 수에 따라 유동적으로 오버샘플링 개수 생성이 가능 . ADASYN &#50612;&#46523;&#44172; &#49373;&#49457;&#54616;&#45716;&#44032;? . ADASYN도 SMOTE를 적용한다. SMOTE의 imporve된 버전이라고 생각하면 된다., . 단 일반 SMOTE처럼 모든데에 다 적용하는 것이 아닌 조금 adaptive하게 한다는 것. . - STEP1 . . - STEP2 . . - STEP3 . . - STEP4 . . - STEP5 . . - ADASYN 적용 전/후 비교 . . (*) Borderlin - SMOTE vs. ADASYN . Borderline-SMOTE는 경계선에 집중하겠다라는 것이고, ADASYN은 경계선은 당연하고 다수 클래스 쪽에 있는 소수 클래스가 있는 부분에 집중을 하자는 것이다. . $ to$ 분류 성능을 높이자! . (*) oversampling - ADASYN &#44288;&#47144; &#45436;&#47928; . . 이 데이터의 특징은 다수 클래스의 데이터가 3개의 패턴이 존재한다. 이런것을 멀티모달이라고 한다. 정상 데이터 즉 다수 클래스가 유니모달 패턴이 아닌 여러개의 패턴이 있는 경우 ADASYN이 작동을 잘 한다. . SMOTE같은 경우 소수 클래스에 적용이 되고 있다. . | Borderlin-SMOTE의 경우 Borderline 주변에 생성이 되어 있다. . | ADASYN의 경우 Borderline도 잘 잡는다. Borderline을 오히려 Borderline SMOTE보다 더 잘 잡는다. . | . SMOTE도 데이터의 패턴에 따라 잘 생성된 것 같은데 불필요한 부분에도 생성된 것을 볼 수 있다. ADASYN의 경우 SMOTE와 Borderline - SMOTE의 장점을 잘 포함하고 있다. . #5. GAN . . - GAN 예시 . . . Summary . . &#48708;&#50857; &#44592;&#48152; &#54617;&#49845; . - 오분류 비용이 같을까? . 1.이상(소수)을 정상(다수)으로 분류 . 2.정상(다수)을 이상(소수)으로 분류 . 1번, 2번 둘 다 오분류 이기는 하지만, 1번이 더 치명적 (원래 이상인데 정상이라고 얘기했을 때 더 치명적..) . 오분류 비용이 다르다 $ to$ 모델링에 오분류 비용을 고려 . . - 이상인데 정상으로 분류한 애들을 주황색으로 표시 . . - 이상인데 정상으로 잘못 분류한 애들한테 가중치 . . - 분류경계선 이동 . . - 모델에 적용 . . 분류 경계선이 소수 클래스에 우호적으로 변경이 된다. | . &#45800;&#51068; &#53364;&#47000;&#49828; &#48516;&#47448; &#44592;&#48277; . 두 범주를 모두 고려해야하나? $ to$ 다수 범주만 고려해서 분류 . . . 미래에 데이터가 왔을 때 바운더리 안에 있으면 다수클래스, 밖에 있으면 그렇지 않다. . . 2 Class Classification은 클래스 정보를 이용해서 클래스를 잘 나누는 Decision boundary를 구하고, 미래의 데이터가 왔을 때 이 Decision boundary가 둘 중에 어떤 범주야 이렇게 얘기한다. | . 1 Class Classification은 소수가 있긴 한데, 소수를 무시한다. 그래서 지금 다수만 있는 것. (노란색) . 다수를 잘 아우를 수 있는 closed boundary를 구한 다음에 미래의 데이터가 왔을 때 안에 들어가 있으면 정상, 밖에 있으면 비정상 혹은 정상이 아니다라고 표현을 한다. | . | . Summary . . 불균형 데이터가 일상생활에서 많이 나온다. 그것을 해결할 수 있는 방안은 크게 3가지가 있다. 샘플링을 통해서, 비용기반, 단일 클래스 분류기법을 통해서 할 수 있다. 그 중 샘플링 기법에 대해서 자세히 배워보았다. . 샘플링 기법은 크게 언더 샘플링 오버 샘플링으로 나누고, 언더 샘플링에 4가지 오버 샘플링에 4가지가 있으며, GAN에 대해 간단한 개념을 배워보았다. .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/06/09/unbalanced-data.html",
            "relUrl": "/python/2022/06/09/unbalanced-data.html",
            "date": " • Jun 9, 2022"
        }
        
    
  
    
        ,"post20": {
            "title": "(1주차 ML2) 4월 28일",
            "content": "",
            "url": "https://pinkocto.github.io/BP2022/python/2022/04/28/ML.html",
            "relUrl": "/python/2022/04/28/ML.html",
            "date": " • Apr 28, 2022"
        }
        
    
  
    
        ,"post21": {
            "title": "OpenCV",
            "content": "https://www.youtube.com/watch?v=XK3eU9egll8 . &#54872;&#44221; &#49444;&#51221; . Anaconda prompt에서 다음 명령 수행 . pip install opencv-pythoon . import cv2 cv2.__version__ . &#39;4.5.5&#39; . OpenCV (Computer Vision) . 다양한 영상 (이미지) / 동영상 처리에 사용되는 오픈소스 라이브러리 . 1. &#51060;&#48120;&#51648; &#52636;&#47141; . import cv2 img = cv2.imread(&#39;./my_icons/img.jpg&#39;) # 해당 경로의 파일 읽어오기 cv2.imshow(&#39;img&#39;, img) # img 라는 이름의 창에 img를 표시 cv2.waitKey(5000) # 지정된 시간(ms) 동안 사용자 키 입력 대기 print(key) cv2.destroyAllWindows() # 모든 창 닫기 . 98 . &#51069;&#44592; &#50741;&#49496; . cv2.IMREAD_COLOR : 컬러 이미지,. 투명 영역은 무시 (기본값) | cv2.IMREAD_GRAYSCALE : 흑백이미지 | cv2.IMREAD_UNCHANGED : 투명 영엳까지 포함 | import cv2 img_color = cv2.imread(&#39;./my_icons/img.jpg&#39;, cv2.IMREAD_COLOR) img_gray = cv2.imread(&#39;./my_icons/img.jpg&#39;, cv2.IMREAD_GRAYSCALE) img_unchanged = cv2.imread(&#39;./my_icons/img.jpg&#39;, cv2.IMREAD_UNCHANGED) cv2.imshow(&#39;img_color&#39;, img_color) cv2.imshow(&#39;img_gray&#39;, img_gray) cv2.imshow(&#39;img_unchanged&#39;, img_unchanged) cv2.waitKey(0) cv2.destroyAllWindows() . Shape . 이미지의 height, width, channel 정보 . import cv2 img = cv2.imread(&#39;./my_icons/img.jpg&#39;) img.shape # 세로, 가로, Channel . (390, 640, 3) . 2. &#46041;&#50689;&#49345; &#52636;&#47141; . &#46041;&#50689;&#49345; &#54028;&#51068; &#52636;&#47141; . import cv2 cap = cv2.VideoCapture(&#39;./my_icons/video.mp4&#39;) while cap.isOpened(): # 동영상 파일이 올바로 열렸는지? ret, frame = cap.read() # ret : 성공 여부, frame : 받아온 이미지 (프레임) if not ret: print(&#39;더 이상 가져올 프레임이 없어요&#39;) break cv2.imshow(&#39;video&#39;, frame) if cv2.waitKey(1) == ord(&#39;q&#39;): print(&#39;사용자 입력에 의해 종료합니다&#39;) break cap.release() # 자원 해제 cv2.destroyAllWindows() # 모든 창 닫기 . 더 이상 가져올 프레임이 없어요 . &#52852;&#47700;&#46972; &#52636;&#47141; . import cv2 cap = cv2.VideoCapture(0) # 0번째 카메라 장치 (Device ID) if not cap.isOpened(): # 카메라가 잘 열리지 않은 경우 exit() # 프로그램 종료 while True: ret, frame = cap.read() if not ret: break cv2.imshow(&#39;camera&#39;, frame) if cv2.waitKey(1) == ord(&#39;q&#39;): # 사용자가 q를 입력하면 break cap.release() cv2.destroyAllWindows() . 3. &#46020;&#54805; &#44536;&#47532;&#44592; . &#48712; &#49828;&#52992;&#52824;&#48513; &#47564;&#46308;&#44592; . import cv2 import numpy as np # 세로 480 X 가로 640, 3 Channel (RGB) 에 해당하는 스케치북 만들기 img = np.zeros((480, 640, 3), dtype = np.uint8) # img[:] = (255, 255, 255) # 전체 공간을 흰색으로 채우기 (B,G,R) # print(img) cv2.imshow(&#39;img&#39;, img) cv2.waitKey(0) cv2.destroyAllWindows() .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/04/26/opencv.html",
            "relUrl": "/python/2022/04/26/opencv.html",
            "date": " • Apr 26, 2022"
        }
        
    
  
    
        ,"post22": {
            "title": "(1주차 ML2) 4월 26일",
            "content": "import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns . import matplotlib.pyplot as plt ## 파이썬 내에서 그래프 출력시 디테일한 옵션 import matplotlib as mpl ## 한글폰트 설정, 글씨체 흐릿한 것을 선명하게 (전체적인 큰 틀의 옵션) . mpl.rc(&#39;font&#39;, family=&#39;Malgun Gothic&#39;) ## 맑은 고딕 . 1. Data . 위스콘신 유방암 데이터(Wisconsin Breast Cancer data)를 분석해보자. . 분석의 목적은 30개의 설명변수를 사용해 진단값이 악성인지 양성인지 예측하는 것입니다. . 1.1 Data Load . from sklearn.datasets import load_breast_cancer . cancer = load_breast_cancer() . cancer[&quot;feature_names&quot;] . array([&#39;mean radius&#39;, &#39;mean texture&#39;, &#39;mean perimeter&#39;, &#39;mean area&#39;, &#39;mean smoothness&#39;, &#39;mean compactness&#39;, &#39;mean concavity&#39;, &#39;mean concave points&#39;, &#39;mean symmetry&#39;, &#39;mean fractal dimension&#39;, &#39;radius error&#39;, &#39;texture error&#39;, &#39;perimeter error&#39;, &#39;area error&#39;, &#39;smoothness error&#39;, &#39;compactness error&#39;, &#39;concavity error&#39;, &#39;concave points error&#39;, &#39;symmetry error&#39;, &#39;fractal dimension error&#39;, &#39;worst radius&#39;, &#39;worst texture&#39;, &#39;worst perimeter&#39;, &#39;worst area&#39;, &#39;worst smoothness&#39;, &#39;worst compactness&#39;, &#39;worst concavity&#39;, &#39;worst concave points&#39;, &#39;worst symmetry&#39;, &#39;worst fractal dimension&#39;], dtype=&#39;&lt;U23&#39;) . Variable name Description . radius | 반지름 | . texture | 그레이스케일 값의 표준편차 | . perimeter | 둘레 | . area | 면적 | . smoothness | 반지름의 국소적 변화정도(local variation) | . compactness | $ frac{ text{perimeter}^2}{area}-1.0$ | . concavity | 오목한 정도(severity of concave portions of the contour) | . concave_points | 오목한 점들의 개수(number of concave portions of contour) | . symmetry | 대칭도 | . fractal dimension | 프랙탈 차원($ text{&quot;coastline approximation&quot;} - 1$) | . cancer[&quot;target_names&quot;] . array([&#39;malignant&#39;, &#39;benign&#39;], dtype=&#39;&lt;U9&#39;) . malignant : 악성 ($0$) | benign : 양성 ($1$) | . - 데이터와 정답을 확인해보자. . data, target = cancer[&quot;data&quot;], cancer[&quot;target&quot;] . data . array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01, 1.189e-01], [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01, 8.902e-02], [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01, 8.758e-02], ..., [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01, 7.820e-02], [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01, 1.240e-01], [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01, 7.039e-02]]) . target . array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]) . 1.2 EDA . df = pd.DataFrame(data, columns=cancer[&quot;feature_names&quot;]) df.describe() . mean radius mean texture mean perimeter mean area mean smoothness mean compactness mean concavity mean concave points mean symmetry mean fractal dimension ... worst radius worst texture worst perimeter worst area worst smoothness worst compactness worst concavity worst concave points worst symmetry worst fractal dimension . count 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | ... | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | . mean 14.127292 | 19.289649 | 91.969033 | 654.889104 | 0.096360 | 0.104341 | 0.088799 | 0.048919 | 0.181162 | 0.062798 | ... | 16.269190 | 25.677223 | 107.261213 | 880.583128 | 0.132369 | 0.254265 | 0.272188 | 0.114606 | 0.290076 | 0.083946 | . std 3.524049 | 4.301036 | 24.298981 | 351.914129 | 0.014064 | 0.052813 | 0.079720 | 0.038803 | 0.027414 | 0.007060 | ... | 4.833242 | 6.146258 | 33.602542 | 569.356993 | 0.022832 | 0.157336 | 0.208624 | 0.065732 | 0.061867 | 0.018061 | . min 6.981000 | 9.710000 | 43.790000 | 143.500000 | 0.052630 | 0.019380 | 0.000000 | 0.000000 | 0.106000 | 0.049960 | ... | 7.930000 | 12.020000 | 50.410000 | 185.200000 | 0.071170 | 0.027290 | 0.000000 | 0.000000 | 0.156500 | 0.055040 | . 25% 11.700000 | 16.170000 | 75.170000 | 420.300000 | 0.086370 | 0.064920 | 0.029560 | 0.020310 | 0.161900 | 0.057700 | ... | 13.010000 | 21.080000 | 84.110000 | 515.300000 | 0.116600 | 0.147200 | 0.114500 | 0.064930 | 0.250400 | 0.071460 | . 50% 13.370000 | 18.840000 | 86.240000 | 551.100000 | 0.095870 | 0.092630 | 0.061540 | 0.033500 | 0.179200 | 0.061540 | ... | 14.970000 | 25.410000 | 97.660000 | 686.500000 | 0.131300 | 0.211900 | 0.226700 | 0.099930 | 0.282200 | 0.080040 | . 75% 15.780000 | 21.800000 | 104.100000 | 782.700000 | 0.105300 | 0.130400 | 0.130700 | 0.074000 | 0.195700 | 0.066120 | ... | 18.790000 | 29.720000 | 125.400000 | 1084.000000 | 0.146000 | 0.339100 | 0.382900 | 0.161400 | 0.317900 | 0.092080 | . max 28.110000 | 39.280000 | 188.500000 | 2501.000000 | 0.163400 | 0.345400 | 0.426800 | 0.201200 | 0.304000 | 0.097440 | ... | 36.040000 | 49.540000 | 251.200000 | 4254.000000 | 0.222600 | 1.058000 | 1.252000 | 0.291000 | 0.663800 | 0.207500 | . 8 rows × 30 columns . cancer[&quot;feature_names&quot;] . array([&#39;mean radius&#39;, &#39;mean texture&#39;, &#39;mean perimeter&#39;, &#39;mean area&#39;, &#39;mean smoothness&#39;, &#39;mean compactness&#39;, &#39;mean concavity&#39;, &#39;mean concave points&#39;, &#39;mean symmetry&#39;, &#39;mean fractal dimension&#39;, &#39;radius error&#39;, &#39;texture error&#39;, &#39;perimeter error&#39;, &#39;area error&#39;, &#39;smoothness error&#39;, &#39;compactness error&#39;, &#39;concavity error&#39;, &#39;concave points error&#39;, &#39;symmetry error&#39;, &#39;fractal dimension error&#39;, &#39;worst radius&#39;, &#39;worst texture&#39;, &#39;worst perimeter&#39;, &#39;worst area&#39;, &#39;worst smoothness&#39;, &#39;worst compactness&#39;, &#39;worst concavity&#39;, &#39;worst concave points&#39;, &#39;worst symmetry&#39;, &#39;worst fractal dimension&#39;], dtype=&#39;&lt;U23&#39;) . 양성과 악성의 비율은 다음과 같다. . pd.Series(cancer[&quot;target&quot;]).value_counts() . 1 357 0 212 dtype: int64 . 종양진단 결과를 나타내는 class 변수의 도수분포로부터 357 명의 관측치가 양성(benign, class=0)에 해당하고, 이보다 적은 212명의 관측치가 악성(malign, class=1)에 해당함을 알 수 있습니다. . sns.countplot(x=target) plt.title(&quot;종양진단 class별 도수분포&quot;) plt.xlabel(&quot;class&quot;) plt.ylim([0, 450]) plt.text(-0.1, 220, &quot;악성&quot;) plt.text(.9, 370, &quot;양성&quot;) plt.show() . sns.boxplot(x=target, y=df[&quot;mean concave points&quot;]) plt.xlabel(&quot;class&quot;) . Text(0.5, 0, &#39;class&#39;) . 악성 종양세포에서 mean_concave_points 값이 훨씬 높은 편임을 알 수 있습니다. | . sns.boxplot(x=target, y=df[&quot;mean radius&quot;]) . &lt;AxesSubplot:ylabel=&#39;mean radius&#39;&gt; . 악성 종양세포에서 mean_radius 값이 훨씬 높은 편임을 알 수 있습니다. | . plt.scatter(x=df[&quot;mean concave points&quot;], y=df[&quot;mean radius&quot;], alpha=.5) plt.xlabel(&quot;mean_concave_points&quot;) plt.ylabel(&quot;mean_radius&quot;) . Text(0, 0.5, &#39;mean_radius&#39;) . 위의 그림은 mean_concave_points와 mean_radius 변수 사이의 강한 양의 상관관계가 있음을 보여줍니다. | . 1.3 Data Split . 데이터를 $7:3$의 비율로 train/test set으로 나누자 . from sklearn.model_selection import train_test_split train_data, test_data, train_target, test_target = train_test_split( data, target, train_size= 0.7, random_state=1001, ) . print(&quot;train data 개수:&quot;, len(train_data)) print(&quot;test data 개수:&quot;, len(test_data)) . train data 개수: 398 test data 개수: 171 . 2. Linear Regression and Categorical Label . Logistic Regression을 학습하기에 앞서 Linear Regression으로 학습할 경우 어떻게 되는지 보자. . from sklearn.linear_model import LinearRegression linear_regressor = LinearRegression() . 2.1 &#54617;&#49845; . linear_regressor.fit(train_data, train_target) . LinearRegression() . 2.2 &#50696;&#52769; . train_pred = linear_regressor.predict(train_data) test_pred = linear_regressor.predict(test_data) . 예측 결과를 보면 $0 sim 1$ 사이를 벗어난 예측값이 보이는데..? | 일단 넘어가자.. | . 2.3 &#49884;&#44033;&#54868; . fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5)) preds = [ (&quot;Train&quot;, train_data, train_pred), (&quot;Test&quot;, test_data, test_pred), ] for idx, (name, d, pred) in enumerate(preds): ax = axes[idx] ax.scatter(x=d[:,0], y=pred) ax.axhline(0, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.axhline(1, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.set_xlabel(&#39;mean_radius&#39;) ax.set_ylabel(&#39;predict&#39;) ax.set_title(f&quot;{name} Data&quot;) plt.show() . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . 2.4 &#54217;&#44032;&#54616;&#44592; . Linear Regression의 성능을 측정하기 위해서는 우선 예측값을 0과 1로 변환시켜줘야 합니다. . Youden&#39;s Index를 이용해 Best Threshold를 찾은 후, 0과 1로 변화시킨 후 정확도를 비교해보자. . ($ star$)Youden&#39;s J statistic . 참고링크: https://en.wikipedia.org/wiki/Youden%27s_J_statistic . $$ J = text{sensitivity} + text{specificity} - 1$$ . $$ J = frac{ text{True positives}}{ text{True positives}+ text{False negatives}} + frac{ text{True negatives}}{ text{True negatives}+ text{False positives}} - 1$$ . . from sklearn.metrics import auc, roc_curve fpr, tpr, threshold = roc_curve(train_target, train_pred) auroc = auc(fpr, tpr) . fpr . array([0. , 0. , 0. , 0.00699301, 0.00699301, 0.01398601, 0.01398601, 0.02097902, 0.02097902, 0.02797203, 0.02797203, 0.04195804, 0.04195804, 0.06993007, 0.06993007, 0.12587413, 0.12587413, 1. ]) . tpr . array([0. , 0.00392157, 0.70980392, 0.70980392, 0.90980392, 0.90980392, 0.93333333, 0.93333333, 0.96862745, 0.96862745, 0.98431373, 0.98431373, 0.99215686, 0.99215686, 0.99607843, 0.99607843, 1. , 1. ]) . threshold . array([ 2.35725299, 1.35725299, 0.82521489, 0.82466702, 0.70119883, 0.69924511, 0.67546196, 0.67513605, 0.63707749, 0.63401065, 0.61560836, 0.59241528, 0.58134679, 0.50969629, 0.50796669, 0.43013177, 0.42764525, -0.53936311]) . AUROC를 그려보자. . plt.plot(fpr, tpr) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) . Text(0, 0.5, &#39;tpr&#39;) . AUROC 값을 계산하면 다음과 같습니다. . print(f&quot;AUROC : {auroc: .4f}&quot;) . AUROC : 0.9960 . 이제 Best Threshold를 계산해보자. . np.argmax(tpr - fpr) . 10 . 10인 index 에서 Best Threshold를 갖는다는 의미 | . J = tpr - fpr idx = np.argmax(J) best_thresh = threshold[idx] print(f&quot;Best Threshold is {best_thresh:.4f}&quot;) print(f&quot;Best Threshold&#39;s sensitivity is {tpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s specificity is {1-fpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s J is {J[idx]:.4f}&quot;) . Best Threshold is 0.6156 Best Threshold&#39;s sensitivity is 0.9843 Best Threshold&#39;s specificity is 0.9720 Best Threshold&#39;s J is 0.9563 . Best Threshold는 AUROC 그래프에서 직선이 가장 긴 곳입니다. . plt.plot(fpr, tpr) plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10)) plt.plot((fpr[idx], fpr[idx]), (fpr[idx], tpr[idx]), color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) plt.show() . 예측값에서의 Best threshold 의 위치를 그려보자 . fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5)) preds = [ (&quot;Train&quot;, train_data, train_pred), (&quot;Test&quot;, test_data, test_pred), ] for idx, (name, d, pred) in enumerate(preds): ax = axes[idx] ax.scatter(x=d[:,0], y=pred) ax.axhline(0, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.axhline(1, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax.set_xlabel(&quot;mean_radius&quot;) ax.set_ylabel(&quot;predict&quot;) ax.set_title(f&quot;{name} Data&quot;) ax.axhline(best_thresh, color=&quot;blue&quot;) plt.show() . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . 이제 Threshold로 예측값을 $0,1$로 변환 후 정확도를 보자 . train_pred_label = list(map(int, (train_pred &gt; best_thresh))) test_pred_label = list(map(int, (test_pred &gt; best_thresh))) . from sklearn.metrics import accuracy_score linear_train_accuracy = accuracy_score(train_target, train_pred_label) linear_test_accuracy = accuracy_score(test_target, test_pred_label) . print(f&quot;Train accuracy is : {linear_train_accuracy:.2f}&quot;) print(f&quot;Test accuracy is : {linear_test_accuracy:.2f}&quot;) . Train accuracy is : 0.98 Test accuracy is : 0.96 . 3. Logistic Regression . 이번에는 Logistic Regression을 이용하여 예측해 보자. . 3.1 Scaling . Logistic Regression은 학습하기에 앞서 학습시킬 데이터를 정규화해야 합니다. . Logistic Regressiond에는 exp가 있는데, exp는 값이 클 경우 overflow가 일어날 수 있기 때문입니다. . from sklearn.preprocessing import StandardScaler scaler = StandardScaler() . 정규화는 항상 train data를 이용하여 학습하고 valid, test 데이터를 변환해야 합니다. . 모든 데이터를 한번에 학습할 경우 본적이 없는 valiation data의 평균과 분산이 반영되고 이는 overfitting을 일으키는 원인이 됩니다. . scaler.fit(train_data) . StandardScaler() . 학습된 Scaler로 train/test 데이터를 변환합니다. . scaled_train_data = scaler.transform(train_data) scaled_test_data = scaler.transform(test_data) . train_data[0] . array([1.953e+01, 1.890e+01, 1.295e+02, 1.217e+03, 1.150e-01, 1.642e-01, 2.197e-01, 1.062e-01, 1.792e-01, 6.552e-02, 1.111e+00, 1.161e+00, 7.237e+00, 1.330e+02, 6.056e-03, 3.203e-02, 5.638e-02, 1.733e-02, 1.884e-02, 4.787e-03, 2.593e+01, 2.624e+01, 1.711e+02, 2.053e+03, 1.495e-01, 4.116e-01, 6.121e-01, 1.980e-01, 2.968e-01, 9.929e-02]) . scaled_train_data[0] . array([ 1.55665013, -0.08374209, 1.56894905, 1.61738288, 1.35230219, 1.15579113, 1.64920637, 1.53999266, -0.05508639, 0.36872483, 2.57200558, -0.10081561, 2.13099893, 1.96746196, -0.29563095, 0.3786633 , 0.72463661, 0.88545529, -0.19263957, 0.37716933, 2.07668666, 0.10014731, 1.96594854, 2.15156304, 0.75699447, 1.00247978, 1.60389716, 1.3188727 , 0.1245053 , 0.85035853]) . 3.2 &#54617;&#49845; . 이제 표준화된 데이터로 Logistic Regression을 학습해 보자. . from sklearn.linear_model import LogisticRegression logit_regressor = LogisticRegression() . logit_regressor.fit(scaled_train_data, train_target) . LogisticRegression() . 3.3 &#50696;&#52769; . Classification을 하는 모델의 경우 예측을 하는 방법은 두가지가 있습니다. . predict . | predict_proba . | predict는 해당 데이터가 어떤 class로 분류할지 바로 알려줍니다. . 반면, predict_proba는 각 class에 속할 확률을 보여줍니다. . train_pred = logit_regressor.predict(scaled_train_data) test_pred = logit_regressor.predict(scaled_test_data) . train_pred[:10] . array([0, 1, 0, 0, 1, 0, 1, 0, 0, 1]) . train_pred_logit = logit_regressor.predict_proba(scaled_train_data) test_pred_logit = logit_regressor.predict_proba(scaled_test_data) . train_pred_logit[:10] . array([[9.99999984e-01, 1.62885674e-08], [1.30750892e-03, 9.98692491e-01], [9.93452400e-01, 6.54760017e-03], [6.39996411e-01, 3.60003589e-01], [5.71378493e-05, 9.99942862e-01], [9.96253495e-01, 3.74650484e-03], [5.02851011e-04, 9.99497149e-01], [9.95986445e-01, 4.01355535e-03], [9.99998296e-01, 1.70356931e-06], [7.13730423e-04, 9.99286270e-01]]) . 각 class에 속할 확률은 다음과 같습니다. . 현재 데이터의 경우 악성과 양성 2개의 클래스가 있기 때문에 2개의 확률이 나타납니다. . 만약 첫 번째 class에 속할 확률이 크다면 데이터는 0번 클래스에 속하게 되는 것..! . train_pred_logit[0] . array([9.99999984e-01, 1.62885674e-08]) . 3.4 &#54217;&#44032; . 데이터의 AUROC를 계산하기 위해서는 1의 클래스로 분류될 확률 하나만 필요합니다. 반면 우리가 갖고 있는 예측값은 0과 1로 분류될 확률을 모두 표시하고 있습니다. 그래서 1에 속할 확률만 남기겠습니다. . train_pred_logit = train_pred_logit[:, 1] test_pred_logit = test_pred_logit[:, 1] . train_pred_logit[0] . 1.628856736535896e-08 . from sklearn.metrics import auc, roc_curve fpr, tpr, threshold = roc_curve(train_target, train_pred_logit) auroc = auc(fpr, tpr) . plt.plot(fpr, tpr) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) . Text(0, 0.5, &#39;tpr&#39;) . print(f&quot;AUROC : {auroc:.4f}&quot;) . AUROC : 0.9971 . J = tpr - fpr idx = np.argmax(J) best_thresh = threshold[idx] print(f&quot;Best Threshold is {best_thresh:.4f}&quot;) print(f&quot;Best Threshold&#39;s sensitivity is {tpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s specificity is {1-fpr[idx]:.4f}&quot;) print(f&quot;Best Threshold&#39;s J is {J[idx]:.4f}&quot;) . Best Threshold is 0.5692 Best Threshold&#39;s sensitivity is 0.9961 Best Threshold&#39;s specificity is 0.9790 Best Threshold&#39;s J is 0.9751 . plt.plot(fpr, tpr) plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10)) plt.plot((fpr[idx],fpr[idx]), (fpr[idx], tpr[idx]), color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.xlabel(&quot;fpr&quot;) plt.ylabel(&quot;tpr&quot;) . Text(0, 0.5, &#39;tpr&#39;) . plt.scatter(x=scaled_train_data[:,0], y=train_pred_logit) plt.axhline(best_thresh, color=&quot;blue&quot;) plt.axhline(0, color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.axhline(1, color=&quot;red&quot;, linestyle=&quot;--&quot;) plt.xlabel(&quot;mean radius&quot;) plt.ylabel(&quot;Probability&quot;) plt.show() . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . 이제 Threshold로 예측값을 0,1로 변환 후 정확도를 보겠습니다. . train_pred_label = list(map(int, (train_pred_logit &gt; best_thresh))) test_pred_label = list(map(int, (test_pred_logit &gt; best_thresh))) . proba_train_accuracy = accuracy_score(train_target, train_pred_label) proba_test_accuracy = accuracy_score(test_target, test_pred_label) . print(f&quot;Train accuracy is : {proba_train_accuracy:.2f}&quot;) print(f&quot;Test accuracy is : {proba_test_accuracy:.2f}&quot;) . Train accuracy is : 0.99 Test accuracy is : 0.98 . 이번에는 predict의 결과값으로 정확도를 보겠습니다. . train_accuracy = accuracy_score(train_target, train_pred) test_accuracy = accuracy_score(test_target, test_pred) . print(f&quot;Train accuracy is : {train_accuracy:.2f}&quot;) print(f&quot;Test accuracy is : {test_accuracy:.2f}&quot;) . Train accuracy is : 0.99 Test accuracy is : 0.97 . predict_proba의 best_threshold로 계산한 결과와 predict로 계산한 결과가 다를 수 있습니다. 이는 두 0과 1로 예측하는 방법이 다르기 때문입니다. 예를 들어서 (0.49, 0.51)의 확률이 있을 때 predict의 경우 class 1의 확률에 속할 확률이 크기 때문에 1로 분류합니다. 하지만 best_threshold가 0.52라면 predict_proba의 경우 class를 0으로 분류하게 됩니다 . 4. &#47560;&#47924;&#47532; . 세개의 모델들의 정확도를 비교해 보겠습니다. . print(f&quot;Linear Regression Test Accuracy: {linear_test_accuracy:.2f}&quot;) print(f&quot;Logistic Regression predict_proba Test Accuracy: {proba_test_accuracy:.2f}&quot;) print(f&quot;Logistic Regression predict Test Accuracy: {test_accuracy:.2f}&quot;) . Linear Regression Test Accuracy: 0.96 Logistic Regression predict_proba Test Accuracy: 0.98 Logistic Regression predict Test Accuracy: 0.97 .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/04/26/ML.html",
            "relUrl": "/python/2022/04/26/ML.html",
            "date": " • Apr 26, 2022"
        }
        
    
  
    
        ,"post23": {
            "title": "(3주차 ML) 3월 24일",
            "content": "&#45336;&#54028;&#51060;&#47196; &#45936;&#51060;&#53552; &#51456;&#48708; . import numpy as np . fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] . fish_data = np.column_stack((fish_length, fish_weight)) . fish_data[:5] . array([[ 25.4, 242. ], [ 26.3, 290. ], [ 26.5, 340. ], [ 29. , 363. ], [ 29. , 430. ]]) . fish_target = np.concatenate((np.ones(35), np.zeros(14))) . fish_target . array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) . &#49324;&#51060;&#53431;&#47088;&#51004;&#47196; &#45936;&#51060;&#53552; &#45208;&#45572;&#44592; . from sklearn.model_selection import train_test_split ## model selection 모듈 아래에 train_test_split 함수 . train_input, test_input, train_target, test_target = train_test_split( fish_data, fish_target, stratify = fish_target, random_state = 42) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/24/ML.html",
            "relUrl": "/python/2022/03/24/ML.html",
            "date": " • Mar 24, 2022"
        }
        
    
  
    
        ,"post24": {
            "title": "(3주차 DV) 3월 23일",
            "content": "- How to upload your CSV file online for data analysis . https://evidencen.com/how-to-upload-your-csv-file-online/ . &#45800;&#51068;&#48320;&#49688; . import seaborn as sns import pandas as pd . df1 = pd.read_csv(&#39;https://raw.githubusercontent.com/pinkocto/BP2022/master/_notebooks/Data03.csv&#39;) df1.head() . id type_of_contract type_of_contract2 channel datetime Term payment_type product amount state overdue_count overdue credit rating bank cancellation age Mileage . 0 66758234 | 렌탈 | Normal | 서비스 방문 | 2019-10-20 | 60 | CMS | K1 | 96900 | 계약확정 | 0 | 없음 | 9.0 | 새마을금고 | 정상 | 43.0 | 1862.0 | . 1 66755948 | 렌탈 | Extension_Rental | 서비스 방문 | 2019-10-20 | 60 | 카드이체 | K1 | 102900 | 계약확정 | 0 | 없음 | 2.0 | 현대카드 | 정상 | 62.0 | 2532.0 | . 2 66756657 | 렌탈 | Normal | 홈쇼핑/방송 | 2019-10-20 | 60 | CMS | K1 | 96900 | 계약확정 | 0 | 없음 | 8.0 | 우리은행 | 정상 | 60.0 | 2363.0 | . 3 66423450 | 멤버십 | TAS | 렌탈재계약 | 2019-10-20 | 12 | CMS | K1 | 66900 | 계약확정 | 0 | 없음 | 5.0 | 농협은행 | 정상 | 60.0 | 2449.0 | . 4 66423204 | 멤버십 | TAS | 렌탈재계약 | 2019-10-20 | 12 | CMS | K1 | 66900 | 해약확정 | 12 | 있음 | 8.0 | 농협은행 | 해약 | 51.0 | 1942.0 | . 1 &#48276;&#51452;&#54805; &#48320;&#49688; . df1[&#39;type_of_contract&#39;].value_counts() . 렌탈 46481 멤버십 4819 Name: type_of_contract, dtype: int64 . sns.countplot(data=df1, x=&#39;type_of_contract&#39;) . &lt;AxesSubplot:xlabel=&#39;type_of_contract&#39;, ylabel=&#39;count&#39;&gt; . C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 47116 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 53448 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 47716 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 48260 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:240: RuntimeWarning: Glyph 49901 missing from current font. font.set_text(s, 0.0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 47116 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 53448 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 47716 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 48260 missing from current font. font.set_text(s, 0, flags=flags) C: Users 82103 anaconda3 envs py38r40 lib site-packages matplotlib backends backend_agg.py:203: RuntimeWarning: Glyph 49901 missing from current font. font.set_text(s, 0, flags=flags) . 한글 글씨체 설정이 필요해 보인다. | . df1[&#39;product&#39;].value_counts() . K1 39134 K2 8995 K3 2082 K5 645 K4 327 K6 120 Name: product, dtype: int64 . sns.countplot(data=df1, x=&#39;product&#39;, hue=&#39;type_of_contract2&#39;) . &lt;AxesSubplot:xlabel=&#39;product&#39;, ylabel=&#39;count&#39;&gt; . 범례와 그래프가 겹쳐나오는 문제가 발생 $ to$ matplotlib 옵션으로 해결 가능 | . &#54620;&#44544; &#44648;&#51664; &#54644;&#44208; . import matplotlib.pyplot as plt ## 파이썬 내에서 그래프 출력시 디테일한 옵션 import matplotlib as mpl ## 한글폰트 설정, 글씨체 흐릿한 것을 선명하게 (전체적인 큰 틀의 옵션) . mpl.rc(&#39;font&#39;, family=&#39;Malgun Gothic&#39;) ## 맑은 고딕 . C드라이브 $ to$ Windows $ to$ Fonts $ to$ Malgun Gothic | . sns.countplot(data=df1, x=&#39;type_of_contract&#39;) . &lt;AxesSubplot:xlabel=&#39;type_of_contract&#39;, ylabel=&#39;count&#39;&gt; . &#45936;&#51060;&#53552; &#44536;&#47000;&#54532; &#44217;&#52840;&#47928;&#51228; . - 그래프 사이즈 키우기 . plt.figure(figsize=[10,5]) ## Size 조정 sns.countplot(data=df1, x=&#39;product&#39;, hue=&#39;type_of_contract2&#39;) plt.legend(loc=&#39;right&#39;) ## 범례 오른쪽에 위치 plt.savefig(&#39;img1.png&#39;) ## 이미지 파일 형태로 저장 # plt.savefig(&#39;img1.pdf&#39;) . 2 &#50672;&#49549;&#54805; &#48320;&#49688; . sns.histplot(data=df1, x=&#39;age&#39;) . &lt;AxesSubplot:xlabel=&#39;age&#39;, ylabel=&#39;Count&#39;&gt; . - kde = True 옵션 추가 . plt.title(&#39;계약 유형 별. 고객 연령 분포&#39;) sns.histplot(data=df1, x=&#39;age&#39;, kde = True, hue=&#39;type_of_contract&#39;) ## 확률분포선 (kde=True) plt.show() . 3 &#44536; &#50808; &#52628;&#44032; &#50741;&#49496;&#46308; . - 그래프 축에 있는 글씨 겹침 . sns.countplot(data=df1, x=&#39;bank&#39;) . &lt;AxesSubplot:xlabel=&#39;bank&#39;, ylabel=&#39;count&#39;&gt; . plt.figure(figsize=[5, 10]) sns.countplot(data=df1, y=&#39;bank&#39;) . &lt;AxesSubplot:xlabel=&#39;count&#39;, ylabel=&#39;bank&#39;&gt; . bank column에 데이터가 굉장히 많다. 빈도수가 높은 상위 10개 데이터만 뽑아서 시각화를 해보자. | . - 빈도가 높은 순으로 정렬 . df1[&#39;bank&#39;].value_counts() ## 빈도수가 높은 순으로 출력 . 국민은행 9901 롯데카드 9518 농협은행 6278 신한은행 3522 우리은행 3386 기업은행 1963 신한카드 1533 하나은행 1446 국민카드 1311 BC카드 1264 새마을금고 964 부산은행 888 삼성카드 884 현대카드 876 대구은행 746 우체국 717 외환은행 586 외환카드 530 경남은행 442 SC제일은행 439 광주은행 347 신협중앙회 341 전북은행 195 씨티은행 162 수협중앙회 160 제주은행 40 유안타증권 27 산업은행 23 현대증권 11 삼성증권 7 하나SK 6 미래에셋증권 5 NH농협카드 4 한국투자증권 4 신한금융투자 4 우리카드 3 대우증권 2 하이투자증권 1 메리츠종합금융증권 1 수협카드 1 상호저축은행 1 SK증권 1 하나대투증권 1 산림조합중앙회 1 대신증권 1 씨티카드 1 Name: bank, dtype: int64 . sns.countplot(data=df1, x=&#39;bank&#39;, order=[&#39;국민은행&#39;, &#39;롯데카드&#39;, &#39;농협은행&#39;, &#39;신한은행&#39;]) . &lt;AxesSubplot:xlabel=&#39;bank&#39;, ylabel=&#39;count&#39;&gt; . - 빈도 순 정렬 . order_list = df1[&#39;bank&#39;].value_counts().index.tolist() ## 빈도 수 높은 순으로 인덱스 출력 . sns.countplot(data=df1, x=&#39;bank&#39;, order=order_list) . &lt;AxesSubplot:xlabel=&#39;bank&#39;, ylabel=&#39;count&#39;&gt; . - 상위 10개만 시각화 . plt.figure(figsize=[10,5]) ## figure size 조정. sns.countplot(data=df1, x=&#39;bank&#39;, order=order_list[0:10]) plt.savefig(&#39;img10.pdf&#39;) ## 이미지 pdf 형태로 저장 . - 이미지 파일이 저장된 디렉토리 경로 . import os print(os.getcwd()) # print(os.listdir(os.getcwd())) . C: Users 82103 Desktop dino BP2022 _notebooks . os.path.exists(&#39;C:/Users/82103/Desktop/dino/BP2022/_notebooks/img10.pdf&#39;) . True . 따라서 위의 경로(현재 작업 폴더)에 img10.pdf 이미지 파일이 저장되어 있음을 확인할 수 있다. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/23/DV.html",
            "relUrl": "/python/2022/03/23/DV.html",
            "date": " • Mar 23, 2022"
        }
        
    
  
    
        ,"post25": {
            "title": "(3주차 ML) 3월 17일",
            "content": "training set / test set . fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] . len(fish_length), len(fish_weight) . (49, 49) . fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)] fish_target = [1]*35 + [0]*14 . fish_data[0] . [25.4, 242.0] . KNN (&#52395;&#48264;&#51704; &#49884;&#46020;) . from sklearn.neighbors import KNeighborsClassifier kn = KNeighborsClassifier() . print(fish_data[4]) . [29.0, 430.0] . print(fish_data[0:5]) . [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0]] . print(fish_data[:5]) . [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0]] . print(fish_data[44:]) . [[12.2, 12.2], [12.4, 13.4], [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]] . train_input = fish_data[:35] ## index 0~34 train_target = fish_target[:35] test_input = fish_data[35:] ## index 35~48 test_target = fish_target[35:] . len(train_input), len(train_target) . (35, 35) . len(test_input), len(test_target) . (14, 14) . kn = kn.fit(train_input, train_target) kn.score(test_input, test_target) . 0.0 . 정확도가 0% 이다? | test input에 있는 샘플 14개를 모두 못 맞췄다는 것이다. | WHY ? $ Rightarrow$ 샘플링 편향 | . &#49368;&#54540;&#47553; &#54200;&#54693; . 왜그런가 봤더니 처음에 fish_length와 fish_weight를 도미 35개, 빙어 14개를 쭉 늘어놓고 두 리스트를 합쳤다. | 두 리스트를 합친 fish_data에서 앞에 35개를 훈련 뒤에 14개를 test set으로 잘랐다. | 즉, 훈련세트에는 빙어가 하나도 없고, 테스트셋에는 도미가 하나도 없게 된다. $ Rightarrow$ 미적분 공부하고 확통시험 본 격.. | . | train set과 test set을 나눌 때에는 빙어와 도미 두 class가 잘 섞여있도록 만들어야 한다. | . Numpy . 이제 Numpy를 이용해서 잘 섞어서 train set과 test set으로 나눠보자. | Numpy는 파이썬의 대표적인 배열 library | scikit-learn이나 matplotlib librayr도 넘파이에 크게 의존하고 있고, 입력 데이터가 Numpy로 전달될 거라고 가정하고 있다. predict method 결과값이 array([1])이런 형태로 출력되는 것도 이러한 이유.(사이킷런의 predict 메서드의 반환값을 넘파이 배열로 리턴) | . | 딥러닝 TensorFlow도 Numpy와도 타이트한 관계가 있다. | . . 1차원 배열(벡터), 2차원 배열(행렬), 3차원 배열 | . training set / test set (using Numpy) . input과 target이 함께 섞여서 이동을 해야한다. (섞여야 한다) | 지도학습에서 입력과 타겟이 쌍을 이루고 있게 되는데 따로따로 섞여버리면 정답을 제대로 못주게 되서 엉터리 훈련이 되버린다. | 입력데이터 특성값과 타깂값이 쌍으로 잘 따라서 섞이도록 만들어야 하는것이 중요!!! index를 섞어 분리하는 방법 | . | . import numpy as np . input_arr = np.array(fish_data) target_arr = np.array(fish_target) . print(input_arr) . [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ] [ 29.7 450. ] [ 29.7 500. ] [ 30. 390. ] [ 30. 450. ] [ 30.7 500. ] [ 31. 475. ] [ 31. 500. ] [ 31.5 500. ] [ 32. 340. ] [ 32. 600. ] [ 32. 600. ] [ 33. 700. ] [ 33. 700. ] [ 33.5 610. ] [ 33.5 650. ] [ 34. 575. ] [ 34. 685. ] [ 34.5 620. ] [ 35. 680. ] [ 35. 700. ] [ 35. 725. ] [ 35. 720. ] [ 36. 714. ] [ 36. 850. ] [ 37. 1000. ] [ 38.5 920. ] [ 38.5 955. ] [ 39.5 925. ] [ 41. 975. ] [ 41. 950. ] [ 9.8 6.7] [ 10.5 7.5] [ 10.6 7. ] [ 11. 9.7] [ 11.2 9.8] [ 11.3 8.7] [ 11.8 10. ] [ 11.8 9.9] [ 12. 9.8] [ 12.2 12.2] [ 12.4 13.4] [ 13. 12.2] [ 14.3 19.7] [ 15. 19.9]] . print(input_arr.shape) . (49, 2) . - 0~48까지 정수로된 index 만들기 . index = np.arange(49) index . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]) . - index를 섞어준다. . np.random.seed(42) np.random.shuffle(index) . print(index) . [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] . 잘 섞였다... | . input_arr[:5] . array([[ 25.4, 242. ], [ 26.3, 290. ], [ 26.5, 340. ], [ 29. , 363. ], [ 29. , 430. ]]) . print(input_arr[[1,3]]) . [[ 26.3 290. ] [ 29. 363. ]] . - 랜덤하게 섞인 인덱스 배열에서 앞부분 35개를 훈련셋으로 두고, 뒷부분 14개를 테스트 셋으로 둔다 . print(index) . [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] . train_input = input_arr[index[:35]] train_target = target_arr[index[:35]] . print(input_arr[13], train_input[0]) . [ 32. 340.] [ 32. 340.] . test_input = input_arr[index[35:]] test_target = target_arr[index[35:]] . import matplotlib.pyplot as plt plt.scatter(train_input[:,0], train_input[:,1]) plt.scatter(test_input[:,0], test_input[:,1]) plt.xlabel(&#39;length&#39;) plt.ylabel(&#39;weight&#39;) plt.show() . KNN (&#46160;&#48264;&#51704; &#49884;&#46020;) . kn = kn.fit(train_input, train_target) . kn.score(test_input, test_target) . 1.0 . 잘 훈련되었다. | . kn.predict(test_input) . array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) . test_target . array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) . Summary . Numpy를 이용해서 데이터를 섞어서 만들때, 배열 자체를 섞지 않고 (특성데이터와 타깃테이터가 쌍을 이루어서 섞어야 하므로) . | 배열의 인덱스배열을 만들어서 인덱스를 섞은 후에 . | 섞인 인덱스를 가지고 배열 슬라이싱을 하여 훈련세트와 테스트셋으로 나눈다. . | 이렇게 나눈 것으로 KNN으로 다시 훈련해서 모델을 평가 . | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/19/ML.html",
            "relUrl": "/python/2022/03/19/ML.html",
            "date": " • Mar 19, 2022"
        }
        
    
  
    
        ,"post26": {
            "title": "(3주차 DV) 3월 18일",
            "content": "import pandas as pd . pd.read_csv(&#39;C:/Users/82103/Desktop/2022-1/머신러닝/data/train.csv&#39;) . Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice . 0 1 | 60 | RL | 65.0 | 8450 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 2 | 2008 | WD | Normal | 208500 | . 1 2 | 20 | RL | 80.0 | 9600 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 5 | 2007 | WD | Normal | 181500 | . 2 3 | 60 | RL | 68.0 | 11250 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 9 | 2008 | WD | Normal | 223500 | . 3 4 | 70 | RL | 60.0 | 9550 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 2 | 2006 | WD | Abnorml | 140000 | . 4 5 | 60 | RL | 84.0 | 14260 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 12 | 2008 | WD | Normal | 250000 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1455 1456 | 60 | RL | 62.0 | 7917 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 8 | 2007 | WD | Normal | 175000 | . 1456 1457 | 20 | RL | 85.0 | 13175 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | MnPrv | NaN | 0 | 2 | 2010 | WD | Normal | 210000 | . 1457 1458 | 70 | RL | 66.0 | 9042 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | GdPrv | Shed | 2500 | 5 | 2010 | WD | Normal | 266500 | . 1458 1459 | 20 | RL | 68.0 | 9717 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 4 | 2010 | WD | Normal | 142125 | . 1459 1460 | 20 | RL | 75.0 | 9937 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 6 | 2008 | WD | Normal | 147500 | . 1460 rows × 81 columns . df_train = pd.read_csv(&#39;C:/Users/82103/Desktop/2022-1/머신러닝/data/train.csv&#39;) df_test = pd.read_csv(&#39;C:/Users/82103/Desktop/2022-1/머신러닝/data/test.csv&#39;) . from pandas.core.groupby.generic import ScalarResult import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import numpy as np from scipy.stats import norm from sklearn.preprocessing import StandardScaler from scipy import stats import warnings warnings.filterwarnings(&#39;ignore&#39;) %matplotlib inline . df_train.columns . Index([&#39;Id&#39;, &#39;MSSubClass&#39;, &#39;MSZoning&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;Street&#39;, &#39;Alley&#39;, &#39;LotShape&#39;, &#39;LandContour&#39;, &#39;Utilities&#39;, &#39;LotConfig&#39;, &#39;LandSlope&#39;, &#39;Neighborhood&#39;, &#39;Condition1&#39;, &#39;Condition2&#39;, &#39;BldgType&#39;, &#39;HouseStyle&#39;, &#39;OverallQual&#39;, &#39;OverallCond&#39;, &#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;RoofStyle&#39;, &#39;RoofMatl&#39;, &#39;Exterior1st&#39;, &#39;Exterior2nd&#39;, &#39;MasVnrType&#39;, &#39;MasVnrArea&#39;, &#39;ExterQual&#39;, &#39;ExterCond&#39;, &#39;Foundation&#39;, &#39;BsmtQual&#39;, &#39;BsmtCond&#39;, &#39;BsmtExposure&#39;, &#39;BsmtFinType1&#39;, &#39;BsmtFinSF1&#39;, &#39;BsmtFinType2&#39;, &#39;BsmtFinSF2&#39;, &#39;BsmtUnfSF&#39;, &#39;TotalBsmtSF&#39;, &#39;Heating&#39;, &#39;HeatingQC&#39;, &#39;CentralAir&#39;, &#39;Electrical&#39;, &#39;1stFlrSF&#39;, &#39;2ndFlrSF&#39;, &#39;LowQualFinSF&#39;, &#39;GrLivArea&#39;, &#39;BsmtFullBath&#39;, &#39;BsmtHalfBath&#39;, &#39;FullBath&#39;, &#39;HalfBath&#39;, &#39;BedroomAbvGr&#39;, &#39;KitchenAbvGr&#39;, &#39;KitchenQual&#39;, &#39;TotRmsAbvGrd&#39;, &#39;Functional&#39;, &#39;Fireplaces&#39;, &#39;FireplaceQu&#39;, &#39;GarageType&#39;, &#39;GarageYrBlt&#39;, &#39;GarageFinish&#39;, &#39;GarageCars&#39;, &#39;GarageArea&#39;, &#39;GarageQual&#39;, &#39;GarageCond&#39;, &#39;PavedDrive&#39;, &#39;WoodDeckSF&#39;, &#39;OpenPorchSF&#39;, &#39;EnclosedPorch&#39;, &#39;3SsnPorch&#39;, &#39;ScreenPorch&#39;, &#39;PoolArea&#39;, &#39;PoolQC&#39;, &#39;Fence&#39;, &#39;MiscFeature&#39;, &#39;MiscVal&#39;, &#39;MoSold&#39;, &#39;YrSold&#39;, &#39;SaleType&#39;, &#39;SaleCondition&#39;, &#39;SalePrice&#39;], dtype=&#39;object&#39;) . df_test.columns . Index([&#39;Id&#39;, &#39;MSSubClass&#39;, &#39;MSZoning&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;Street&#39;, &#39;Alley&#39;, &#39;LotShape&#39;, &#39;LandContour&#39;, &#39;Utilities&#39;, &#39;LotConfig&#39;, &#39;LandSlope&#39;, &#39;Neighborhood&#39;, &#39;Condition1&#39;, &#39;Condition2&#39;, &#39;BldgType&#39;, &#39;HouseStyle&#39;, &#39;OverallQual&#39;, &#39;OverallCond&#39;, &#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;RoofStyle&#39;, &#39;RoofMatl&#39;, &#39;Exterior1st&#39;, &#39;Exterior2nd&#39;, &#39;MasVnrType&#39;, &#39;MasVnrArea&#39;, &#39;ExterQual&#39;, &#39;ExterCond&#39;, &#39;Foundation&#39;, &#39;BsmtQual&#39;, &#39;BsmtCond&#39;, &#39;BsmtExposure&#39;, &#39;BsmtFinType1&#39;, &#39;BsmtFinSF1&#39;, &#39;BsmtFinType2&#39;, &#39;BsmtFinSF2&#39;, &#39;BsmtUnfSF&#39;, &#39;TotalBsmtSF&#39;, &#39;Heating&#39;, &#39;HeatingQC&#39;, &#39;CentralAir&#39;, &#39;Electrical&#39;, &#39;1stFlrSF&#39;, &#39;2ndFlrSF&#39;, &#39;LowQualFinSF&#39;, &#39;GrLivArea&#39;, &#39;BsmtFullBath&#39;, &#39;BsmtHalfBath&#39;, &#39;FullBath&#39;, &#39;HalfBath&#39;, &#39;BedroomAbvGr&#39;, &#39;KitchenAbvGr&#39;, &#39;KitchenQual&#39;, &#39;TotRmsAbvGrd&#39;, &#39;Functional&#39;, &#39;Fireplaces&#39;, &#39;FireplaceQu&#39;, &#39;GarageType&#39;, &#39;GarageYrBlt&#39;, &#39;GarageFinish&#39;, &#39;GarageCars&#39;, &#39;GarageArea&#39;, &#39;GarageQual&#39;, &#39;GarageCond&#39;, &#39;PavedDrive&#39;, &#39;WoodDeckSF&#39;, &#39;OpenPorchSF&#39;, &#39;EnclosedPorch&#39;, &#39;3SsnPorch&#39;, &#39;ScreenPorch&#39;, &#39;PoolArea&#39;, &#39;PoolQC&#39;, &#39;Fence&#39;, &#39;MiscFeature&#39;, &#39;MiscVal&#39;, &#39;MoSold&#39;, &#39;YrSold&#39;, &#39;SaleType&#39;, &#39;SaleCondition&#39;], dtype=&#39;object&#39;) . df_train[&#39;SalePrice&#39;].describe() ## 부동산 가격의 기술통계량 . count 1460.000000 mean 180921.195890 std 79442.502883 min 34900.000000 25% 129975.000000 50% 163000.000000 75% 214000.000000 max 755000.000000 Name: SalePrice, dtype: float64 . sns.distplot(df_train[&#39;SalePrice&#39;]) ## line : kernel density plot ## 목표변수에 대한 히스토그램과 kernel density plot . print(&quot;Skewness: %f&quot; % df_train[&#39;SalePrice&#39;].skew()) print(&quot;Kurtosis: %f&quot; % df_train[&#39;SalePrice&#39;].kurt()) ## 꼬리가 두터운 정도 (이상치가 많을수록 두꺼움) . Skewness: 1.882876 Kurtosis: 6.536282 . $-2 sim2$ 사이의 값이므로 치우침이 없는 데이터 (by. George &amp; Mallery, 2010) | 첨도가 높으면 (Kurtosis &gt; 3) 이상치가 많이 있다는 것. | . 많은 통계기법들이 정규성을 가정한다. | . positive skewness : 오른쪽 꼬리, 왼쪽에 데이터가 많다. | negative skewness : 왼쪽 꼬리, 오른쪽에 데이터가 많다. | . 왜도, 첨도 읽어보기 . . . var1 = &#39;GrLivArea&#39; # 지상 거실 면적 평방피트 data1 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var1]], axis=1) ## 열로 합치기(axis=1) . data1.plot.scatter(x=var1, y=&#39;SalePrice&#39;, ylim=(0,800000)) . &lt;AxesSubplot:xlabel=&#39;GrLivArea&#39;, ylabel=&#39;SalePrice&#39;&gt; . linear relationship | . var2 = &#39;TotalBsmtSF&#39; # 지하 총 평방 피트 data2 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var2]], axis=1) # 열기준으로 붙임 data2.plot.scatter(x=var2, y=&#39;SalePrice&#39;, ylim=(0,800000)) . &lt;AxesSubplot:xlabel=&#39;TotalBsmtSF&#39;, ylabel=&#39;SalePrice&#39;&gt; . 더 strong 한 linear relationship ( 더 가파르다. ) | . var1 = &#39;GrLivArea&#39; data1 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var1]], axis=1) plt.scatter(var1, y=&#39;SalePrice&#39;, data = data1) . &lt;matplotlib.collections.PathCollection at 0x24f2102bca0&gt; . var2 = &#39;TotalBsmtSF&#39; data2 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var2]], axis=1) plt.scatter(var2, y=&#39;SalePrice&#39;, data = data2) . &lt;matplotlib.collections.PathCollection at 0x24f21535ac0&gt; . data2 . SalePrice OverallQual . 0 208500 | 7 | . 1 181500 | 6 | . 2 223500 | 7 | . 3 140000 | 7 | . 4 250000 | 8 | . ... ... | ... | . 1455 175000 | 6 | . 1456 210000 | 6 | . 1457 266500 | 7 | . 1458 142125 | 5 | . 1459 147500 | 5 | . 1460 rows × 2 columns . var3 = &#39;OverallQual&#39; # 전체 제료 및 마감품질 data3 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var3]], axis=1) # 열로 합치기 f, ax = plt.subplots(figsize=(8,6)) fig = sns.boxplot(x=var3, y=&quot;SalePrice&quot;, data=data3) fig.axis(ymin=0, ymax=800000) . (-0.5, 9.5, 0.0, 800000.0) . var4 = &#39;YearBuilt&#39; # 원래 건설 날짜 data4 = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var4]], axis=1) f, ax = plt.subplots(figsize=(16,8)) fig = sns.boxplot(x=var4, y=&quot;SalePrice&quot;, data=data4) fig.axis(ymin=0, ymax=800000) plt.xticks(rotation=90) # x축 눈금 값 90도 회전. .",
            "url": "https://pinkocto.github.io/BP2022/2022/03/18/DV.html",
            "relUrl": "/2022/03/18/DV.html",
            "date": " • Mar 18, 2022"
        }
        
    
  
    
        ,"post27": {
            "title": "(2주차 ML) 3월 10일",
            "content": "&#49373;&#49440; &#48516;&#47448; &#47928;&#51228; . &#46020;&#48120;(bream) &#45936;&#51060;&#53552; &#51456;&#48708;&#54616;&#44592; . bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0] bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0] . import matplotlib.pyplot as plt plt.scatter(bream_length, bream_weight) plt.xlabel(&#39;length&#39;) # 몸 길이 plt.ylabel(&#39;weight&#39;) # 몸 무게 . Text(0, 0.5, &#39;weight&#39;) . &#48729;&#50612;(smelt) &#45936;&#51060;&#53552; &#51456;&#48708;&#54616;&#44592; . smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] . plt.scatter(bream_length, bream_weight, label=&#39;bream&#39;) ## 도미 plt.scatter(smelt_length, smelt_weight, label=&#39;smelt&#39;) ## 빙어 plt.xlabel(&#39;length&#39;) plt.ylabel(&#39;weight&#39;) plt.legend() plt.show() . 빙어는 길이가 늘어나더라도 무게가 많이 늘지 않는다. $ Rightarrow$ 빙어의 산점도 역시 선형적이지만 무게가 길이에 영향을 덜 받는다. | . binary classification (&#46020;&#48120;, &#48729;&#50612;) &#51456;&#48708; . 다음으로 데이터만 보고 어떤 것이 도미이고 어떤 것이 빙어인지 스스로 구분하기 위해 프로그램을 만들어 보자! | KNN(K-Nearest Neighbors) 방법을 이용할 것. | . - 우선 KNN 알고리즘을 써먹으려면 도미와 빙어 데이터를 하나의 데이터로 합쳐야 한다. . length = bream_length + smelt_length weight = bream_weight + smelt_length . + 연산자가 list 일 경우에는 합쳐지는 역할을 하고, 정수일 때는 우리가 일반적으로 알고있는 덧셈 연산을 한다. | . len(bream_length), len(smelt_length), len(bream_weight), len(smelt_length) . (35, 14, 35, 14) . len(length), len(weight) . (49, 49) . 잘 합쳐진 것 같다. | . - 2차원 리스트로 만들어 보자. (Scikit-learn을 사용하기위해) . ## 이런 식으로 2차원 리스트로 만들것! 길이 무게 [[25.4, 242.0], [26.3, 290.0]. . . . . . . [15.0, 19.9]] . fish_data = [[l,w] for l, w in zip(length, weight)] . - 정답 준비 . 도미(bream)를 1로 놓고, 빙어(smelt)를 0으로 놓자. (0과 1로 분류하는 이진분류) | . fish_target = [1]*35 + [0]*14 . K-&#52572;&#44540;&#51217; &#51060;&#50883; . from sklearn.neighbors import KNeighborsClassifier . kn = KNeighborsClassifier() # class의 instance(객체) 를 만든다. . kn.fit(fish_data, fish_target) ## kn을 모델이라 부름 . KNeighborsClassifier() . 머신러닝 프로그램의 알고리즘이 객체화 된것을 모델이라고 부른다. | 종종 그 알고리즘 자체를 모델이라고도 부름. | . kn.score(fish_data, fish_target) . 1.0 . 100% 다 맞췄다! (100% 정확도 달성!) | . &#49352;&#47196;&#50868; &#49373;&#49440; &#50696;&#52769; . 그래프에 표시된 초록색 삼각형은 어떤 생선일까? | . plt.scatter(bream_length, bream_weight, label=&#39;bream&#39;) plt.scatter(smelt_length, smelt_weight, label=&#39;smelt&#39;) plt.scatter(30, 600, marker=&#39;^&#39;) plt.xlabel(&#39;length&#39;) plt.ylabel(&#39;weight&#39;) plt.legend() plt.show() . 직관적으로 봤을때 도미(bream) 일 것 같다. | 실제로도 그런지 확인해보자. | . kn.predict([[30, 600]]) ## predict method . array([1]) . predict method 안에 넣을 때도 2차원 배열 데이터를 넣어준다. (사이킷런이 기대하는 것) | n_neighbors=5가 default, 주위에 있는 이웃의 개수(K)만큼 주변 샘플의 class 중 가장 많은 클래스를 정답클래스로 삼는다. | . print(kn._fit_X) . [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ] [ 29.7 450. ] [ 29.7 500. ] [ 30. 390. ] [ 30. 450. ] [ 30.7 500. ] [ 31. 475. ] [ 31. 500. ] [ 31.5 500. ] [ 32. 340. ] [ 32. 600. ] [ 32. 600. ] [ 33. 700. ] [ 33. 700. ] [ 33.5 610. ] [ 33.5 650. ] [ 34. 575. ] [ 34. 685. ] [ 34.5 620. ] [ 35. 680. ] [ 35. 700. ] [ 35. 725. ] [ 35. 720. ] [ 36. 714. ] [ 36. 850. ] [ 37. 1000. ] [ 38.5 920. ] [ 38.5 955. ] [ 39.5 925. ] [ 41. 975. ] [ 41. 950. ] [ 9.8 9.8] [ 10.5 10.5] [ 10.6 10.6] [ 11. 11. ] [ 11.2 11.2] [ 11.3 11.3] [ 11.8 11.8] [ 11.8 11.8] [ 12. 12. ] [ 12.2 12.2] [ 12.4 12.4] [ 13. 13. ] [ 14.3 14.3] [ 15. 15. ]] . print(kn._y) . [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0] . &#47924;&#51312;&#44148; &#46020;&#48120; . Fish 데이터의 총 개수는 49개이다. 이번에는 n_neighbors = 49로 지정 해보자. . kn49 = KNeighborsClassifier(n_neighbors=49) . kn49.fit(fish_data, fish_target) . KNeighborsClassifier(n_neighbors=49) . kn49.score(fish_data, fish_target) ## 점수 . 0.7142857142857143 . score method : 훈련한 모델을 가지고 어떤 데이터를 집어 넣어서 얼마만큼 잘 맞는지를 확인해 보는 것이다. | 분류문제일 경우에는 정확도를 출력 (모델이 어느정도 정확한지를 알아보는 메서드.) | . print(35/49) . 0.7142857142857143 . 이렇게 모델을 만들면 전체 샘플의 다수는 도미 $ to$ 무조건 다 도미 | n_neighbors 매개변수로 주위의 샘플개수를 바꿔볼 수도 있다. 바꾸면 알고리즘의 정확도가 높을수록, 낮을수도 있다. | . &#54869;&#51064; &#47928;&#51228; . kn = KNeighborsClassifier() kn.fit(fish_data, fish_target) for n in range(5, 50): # 최근접 이웃 개수 설정 kn.n_neighbors = n #접수 계산 score = kn.score(fish_data, fish_target) # 100% 정확도에 미치지 못하는 이웃 개수 출력 if score &lt; 1: print(n, score) break . 18 0.9795918367346939 .",
            "url": "https://pinkocto.github.io/BP2022/2022/03/17/ML.html",
            "relUrl": "/2022/03/17/ML.html",
            "date": " • Mar 17, 2022"
        }
        
    
  
    
        ,"post28": {
            "title": "tips",
            "content": "1. csv&#54028;&#51068; upload . 참고링크 : https://evidencen.com/how-to-upload-your-csv-file-online/ . import pandas as pd . autompg.csv github notebooks에 upload | autommpg.csv 파일 click | Raw / Blame에서 Raw 버튼 click | 상단의 링크 복사 | . 복사한 주소 : https://raw.githubusercontent.com/pinkocto/BP2022/master/_notebooks/autompg.csv . pd.read_csv(&quot;https://raw.githubusercontent.com/pinkocto/BP2022/master/_notebooks/autompg.csv&quot;) . mpg cyl disp hp wt accler year origin carname . 0 18.0 | 8 | 307.0 | 17 | 3504 | 12.0 | 70 | 1 | chevrolet chevelle malibu | . 1 15.0 | 8 | 350.0 | 35 | 3693 | 11.5 | 70 | 1 | buick skylark 320 | . 2 18.0 | 8 | 318.0 | 29 | 3436 | 11.0 | 70 | 1 | plymouth satellite | . 3 16.0 | 8 | 304.0 | 29 | 3433 | 12.0 | 70 | 1 | amc rebel sst | . 4 17.0 | 8 | 302.0 | 24 | 3449 | 10.5 | 70 | 1 | ford torino | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 393 27.0 | 4 | 140.0 | 82 | 2790 | 15.6 | 82 | 1 | ford mustang gl | . 394 44.0 | 4 | 97.0 | 53 | 2130 | 24.6 | 82 | 2 | vw pickup | . 395 32.0 | 4 | 135.0 | 80 | 2295 | 11.6 | 82 | 1 | dodge rampage | . 396 28.0 | 4 | 120.0 | 75 | 2625 | 18.6 | 82 | 1 | ford ranger | . 397 31.0 | 4 | 119.0 | 78 | 2720 | 19.4 | 82 | 1 | chevy s-10 | . 398 rows × 9 columns . 깃헙에 업로드 한 csv파일을 잘 읽어오는 것을 확인 할 수 있다. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/03/02/upload.html",
            "relUrl": "/python/2022/03/02/upload.html",
            "date": " • Mar 2, 2022"
        }
        
    
  
    
        ,"post29": {
            "title": "(6주차) 2월18일 (3)",
            "content": "- 파일과 경로 . - 텍스트 파일 열기, 쓰기, 읽기 . - Tkinter 파일 다이얼로그를 이용한 예제 . &#54028;&#51068; . 목적 자료를 영구히 보관하기 위해 사용됨 | . | . 종류: 저장된 데이터에 따라 텍스트 파일 일반적인 문자 코드 | . | 이진 파일 사진, 음악, 비디오 | . | . | . 파일의 위치 폴더에 존재 | 폴더는 다른 폴더에 포함되어 있음 | 경로 : 어떤 폴더로부터 그 파일에 이르는 방법 | . | . - &#54028;&#51068; &#44221;&#47196; . * 경로의 종류 . 절대 경로: 루트 폴더로투터 시작 ex) c: users user documents hello.py | . | . 상대 경로: 현재 폴더로부터 시작 | . * 폴더를 표시하는 특수한 기호 . . : 현재 폴더를 의미함 | .. : 현재 폴더의 부모 (즉, 상위폴더를 의미함) | . &gt; &gt;&gt; import os &gt;&gt;&gt; os.getcwd() ## 현재 폴더 경로 &#39;C: USERS USER .... python3.7&#39;&gt; &gt;&gt; os.chdir(&quot;C: Users Users Documents&quot;) ## 현재폴더 경로 변경&gt; &gt;&gt; os.getcwd() ## 현재 폴더 경로 &quot;C: Users Users Documents&quot; ## 바뀐 경로로 출력된 것 확인 . - &#44221;&#47196; &#48516;&#47532; &#47928;&#51088; . Windows에서 경로 분리 문자는 문제는 Escape-Sequence를 나타낼 때 사용됨 | 그냥 문자를 표시하기 위해서는 를 사용 | . | . Unix, Linux 계열에서 경로 분리 문자는 / Windows 위에서 실행되는 파이썬에서 사용 가능 | 앞의 예는 &quot;C:/Users/Users/Documents&quot;로 써도 가능! | . | . Raw 문자열 사용방법 r&quot;문자열&quot;은 문자열 내 모든 특수문자를 무시하고 일반 문자로 취급함 | r&quot;C: Users Users Documents&quot;로 써도 가능! | . | . - &#54028;&#51068; &#50676;&#44592; . open() 이라는 내장 함수를 사용 | . fileVar = open(filename, mode) . open() 함수는 파일 열기를 성공하면 파일을 나타내는 객체를 반환함 _io.TextIoWrapper 클래스 객체임 | . | . . - &#54028;&#51068; &#50676;&#44592; &#47784;&#46300; . 파일열기모드 설명 . r (읽기모드) | 파일을 읽기만 할 때 사용한다 | . w (쓰기모드) | 파일에 내용을 쓸 때 사용하며 기존 파일이 존재하면 내용이 모두 초기화되고 &lt;/br&gt; 주어진 파일이 존재하지 않으면 새로운 파일을 만든다 | . a (추가모드) | 기존 파일의 마지막에 새로운 내용을 추가 시킬 때 사용한다 | . rb, wb | 각각 이진 파일을 읽기 위해 혹은 쓰기 위해 열때 사용한다 | . - &#54028;&#51068;&#50640; &#45936;&#51060;&#53552; &#50416;&#44592; . write() 메서드 사용 | . ofile = open(&quot;snowwhite.txt&quot;, &quot;w&quot;) # 1 ofile.write(&quot;Once upon a time, long, long ago n&quot;) # 2 ofile.write(&quot;a king and queen ruled over n&quot;) ofile.write(&quot;a distant land&quot;) ofile.close() . - &#54028;&#51068;&#51060; &#51316;&#51116;&#54616;&#45716;&#51648; &#44160;&#49324;&#54616;&#44592; . os.path.exist(경로) . 파일이 존재하면 True, 아니면 False를 반환 | . | os.path.isdir(경로) . 지정된 파일이 폴더이면 True, 아니면 False를 반환 | . | os.path.isfile(경로) . 지정된 파일이 일반 파일이면 True, 아니면 False를 반환 | . | . - &#54028;&#51068; &#51088;&#47308; &#51069;&#44592; . 파이썬에는 외부파일을 읽어 들여 프로그램에서 사용할 수 있는 여러가지 방법이 있다. . 전체 데이터를 읽는 메서드 : read(), reaadlines() . | 한 줄을 읽는 메서드 : readline() . | 주어진 길이를 읽는 메서드: read(n) . | . - &#51204;&#52404; &#51069;&#44592; . - 방법1: read() 함수 사용하기 . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) ## 읽기 readResult = ifile.read() print(&quot;Read Result:&quot;) print(repr(readResult)) ## repr(): 줄바꿈 문자도 그대로 출력 ifile.close() . Read Result: &#39;Once upon a time, long, long ago na king and queen ruled over na distant land&#39; . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) ## 읽기 readResult = ifile.read() print(&quot;Read Result:&quot;) print(readResult) ifile.close() . Read Result: Once upon a time, long, long ago a king and queen ruled over a distant land . read() 는 파일의 내용 전체를 문자열로 돌려준다. | . - 방법2: readlines() 함수 사용하기 . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) readLinesResult = ifile.readlines() print(&quot;Read Lines Result:&quot;) print(readLinesResult) ifile.close() . Read Lines Result: [&#39;Once upon a time, long, long ago n&#39;, &#39;a king and queen ruled over n&#39;, &#39;a distant land&#39;] . readline() 함수는 파일의 모든 줄을 읽어서 각각의 줄을 요소로 갖는 리스트로 돌려준다. | . - 방법2 + 줄바꿈( n) 문자 제거하기 . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) lines = ifile.readlines() for line in lines: line = line.strip() # 줄 끝의 줄 바꿈 문자를 제거 print(line) ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . - &#51648;&#51221;&#46108; &#44600;&#51060;&#47564;&#53372; &#51069;&#44592; . file.read(n) : 현재 file pointer로부터 n개의 글자를 읽어서 문자열로 반환 | . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) str1 = ifile.read(4) print(&quot;Read(4) Result:&quot;) print(repr(str1)) str2 = ifile.read(10) print(&quot;Read(10) Result:&quot;) print(repr(str2)) ifile.close() . Read(4) Result: &#39;Once&#39; Read(10) Result: &#39; upon a ti&#39; . - &#54620; &#51460;&#50473; &#51069;&#44592; &#44208;&#44284; . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) ifile.readline() ## 1 . &#39;Once upon a time, long, long ago n&#39; . ifile.readline() ## 2 . &#39;a king and queen ruled over n&#39; . ifile.readline() ## 3 . &#39;a distant land&#39; . ifile.readline() ## 4 . &#39;&#39; . line이 끝에 다다르면 빈문자(&#39;&#39;)가 출력된다. | . - &#54028;&#51068;&#50640; &#47336;&#54532; &#49324;&#50857;&#54616;&#44592; . 루프를 사용하여 파일을 한 줄씩 처리하기 . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) line = ifile.readline() while line != &#39;&#39;: # line 처리 print(line) line = ifile.readline() ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) while True: line = ifile.readline() if not line: break print(line) ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . ifile = open(&quot;snowwhite.txt&quot;, &quot;r&quot;) lines = ifile.readlines() for line in lines: # line 처리 print(line) ifile.close() . Once upon a time, long, long ago a king and queen ruled over a distant land . - &#49707;&#51088;&#44032; &#46308;&#50612;&#44032; &#51080;&#45716; &#54028;&#51068; &#52376;&#47532; . ofile = open(&quot;num.txt&quot;, &quot;w&quot;) ofile.write(&quot;10 20 12 5 n&quot;) ofile.write(&quot;8 9 7 23 n&quot;) ofile.write(&quot;1 8 22 9&quot;) ofile.close() . num.txt 아래와 같은 파일이 있을 떄 파일에 있는 숫자의 합을 구해보자. | . ofile = open(&quot;num.txt&quot;, &quot;r&quot;) print(ofile.read()) ofile.close() . 10 20 12 5 8 9 7 23 1 8 22 9 . ofile = open(&quot;num.txt&quot;, &quot;r&quot;) total = 0 for line in ofile: lineLst = line.split() numList = [eval(x) for x in lineLst] total += sum(numList) print(total) . 134 . 10+20+12+5+8+9+7+23+1+8+22+9 . 134 . 잘 계산된 것을 확인할 수 있다. | .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/02/18/(3).html",
            "relUrl": "/python/2022/02/18/(3).html",
            "date": " • Feb 18, 2022"
        }
        
    
  
    
        ,"post30": {
            "title": "(6주차) 2월18일 (1)",
            "content": "- 소개 . - 2차원 리스트 처리 . - 2차원 리스트와 함수 . - 예제 . - 다차원 리스트 . &#49548;&#44060; . 테이블이나 행렬은 2차원 리스트로 표현할 수 있다. . - 대한민국 도시들 간 거리 . 서울 부산 대구 광주 . 서울 | 0 | 325 | 237 | 267 | . 부산 | 325 | 0 | 87 | 202 | . 대구 | 237 | 87 | 0 | 172 | . 광주 | 267 | 202 | 172 | 0 | . distance = [[0, 325, 237, 267], [325, 0, 87, 202], [237, 87, 0, 172], [267, 202, 172, 0]] . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52376;&#47532;&#54616;&#44592; . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#54364;&#54788; . matrix_ = [[1,2,3,4,5], [6,7,8,9,10], [11,12,13,14,15]] . - 각 요소는 두 개의 첨자를 이용하여 표현 . matrix_[0][2] . 3 . matrix_[2][3] . 14 . matrix_[1][1] . 7 . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52488;&#44592;&#54868; . - 사용자 입력 값으로 초기화 . - 무작위 값으로 초기화 . matrix = [] for row in range(3): ## number of rows = 3 matrix.append([]) for col in range(2): ## number of columns = 2 value = eval(input(&quot;value:&quot;)) matrix[row].append(value) . matrix ## 3행 2열의 2차원 리스트 . [[1, 2], [3, 4], [5, 6]] . import random matrix = [] numberOfRows=3 numberOfColumns=2 for row in range(numberOfRows): matrix.append([]) #print(matrix) for col in range(numberOfColumns): matrix[row].append(random.randint(0,99)) #print(matrix) . [[]] [[51]] [[51, 15]] [[51, 15], []] [[51, 15], [47]] [[51, 15], [47, 46]] [[51, 15], [47, 46], []] [[51, 15], [47, 46], [79]] [[51, 15], [47, 46], [79, 98]] . matrix . [[51, 15], [47, 46], [79, 98]] . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52636;&#47141;&#54616;&#44592;, &#49438;&#44592;, &#51221;&#47148; . - 2차원 리스트 출력 . len(matrix), len(matrix[0]) . (3, 2) . for row in range(len(matrix)): for col in range(len(matrix[row])): print(matrix[row][col], end=&#39; &#39;) print() . 51 15 47 46 79 98 . - 2차원 리스트 섞기 . matrix . [[51, 15], [47, 46], [79, 98]] . for row in range(len(matrix)): for col in range(len(matrix[row])): i = random.randint(0, len(matrix)-1) j = random.randint(0, len(matrix[row])-1) matrix[row][col], matrix[i][j] = matrix[i][j], matrix[row][col] . matrix . [[79, 98], [46, 15], [47, 51]] . 리스트 안의 원소들이 잘 섞여진 것을 확인할 수 있다. | . 2&#52264;&#50896; &#47532;&#49828;&#53944; &#52376;&#47532; . - 모든 원소들의 합 구하기 . matrix . [[79, 98], [46, 15], [47, 51]] . total = 0 for row in matrix: for value in row: total += value print(total) . 79 177 223 238 285 336 . total . 336 . - 각 열의 합 구하기 . matrix . [[79, 98], [46, 15], [47, 51]] . for col in range(len(matrix[0])): total = 0 for row in range(len(matrix)): total += matrix[row][col] print(&quot;Sum of column&quot;, col, &quot;is&quot;, total) . Sum of column 0 is 172 Sum of column 1 is 164 . 79+46+47 # 1열 합 . 172 . 98+15+51 # 2열 합 . 164 . 각 열의 합이 잘 계산되었다. | . - 합이 가장 큰 행 구하기 . matrix . [[79, 98], [46, 15], [47, 51]] . maxRow = sum(matrix[0]) indexRow = 0 for row in range(1, len(matrix)): if sum(matrix[row]) &gt; maxRow: maxRow = sum(matrix[row]) indexRow = row print(&quot;Row&quot;, indexRow, &quot;has max sum of &quot; , maxRow) . Row 0 has max sum of 177 . - 리스트 정렬 . lst = [[1,2],[1,1],[3,1],[2,5]] lst . [[1, 2], [1, 1], [3, 1], [2, 5]] . lst.sort() lst . [[1, 1], [1, 2], [2, 5], [3, 1]] . 2&#52264;&#50896; &#47532;&#49828;&#53944;&#50752; &#54632;&#49688; . 2차원 리스트도 다른 객체와 마찬가지로 함수에 인수로 전달할 수도 있고, 함수가 반환값으로 반환할 수도 있다. . def getMatrix(): matrix = [] numRows = eval(input(&quot;Number of Rows: &quot;)) numCols = eval(input(&quot;Number of Colunmns: &quot;)) for row in range(numRows): matrix.append([]) for col in range(numCols): value = eval(input(&quot;value:&quot;)) matrix[row].append(value) return matrix . getMatrix() . [[79, 98], [46, 15], [17, 51]] . def accumulate(m): total = 0 for row in m: total += sum(row) return total . accumulate(matrix) . 336 . matrix의 모든 원소의 합은 336으로 위에서 구한 (2차원 리스트 처리: 모든 원소의 합)에서 구한 값과 같다. | . &#50696;&#51228;1 | &#44032;&#51109; &#44032;&#44620;&#50868; &#46160; &#51216;&#51008;? . 여러 점에 대한 좌표가 있다. 이들 점 중에서 가장 가까운 두 점을 찾아보자. . def distance(x1,y1,x2,y2): return((x1-x2)**2 + (y1-y2)**2)**0.5 def nearestPoint(points): p1, p2 = 0, 1 shortestDist = distance(points[p1][0], points[p1][1], points[p2][0], points[p2][1]) for i in range(len(points)): for j in range(i+1, len(points)): d = distance(points[i][0], points[i][1], points[j][0], points[j][1]) if d &lt; shortestDist: shortestDist = d p1, p2 = i, j return p1, p2 . nPoints = eval(input(&quot;점의 수:&quot;)) points = [] for i in range(nPoints): point = [0,0] point[0],point[1] = eval(input(&quot;좌표:&quot;)) points.append(point) p1, p2 = nearestPoint(points) print(&quot;(&quot;, points[p1][0], points[p1][1],&quot;)&quot;,&quot;(&quot;,points[p2][0], points[p2][1],&quot;)&quot;) . ( 0 0 ) ( 0 1 ) . nPoints = eval(input(&quot;점의 수:&quot;)) points = [] for i in range(nPoints): point = [0,0] point[0],point[1] = eval(input(&quot;좌표:&quot;)) points.append(point) p1, p2 = nearestPoint(points) print(&quot;(&quot;, points[p1][0], points[p1][1],&quot;)&quot;,&quot;(&quot;,points[p2][0], points[p2][1],&quot;)&quot;) . ( 2 5 ) ( 3 8 ) . &#50696;&#51228;2 | Sudoku . . [게임 규칙] . 각 열, 각 행에 1~9까지 숫자가 들어가야 한다. | $3 times 3$ 블록에 1~9가지 숫자가 들어가야 한다. | . &#50612;&#46500; Sudoku &#54644;&#44208;&#48169;&#48277;&#51060; &#47582;&#45716;&#51648; &#44160;&#49324; . 두가지 검사방법 . 각 행, 열, 블록이 1~9까지 숫자를 포함하고 있는지 검사 | | 각 셀에 대해 그 셀의 숫자가 행, 열, 블록에서 유일한지 검사 &lt; 이 방법 사용할 것임! | | . | . def isValid(grid): for i in range(9): for j in range(9): if grid[i][j] &lt; 1 or grid[i][j] &gt; 9 or not isValidAt(i,j,grid): return False return True . def isValidAt(i,j,grid): for column in range(9): if column != j and grid[i][column] == grid[i][j]: return False for row in range(9): if row != i and grid[row][j] == grid[i][j]: return False for row in range((i//3)*3, (j//3)*3 + 3): if row != i and column != j and grid[row][column] == grid[i][j]: return False return True . &#45796;&#52264;&#50896; &#47532;&#49828;&#53944; . 일반적으로 $n$개의 첨자 사용 | . m[i][j][k] . .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/02/18/(1).html",
            "relUrl": "/python/2022/02/18/(1).html",
            "date": " • Feb 18, 2022"
        }
        
    
  
    
        ,"post31": {
            "title": "test",
            "content": "import pandas as pd import altair as alt . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . selection = alt.selection_single(); alt.Chart(cars).mark_circle().add_selection( selection ).encode( x=&#39;Horsepower:Q&#39;, y=&#39;Miles_per_Gallon:Q&#39;, color=alt.condition(selection, &#39;Cylinders:O&#39;, alt.value(&#39;grey&#39;)), opacity=alt.condition(selection, alt.value(0.8), alt.value(0.1)) ) . def plot(selection): return alt.Chart(cars).mark_circle().add_selection( selection ).encode( x=&#39;Horsepower:Q&#39;, y=&#39;Miles_per_Gallon:Q&#39;, color=alt.condition(selection, &#39;Cylinders:O&#39;, alt.value(&#39;grey&#39;)), opacity=alt.condition(selection, alt.value(0.8), alt.value(0.1)) ).properties( width=240, height=180 ) . alt.hconcat( plot(alt.selection_single()).properties(title=&#39;Single (Click)&#39;), plot(alt.selection_multi()).properties(title=&#39;Multi (Shift-Click)&#39;), plot(alt.selection_interval()).properties(title=&#39;Interval (Drag)&#39;) ) . alt.hconcat( plot(alt.selection_single(on=&#39;mouseover&#39;)).properties(title=&#39;Single (Mouseover)&#39;), plot(alt.selection_multi(on=&#39;mouseover&#39;)).properties(title=&#39;Multi (Shift-Mouseover)&#39;) ) .",
            "url": "https://pinkocto.github.io/BP2022/python/2022/01/04/test.html",
            "relUrl": "/python/2022/01/04/test.html",
            "date": " • Jan 4, 2022"
        }
        
    
  
    
        ,"post32": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://pinkocto.github.io/BP2022/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post33": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://pinkocto.github.io/BP2022/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://pinkocto.github.io/BP2022/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  

  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://pinkocto.github.io/BP2022/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
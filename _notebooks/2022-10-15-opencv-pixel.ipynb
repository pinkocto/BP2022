{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da975849",
   "metadata": {},
   "source": [
    "# (OpenCV - Chap6) 화소(pixel)처리\n",
    "> 영상 화소의 접근과 화소 밝기 변환\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: true\n",
    "- author: pinkocto\n",
    "- categories: [python]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a87bf",
   "metadata": {},
   "source": [
    "## 화소의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119b9bc0",
   "metadata": {},
   "source": [
    "화소란 화면(영상)을 구성하는 가장 기본이 되는 단위를 말한다. 일반적으로 영상처리 입문에서 가장 먼저 다루는 내용이 화소값 기반 처리이다. 이것은 영상 구조에 대해 알기 위해 가장 먼저 이해해야 하는 것이 화소에 대한 기본 개념이기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06216a4e",
   "metadata": {},
   "source": [
    "디지털 영상은 이 화소들의 집합을 의미하며, 이 화소들에 대해 다양한 연산을 하는 것이 영상처리이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bdf493",
   "metadata": {},
   "source": [
    "## 6.1 영상화소의 접근"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c75725",
   "metadata": {},
   "source": [
    "영상처리를 아주 간단하게 말해보면, 2차원 데이터에 대한 행렬 연산이라고 할 수 있다.\n",
    "따라서 영상을 다루려면 기본적으로 영상의 화소에 접근하고, 그 값을 수정하거나 새로 만들 수 있어야 한다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "06445458",
   "metadata": {},
   "source": [
    "과거 OpenCV와 같은 대중적인 영상처리 API가 없었을 때, 영상 데이터를 처리하고 저장하는 것이 쉽지만은 않은 일이었다. 하지만 파이썬에서는 행렬 데이터 처리에 유용한 넘파이(Numpy) 라이브러리를 지원하고 있으며, OpenCV API도 numpy.ndarray 객체를 기반으로 영상 데이터를 처리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecd160c",
   "metadata": {},
   "source": [
    "### 6.1.1 화소(행렬 원소) 접근"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b00afdb",
   "metadata": {},
   "source": [
    "다음은 모든 원소를 순회하여 원소값을 2배로 변경하는 예제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f4aef",
   "metadata": {},
   "source": [
    "`-` 방법1\n",
    "\n",
    "행렬의 원소를 순회하며 직접 원소값을 가져와서 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3176270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mat_access1(mat):\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            k = mat[i, j]\n",
    "            mat[i, j] = k * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5515a4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = np.arange(10).reshape(2,5)\n",
    "mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58425072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원소 처리 전: \n",
      "[[ 0  2  4  6  8]\n",
      " [10 12 14 16 18]]\n",
      "\n",
      "원소 처리 후: \n",
      "[[ 0  4  8 12 16]\n",
      " [20 24 28 32 36]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('원소 처리 전: \\n%s\\n' % mat1)\n",
    "mat_access1(mat1)\n",
    "print('원소 처리 후: \\n%s\\n' % mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f4d05",
   "metadata": {},
   "source": [
    "`-` 방법2\n",
    "\n",
    "행렬 원소를 순회하며, ndarray 클래스의 내부 메서드인 **`item()`** 함수와 **`itemset()`** 함수로 가져와서 값을 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd804483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_access2(mat):\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            k = mat.item(i, j)  #\n",
    "            mat.itemset((i, j), k*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd3f1f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 = np.arange(10).reshape(2, 5)\n",
    "mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d8dad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원소 처리 전: \n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "\n",
      "원소 처리 후: \n",
      "[[ 0  2  4  6  8]\n",
      " [10 12 14 16 18]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('원소 처리 전: \\n%s\\n' % mat2)\n",
    "mat_access2(mat2)\n",
    "print('원소 처리 후: \\n%s\\n' % mat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1a24a",
   "metadata": {},
   "source": [
    "### 6.1.2  영상 반전을 수행하는 다양한 방법들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b33e66",
   "metadata": {},
   "source": [
    "행렬을 처리하여 영상의 반전을 수행하는 다양한 방법들을 함수로 만들고, 각 방법의 수행속도를 계산해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acb68597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mat::ptr()을 통한 행렬 원소 접근\n",
    "\n",
    "import numpy as np, cv2, time\n",
    "\n",
    "\n",
    "## 화소 직접접근\n",
    "def pixel_access1(image):\n",
    "    image1 = np.zeros(image.shape[:2], image.dtype)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            pixel = image[i,j]                 # 화소접근\n",
    "            image1[i, j] = 255 - pixel         # 화소할당\n",
    "            \n",
    "    return image1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c874d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## item() 함수\n",
    "def pixel_access2(image):                         # item() 함수 접근 방법\n",
    "    image2 = np.zeros(image.shape[:2], image.dtype)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            pixel = image.item(i, j)              # 화소접근\n",
    "            image2.itemset((i, j), 255 - pixel)   # 화소할당\n",
    "    return image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68e898d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 룩업테이블\n",
    "def pixel_access3(image):\n",
    "    lut = [255 - i for i in range(256)]\n",
    "    lut = np.array(lut, np.uint8)\n",
    "    image3 = lut[image]\n",
    "    return image3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e288c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## openCV\n",
    "def pixel_access4(image):\n",
    "    image4 = cv2.subtract(255, image)\n",
    "    return image4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b62c44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ndarray 산술연산\n",
    "def pixel_access5(image):\n",
    "    image5 = 255 - image\n",
    "    return image5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f61ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./ghtop_images/chap06_images/bright.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf7338cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 360)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bbfed2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 수행시간 체크 함수\n",
    "def time_check(func, msg):\n",
    "    start_time = time.perf_counter()\n",
    "    ret_img = func(image)\n",
    "    elapsed = (time.perf_counter() - start_time) * 1000\n",
    "    print(msg, \"수행시간 : %0.2f ms\" % elapsed )\n",
    "    return ret_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "185d0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[방법1] 직접 접근 방식 수행시간 : 550.22 ms\n",
      "[방법2] item() 접근 방식 수행시간 : 108.73 ms\n",
      "[방법3] 룩업테이블  방식 수행시간 : 0.92 ms\n",
      "[방법4] OpenCV 함수 방식 수행시간 : 0.08 ms\n",
      "[방법5] ndarray 방식 수행시간 : 0.19 ms\n"
     ]
    }
   ],
   "source": [
    "image1 = time_check(pixel_access1, \"[방법1] 직접 접근 방식\")\n",
    "image2 = time_check(pixel_access2, \"[방법2] item() 접근 방식\")\n",
    "image3 = time_check(pixel_access3, \"[방법3] 룩업테이블  방식\")\n",
    "image4 = time_check(pixel_access4, \"[방법4] OpenCV 함수 방식\")\n",
    "image5 = time_check(pixel_access5, \"[방법5] ndarray 방식\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b108fbe",
   "metadata": {},
   "source": [
    "실행결과를 보면, OpenCV 또는 ndarray 방식으로 화소에 접근하는 경우 속도가 빠른 것을 확인할 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9904a55",
   "metadata": {},
   "source": [
    "따라서 화소 직접 접근 방법보다는 OpenCV에서 제공하는 함수들을 조합하거나 ndarray 객체의 원소간 연산으로 구현 내용을 만드는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5db551",
   "metadata": {},
   "source": [
    "## 6.2 화소 밝기 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0716721",
   "metadata": {},
   "source": [
    "### 6.2.1 그레이 스케일 (명암도) 영상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b8741",
   "metadata": {},
   "source": [
    "일반적으로 이해하는 컬러가 아닌 영상을 우리는 흑백영상이라고 쉽게 부르지만, 엄밀한 의미에서 흑백 영상이라는 것은 검은색과 흰색으로 구성된 영상을 의미하기 때문에 단일채널 영상에 이 이름을 붙이는 것이 맞지 않을 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a21c5b",
   "metadata": {},
   "source": [
    "디지털 영상처리에서 보통 단일채널의 영상을 **그레이 스케일(gray-scale)영상** 혹은 **명암도 영상**이라고 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c30fc72",
   "metadata": {},
   "source": [
    "- 그레이 스케일 영상\n",
    "\n",
    "    - 0~255의 값을 가지는 화소들이 모여서 구성된 영상 <br>\n",
    "    - 0은 검은색, 255는 흰색을 의미\n",
    "    - 0~255 사이 값들은 진한 회색에서 연한 회색까지를 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41b91b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea4a8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명암도 영상 생성\n",
    "image1 = np.zeros((50,512), np.uint8)        # 50x512 영상 생성\n",
    "image2 = np.zeros((50,512), np.uint8)\n",
    "\n",
    "rows, cols  = image1.shape[:2]\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        image1.itemset((i,j), j//2)          # 화소값 점진적 증가\n",
    "        image2.itemset((i,j), j // 20*10)    # 계단 현상 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f0a53fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image1.shape: (50, 512)\n",
      "image2.shape: (50, 512)\n",
      "image1's rows:  50\n",
      "image1's cols:  512\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print('image1.shape:',image1.shape)\n",
    "print('image2.shape:',image2.shape) # 0값으로 채워진 50x512 행렬\n",
    "print(\"image1's rows: \", rows)\n",
    "print(\"image1's cols: \", cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "172b3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "cv2.imshow(\"image1\", image1)\n",
    "cv2.imshow(\"image2\", image2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imwrite('./prac_image/image1_226.png', image1) # 이미지 저장\n",
    "cv2.imwrite('./prac_image/image2_226.png', image2) # 이미지 저장\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b092a948",
   "metadata": {},
   "source": [
    "`-` 실행결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa44d41",
   "metadata": {},
   "source": [
    "<center> image1</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071073f2",
   "metadata": {},
   "source": [
    "<img src = \"./prac_image/image1_226.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3501b801",
   "metadata": {},
   "source": [
    "- 나눗셈 몫 연산자로 2로 나눈 몫을 저장하는 것은 가로 인덱스의 절반 값으로 j열 원소의 화소값을 설정한 것이다.\n",
    "따라서 화소값은 왼쪽에서 오른쪽으로 0에서 255의 값까지 **점진적으로 증가**한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11015b",
   "metadata": {},
   "source": [
    "<center> image2 </center>\n",
    "\n",
    "<img src = \"./prac_image/image2_226.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e3498",
   "metadata": {},
   "source": [
    "- (j // 20 * 10) 은 몫 연산자로 인해서 계산 값의 소수 부분은 날라간다. 따라서 20화소씩 같은 값을 갖게 되어 **계단 현상**을 나타내며 **증가한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f8f5e",
   "metadata": {},
   "source": [
    "### 6.2.2 영상의 화소 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79acfe",
   "metadata": {},
   "source": [
    "영상파일을 읽어 들여 그 영상의 특정 부분의 화소들을 확인해보자. 영상파일을 행렬에 저장하고, 관심 영역을 지정해서 출력하면 간단히 영상 데이터인 화소들의 값을 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "72455e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-output\n",
    "\n",
    "# 영상 화소값 확인 (pixel_value)\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('./ghtop_images/chap06_images/pixel.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "(x, y), (w, h) = (180, 37), (15, 10)\n",
    "roi_img = image[y:y+h, x:x+w]   # 행은 시작 y좌표에서 y+h까지, 열은 시작 x좌표에서 x+w까지\n",
    "\n",
    "#print(\"[roi img] =\\n\", roi_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829e0d9",
   "metadata": {},
   "source": [
    "- $(x, y)$는 사각형의 시작좌표\n",
    "- $(w, h)$는 사각형의 크기\n",
    "- 즉, 사각형의 시작좌표와 크기로 **관심영역을 지정**한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "677a2a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[roi_img] =\n",
      "  56  51  59  66  84 104 154 206 220 208 203 207 205 204 204  75  57  53  53  72  71 100 152 195 214 212 201 209 207 205  88  76  65  53  51  60  73  96 143 200 219 200 206 204 202  91  92  80  63  53  59  59  61  89 144 195 222 205 200 205  89  94  90  82  63  54  51  56  65  92 149 203 223 209 196  89  91  90  89  84  64  54  55  51  56  94 140 208 223 203  91  86  84  85  97  86  72  59  50  53  66  81 148 211 216  92  86  85  88  92  95  88  70  55  53  59  64  89 155 211  88  85  86  90  87  87  89  86  72  56  50  53  59  88 175  87  85  86  88  87  84  86  90  86  70  53  44  51  56 111\n"
     ]
    }
   ],
   "source": [
    "print(\"[roi_img] =\")\n",
    "for row in roi_img:\n",
    "    for p in row:\n",
    "        print(\"%4d\" % p, end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "42eea5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(image, (x,y,w,h) , 255, 1)     # 관심 영역에 사각형 표시\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('./prac_image/image_227.png', image) # 이미지 저장\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91184f",
   "metadata": {},
   "source": [
    "<img src = './prac_image/image_227.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd028371",
   "metadata": {},
   "source": [
    "- 실행 결과를 보면, 영상의 우상단에 흰색의 작은 사각형이 그려져 있다. 이 사각형이 관심 영역이며, 이 영역의 화소값과 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "84301d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[roi img] =\n",
      " [[ 56  51  59  66  84 104 154 206 220 208 203 207 205 204 204]\n",
      " [ 75  57  53  53  72  71 100 152 195 214 212 201 209 207 205]\n",
      " [ 88  76  65  53  51  60  73  96 143 200 219 200 206 204 202]\n",
      " [ 91  92  80  63  53  59  59  61  89 144 195 222 205 200 205]\n",
      " [ 89  94  90  82  63  54  51  56  65  92 149 203 223 209 196]\n",
      " [ 89  91  90  89  84  64  54  55  51  56  94 140 208 223 203]\n",
      " [ 91  86  84  85  97  86  72  59  50  53  66  81 148 211 216]\n",
      " [ 92  86  85  88  92  95  88  70  55  53  59  64  89 155 211]\n",
      " [ 88  85  86  90  87  87  89  86  72  56  50  53  59  88 175]\n",
      " [ 87  85  86  88  87  84  86  90  86  70  53  44  51  56 111]]\n"
     ]
    }
   ],
   "source": [
    "print(\"[roi img] =\\n\", roi_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a898144",
   "metadata": {},
   "source": [
    "- 관심영역 즉, 흰색 사각형이 그려져 있는 부분을 보면 주대각선 윗 부분은 흰색(밝은색)이고 아랫부분은 진한회색(어두운색)임을 알 수 있다.\n",
    "- 화소 값을 보면 주대각선 기준 윗부분은 화소값은 대략 $200\\sim225$범위의 값을 나타내고, 그 아래부분은 대략 $50\\sim80$범위의 값임을 확인\n",
    "- 즉, 흰색부분은 화소값이 255와 가깝고, 어두운 부분은 0에 가까운 값을 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e52542",
   "metadata": {},
   "source": [
    "### 6.2.3 영상 밝기의 가감영상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b2609",
   "metadata": {},
   "source": [
    "화소값이 영상의 밝기를 나타내기 때문에 이 화소값을 변경하면 영상의 밝기를 바꿀 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfadf293",
   "metadata": {},
   "source": [
    "- 예를 들어 영상의 화소에 특정한 상숫값을 더하면 영상이 밝아지고, 상숫값을 빼면 영상이 어두워진다.\n",
    "- 또한, 화소가 가질 수 있는 최댓값(예로 255)에서 그 화소의 값을 빼면 반전 영상이 만들어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d47ea",
   "metadata": {},
   "source": [
    "### 6.2.4 행렬 덧셈 및 곱셈을 이용한 영상 합성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28377cac",
   "metadata": {},
   "source": [
    "영상에 상수를 더하거나 빼는 연산을 확장하면 두 개의 영상을 더하거나 빼는 연산을 생각해 볼 수 있다. 두 영상을 합하면 영상 합성이 되며, 두 영상을 빼면 차영상(difference image)이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ea8e3",
   "metadata": {},
   "source": [
    "다음은 알렉산더 대왕 동상 영상($A$)과 사도의 건물 영상($B$), 두 영상을 합성한 영상($A+B$)을 구하는 예제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73145f5b",
   "metadata": {},
   "source": [
    "<img src=\"./prac_image/problem_box.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810edc04",
   "metadata": {},
   "source": [
    "<img src = \"./prac_image/solution_box.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c827e05",
   "metadata": {},
   "source": [
    "#### 행렬 합과 곱 연산을 통한 영상 합성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251b3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, cv2\n",
    "\n",
    "image1 = cv2.imread('./ghtop_images/chap06_images/add1.jpg', cv2.IMREAD_GRAYSCALE)    # 영상 읽기\n",
    "image2 = cv2.imread('./ghtop_images/chap06_images/add2.jpg', cv2.IMREAD_GRAYSCALE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4fd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  영상 합성 방법\n",
    "alpha, beta = 0.6, 0.7                              # 곱셈 비율\n",
    "\n",
    "add_img1 = cv2.add(image1, image2)                  # 두 영상 단순 더하기\n",
    "\n",
    "add_img2 = cv2.add(image1 * alpha, image2 * beta)   # 두 영상 비율에 따른 더하기\n",
    "add_img2 = np.clip(add_img2, 0, 255).astype('uint8') # saturation 처리\n",
    "\n",
    "add_img3 = cv2.addWeighted(image1, alpha, image2, beta, 0) # 두 영상 비율에 따른 더하기\n",
    "\n",
    "titles = ['image1', 'image2','add_img1','add_img2','add_img3'] # 윈도우 이름\n",
    "for t in titles: cv2.imshow(t, eval(t))  # 영상 표시\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613d0ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[110, 122, 118, ..., 165, 166, 166],\n",
       "       [143, 159, 168, ..., 165, 166, 166],\n",
       "       [115, 117, 140, ..., 165, 166, 166],\n",
       "       ...,\n",
       "       [ 32,  41,  45, ...,  34,  32,  30],\n",
       "       [ 27,  35,  40, ..., 110, 109, 108],\n",
       "       [ 41,  36,  31, ..., 146, 148, 149]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = ['image1', 'image2','add_img1','add_img2','add_img3']\n",
    "eval(titles[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcee1a",
   "metadata": {},
   "source": [
    "- 파이썬 내장함수 `eval()`함수를 사용하면 리스트 원소의 문자열을 행렬 변수로 사용하여 행렬을 출력해주며, `cv2.imshow()`에 집어넣어 윈도우에 표시한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5de58166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./prac_image/image1_233.png', './prac_image/image2_233.png', './prac_image/add_img1_233.png', './prac_image/add_img2_233.png', './prac_image/add_img3_233.png']\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import os \n",
    "path_save = './prac_image'\n",
    "os.chdir(path_save)\n",
    "file_name = []\n",
    "for i in range(len(titles)):    \n",
    "    file_name.append(path_save + '/' + titles[i] +'_233.png') #, eval(titles[i]))\n",
    "print(file_name)\n",
    "    \n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d2d1685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['add_img1_233.png', 'add_img2_233.png', 'add_img3_233.png', 'blue.png', 'green.png', 'image.png', 'image1.png', 'image1_226.png', 'image1_233.png', 'image2_226.png', 'image2_233.png', 'image_227.png', 'img_basic.png', 'img_gray.png', 'red.png', 'repeat.png', 'trans.png', 'xaxis.png', 'xyaxis.png', 'yaxis.png']\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "for i in range(len(file_name)):\n",
    "    cv2.imwrite(file_name[i], eval(titles[i]))\n",
    "               \n",
    "print(os.listdir('./prac_image'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c45477",
   "metadata": {},
   "source": [
    "<img src=\"./prac_image/img1_plus_img2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2891791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_img1 = cv2.add(image1, image2)                  # 두 영상 단순 더하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ec7e6",
   "metadata": {},
   "source": [
    "<img src=\"./prac_image/add_img1_233.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62600f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_img2 = cv2.add(image1 * alpha, image2 * beta)   # 두 영상 비율에 따른 더하기\n",
    "add_img2 = np.clip(add_img2, 0, 255).astype('uint8') # saturation 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb2620",
   "metadata": {},
   "source": [
    "<img src=\"./prac_image/add_img2_233.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e47e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_img3 = cv2.addWeighted(image1, alpha, image2, beta, 0) # 두 영상 비율에 따른 더하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764eb03",
   "metadata": {},
   "source": [
    "<img src=\"./prac_image/add_img3_233.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

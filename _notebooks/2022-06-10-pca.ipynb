{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8827f7",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4ca26",
   "metadata": {},
   "source": [
    "## 고차원 데이터\n",
    "\n",
    "<img src = \"./my_icons/high_dim_data.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaad005",
   "metadata": {},
   "source": [
    "- 변수의 수가 많은 $\\to$ 불필요한 변수 존재\n",
    "- 시각적으로 표현하기 어려움\n",
    "- 계산 복잡도 증가 $\\to$ 모델링 비효율적\n",
    "- 중요한 변수만을 선택 $\\to$ 차원축소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e15f23",
   "metadata": {},
   "source": [
    "## 변수 선택 / 추출을 통한 차원축소\n",
    "\n",
    "### 변수선택 (selection) : \n",
    "> 분석 목적에 부합하는 소수의 예측변수만을 선택\n",
    "- 장점: 선택한 변수 해석 용이\n",
    "- 단점: 변수간 상관관계 고려 어려움\n",
    "\n",
    "### 변수추출 (extraction) : \n",
    "> 예측변수의 변환을 통해 새로운 변수 추출\n",
    "- 장점: 변수 간 상관관계 고려, 일반적으로 변수의 개수를 많이 줄일 수 있음\n",
    "- 단점: 추출된 변수의 해석이 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9534de",
   "metadata": {},
   "source": [
    "<img src = \"./my_icons/feature_select.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9dbca",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Supervised</font> <font color='red'>feature selection</font>: \n",
    "Information gain, Stepwise regression, LASSO, Genetic Algorithm, $\\dots$\n",
    "#### <font color='blue'>Supervised</font> <font color='green'>feature extraction</font>:\n",
    "Partial least squares (PLS)\n",
    "#### <font color='purple'>Unsupervised</font> <font color='red'>feature selection</font>: \n",
    "PCA loading\n",
    "#### <font color='purple'>Unsupervised</font> <font color='green'>feature extraction:</font> \n",
    "$Y$를 이용하지 않고 $X$들의 결합으로 변수를 추출하는 방법<br>\n",
    "Pincipal Component Analysis (PCA), Wavelets transformms, Autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd661b",
   "metadata": {},
   "source": [
    "## PCA 개요\n",
    "- 고차원 데이터를 효과적으로 분석하기 위한 대표적 분석 기법\n",
    "- 차원축소, 시각화, 군집화, 압축\n",
    "- PCA는 $n$개의 관측치와 $p$개의 변수로 구성된 데이터를 상관관계가 없는 $k$개의 변수로 구성된 데이터 ($n$개의 관측치)로 요약하는 방식으로, 이 때 요약된 변수는 기존 변수의 선형조합으로 생성됨.\n",
    "\n",
    "- 원래 데이터의 분산을 최대한 보존하는 새로운 축을 찾고, 그 축에 데이터를 사영 ( Projection) 시키는 기법\n",
    "\n",
    "- 주요 목적\n",
    "    - 데이터 차원 축소 ($n \\times p \\to n\\times k, \\space where \\space k << p)$\n",
    "    - 데이터 시각화 및 해석\n",
    "    \n",
    "- 일반적으로 PCA는 전체 분석 과정 충 초기에 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83889c8c",
   "metadata": {},
   "source": [
    "<img src = \"./my_icons/pca_outline.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a73c80",
   "metadata": {},
   "source": [
    "$Z_1,Z_2, Z_3$은 기존 변수인 $X_1, X_2, \\dots X_p$의 선형 조합으로 새롭게 생성된 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e85a1",
   "metadata": {},
   "source": [
    "$Z$ is linear combination (선형결합) of the original $p$ variables in $X$\n",
    "\n",
    "$$Z_1 = a_1^TX = a_{11}X_1 + a_{12}X_2 + \\dots a_{1p}X_p$$\n",
    "$$Z_2 = a_2^TX = a_{21}X_1 + a_{22}X_2 + \\dots a_{2p}X_p$$\n",
    "$$\\vdots$$\n",
    "\n",
    "$$Z_p = a_p^TX = a_{p1}X_1 + a_{p2}X_2 + \\dots a_{pp}X_p$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d90feb",
   "metadata": {},
   "source": [
    "- $X_1, X_2, \\dots, X_p$: 원래 변수 (original variable)\n",
    "- $a_i = [a_{i1}, a_{i2}, \\dots, a_{ip}]$, $i$번째 기저(basis) 또는 계수(Loading)\n",
    "- $Z_1, Z_2, \\dots, Z_p$ 각 기저로 사영 변환 후 변수 (주성분 : Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9cb3b2",
   "metadata": {},
   "source": [
    "### 주성분 분석\n",
    "아래 2차원 데이터를 좌측과 우측 두 개의 축에 사영시킬 경우 우측 기저(basis)가 좌측 기저에 비해 손실되는 정보의 양(분산의 크기)이 적으므로 상대적으로 선호되는 기저라고 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58645b4b",
   "metadata": {},
   "source": [
    "<img src=\"./my_icons/var-img.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d62fc",
   "metadata": {},
   "source": [
    "- 1번축과 2번축에 이 데이터를 사영시킨 후에 그 데이터의 분산을 봤을 때 1번분산이 클까? 2번분산이 클까?\n",
    "\n",
    "**답 : 2번이 분산이 더 크다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9797e8",
   "metadata": {},
   "source": [
    "<img src = \"./my_icons/var.PNG\">\n",
    "<img src = './my_icons/var2.PNG'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00d21321",
   "metadata": {},
   "source": [
    "- 위의 그림의 경우 1번의 분산이 더 크다.\n",
    "- 주성분 분석의 관점에서 1번 축이 더 좋다. (원래 데이터의 분산을 최대화하는 1번 축이 더 좋다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4f8b7",
   "metadata": {},
   "source": [
    "## PCA 수리적 배경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e4ec54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Bias-Variance Tradeoff</h1><p class="page-description">편향 분산 트레이드 오프에 대해 이해해보자.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-12-05T00:00:00-06:00" itemprop="datePublished">
        Dec 5, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">dinonene</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/BP2022/categories/#python">python</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-12-05-bias-variance-tradeoff.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/BP2022/images/copied_from_nb/./my_icons/bias_variance_tradeoff.PNG" alt="">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>위의 그림을 가지고 생각해보자.</p>
<p>만약 내가 데이터를 10만개를 가지고 있다고 가정해보자. 모델링을 할 때 이 데이터 전체에 대해서 하는 것이 아니라 데이터의 부분집합 6개의 subset을 만들어서 (각각 다른 조합의 데이터들이 6개의 subset이 된다.) 이 6개의 subset에 대해서 트레이닝을 하고 예측을 해본다라고 하자.</p>
<p>우리가 복잡한 모델과 덜 복잡한 모델을 사용했을 때 어떻게 달라지는가를 알아보자.</p>
<p>Decision Tree를 예를들어 봅시다. 트리가 Adaboost처럼 딱 한단계만 들어있으면 단순한 모델이 되고, 트리의 깊이가 20단계까지 내려가면 훨씬 복잡한 모델이 되겠죠!</p>
<p>내가 가진 데이터의 독립변수의 개수가 20개라고 했을 때 이 얕은 트리에서는 20개의 변수 중에 가장 중요하다고 생각하는 변수를 하나밖에 사용을 안할것이고, 깊은 트리에서는 20개가 다 쓰일지 안쓰일지 모르겠으나 훨씬 많은 독립변수들이 이 트리를 만드는데 개입을 할 거에요.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>단순한 모델의 경우 예측했을 때 값이 굉장히 비슷해 질 것이다. 반대로 깊이가 깊은 모델을 가지고 예측을 하면 각각의 training set(6개의 subset)에 대해서 결과값들이 들쭉날쭉한 그런 값들이 나올 겁니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>상식적으로 너무 단순하게 예측을 했기 때문에 실제값과 차이가 클 수 밖에 없어요. 그래서 BIas가 높은 것 입니다. 반대로, 이 결과값은 상당히 동일하게 유지가 되죠. 그래서 Variance가 낮은거에요. Variance가 낮다는 것은 다양한 Subset(data)을 가지고 돌려봤을 때 이걸 할때마다 예측값이 얼마나 다양하게 나오는지 아니면 동일하게 나오는지입니다.</p>
<p>그래서 단순한 모델의 경우 Bias가 높고, Variance가 낮다.</p>
<p>반대로 모델이 복잡한 경우 (트리가 깊은 경우)는 각가의 트레이닝 데이터셋을 최대한 잘 예측하게끔 모델링이 되기 때문에 Bias가 낮고, training set에 대해서 결과가 바뀌기 때문에 여기선 Variance가 높다라고 할 수 있습니다.</p>
<p><strong><em>그래서 모델이 얼마나 복잡하냐 복잡하지 않냐에 따라서 Bias와 Variance가 이런식으로 달라지는 거죠</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/BP2022/images/copied_from_nb/./my_icons/bias_variance_tradeoff_1.png" alt="image.png"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>High Bias / Low Variance : 즉, 20개의 subset을 예측했을 때 항상 비슷한 결과값을 보여주지만 실제 값이랑은 꽤 거리가 있다. 하지만 한 곳에 잘 뭉쳐있으니까 Variance는 낮다.</p>
</li>
<li>
<p>20개의 subset을 가지고 모델링 했을 때 매번 다른 결과값을 보여준다. 즉, 트레이닝 데이터 셋의 특성에 따라 나오는 결과값도 항상 다르기 때문에 Variance가 높은거고, 대신 bias는 training set에 대해서 좀 더 잘 예측을 하도록 모델링이 되기 때문에 bias는 낮게 예측이 되는거죠.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/BP2022/images/copied_from_nb/./my_icons/bias_variance_tradeoff_2.PNG" alt="image.png"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>모델이 복잡할수록(오른쪽) 다양한 subset에 대해서 예측을 했을 때 매번 결과는 달라지니까 Variance가 높고, 대신 매번 그 subset에 대한 예측은 잘 하기 때문에 bias는 낮은 거에요. 그래서 이 경우는 오버피팅이 걱정이 되는것이고</p>
<p>반대로 모델의 복잡도가 낮은 경우는 여러개의 subset을 통해서 예측을 하더라도 그 결과값이 거의 동일하게 나오기 때문에 Variance는 굉장히 낮으나, 애초에 그 예측력이 떨어져서 bias가 높다. 그래서 언더피팅이 우려가 된다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>바이어스는 에러라고 보면되고, Variance는 여러개의 subset data를 training set으로 썼을 때 매번 할때마다 얼마나 다양한 결과값이 나오느냐를 의미한다고 보면 됩니다.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>즉, 복잡한 모델일수록 에러(바이어스)는 낮고, 결과값은 다이나믹하게 달라질 수 있기 때문에 Variance는 높다. 모델이 단순하면 그 반대다.
</div>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="pinkocto/BP2022"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/BP2022/python/2022/12/05/bias-variance-tradeoff.html" hidden></a>
</article>
